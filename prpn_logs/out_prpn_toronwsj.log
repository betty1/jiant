Starting main job...
04/19 01:45:14 PM: fastText library not found!
04/19 01:45:15 PM: Loading config from config/prpn.conf
04/19 01:45:15 PM: Waiting on git info....
04/19 01:45:15 PM: Git branch: prpn
04/19 01:45:15 PM: Git SHA: 39abaff9a9d1348ba93e4fc947b6e185ef98e6db
04/19 01:45:15 PM: Parsed args: 
{
  "FASTTEXT_MODEL_FILE": "",
  "JIANT_DATA_DIR": "/scratch/pmh330/jiant-data/",
  "NFS_PROJECT_PREFIX": "/beegfs/pmh330/jiant-prpn-outs",
  "allow_missing_task_map": 0,
  "allow_reuse_of_pretraining_parameters": 0,
  "allow_untrained_encoder_parameters": 0,
  "batch_size": 16,
  "bert_embeddings_mode": "none",
  "bert_fine_tune": 0,
  "bert_model_name": "",
  "bidirectional": 0,
  "bpp_base": 1,
  "char_embs": 0,
  "char_filter_sizes": "2,3,4,5",
  "classifier": "mlp",
  "classifier_dropout": 0.2,
  "classifier_hid_dim": 512,
  "classifier_loss_fn": "",
  "classifier_span_pooling": "x,y",
  "cola": {},
  "cola_classifier_dropout": 0.2,
  "cola_classifier_hid_dim": 256,
  "cola_d_proj": 256,
  "cola_lr": 0.0003,
  "cola_val_interval": 100,
  "cove": 0,
  "cove_fine_tune": 0,
  "cuda": 0,
  "d_char": 100,
  "d_ff": 2048,
  "d_hid": 400,
  "d_hid_attn": 512,
  "d_proj": 512,
  "d_tproj": 64,
  "d_word": 200,
  "data_dir": "/scratch/pmh330/jiant-data/",
  "dec_val_scale": 250,
  "do_full_eval": 1,
  "do_pretrain": 1,
  "do_target_task_training": 0,
  "dropout": 0.2,
  "dropout_embs": 0.2,
  "edgeprobe_cnn_context": 0,
  "edges-ccg-parse": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-ccg-tag": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-constituent-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-constituent-ptb": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-coref-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-coref-ontonotes-conll": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-dep-labeling": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-dep-labeling-ewt": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-dpr": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-ner-conll2003": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 250
  },
  "edges-ner-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-ner-tacred": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-nonterminal-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-pos-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-rel-semeval": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-rel-tacred": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-spr1": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-spr2": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-srl-conll2005": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-srl-conll2012": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-tmpl": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "elmo": 0,
  "elmo_chars_only": 1,
  "elmo_weight_file_path": "none",
  "embeddings_train": 0,
  "eval_data_fraction": 1,
  "eval_max_vals": 1000,
  "eval_val_interval": 500,
  "exp_dir": "/beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/",
  "exp_name": "prpn-wsj-toronto",
  "fastText": 0,
  "fastText_model_file": "",
  "force_include_wsj_vocabulary": 0,
  "global_ro_exp_dir": "/nfs/jsalt/share/exp/default",
  "grounded": {},
  "grounded_d_proj": 2048,
  "groundedsw": {},
  "groundedsw_d_proj": 2048,
  "is_probing_task": 0,
  "keep_all_checkpoints": 0,
  "load_eval_checkpoint": "none",
  "load_model": 1,
  "local_log_path": "/beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0/log.log",
  "lr": 0.001,
  "lr_decay_factor": 0.5,
  "lr_patience": 5,
  "max_char_v_size": 250,
  "max_epochs": -1,
  "max_grad_norm": 0.5,
  "max_seq_len": 70,
  "max_targ_word_v_size": 20000,
  "max_vals": 1000,
  "max_word_v_size": 30000,
  "min_lr": 1e-06,
  "mnli": {},
  "mnli-alt": {},
  "mnli-alt_classifier_dropout": 0.2,
  "mnli-alt_classifier_hid_dim": 512,
  "mnli-alt_lr": 0.0003,
  "mnli-alt_pair_attn": 1,
  "mnli-alt_val_interval": 1000,
  "mnli-diagnostic": {
    "use_classifier": "mnli"
  },
  "mnli_classifier_dropout": 0.2,
  "mnli_classifier_hid_dim": 512,
  "mnli_lr": 0.0003,
  "mnli_pair_attn": 1,
  "mnli_val_interval": 1000,
  "mrpc": {},
  "mrpc_classifier_dropout": 0.2,
  "mrpc_classifier_hid_dim": 256,
  "mrpc_d_proj": 256,
  "mrpc_lr": 0.0003,
  "mrpc_pair_attn": 0,
  "mrpc_val_interval": 100,
  "n_char_filters": 100,
  "n_heads": 8,
  "n_layers_enc": 2,
  "n_layers_highway": 0,
  "n_slots": 15,
  "nli-prob": {
    "probe_path": ""
  },
  "onlstm_chunk_size": 10,
  "onlstm_dropconnect": 0.5,
  "onlstm_dropouth": 0.3,
  "onlstm_dropouti": 0.3,
  "onlstm_tying": 0,
  "openai_embeddings_mode": "none",
  "openai_transformer": 0,
  "openai_transformer_ckpt": "",
  "openai_transformer_fine_tune": 0,
  "optimizer": "adam",
  "pair_attn": 1,
  "patience": 5,
  "pool_type": "max",
  "pretrain_tasks": "toronto_lm,wsj",
  "project_dir": "/beegfs/pmh330/jiant-prpn-outs",
  "qnli": {},
  "qnli-alt": {},
  "qnli-alt_classifier_dropout": 0.2,
  "qnli-alt_classifier_hid_dim": 512,
  "qnli-alt_lr": 0.0003,
  "qnli-alt_pair_attn": 1,
  "qnli-alt_val_interval": 1000,
  "qnli_classifier_dropout": 0.2,
  "qnli_classifier_hid_dim": 512,
  "qnli_lr": 0.0003,
  "qnli_pair_attn": 1,
  "qnli_val_interval": 1000,
  "qqp": {},
  "qqp-alt": {},
  "qqp-alt_classifier_dropout": 0.2,
  "qqp-alt_classifier_hid_dim": 512,
  "qqp-alt_lr": 0.0003,
  "qqp-alt_pair_attn": 1,
  "qqp-alt_val_interval": 1000,
  "qqp_classifier_dropout": 0.2,
  "qqp_classifier_hid_dim": 512,
  "qqp_lr": 0.0003,
  "qqp_pair_attn": 1,
  "qqp_val_interval": 1000,
  "random_seed": 1234,
  "reindex_tasks": "",
  "reload_indexing": 0,
  "reload_tasks": 0,
  "reload_vocab": 0,
  "remote_log_name": "prpn-wsj-toronto__prpn-0",
  "rte": {},
  "rte_classifier_dropout": 0.4,
  "rte_classifier_hid_dim": 128,
  "rte_d_proj": 128,
  "rte_lr": 0.0003,
  "rte_pair_attn": 0,
  "rte_val_interval": 100,
  "run_dir": "/beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0",
  "run_name": "prpn-0",
  "s2s": {
    "attention": "bilinear",
    "d_hid_dec": 1024,
    "n_layers_dec": 1,
    "output_proj_input_dim": 1024,
    "target_embedding_dim": 300
  },
  "scaling_method": "uniform",
  "scheduler_threshold": 0.0001,
  "sent_enc": "prpn",
  "sep_embs_for_skip": 0,
  "shared_optimizer": 1,
  "shared_pair_attn": 0,
  "skip_embs": 0,
  "sst": {},
  "sst_classifier_dropout": 0.2,
  "sst_classifier_hid_dim": 256,
  "sst_d_proj": 256,
  "sst_lr": 0.0003,
  "sst_val_interval": 100,
  "sts-b": {},
  "sts-b-alt": {},
  "sts-b-alt_classifier_dropout": 0.2,
  "sts-b-alt_classifier_hid_dim": 512,
  "sts-b-alt_lr": 0.0003,
  "sts-b-alt_pair_attn": 1,
  "sts-b-alt_val_interval": 1000,
  "sts-b_classifier_dropout": 0.2,
  "sts-b_classifier_hid_dim": 512,
  "sts-b_lr": 0.0003,
  "sts-b_pair_attn": 1,
  "sts-b_val_interval": 1000,
  "target_tasks": "wsj",
  "tokenizer": "MosesTokenizer",
  "track_batch_utilization": 0,
  "trainer_type": "sampling",
  "training_data_fraction": 1,
  "transfer_paradigm": "frozen",
  "use_classifier": "",
  "val_data_limit": 5000,
  "val_interval": 1000,
  "warmup": 4000,
  "weighting_method": "proportional",
  "wnli": {},
  "wnli_classifier_dropout": 0.4,
  "wnli_classifier_hid_dim": 128,
  "wnli_d_proj": 128,
  "wnli_lr": 0.0003,
  "wnli_pair_attn": 0,
  "wnli_val_interval": 100,
  "word_embs": "scratch",
  "word_embs_file": "",
  "write_preds": 0,
  "write_strict_glue_format": 0
}
04/19 01:45:15 PM: Saved config to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0/params.conf
04/19 01:45:15 PM: Using random seed 1234
04/19 01:45:15 PM: Using GPU 0
04/19 01:45:15 PM: Loading tasks...
04/19 01:45:15 PM: Writing pre-preprocessed tasks to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/
04/19 01:45:15 PM: 	Creating task toronto_lm from scratch
04/19 01:45:15 PM: BLEU scoring is turned off (current code in progress).Please use outputed prediction files to score offline
04/19 01:46:02 PM: 	Task 'toronto_lm': train=2907826 val=2234 test=1178
04/19 01:46:02 PM: 	Creating task wsj from scratch
04/19 01:46:02 PM: BLEU scoring is turned off (current code in progress).Please use outputed prediction files to score offline
04/19 01:46:02 PM: 	Task 'wsj': train=13280 val=1054 test=1178
04/19 01:46:02 PM: 	Finished loading tasks: toronto_lm wsj.
04/19 01:46:02 PM: 	Building vocab from scratch
04/19 01:46:02 PM: 	Counting words for task: 'toronto_lm'
04/19 01:49:16 PM: 	Counting words for task: 'wsj'
04/19 01:49:18 PM: 	Finished counting words
04/19 01:49:18 PM: 	Saved vocab to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/vocab
04/19 01:49:24 PM: Loading token dictionary from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/vocab.
04/19 01:49:24 PM: 	Loaded vocab from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/vocab
04/19 01:49:24 PM: 	Vocab namespace tokens: size 30002
04/19 01:49:24 PM: 	Vocab namespace chars: size 81
04/19 01:49:24 PM: 	Finished building vocab.
04/19 01:49:24 PM: 	Task 'toronto_lm', split 'train': indexing from scratch
Starting main job...
04/19 02:11:24 PM: fastText library not found!
04/19 02:11:25 PM: Loading config from config/prpn.conf
04/19 02:11:25 PM: Waiting on git info....
04/19 02:11:26 PM: Git branch: prpn
04/19 02:11:26 PM: Git SHA: 39abaff9a9d1348ba93e4fc947b6e185ef98e6db
04/19 02:11:26 PM: Parsed args: 
{
  "FASTTEXT_MODEL_FILE": "",
  "JIANT_DATA_DIR": "/scratch/pmh330/jiant-data/",
  "NFS_PROJECT_PREFIX": "/beegfs/pmh330/jiant-prpn-outs",
  "allow_missing_task_map": 0,
  "allow_reuse_of_pretraining_parameters": 0,
  "allow_untrained_encoder_parameters": 0,
  "batch_size": 64,
  "bert_embeddings_mode": "none",
  "bert_fine_tune": 0,
  "bert_model_name": "",
  "bidirectional": 0,
  "bpp_base": 1,
  "char_embs": 0,
  "char_filter_sizes": "2,3,4,5",
  "classifier": "mlp",
  "classifier_dropout": 0.2,
  "classifier_hid_dim": 512,
  "classifier_loss_fn": "",
  "classifier_span_pooling": "x,y",
  "cola": {},
  "cola_classifier_dropout": 0.2,
  "cola_classifier_hid_dim": 256,
  "cola_d_proj": 256,
  "cola_lr": 0.0003,
  "cola_val_interval": 100,
  "cove": 0,
  "cove_fine_tune": 0,
  "cuda": 0,
  "d_char": 100,
  "d_ff": 2048,
  "d_hid": 1200,
  "d_hid_attn": 512,
  "d_proj": 512,
  "d_tproj": 64,
  "d_word": 800,
  "data_dir": "/scratch/pmh330/jiant-data/",
  "dec_val_scale": 250,
  "do_full_eval": 1,
  "do_pretrain": 1,
  "do_target_task_training": 0,
  "dropout": 0.7,
  "dropout_embs": 0.7,
  "edgeprobe_cnn_context": 0,
  "edges-ccg-parse": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-ccg-tag": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-constituent-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-constituent-ptb": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-coref-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-coref-ontonotes-conll": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-dep-labeling": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-dep-labeling-ewt": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-dpr": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-ner-conll2003": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 250
  },
  "edges-ner-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-ner-tacred": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-nonterminal-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-pos-ontonotes": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 250,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-rel-semeval": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-rel-tacred": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-spr1": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-spr2": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 100
  },
  "edges-srl-conll2005": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "edges-srl-conll2012": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 1000
  },
  "edges-tmpl": {
    "classifier_dropout": 0.3,
    "classifier_hid_dim": 256,
    "classifier_loss_fn": "sigmoid",
    "classifier_span_pooling": "attn",
    "max_vals": 100,
    "pair_attn": 0,
    "val_interval": 500
  },
  "elmo": 0,
  "elmo_chars_only": 1,
  "elmo_weight_file_path": "none",
  "embeddings_train": 0,
  "eval_data_fraction": 1,
  "eval_max_vals": 1000,
  "eval_val_interval": 500,
  "exp_dir": "/beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/",
  "exp_name": "prpn-wsj-2",
  "fastText": 0,
  "fastText_model_file": "",
  "force_include_wsj_vocabulary": 0,
  "global_ro_exp_dir": "/nfs/jsalt/share/exp/default",
  "grounded": {},
  "grounded_d_proj": 2048,
  "groundedsw": {},
  "groundedsw_d_proj": 2048,
  "is_probing_task": 0,
  "keep_all_checkpoints": 0,
  "load_eval_checkpoint": "none",
  "load_model": 1,
  "local_log_path": "/beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0/log.log",
  "lr": 0.003,
  "lr_decay_factor": 0.5,
  "lr_patience": 5,
  "max_char_v_size": 250,
  "max_epochs": -1,
  "max_grad_norm": 1.0,
  "max_seq_len": 50,
  "max_targ_word_v_size": 20000,
  "max_vals": 1000,
  "max_word_v_size": 30000,
  "min_lr": 1e-06,
  "mnli": {},
  "mnli-alt": {},
  "mnli-alt_classifier_dropout": 0.2,
  "mnli-alt_classifier_hid_dim": 512,
  "mnli-alt_lr": 0.0003,
  "mnli-alt_pair_attn": 1,
  "mnli-alt_val_interval": 1000,
  "mnli-diagnostic": {
    "use_classifier": "mnli"
  },
  "mnli_classifier_dropout": 0.2,
  "mnli_classifier_hid_dim": 512,
  "mnli_lr": 0.0003,
  "mnli_pair_attn": 1,
  "mnli_val_interval": 1000,
  "mrpc": {},
  "mrpc_classifier_dropout": 0.2,
  "mrpc_classifier_hid_dim": 256,
  "mrpc_d_proj": 256,
  "mrpc_lr": 0.0003,
  "mrpc_pair_attn": 0,
  "mrpc_val_interval": 100,
  "n_char_filters": 100,
  "n_heads": 8,
  "n_layers_enc": 2,
  "n_layers_highway": 0,
  "n_slots": 15,
  "nli-prob": {
    "probe_path": ""
  },
  "onlstm_chunk_size": 10,
  "onlstm_dropconnect": 0.5,
  "onlstm_dropouth": 0.3,
  "onlstm_dropouti": 0.3,
  "onlstm_tying": 0,
  "openai_embeddings_mode": "none",
  "openai_transformer": 0,
  "openai_transformer_ckpt": "",
  "openai_transformer_fine_tune": 0,
  "optimizer": "adam",
  "pair_attn": 1,
  "patience": 5,
  "pool_type": "max",
  "pretrain_tasks": "wsj",
  "project_dir": "/beegfs/pmh330/jiant-prpn-outs",
  "qnli": {},
  "qnli-alt": {},
  "qnli-alt_classifier_dropout": 0.2,
  "qnli-alt_classifier_hid_dim": 512,
  "qnli-alt_lr": 0.0003,
  "qnli-alt_pair_attn": 1,
  "qnli-alt_val_interval": 1000,
  "qnli_classifier_dropout": 0.2,
  "qnli_classifier_hid_dim": 512,
  "qnli_lr": 0.0003,
  "qnli_pair_attn": 1,
  "qnli_val_interval": 1000,
  "qqp": {},
  "qqp-alt": {},
  "qqp-alt_classifier_dropout": 0.2,
  "qqp-alt_classifier_hid_dim": 512,
  "qqp-alt_lr": 0.0003,
  "qqp-alt_pair_attn": 1,
  "qqp-alt_val_interval": 1000,
  "qqp_classifier_dropout": 0.2,
  "qqp_classifier_hid_dim": 512,
  "qqp_lr": 0.0003,
  "qqp_pair_attn": 1,
  "qqp_val_interval": 1000,
  "random_seed": 1234,
  "reindex_tasks": "",
  "reload_indexing": 0,
  "reload_tasks": 0,
  "reload_vocab": 0,
  "remote_log_name": "prpn-wsj-2__prpn-0",
  "rte": {},
  "rte_classifier_dropout": 0.4,
  "rte_classifier_hid_dim": 128,
  "rte_d_proj": 128,
  "rte_lr": 0.0003,
  "rte_pair_attn": 0,
  "rte_val_interval": 100,
  "run_dir": "/beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0",
  "run_name": "prpn-0",
  "s2s": {
    "attention": "bilinear",
    "d_hid_dec": 1024,
    "n_layers_dec": 1,
    "output_proj_input_dim": 1024,
    "target_embedding_dim": 300
  },
  "scaling_method": "uniform",
  "scheduler_threshold": 0.0001,
  "sent_enc": "prpn",
  "sep_embs_for_skip": 0,
  "shared_optimizer": 1,
  "shared_pair_attn": 0,
  "skip_embs": 0,
  "sst": {},
  "sst_classifier_dropout": 0.2,
  "sst_classifier_hid_dim": 256,
  "sst_d_proj": 256,
  "sst_lr": 0.0003,
  "sst_val_interval": 100,
  "sts-b": {},
  "sts-b-alt": {},
  "sts-b-alt_classifier_dropout": 0.2,
  "sts-b-alt_classifier_hid_dim": 512,
  "sts-b-alt_lr": 0.0003,
  "sts-b-alt_pair_attn": 1,
  "sts-b-alt_val_interval": 1000,
  "sts-b_classifier_dropout": 0.2,
  "sts-b_classifier_hid_dim": 512,
  "sts-b_lr": 0.0003,
  "sts-b_pair_attn": 1,
  "sts-b_val_interval": 1000,
  "target_tasks": "wsj",
  "tokenizer": "MosesTokenizer",
  "track_batch_utilization": 0,
  "trainer_type": "sampling",
  "training_data_fraction": 1,
  "transfer_paradigm": "frozen",
  "use_classifier": "",
  "val_data_limit": 5000,
  "val_interval": 1000,
  "warmup": 4000,
  "weighting_method": "proportional",
  "wnli": {},
  "wnli_classifier_dropout": 0.4,
  "wnli_classifier_hid_dim": 128,
  "wnli_d_proj": 128,
  "wnli_lr": 0.0003,
  "wnli_pair_attn": 0,
  "wnli_val_interval": 100,
  "word_embs": "scratch",
  "word_embs_file": "",
  "write_preds": 0,
  "write_strict_glue_format": 0
}
04/19 02:11:26 PM: Saved config to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0/params.conf
04/19 02:11:26 PM: Using random seed 1234
04/19 02:11:26 PM: Using GPU 0
04/19 02:11:26 PM: Loading tasks...
04/19 02:11:26 PM: Writing pre-preprocessed tasks to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/
04/19 02:11:26 PM: 	Creating task wsj from scratch
04/19 02:11:26 PM: BLEU scoring is turned off (current code in progress).Please use outputed prediction files to score offline
04/19 02:11:26 PM: 	Task 'wsj': train=18592 val=1476 test=1649
04/19 02:11:26 PM: 	Finished loading tasks: wsj.
04/19 02:11:26 PM: 	Building vocab from scratch
04/19 02:11:26 PM: 	Counting words for task: 'wsj'
04/19 02:11:27 PM: 	Finished counting words
04/19 02:11:27 PM: vocabulary serialization directory /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/vocab is not empty
04/19 02:11:27 PM: 	Saved vocab to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/vocab
04/19 02:11:27 PM: Loading token dictionary from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/vocab.
04/19 02:11:27 PM: 	Loaded vocab from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/vocab
04/19 02:11:27 PM: 	Vocab namespace tokens: size 10002
04/19 02:11:27 PM: 	Vocab namespace chars: size 57
04/19 02:11:27 PM: 	Finished building vocab.
04/19 02:11:27 PM: 	Task 'wsj', split 'train': indexing from scratch
04/19 02:11:37 PM: 	Task 'wsj', split 'train': saved 18592 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/preproc/wsj__train_data
04/19 02:11:37 PM: 	Task 'wsj', split 'val': indexing from scratch
04/19 02:11:38 PM: 	Task 'wsj', split 'val': saved 1476 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/preproc/wsj__val_data
04/19 02:11:38 PM: 	Task 'wsj', split 'test': indexing from scratch
04/19 02:11:39 PM: 	Task 'wsj', split 'test': saved 1649 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/preproc/wsj__test_data
04/19 02:11:39 PM: 	Task 'wsj': cleared in-memory data.
04/19 02:11:39 PM: 	Finished indexing tasks
04/19 02:11:39 PM: 	Lazy-loading indexed data for task='wsj' from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/preproc
04/19 02:11:39 PM: All tasks initialized with data iterators.
04/19 02:11:39 PM: 	  Training on wsj
04/19 02:11:39 PM: 	  Evaluating on wsj
04/19 02:11:39 PM: 	Finished loading tasks in 13.332s
04/19 02:11:39 PM: 	 Tasks: ['wsj']
04/19 02:11:39 PM: Building model...
04/19 02:11:39 PM: 	Training word embeddings from scratch.
04/19 02:11:39 PM: 	Not using character embeddings!
04/19 02:11:40 PM: Initializing parameters
04/19 02:11:40 PM: Done initializing parameters; the following parameters are using their default initialization from their code
04/19 02:11:40 PM:    prpnlayer.emb.weight
04/19 02:11:40 PM:    prpnlayer.embedder.token_embedder_words.weight
04/19 02:11:40 PM:    prpnlayer.parser.gate.1.bias
04/19 02:11:40 PM:    prpnlayer.parser.gate.1.weight
04/19 02:11:40 PM:    prpnlayer.parser.gate.2.bias
04/19 02:11:40 PM:    prpnlayer.parser.gate.2.weight
04/19 02:11:40 PM:    prpnlayer.parser.gate.5.bias
04/19 02:11:40 PM:    prpnlayer.parser.gate.5.weight
04/19 02:11:40 PM:    prpnlayer.predictor.ffd.1.bias
04/19 02:11:40 PM:    prpnlayer.predictor.ffd.1.weight
04/19 02:11:40 PM:    prpnlayer.predictor.ffd.2.bias
04/19 02:11:40 PM:    prpnlayer.predictor.ffd.2.weight
04/19 02:11:40 PM:    prpnlayer.predictor.projector_pred.1.bias
04/19 02:11:40 PM:    prpnlayer.predictor.projector_pred.1.weight
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.bias_hh
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.bias_ih
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.c_norm.beta
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.c_norm.gamma
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.hh.0.bias
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.hh.0.weight
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.hh.1.beta
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.hh.1.gamma
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.ih.0.bias
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.ih.0.weight
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.ih.1.beta
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.ih.1.gamma
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.weight_hh
04/19 02:11:40 PM:    prpnlayer.reader.0.memory_rnn.weight_ih
04/19 02:11:40 PM:    prpnlayer.reader.0.projector_summ.1.bias
04/19 02:11:40 PM:    prpnlayer.reader.0.projector_summ.1.weight
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.bias_hh
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.bias_ih
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.c_norm.beta
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.c_norm.gamma
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.hh.0.bias
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.hh.0.weight
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.hh.1.beta
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.hh.1.gamma
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.ih.0.bias
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.ih.0.weight
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.ih.1.beta
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.ih.1.gamma
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.weight_hh
04/19 02:11:40 PM:    prpnlayer.reader.1.memory_rnn.weight_ih
04/19 02:11:40 PM:    prpnlayer.reader.1.projector_summ.1.bias
04/19 02:11:40 PM:    prpnlayer.reader.1.projector_summ.1.weight
04/19 02:11:40 PM: Initializing parameters
04/19 02:11:40 PM: Done initializing parameters; the following parameters are using their default initialization from their code
04/19 02:11:40 PM:    _phrase_layer.emb.weight
04/19 02:11:40 PM:    _phrase_layer.parser.gate.1.bias
04/19 02:11:40 PM:    _phrase_layer.parser.gate.1.weight
04/19 02:11:40 PM:    _phrase_layer.parser.gate.2.bias
04/19 02:11:40 PM:    _phrase_layer.parser.gate.2.weight
04/19 02:11:40 PM:    _phrase_layer.parser.gate.5.bias
04/19 02:11:40 PM:    _phrase_layer.parser.gate.5.weight
04/19 02:11:40 PM:    _phrase_layer.predictor.ffd.1.bias
04/19 02:11:40 PM:    _phrase_layer.predictor.ffd.1.weight
04/19 02:11:40 PM:    _phrase_layer.predictor.ffd.2.bias
04/19 02:11:40 PM:    _phrase_layer.predictor.ffd.2.weight
04/19 02:11:40 PM:    _phrase_layer.predictor.projector_pred.1.bias
04/19 02:11:40 PM:    _phrase_layer.predictor.projector_pred.1.weight
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.bias_hh
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.bias_ih
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.c_norm.beta
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.c_norm.gamma
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.hh.0.bias
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.hh.0.weight
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.hh.1.beta
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.hh.1.gamma
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.ih.0.bias
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.ih.0.weight
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.ih.1.beta
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.ih.1.gamma
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.weight_hh
04/19 02:11:40 PM:    _phrase_layer.reader.0.memory_rnn.weight_ih
04/19 02:11:40 PM:    _phrase_layer.reader.0.projector_summ.1.bias
04/19 02:11:40 PM:    _phrase_layer.reader.0.projector_summ.1.weight
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.bias_hh
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.bias_ih
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.c_norm.beta
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.c_norm.gamma
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.hh.0.bias
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.hh.0.weight
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.hh.1.beta
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.hh.1.gamma
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.ih.0.bias
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.ih.0.weight
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.ih.1.beta
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.ih.1.gamma
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.weight_hh
04/19 02:11:40 PM:    _phrase_layer.reader.1.memory_rnn.weight_ih
04/19 02:11:40 PM:    _phrase_layer.reader.1.projector_summ.1.bias
04/19 02:11:40 PM:    _phrase_layer.reader.1.projector_summ.1.weight
04/19 02:11:40 PM:    _text_field_embedder.token_embedder_words.weight
04/19 02:11:40 PM: Using PRPN sentence encoder!
04/19 02:11:40 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:11:40 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:11:40 PM: cls_type = mlp
04/19 02:11:40 PM: d_hid = 512
04/19 02:11:40 PM: d_proj = 512
04/19 02:11:40 PM: shared_pair_attn = 0
04/19 02:11:40 PM: attn = 1
04/19 02:11:40 PM: d_hid_attn = 512
04/19 02:11:40 PM: dropout = 0.2
04/19 02:11:40 PM: cls_loss_fn = 
04/19 02:11:40 PM: cls_span_pooling = x,y
04/19 02:11:40 PM: edgeprobe_cnn_context = 0
04/19 02:11:40 PM: use_classifier = wsj
04/19 02:11:40 PM: 	Task 'wsj' params: {
  "cls_type": "mlp",
  "d_hid": 512,
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 1,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "",
  "cls_span_pooling": "x,y",
  "edgeprobe_cnn_context": 0,
  "use_classifier": "wsj"
}
04/19 02:11:45 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): ElmoTextFieldEmbedder(
      (token_embedder_words): Embedding()
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): PRPN(
      (drop): Dropout(p=0.7)
      (idrop): Dropout(p=0.5)
      (rdrop): Dropout(p=0.5)
      (embedder): ElmoTextFieldEmbedder(
        (token_embedder_words): Embedding()
      )
      (emb): Embedding(10002, 800)
      (parser): ParsingNetwork(
        (drop): Dropout(p=0.5)
        (gate): Sequential(
          (0): Dropout(p=0.5)
          (1): Conv1d(800, 1200, kernel_size=(6,), stride=(1,))
          (2): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Dropout(p=0.5)
          (5): Conv1d(1200, 2, kernel_size=(1,), stride=(1,), groups=2)
          (6): Sigmoid()
        )
      )
      (reader): ModuleList(
        (0): ReadingNetwork(
          (drop): Dropout(p=0.7)
          (memory_rnn): LSTMCell(
            800, 1200
            (ih): Sequential(
              (0): Linear(in_features=800, out_features=4800, bias=True)
              (1): LayerNorm()
            )
            (hh): Sequential(
              (0): Linear(in_features=1200, out_features=4800, bias=True)
              (1): LayerNorm()
            )
            (c_norm): LayerNorm()
            (drop): Dropout(p=0)
          )
          (projector_summ): Sequential(
            (0): Dropout(p=0.5)
            (1): Linear(in_features=2000, out_features=1200, bias=True)
            (2): Dropout(p=0.5)
          )
        )
        (1): ReadingNetwork(
          (drop): Dropout(p=0.5)
          (memory_rnn): LSTMCell(
            1200, 1200
            (ih): Sequential(
              (0): Linear(in_features=1200, out_features=4800, bias=True)
              (1): LayerNorm()
            )
            (hh): Sequential(
              (0): Linear(in_features=1200, out_features=4800, bias=True)
              (1): LayerNorm()
            )
            (c_norm): LayerNorm()
            (drop): Dropout(p=0)
          )
          (projector_summ): Sequential(
            (0): Dropout(p=0.5)
            (1): Linear(in_features=2400, out_features=1200, bias=True)
            (2): Dropout(p=0.5)
          )
        )
      )
      (predictor): PredictNetwork(
        (drop): Dropout(p=0.5)
        (projector_pred): Sequential(
          (0): Dropout(p=0.5)
          (1): Linear(in_features=1200, out_features=1200, bias=True)
          (2): Dropout(p=0.5)
        )
        (ffd): Sequential(
          (0): Dropout(p=0.5)
          (1): Linear(in_features=2400, out_features=800, bias=True)
          (2): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Tanh()
        )
      )
    )
    (_dropout): Dropout(p=0.7)
  )
  (wsj_hid2voc): Linear(in_features=800, out_features=10002, bias=True)
  (wsj_mdl): Linear(in_features=800, out_features=10002, bias=True)
)
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.emb.weight: torch.Size([10002, 800]) = 8001600
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.1.weight: torch.Size([1200, 800, 6]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.1.bias: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.2.weight: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.2.bias: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.5.weight: torch.Size([2, 600, 1]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.5.bias: torch.Size([2]) = 2
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.weight_ih: torch.Size([4800, 800]) = 3840000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.weight_hh: torch.Size([4800, 1200]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.bias_ih: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.bias_hh: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.0.weight: torch.Size([4800, 800]) = 3840000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.0.bias: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.1.gamma: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.1.beta: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.0.weight: torch.Size([4800, 1200]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.0.bias: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.1.gamma: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.1.beta: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.c_norm.gamma: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.c_norm.beta: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.projector_summ.1.weight: torch.Size([1200, 2000]) = 2400000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.projector_summ.1.bias: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.weight_ih: torch.Size([4800, 1200]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.weight_hh: torch.Size([4800, 1200]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.bias_ih: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.bias_hh: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.0.weight: torch.Size([4800, 1200]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.0.bias: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.1.gamma: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.1.beta: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.0.weight: torch.Size([4800, 1200]) = 5760000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.0.bias: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.1.gamma: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.1.beta: torch.Size([4800]) = 4800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.c_norm.gamma: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.c_norm.beta: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.projector_summ.1.weight: torch.Size([1200, 2400]) = 2880000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.projector_summ.1.bias: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.predictor.projector_pred.1.weight: torch.Size([1200, 1200]) = 1440000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.predictor.projector_pred.1.bias: torch.Size([1200]) = 1200
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.1.weight: torch.Size([800, 2400]) = 1920000
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.1.bias: torch.Size([800]) = 800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.2.weight: torch.Size([800]) = 800
04/19 02:11:45 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.2.bias: torch.Size([800]) = 800
04/19 02:11:45 PM: >> Trainable param wsj_hid2voc.weight: torch.Size([10002, 800]) = 8001600
04/19 02:11:45 PM: >> Trainable param wsj_hid2voc.bias: torch.Size([10002]) = 10002
04/19 02:11:45 PM: Total number of parameters: 80747204 (8.07472e+07)
04/19 02:11:45 PM: Number of trainable parameters: 72745604 (7.27456e+07)
04/19 02:11:45 PM: 	Finished building model in 5.891s
04/19 02:11:45 PM: Will run the following steps:
Training model on tasks: wsj
Evaluating model on tasks: wsj
04/19 02:11:45 PM: Training...
04/19 02:11:45 PM: 	Using ReduceLROnPlateau scheduler!
04/19 02:11:45 PM: patience = 5
04/19 02:11:45 PM: val_interval = 1000
04/19 02:11:45 PM: max_vals = 1000
04/19 02:11:45 PM: cuda_device = 0
04/19 02:11:45 PM: grad_norm = 1.0
04/19 02:11:45 PM: grad_clipping = None
04/19 02:11:45 PM: lr_decay = 0.99
04/19 02:11:45 PM: min_lr = 1e-06
04/19 02:11:45 PM: keep_all_checkpoints = 0
04/19 02:11:45 PM: val_data_limit = 5000
04/19 02:11:45 PM: max_epochs = -1
04/19 02:11:45 PM: dec_val_scale = 250
04/19 02:11:45 PM: training_data_fraction = 1
04/19 02:11:45 PM: type = adam
04/19 02:11:45 PM: parameter_groups = None
04/19 02:11:45 PM: Number of trainable parameters: 72745604
04/19 02:11:45 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:11:45 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:11:45 PM: lr = 0.003
04/19 02:11:45 PM: amsgrad = True
04/19 02:11:45 PM: type = reduce_on_plateau
04/19 02:11:45 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:11:45 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:11:45 PM: mode = min
04/19 02:11:45 PM: factor = 0.5
04/19 02:11:45 PM: patience = 5
04/19 02:11:45 PM: threshold = 0.0001
04/19 02:11:45 PM: threshold_mode = abs
04/19 02:11:45 PM: verbose = True
04/19 02:11:45 PM: type = adam
04/19 02:11:45 PM: parameter_groups = None
04/19 02:11:45 PM: Number of trainable parameters: 72745604
04/19 02:11:45 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:11:45 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:11:45 PM: lr = 0.003
04/19 02:11:45 PM: amsgrad = True
04/19 02:11:45 PM: type = reduce_on_plateau
04/19 02:11:45 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:11:45 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:11:45 PM: mode = min
04/19 02:11:45 PM: factor = 0.5
04/19 02:11:45 PM: patience = 5
04/19 02:11:45 PM: threshold = 0.0001
04/19 02:11:45 PM: threshold_mode = abs
04/19 02:11:45 PM: verbose = True
04/19 02:11:45 PM: Not loading.
04/19 02:11:45 PM: Training examples per task: {'wsj': 18592}
04/19 02:11:45 PM: Sampling tasks proportional to number of training examples.
04/19 02:11:45 PM: Using weighting method: proportional, with normalized sample weights [1.] 
04/19 02:11:45 PM: Using loss scaling method: uniform, with weights {'wsj': 1.0}
04/19 02:11:45 PM: Beginning training. Stopping metric: wsj_perplexity
/home/pmh330/miniconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/pmh330/miniconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
04/19 02:11:55 PM: Update 8: task wsj, batch 8 (8): perplexity: 11763.4739, wsj_loss: 9.3728 ||
04/19 02:12:06 PM: Update 24: task wsj, batch 24 (24): perplexity: 6824.2349, wsj_loss: 8.8282 ||
04/19 02:12:16 PM: Update 40: task wsj, batch 40 (40): perplexity: 3369.9001, wsj_loss: 8.1226 ||
04/19 02:12:27 PM: Update 56: task wsj, batch 56 (56): perplexity: 2298.3658, wsj_loss: 7.7400 ||
04/19 02:12:37 PM: Update 72: task wsj, batch 72 (72): perplexity: 1828.5422, wsj_loss: 7.5113 ||
04/19 02:12:48 PM: Update 88: task wsj, batch 88 (88): perplexity: 1558.0192, wsj_loss: 7.3512 ||
04/19 02:12:58 PM: Update 104: task wsj, batch 104 (104): perplexity: 1385.5987, wsj_loss: 7.2339 ||
04/19 02:13:08 PM: Update 120: task wsj, batch 120 (120): perplexity: 1269.4241, wsj_loss: 7.1463 ||
04/19 02:13:19 PM: Update 136: task wsj, batch 136 (136): perplexity: 1188.1940, wsj_loss: 7.0802 ||
04/19 02:13:29 PM: Update 152: task wsj, batch 152 (152): perplexity: 1115.6936, wsj_loss: 7.0172 ||
04/19 02:13:40 PM: Update 159: task wsj, batch 159 (159): perplexity: 1088.9501, wsj_loss: 6.9930 ||
04/19 02:13:50 PM: Update 175: task wsj, batch 175 (175): perplexity: 1034.2362, wsj_loss: 6.9414 ||
04/19 02:14:00 PM: Update 191: task wsj, batch 191 (191): perplexity: 985.8526, wsj_loss: 6.8935 ||
04/19 02:14:11 PM: Update 207: task wsj, batch 207 (207): perplexity: 944.5987, wsj_loss: 6.8508 ||
04/19 02:14:21 PM: Update 223: task wsj, batch 223 (223): perplexity: 908.6838, wsj_loss: 6.8120 ||
04/19 02:14:32 PM: Update 239: task wsj, batch 239 (239): perplexity: 878.0528, wsj_loss: 6.7777 ||
04/19 02:14:42 PM: Update 255: task wsj, batch 255 (255): perplexity: 848.4910, wsj_loss: 6.7435 ||
04/19 02:14:52 PM: Update 271: task wsj, batch 271 (271): perplexity: 822.4810, wsj_loss: 6.7123 ||
04/19 02:15:03 PM: Update 287: task wsj, batch 287 (287): perplexity: 801.0636, wsj_loss: 6.6859 ||
04/19 02:15:13 PM: Update 295: task wsj, batch 295 (295): perplexity: 791.0200, wsj_loss: 6.6733 ||
04/19 02:15:23 PM: Update 311: task wsj, batch 311 (311): perplexity: 772.3259, wsj_loss: 6.6494 ||
04/19 02:15:34 PM: Update 327: task wsj, batch 327 (327): perplexity: 757.7407, wsj_loss: 6.6303 ||
04/19 02:15:44 PM: Update 343: task wsj, batch 343 (343): perplexity: 742.3219, wsj_loss: 6.6098 ||
04/19 02:15:55 PM: Update 359: task wsj, batch 359 (359): perplexity: 726.5517, wsj_loss: 6.5883 ||
04/19 02:16:05 PM: Update 375: task wsj, batch 375 (375): perplexity: 713.5347, wsj_loss: 6.5702 ||
04/19 02:16:15 PM: Update 391: task wsj, batch 391 (391): perplexity: 700.8498, wsj_loss: 6.5523 ||
04/19 02:16:26 PM: Update 407: task wsj, batch 407 (407): perplexity: 688.6655, wsj_loss: 6.5348 ||
04/19 02:16:36 PM: Update 423: task wsj, batch 423 (423): perplexity: 676.1326, wsj_loss: 6.5164 ||
04/19 02:16:47 PM: Update 439: task wsj, batch 439 (439): perplexity: 665.8452, wsj_loss: 6.5011 ||
04/19 02:16:59 PM: Update 450: task wsj, batch 450 (450): perplexity: 658.2977, wsj_loss: 6.4897 ||
04/19 02:17:10 PM: Update 466: task wsj, batch 466 (466): perplexity: 647.5788, wsj_loss: 6.4732 ||
04/19 02:17:20 PM: Update 482: task wsj, batch 482 (482): perplexity: 636.7423, wsj_loss: 6.4564 ||
04/19 02:17:31 PM: Update 498: task wsj, batch 498 (498): perplexity: 626.1212, wsj_loss: 6.4395 ||
04/19 02:17:41 PM: Update 514: task wsj, batch 514 (514): perplexity: 616.8693, wsj_loss: 6.4247 ||
04/19 02:17:52 PM: Update 530: task wsj, batch 530 (530): perplexity: 607.5921, wsj_loss: 6.4095 ||
04/19 02:18:02 PM: Update 546: task wsj, batch 546 (546): perplexity: 599.2671, wsj_loss: 6.3957 ||
04/19 02:18:12 PM: Update 562: task wsj, batch 562 (562): perplexity: 590.3262, wsj_loss: 6.3807 ||
04/19 02:18:23 PM: Update 578: task wsj, batch 578 (578): perplexity: 582.4972, wsj_loss: 6.3673 ||
04/19 02:18:33 PM: Update 585: task wsj, batch 585 (585): perplexity: 579.1020, wsj_loss: 6.3615 ||
04/19 02:18:43 PM: Update 601: task wsj, batch 601 (601): perplexity: 571.7328, wsj_loss: 6.3487 ||
04/19 02:18:54 PM: Update 617: task wsj, batch 617 (617): perplexity: 564.5431, wsj_loss: 6.3360 ||
04/19 02:19:04 PM: Update 633: task wsj, batch 633 (633): perplexity: 558.2304, wsj_loss: 6.3248 ||
04/19 02:19:14 PM: Update 649: task wsj, batch 649 (649): perplexity: 552.4103, wsj_loss: 6.3143 ||
04/19 02:19:25 PM: Update 665: task wsj, batch 665 (665): perplexity: 546.2620, wsj_loss: 6.3031 ||
04/19 02:19:35 PM: Update 681: task wsj, batch 681 (681): perplexity: 540.3563, wsj_loss: 6.2922 ||
04/19 02:19:45 PM: Update 697: task wsj, batch 697 (697): perplexity: 534.5819, wsj_loss: 6.2815 ||
04/19 02:19:56 PM: Update 713: task wsj, batch 713 (713): perplexity: 529.0250, wsj_loss: 6.2710 ||
04/19 02:20:06 PM: Update 729: task wsj, batch 729 (729): perplexity: 523.6443, wsj_loss: 6.2608 ||
04/19 02:20:20 PM: Update 742: task wsj, batch 742 (742): perplexity: 519.6081, wsj_loss: 6.2531 ||
04/19 02:20:30 PM: Update 758: task wsj, batch 758 (758): perplexity: 514.4961, wsj_loss: 6.2432 ||
04/19 02:20:41 PM: Update 774: task wsj, batch 774 (774): perplexity: 509.2970, wsj_loss: 6.2330 ||
04/19 02:20:51 PM: Update 790: task wsj, batch 790 (790): perplexity: 503.9988, wsj_loss: 6.2226 ||
04/19 02:21:02 PM: Update 806: task wsj, batch 806 (806): perplexity: 498.6408, wsj_loss: 6.2119 ||
04/19 02:21:12 PM: Update 822: task wsj, batch 822 (822): perplexity: 493.5992, wsj_loss: 6.2017 ||
04/19 02:21:22 PM: Update 838: task wsj, batch 838 (838): perplexity: 488.9496, wsj_loss: 6.1923 ||
04/19 02:21:33 PM: Update 854: task wsj, batch 854 (854): perplexity: 484.1381, wsj_loss: 6.1824 ||
04/19 02:21:43 PM: Update 870: task wsj, batch 870 (870): perplexity: 479.3356, wsj_loss: 6.1724 ||
04/19 02:21:53 PM: Update 878: task wsj, batch 878 (878): perplexity: 477.3575, wsj_loss: 6.1683 ||
04/19 02:22:04 PM: Update 894: task wsj, batch 894 (894): perplexity: 473.8979, wsj_loss: 6.1610 ||
04/19 02:22:14 PM: Update 910: task wsj, batch 910 (910): perplexity: 470.0031, wsj_loss: 6.1527 ||
04/19 02:22:24 PM: Update 926: task wsj, batch 926 (926): perplexity: 466.1698, wsj_loss: 6.1445 ||
04/19 02:22:35 PM: Update 942: task wsj, batch 942 (942): perplexity: 462.4062, wsj_loss: 6.1364 ||
04/19 02:22:45 PM: Update 958: task wsj, batch 958 (958): perplexity: 458.5462, wsj_loss: 6.1281 ||
04/19 02:22:56 PM: Update 974: task wsj, batch 974 (974): perplexity: 455.3828, wsj_loss: 6.1211 ||
04/19 02:23:06 PM: Update 990: task wsj, batch 990 (990): perplexity: 451.9869, wsj_loss: 6.1137 ||
04/19 02:23:13 PM: ***** Pass 1000 / Epoch 1 *****
04/19 02:23:13 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 02:23:13 PM: Validating...
04/19 02:23:16 PM: Batch 12/24: perplexity: 246.3008, wsj_loss: 5.5066 || , for evaluation data
04/19 02:23:19 PM: Best model found for wsj.
04/19 02:23:19 PM: Best model found for micro.
04/19 02:23:19 PM: Best model found for macro.
04/19 02:23:19 PM: Advancing scheduler.
04/19 02:23:19 PM: 	Best macro_avg: 217.262
04/19 02:23:19 PM: 	# bad epochs: 0
04/19 02:23:19 PM: Statistic: wsj_loss
04/19 02:23:19 PM: 	training: 6.109029
04/19 02:23:19 PM: 	validation: 5.381103
04/19 02:23:19 PM: Statistic: macro_avg
04/19 02:23:19 PM: 	validation: 217.261869
04/19 02:23:19 PM: Statistic: micro_avg
04/19 02:23:19 PM: 	validation: 217.261869
04/19 02:23:19 PM: Statistic: wsj_perplexity
04/19 02:23:19 PM: 	training: 449.901691
04/19 02:23:19 PM: 	validation: 217.261869
04/19 02:23:19 PM: global_lr: 0.003000
04/19 02:23:20 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 02:23:27 PM: Update 1011: task wsj, batch 11 (1011): perplexity: 279.0464, wsj_loss: 5.6314 ||
04/19 02:23:37 PM: Update 1027: task wsj, batch 27 (1027): perplexity: 280.4433, wsj_loss: 5.6364 ||
04/19 02:23:47 PM: Update 1035: task wsj, batch 35 (1035): perplexity: 282.3729, wsj_loss: 5.6432 ||
04/19 02:23:52 PM: 	Task 'toronto_lm', split 'train': saved 2907826 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc/toronto_lm__train_data
04/19 02:23:52 PM: 	Task 'toronto_lm', split 'val': indexing from scratch
04/19 02:23:54 PM: 	Task 'toronto_lm', split 'val': saved 2234 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc/toronto_lm__val_data
04/19 02:23:54 PM: 	Task 'toronto_lm', split 'test': indexing from scratch
04/19 02:23:55 PM: 	Task 'toronto_lm', split 'test': saved 1178 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc/toronto_lm__test_data
04/19 02:23:55 PM: 	Task 'toronto_lm': cleared in-memory data.
04/19 02:23:55 PM: 	Task 'wsj', split 'train': indexing from scratch
04/19 02:23:58 PM: Update 1051: task wsj, batch 51 (1051): perplexity: 273.6765, wsj_loss: 5.6119 ||
04/19 02:24:05 PM: 	Task 'wsj', split 'train': saved 13280 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc/wsj__train_data
04/19 02:24:05 PM: 	Task 'wsj', split 'val': indexing from scratch
04/19 02:24:06 PM: 	Task 'wsj', split 'val': saved 1054 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc/wsj__val_data
04/19 02:24:06 PM: 	Task 'wsj', split 'test': indexing from scratch
04/19 02:24:07 PM: 	Task 'wsj', split 'test': saved 1178 instances to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc/wsj__test_data
04/19 02:24:07 PM: 	Task 'wsj': cleared in-memory data.
04/19 02:24:07 PM: 	Finished indexing tasks
04/19 02:24:07 PM: 	Lazy-loading indexed data for task='toronto_lm' from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc
04/19 02:24:07 PM: 	Lazy-loading indexed data for task='wsj' from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/preproc
04/19 02:24:07 PM: All tasks initialized with data iterators.
04/19 02:24:07 PM: 	  Training on toronto_lm, wsj
04/19 02:24:07 PM: 	  Evaluating on wsj
04/19 02:24:07 PM: 	Finished loading tasks in 2331.322s
04/19 02:24:07 PM: 	 Tasks: ['toronto_lm', 'wsj']
04/19 02:24:07 PM: Building model...
04/19 02:24:07 PM: 	Training word embeddings from scratch.
04/19 02:24:07 PM: 	Not using character embeddings!
04/19 02:24:07 PM: Initializing parameters
04/19 02:24:07 PM: Done initializing parameters; the following parameters are using their default initialization from their code
04/19 02:24:07 PM:    prpnlayer.emb.weight
04/19 02:24:07 PM:    prpnlayer.embedder.token_embedder_words.weight
04/19 02:24:07 PM:    prpnlayer.parser.gate.1.bias
04/19 02:24:07 PM:    prpnlayer.parser.gate.1.weight
04/19 02:24:07 PM:    prpnlayer.parser.gate.2.bias
04/19 02:24:07 PM:    prpnlayer.parser.gate.2.weight
04/19 02:24:07 PM:    prpnlayer.parser.gate.5.bias
04/19 02:24:07 PM:    prpnlayer.parser.gate.5.weight
04/19 02:24:07 PM:    prpnlayer.predictor.ffd.1.bias
04/19 02:24:07 PM:    prpnlayer.predictor.ffd.1.weight
04/19 02:24:07 PM:    prpnlayer.predictor.ffd.2.bias
04/19 02:24:07 PM:    prpnlayer.predictor.ffd.2.weight
04/19 02:24:07 PM:    prpnlayer.predictor.projector_pred.1.bias
04/19 02:24:07 PM:    prpnlayer.predictor.projector_pred.1.weight
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.bias_hh
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.bias_ih
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.c_norm.beta
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.c_norm.gamma
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.hh.0.bias
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.hh.0.weight
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.hh.1.beta
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.hh.1.gamma
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.ih.0.bias
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.ih.0.weight
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.ih.1.beta
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.ih.1.gamma
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.weight_hh
04/19 02:24:07 PM:    prpnlayer.reader.0.memory_rnn.weight_ih
04/19 02:24:07 PM:    prpnlayer.reader.0.projector_summ.1.bias
04/19 02:24:07 PM:    prpnlayer.reader.0.projector_summ.1.weight
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.bias_hh
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.bias_ih
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.c_norm.beta
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.c_norm.gamma
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.hh.0.bias
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.hh.0.weight
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.hh.1.beta
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.hh.1.gamma
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.ih.0.bias
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.ih.0.weight
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.ih.1.beta
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.ih.1.gamma
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.weight_hh
04/19 02:24:07 PM:    prpnlayer.reader.1.memory_rnn.weight_ih
04/19 02:24:07 PM:    prpnlayer.reader.1.projector_summ.1.bias
04/19 02:24:07 PM:    prpnlayer.reader.1.projector_summ.1.weight
04/19 02:24:07 PM: Initializing parameters
04/19 02:24:07 PM: Done initializing parameters; the following parameters are using their default initialization from their code
04/19 02:24:07 PM:    _phrase_layer.emb.weight
04/19 02:24:07 PM:    _phrase_layer.parser.gate.1.bias
04/19 02:24:07 PM:    _phrase_layer.parser.gate.1.weight
04/19 02:24:07 PM:    _phrase_layer.parser.gate.2.bias
04/19 02:24:07 PM:    _phrase_layer.parser.gate.2.weight
04/19 02:24:07 PM:    _phrase_layer.parser.gate.5.bias
04/19 02:24:07 PM:    _phrase_layer.parser.gate.5.weight
04/19 02:24:07 PM:    _phrase_layer.predictor.ffd.1.bias
04/19 02:24:07 PM:    _phrase_layer.predictor.ffd.1.weight
04/19 02:24:07 PM:    _phrase_layer.predictor.ffd.2.bias
04/19 02:24:07 PM:    _phrase_layer.predictor.ffd.2.weight
04/19 02:24:07 PM:    _phrase_layer.predictor.projector_pred.1.bias
04/19 02:24:07 PM:    _phrase_layer.predictor.projector_pred.1.weight
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.bias_hh
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.bias_ih
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.c_norm.beta
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.c_norm.gamma
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.hh.0.bias
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.hh.0.weight
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.hh.1.beta
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.hh.1.gamma
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.ih.0.bias
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.ih.0.weight
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.ih.1.beta
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.ih.1.gamma
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.weight_hh
04/19 02:24:07 PM:    _phrase_layer.reader.0.memory_rnn.weight_ih
04/19 02:24:07 PM:    _phrase_layer.reader.0.projector_summ.1.bias
04/19 02:24:07 PM:    _phrase_layer.reader.0.projector_summ.1.weight
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.bias_hh
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.bias_ih
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.c_norm.beta
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.c_norm.gamma
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.hh.0.bias
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.hh.0.weight
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.hh.1.beta
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.hh.1.gamma
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.ih.0.bias
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.ih.0.weight
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.ih.1.beta
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.ih.1.gamma
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.weight_hh
04/19 02:24:07 PM:    _phrase_layer.reader.1.memory_rnn.weight_ih
04/19 02:24:07 PM:    _phrase_layer.reader.1.projector_summ.1.bias
04/19 02:24:07 PM:    _phrase_layer.reader.1.projector_summ.1.weight
04/19 02:24:07 PM:    _text_field_embedder.token_embedder_words.weight
04/19 02:24:07 PM: Using PRPN sentence encoder!
04/19 02:24:07 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:07 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:07 PM: cls_type = mlp
04/19 02:24:07 PM: d_hid = 512
04/19 02:24:07 PM: d_proj = 512
04/19 02:24:07 PM: shared_pair_attn = 0
04/19 02:24:07 PM: attn = 1
04/19 02:24:07 PM: d_hid_attn = 512
04/19 02:24:07 PM: dropout = 0.2
04/19 02:24:07 PM: cls_loss_fn = 
04/19 02:24:07 PM: cls_span_pooling = x,y
04/19 02:24:07 PM: edgeprobe_cnn_context = 0
04/19 02:24:07 PM: use_classifier = wsj
04/19 02:24:07 PM: 	Task 'wsj' params: {
  "cls_type": "mlp",
  "d_hid": 512,
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 1,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "",
  "cls_span_pooling": "x,y",
  "edgeprobe_cnn_context": 0,
  "use_classifier": "wsj"
}
04/19 02:24:07 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:07 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:07 PM: cls_type = mlp
04/19 02:24:07 PM: d_hid = 512
04/19 02:24:07 PM: d_proj = 512
04/19 02:24:07 PM: shared_pair_attn = 0
04/19 02:24:07 PM: attn = 1
04/19 02:24:07 PM: d_hid_attn = 512
04/19 02:24:07 PM: dropout = 0.2
04/19 02:24:07 PM: cls_loss_fn = 
04/19 02:24:07 PM: cls_span_pooling = x,y
04/19 02:24:07 PM: edgeprobe_cnn_context = 0
04/19 02:24:07 PM: use_classifier = toronto_lm
04/19 02:24:07 PM: 	Task 'toronto_lm' params: {
  "cls_type": "mlp",
  "d_hid": 512,
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 1,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "",
  "cls_span_pooling": "x,y",
  "edgeprobe_cnn_context": 0,
  "use_classifier": "toronto_lm"
}
04/19 02:24:08 PM: Update 1067: task wsj, batch 67 (1067): perplexity: 271.3224, wsj_loss: 5.6033 ||
04/19 02:24:11 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): ElmoTextFieldEmbedder(
      (token_embedder_words): Embedding()
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): PRPN(
      (drop): Dropout(p=0.2)
      (idrop): Dropout(p=0.2)
      (rdrop): Dropout(p=0.0)
      (embedder): ElmoTextFieldEmbedder(
        (token_embedder_words): Embedding()
      )
      (emb): Embedding(30002, 200)
      (parser): ParsingNetwork(
        (drop): Dropout(p=0.2)
        (gate): Sequential(
          (0): Dropout(p=0.2)
          (1): Conv1d(200, 400, kernel_size=(6,), stride=(1,))
          (2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Dropout(p=0.2)
          (5): Conv1d(400, 2, kernel_size=(1,), stride=(1,), groups=2)
          (6): Sigmoid()
        )
      )
      (reader): ModuleList(
        (0): ReadingNetwork(
          (drop): Dropout(p=0.2)
          (memory_rnn): LSTMCell(
            200, 400
            (ih): Sequential(
              (0): Linear(in_features=200, out_features=1600, bias=True)
              (1): LayerNorm()
            )
            (hh): Sequential(
              (0): Linear(in_features=400, out_features=1600, bias=True)
              (1): LayerNorm()
            )
            (c_norm): LayerNorm()
            (drop): Dropout(p=0)
          )
          (projector_summ): Sequential(
            (0): Dropout(p=0.2)
            (1): Linear(in_features=600, out_features=400, bias=True)
            (2): Dropout(p=0.2)
          )
        )
        (1): ReadingNetwork(
          (drop): Dropout(p=0.2)
          (memory_rnn): LSTMCell(
            400, 400
            (ih): Sequential(
              (0): Linear(in_features=400, out_features=1600, bias=True)
              (1): LayerNorm()
            )
            (hh): Sequential(
              (0): Linear(in_features=400, out_features=1600, bias=True)
              (1): LayerNorm()
            )
            (c_norm): LayerNorm()
            (drop): Dropout(p=0)
          )
          (projector_summ): Sequential(
            (0): Dropout(p=0.2)
            (1): Linear(in_features=800, out_features=400, bias=True)
            (2): Dropout(p=0.2)
          )
        )
      )
      (predictor): PredictNetwork(
        (drop): Dropout(p=0.2)
        (projector_pred): Sequential(
          (0): Dropout(p=0.2)
          (1): Linear(in_features=400, out_features=400, bias=True)
          (2): Dropout(p=0.2)
        )
        (ffd): Sequential(
          (0): Dropout(p=0.2)
          (1): Linear(in_features=800, out_features=200, bias=True)
          (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Tanh()
        )
      )
    )
    (_dropout): Dropout(p=0.2)
  )
  (toronto_lm_hid2voc): Linear(in_features=200, out_features=30002, bias=True)
  (toronto_lm_mdl): Linear(in_features=200, out_features=30002, bias=True)
  (wsj_hid2voc): Linear(in_features=200, out_features=30002, bias=True)
  (wsj_mdl): Linear(in_features=200, out_features=30002, bias=True)
)
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.emb.weight: torch.Size([30002, 200]) = 6000400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.1.weight: torch.Size([400, 200, 6]) = 480000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.1.bias: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.2.weight: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.2.bias: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.5.weight: torch.Size([2, 200, 1]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.parser.gate.5.bias: torch.Size([2]) = 2
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.weight_ih: torch.Size([1600, 200]) = 320000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.weight_hh: torch.Size([1600, 400]) = 640000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.bias_ih: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.bias_hh: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.0.weight: torch.Size([1600, 200]) = 320000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.0.bias: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.1.gamma: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.ih.1.beta: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.0.weight: torch.Size([1600, 400]) = 640000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.0.bias: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.1.gamma: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.hh.1.beta: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.c_norm.gamma: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.memory_rnn.c_norm.beta: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.projector_summ.1.weight: torch.Size([400, 600]) = 240000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.0.projector_summ.1.bias: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.weight_ih: torch.Size([1600, 400]) = 640000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.weight_hh: torch.Size([1600, 400]) = 640000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.bias_ih: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.bias_hh: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.0.weight: torch.Size([1600, 400]) = 640000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.0.bias: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.1.gamma: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.ih.1.beta: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.0.weight: torch.Size([1600, 400]) = 640000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.0.bias: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.1.gamma: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.hh.1.beta: torch.Size([1600]) = 1600
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.c_norm.gamma: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.memory_rnn.c_norm.beta: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.projector_summ.1.weight: torch.Size([400, 800]) = 320000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.reader.1.projector_summ.1.bias: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.predictor.projector_pred.1.weight: torch.Size([400, 400]) = 160000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.predictor.projector_pred.1.bias: torch.Size([400]) = 400
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.1.weight: torch.Size([200, 800]) = 160000
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.1.bias: torch.Size([200]) = 200
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.2.weight: torch.Size([200]) = 200
04/19 02:24:11 PM: >> Trainable param sent_encoder._phrase_layer.predictor.ffd.2.bias: torch.Size([200]) = 200
04/19 02:24:11 PM: >> Trainable param toronto_lm_hid2voc.weight: torch.Size([30002, 200]) = 6000400
04/19 02:24:11 PM: >> Trainable param toronto_lm_hid2voc.bias: torch.Size([30002]) = 30002
04/19 02:24:11 PM: >> Trainable param wsj_hid2voc.weight: torch.Size([30002, 200]) = 6000400
04/19 02:24:11 PM: >> Trainable param wsj_hid2voc.bias: torch.Size([30002]) = 30002
04/19 02:24:11 PM: Total number of parameters: 29932206 (2.99322e+07)
04/19 02:24:11 PM: Number of trainable parameters: 23931806 (2.39318e+07)
04/19 02:24:11 PM: 	Finished building model in 4.565s
04/19 02:24:11 PM: Will run the following steps:
Training model on tasks: toronto_lm,wsj
Evaluating model on tasks: wsj
04/19 02:24:11 PM: Training...
04/19 02:24:11 PM: 	Using ReduceLROnPlateau scheduler!
04/19 02:24:11 PM: patience = 5
04/19 02:24:11 PM: val_interval = 1000
04/19 02:24:11 PM: max_vals = 1000
04/19 02:24:11 PM: cuda_device = 0
04/19 02:24:11 PM: grad_norm = 0.5
04/19 02:24:11 PM: grad_clipping = None
04/19 02:24:11 PM: lr_decay = 0.99
04/19 02:24:11 PM: min_lr = 1e-06
04/19 02:24:11 PM: keep_all_checkpoints = 0
04/19 02:24:11 PM: val_data_limit = 5000
04/19 02:24:11 PM: max_epochs = -1
04/19 02:24:11 PM: dec_val_scale = 250
04/19 02:24:11 PM: training_data_fraction = 1
04/19 02:24:11 PM: type = adam
04/19 02:24:11 PM: parameter_groups = None
04/19 02:24:11 PM: Number of trainable parameters: 23931806
04/19 02:24:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:11 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:11 PM: lr = 0.001
04/19 02:24:11 PM: amsgrad = True
04/19 02:24:11 PM: type = reduce_on_plateau
04/19 02:24:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:11 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:11 PM: mode = max
04/19 02:24:11 PM: factor = 0.5
04/19 02:24:11 PM: patience = 5
04/19 02:24:11 PM: threshold = 0.0001
04/19 02:24:11 PM: threshold_mode = abs
04/19 02:24:11 PM: verbose = True
04/19 02:24:11 PM: type = adam
04/19 02:24:11 PM: parameter_groups = None
04/19 02:24:11 PM: Number of trainable parameters: 23931806
04/19 02:24:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:11 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:11 PM: lr = 0.001
04/19 02:24:11 PM: amsgrad = True
04/19 02:24:11 PM: type = reduce_on_plateau
04/19 02:24:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:11 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:11 PM: mode = max
04/19 02:24:11 PM: factor = 0.5
04/19 02:24:11 PM: patience = 5
04/19 02:24:11 PM: threshold = 0.0001
04/19 02:24:11 PM: threshold_mode = abs
04/19 02:24:11 PM: verbose = True
04/19 02:24:11 PM: type = adam
04/19 02:24:11 PM: parameter_groups = None
04/19 02:24:11 PM: Number of trainable parameters: 23931806
04/19 02:24:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:11 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:11 PM: lr = 0.001
04/19 02:24:11 PM: amsgrad = True
04/19 02:24:11 PM: type = reduce_on_plateau
04/19 02:24:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
04/19 02:24:11 PM: CURRENTLY DEFINED PARAMETERS: 
04/19 02:24:11 PM: mode = max
04/19 02:24:11 PM: factor = 0.5
04/19 02:24:11 PM: patience = 5
04/19 02:24:11 PM: threshold = 0.0001
04/19 02:24:11 PM: threshold_mode = abs
04/19 02:24:11 PM: verbose = True
04/19 02:24:11 PM: Not loading.
04/19 02:24:11 PM: Training examples per task: {'toronto_lm': 2907826, 'wsj': 13280}
04/19 02:24:11 PM: Sampling tasks proportional to number of training examples.
04/19 02:24:11 PM: Using weighting method: proportional, with normalized sample weights [0.9955 0.0045] 
04/19 02:24:11 PM: Using loss scaling method: uniform, with weights {'toronto_lm': 1.0, 'wsj': 1.0}
04/19 02:24:11 PM: Beginning training. Stopping metric: macro_avg
04/19 02:24:19 PM: Update 1083: task wsj, batch 83 (1083): perplexity: 269.0661, wsj_loss: 5.5950 ||
/home/pmh330/miniconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/pmh330/miniconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
04/19 02:24:22 PM: Update 5: task toronto_lm, batch 5 (5): perplexity: 31550.7514, toronto_lm_loss: 10.3594 ||
04/19 02:24:29 PM: Update 1099: task wsj, batch 99 (1099): perplexity: 266.6488, wsj_loss: 5.5859 ||
04/19 02:24:35 PM: Update 18: task toronto_lm, batch 18 (18): perplexity: 29398.5936, toronto_lm_loss: 10.2887 ||
04/19 02:24:39 PM: Update 1115: task wsj, batch 115 (1115): perplexity: 265.9904, wsj_loss: 5.5835 ||
04/19 02:24:45 PM: Update 31: task toronto_lm, batch 31 (31): perplexity: 26227.6538, toronto_lm_loss: 10.1746 ||
04/19 02:24:50 PM: Update 1131: task wsj, batch 131 (1131): perplexity: 264.7082, wsj_loss: 5.5786 ||
04/19 02:24:55 PM: Update 44: task toronto_lm, batch 44 (44): perplexity: 21528.3700, toronto_lm_loss: 9.9771 ||
04/19 02:25:00 PM: Update 1147: task wsj, batch 147 (1147): perplexity: 264.8768, wsj_loss: 5.5793 ||
04/19 02:25:05 PM: Update 57: task toronto_lm, batch 57 (57): perplexity: 17097.3759, toronto_lm_loss: 9.7467 ||
04/19 02:25:11 PM: Update 1163: task wsj, batch 163 (1163): perplexity: 264.7027, wsj_loss: 5.5786 ||
04/19 02:25:16 PM: Update 71: task toronto_lm, batch 71 (71): perplexity: 12996.8614, toronto_lm_loss: 9.4725 ||
04/19 02:25:21 PM: Update 1170: task wsj, batch 170 (1170): perplexity: 264.7576, wsj_loss: 5.5788 ||
04/19 02:25:26 PM: Update 84: task toronto_lm, batch 84 (84): perplexity: 9891.5595, toronto_lm_loss: 9.1994 ||
04/19 02:25:31 PM: Update 1186: task wsj, batch 186 (1186): perplexity: 264.8302, wsj_loss: 5.5791 ||
04/19 02:25:36 PM: Update 97: task toronto_lm, batch 97 (97): perplexity: 7377.7007, toronto_lm_loss: 8.9062 ||
04/19 02:25:42 PM: Update 1202: task wsj, batch 202 (1202): perplexity: 264.4014, wsj_loss: 5.5775 ||
04/19 02:25:47 PM: Update 110: task toronto_lm, batch 110 (110): perplexity: 5508.5632, toronto_lm_loss: 8.6141 ||
04/19 02:25:52 PM: Update 1218: task wsj, batch 218 (1218): perplexity: 264.2287, wsj_loss: 5.5768 ||
04/19 02:25:57 PM: Update 123: task toronto_lm, batch 123 (123): perplexity: 4185.3443, toronto_lm_loss: 8.3393 ||
04/19 02:26:02 PM: Update 1234: task wsj, batch 234 (1234): perplexity: 264.1359, wsj_loss: 5.5765 ||
04/19 02:26:07 PM: Update 136: task toronto_lm, batch 136 (136): perplexity: 3293.1495, toronto_lm_loss: 8.0996 ||
04/19 02:26:13 PM: Update 1250: task wsj, batch 250 (1250): perplexity: 263.5959, wsj_loss: 5.5744 ||
04/19 02:26:17 PM: Update 149: task toronto_lm, batch 149 (149): perplexity: 2671.8260, toronto_lm_loss: 7.8905 ||
04/19 02:26:23 PM: Update 1266: task wsj, batch 266 (1266): perplexity: 263.1028, wsj_loss: 5.5725 ||
04/19 02:26:27 PM: Update 162: task toronto_lm, batch 162 (162): perplexity: 2238.0931, toronto_lm_loss: 7.7134 ||
04/19 02:26:34 PM: Update 1282: task wsj, batch 282 (1282): perplexity: 262.0156, wsj_loss: 5.5684 ||
04/19 02:26:38 PM: Update 176: task toronto_lm, batch 176 (176): perplexity: 1884.5127, toronto_lm_loss: 7.5414 ||
04/19 02:26:44 PM: Update 1298: task wsj, batch 298 (1298): perplexity: 261.5517, wsj_loss: 5.5666 ||
04/19 02:26:48 PM: Update 189: task toronto_lm, batch 189 (189): perplexity: 1641.4335, toronto_lm_loss: 7.4033 ||
04/19 02:26:55 PM: Update 1314: task wsj, batch 314 (1314): perplexity: 261.3500, wsj_loss: 5.5659 ||
04/19 02:27:04 PM: Update 199: task wsj, batch 1 (1): perplexity: 32731.9114, wsj_loss: 10.3961 ||
04/19 02:27:04 PM: Update 200: task toronto_lm, batch 199 (199): perplexity: 1492.6980, toronto_lm_loss: 7.3083 ||
04/19 02:27:08 PM: Update 1326: task wsj, batch 326 (1326): perplexity: 261.0137, wsj_loss: 5.5646 ||
04/19 02:27:15 PM: Update 213: task toronto_lm, batch 212 (212): perplexity: 1334.9171, toronto_lm_loss: 7.1966 ||
04/19 02:27:19 PM: Update 1342: task wsj, batch 342 (1342): perplexity: 259.8936, wsj_loss: 5.5603 ||
04/19 02:27:25 PM: Update 226: task toronto_lm, batch 225 (225): perplexity: 1207.9113, toronto_lm_loss: 7.0966 ||
04/19 02:27:29 PM: Update 1358: task wsj, batch 358 (1358): perplexity: 258.7946, wsj_loss: 5.5560 ||
04/19 02:27:35 PM: Update 239: task toronto_lm, batch 238 (238): perplexity: 1101.7696, toronto_lm_loss: 7.0047 ||
04/19 02:27:39 PM: Update 1374: task wsj, batch 374 (1374): perplexity: 257.7764, wsj_loss: 5.5521 ||
04/19 02:27:45 PM: Update 252: task toronto_lm, batch 251 (251): perplexity: 1008.9162, toronto_lm_loss: 6.9166 ||
04/19 02:27:50 PM: Update 1390: task wsj, batch 390 (1390): perplexity: 256.7769, wsj_loss: 5.5482 ||
04/19 02:27:55 PM: Update 265: task toronto_lm, batch 264 (264): perplexity: 934.7471, toronto_lm_loss: 6.8403 ||
04/19 02:28:00 PM: Update 1406: task wsj, batch 406 (1406): perplexity: 255.9048, wsj_loss: 5.5448 ||
04/19 02:28:05 PM: Update 278: task toronto_lm, batch 277 (277): perplexity: 871.7985, toronto_lm_loss: 6.7706 ||
04/19 02:28:11 PM: Update 1422: task wsj, batch 422 (1422): perplexity: 254.9619, wsj_loss: 5.5411 ||
04/19 02:28:15 PM: Update 291: task toronto_lm, batch 290 (290): perplexity: 817.6193, toronto_lm_loss: 6.7064 ||
04/19 02:28:21 PM: Update 1438: task wsj, batch 438 (1438): perplexity: 254.2756, wsj_loss: 5.5384 ||
04/19 02:28:26 PM: Update 304: task toronto_lm, batch 303 (303): perplexity: 771.1364, toronto_lm_loss: 6.6479 ||
04/19 02:28:31 PM: Update 1454: task wsj, batch 454 (1454): perplexity: 253.0757, wsj_loss: 5.5337 ||
04/19 02:28:36 PM: Update 317: task toronto_lm, batch 316 (316): perplexity: 729.8656, toronto_lm_loss: 6.5929 ||
04/19 02:28:42 PM: Update 1463: task wsj, batch 463 (1463): perplexity: 252.6075, wsj_loss: 5.5318 ||
04/19 02:28:46 PM: Update 330: task toronto_lm, batch 329 (329): perplexity: 693.2333, toronto_lm_loss: 6.5414 ||
04/19 02:28:53 PM: Update 1479: task wsj, batch 479 (1479): perplexity: 252.3377, wsj_loss: 5.5308 ||
04/19 02:28:56 PM: Update 343: task toronto_lm, batch 342 (342): perplexity: 660.7164, toronto_lm_loss: 6.4933 ||
04/19 02:29:03 PM: Update 1495: task wsj, batch 495 (1495): perplexity: 251.9095, wsj_loss: 5.5291 ||
04/19 02:29:06 PM: Update 356: task toronto_lm, batch 355 (355): perplexity: 630.5508, toronto_lm_loss: 6.4466 ||
04/19 02:29:13 PM: Update 1511: task wsj, batch 511 (1511): perplexity: 251.2963, wsj_loss: 5.5266 ||
04/19 02:29:16 PM: Update 369: task toronto_lm, batch 368 (368): perplexity: 603.7685, toronto_lm_loss: 6.4032 ||
04/19 02:29:24 PM: Update 1527: task wsj, batch 527 (1527): perplexity: 250.9157, wsj_loss: 5.5251 ||
04/19 02:29:27 PM: Update 383: task toronto_lm, batch 382 (382): perplexity: 577.1492, toronto_lm_loss: 6.3581 ||
04/19 02:29:34 PM: Update 1543: task wsj, batch 543 (1543): perplexity: 250.2087, wsj_loss: 5.5223 ||
04/19 02:29:37 PM: Update 396: task toronto_lm, batch 395 (395): perplexity: 555.5488, toronto_lm_loss: 6.3200 ||
04/19 02:29:45 PM: Update 1559: task wsj, batch 559 (1559): perplexity: 249.8063, wsj_loss: 5.5207 ||
04/19 02:29:47 PM: Update 409: task toronto_lm, batch 408 (408): perplexity: 535.7877, toronto_lm_loss: 6.2837 ||
04/19 02:29:55 PM: Update 1575: task wsj, batch 575 (1575): perplexity: 249.2956, wsj_loss: 5.5186 ||
04/19 02:29:57 PM: Update 422: task toronto_lm, batch 421 (421): perplexity: 517.8011, toronto_lm_loss: 6.2496 ||
04/19 02:30:06 PM: Update 1591: task wsj, batch 591 (1591): perplexity: 248.7873, wsj_loss: 5.5166 ||
04/19 02:30:07 PM: Update 435: task toronto_lm, batch 434 (434): perplexity: 500.3174, toronto_lm_loss: 6.2152 ||
04/19 02:30:16 PM: Update 1607: task wsj, batch 607 (1607): perplexity: 248.4967, wsj_loss: 5.5154 ||
04/19 02:30:18 PM: Update 449: task toronto_lm, batch 448 (448): perplexity: 483.3935, toronto_lm_loss: 6.1808 ||
04/19 02:30:28 PM: Update 462: task toronto_lm, batch 461 (461): perplexity: 470.2903, toronto_lm_loss: 6.1534 ||
04/19 02:30:29 PM: Update 1618: task wsj, batch 618 (1618): perplexity: 248.1709, wsj_loss: 5.5141 ||
04/19 02:30:38 PM: Update 475: task toronto_lm, batch 474 (474): perplexity: 457.1832, toronto_lm_loss: 6.1251 ||
04/19 02:30:39 PM: Update 1634: task wsj, batch 634 (1634): perplexity: 247.2929, wsj_loss: 5.5106 ||
04/19 02:30:49 PM: Update 488: task toronto_lm, batch 487 (487): perplexity: 446.0494, toronto_lm_loss: 6.1004 ||
04/19 02:30:50 PM: Update 1650: task wsj, batch 650 (1650): perplexity: 246.4816, wsj_loss: 5.5073 ||
04/19 02:30:59 PM: Update 501: task toronto_lm, batch 500 (500): perplexity: 434.1502, toronto_lm_loss: 6.0734 ||
04/19 02:31:00 PM: Update 1666: task wsj, batch 666 (1666): perplexity: 245.6011, wsj_loss: 5.5037 ||
04/19 02:31:09 PM: Update 514: task toronto_lm, batch 513 (513): perplexity: 422.5161, toronto_lm_loss: 6.0462 ||
04/19 02:31:10 PM: Update 1682: task wsj, batch 682 (1682): perplexity: 244.9404, wsj_loss: 5.5010 ||
04/19 02:31:19 PM: Update 527: task toronto_lm, batch 526 (526): perplexity: 412.4973, toronto_lm_loss: 6.0222 ||
04/19 02:31:21 PM: Update 1698: task wsj, batch 698 (1698): perplexity: 244.3330, wsj_loss: 5.4985 ||
04/19 02:31:29 PM: Update 540: task toronto_lm, batch 539 (539): perplexity: 403.5273, toronto_lm_loss: 6.0002 ||
04/19 02:31:31 PM: Update 1714: task wsj, batch 714 (1714): perplexity: 243.7371, wsj_loss: 5.4961 ||
04/19 02:31:39 PM: Update 553: task toronto_lm, batch 552 (552): perplexity: 394.4997, toronto_lm_loss: 5.9776 ||
04/19 02:31:42 PM: Update 1730: task wsj, batch 730 (1730): perplexity: 242.8815, wsj_loss: 5.4926 ||
04/19 02:31:50 PM: Update 567: task toronto_lm, batch 566 (566): perplexity: 385.4596, toronto_lm_loss: 5.9544 ||
04/19 02:31:52 PM: Update 1746: task wsj, batch 746 (1746): perplexity: 242.2833, wsj_loss: 5.4901 ||
04/19 02:32:00 PM: Update 580: task toronto_lm, batch 579 (579): perplexity: 377.7318, toronto_lm_loss: 5.9342 ||
04/19 02:32:03 PM: Update 1754: task wsj, batch 754 (1754): perplexity: 241.8604, wsj_loss: 5.4884 ||
04/19 02:32:11 PM: Update 594: task toronto_lm, batch 593 (593): perplexity: 369.2654, toronto_lm_loss: 5.9115 ||
04/19 02:32:13 PM: Update 1770: task wsj, batch 770 (1770): perplexity: 241.5710, wsj_loss: 5.4872 ||
04/19 02:32:21 PM: Update 607: task toronto_lm, batch 606 (606): perplexity: 361.6494, toronto_lm_loss: 5.8907 ||
04/19 02:32:23 PM: Update 1786: task wsj, batch 786 (1786): perplexity: 241.1806, wsj_loss: 5.4855 ||
04/19 02:32:32 PM: Update 621: task toronto_lm, batch 620 (620): perplexity: 354.3526, toronto_lm_loss: 5.8703 ||
04/19 02:32:34 PM: Update 1802: task wsj, batch 802 (1802): perplexity: 240.7994, wsj_loss: 5.4840 ||
04/19 02:32:44 PM: Update 627: task toronto_lm, batch 626 (626): perplexity: 351.4508, toronto_lm_loss: 5.8621 ||
04/19 02:32:44 PM: Update 1818: task wsj, batch 818 (1818): perplexity: 240.3342, wsj_loss: 5.4820 ||
04/19 02:32:54 PM: Update 640: task toronto_lm, batch 639 (639): perplexity: 349.8490, toronto_lm_loss: 5.8575 ||
04/19 02:32:55 PM: Update 1834: task wsj, batch 834 (1834): perplexity: 239.8391, wsj_loss: 5.4800 ||
04/19 02:33:04 PM: Update 653: task toronto_lm, batch 652 (652): perplexity: 346.9987, toronto_lm_loss: 5.8493 ||
04/19 02:33:05 PM: Update 1850: task wsj, batch 850 (1850): perplexity: 239.3415, wsj_loss: 5.4779 ||
04/19 02:33:14 PM: Update 666: task toronto_lm, batch 665 (665): perplexity: 344.8454, toronto_lm_loss: 5.8431 ||
04/19 02:33:16 PM: Update 1866: task wsj, batch 866 (1866): perplexity: 238.9406, wsj_loss: 5.4762 ||
04/19 02:33:24 PM: Update 679: task toronto_lm, batch 678 (678): perplexity: 342.2139, toronto_lm_loss: 5.8354 ||
04/19 02:33:26 PM: Update 1882: task wsj, batch 882 (1882): perplexity: 238.4910, wsj_loss: 5.4743 ||
04/19 02:33:34 PM: Update 692: task toronto_lm, batch 691 (691): perplexity: 339.4592, toronto_lm_loss: 5.8274 ||
04/19 02:33:37 PM: Update 1898: task wsj, batch 898 (1898): perplexity: 238.0929, wsj_loss: 5.4727 ||
04/19 02:33:45 PM: Update 705: task toronto_lm, batch 704 (704): perplexity: 336.7481, toronto_lm_loss: 5.8193 ||
04/19 02:33:50 PM: Update 1910: task wsj, batch 910 (1910): perplexity: 237.6705, wsj_loss: 5.4709 ||
04/19 02:33:55 PM: Update 718: task toronto_lm, batch 717 (717): perplexity: 333.9211, toronto_lm_loss: 5.8109 ||
04/19 02:34:01 PM: Update 1926: task wsj, batch 926 (1926): perplexity: 236.9430, wsj_loss: 5.4678 ||
04/19 02:34:05 PM: Update 731: task toronto_lm, batch 730 (730): perplexity: 331.4527, toronto_lm_loss: 5.8035 ||
04/19 02:34:11 PM: Update 1942: task wsj, batch 942 (1942): perplexity: 236.3328, wsj_loss: 5.4652 ||
04/19 02:34:15 PM: Update 744: task toronto_lm, batch 743 (743): perplexity: 328.7929, toronto_lm_loss: 5.7954 ||
04/19 02:34:22 PM: Update 1958: task wsj, batch 958 (1958): perplexity: 235.8707, wsj_loss: 5.4633 ||
04/19 02:34:25 PM: Update 757: task toronto_lm, batch 756 (756): perplexity: 326.6698, toronto_lm_loss: 5.7889 ||
04/19 02:34:32 PM: Update 1974: task wsj, batch 974 (1974): perplexity: 235.2528, wsj_loss: 5.4607 ||
04/19 02:34:36 PM: Update 771: task toronto_lm, batch 770 (770): perplexity: 323.9494, toronto_lm_loss: 5.7806 ||
04/19 02:34:42 PM: Update 1990: task wsj, batch 990 (1990): perplexity: 234.5894, wsj_loss: 5.4578 ||
04/19 02:34:46 PM: Update 784: task toronto_lm, batch 783 (783): perplexity: 321.5256, toronto_lm_loss: 5.7731 ||
04/19 02:34:49 PM: ***** Pass 2000 / Epoch 2 *****
04/19 02:34:49 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 02:34:49 PM: Validating...
04/19 02:34:53 PM: Batch 15/24: perplexity: 177.4889, wsj_loss: 5.1789 || , for evaluation data
04/19 02:34:55 PM: Best model found for wsj.
04/19 02:34:55 PM: Best model found for micro.
04/19 02:34:55 PM: Best model found for macro.
04/19 02:34:55 PM: Advancing scheduler.
04/19 02:34:55 PM: 	Best macro_avg: 164.379
04/19 02:34:55 PM: 	# bad epochs: 0
04/19 02:34:55 PM: Statistic: wsj_loss
04/19 02:34:55 PM: 	training: 5.456572
04/19 02:34:55 PM: 	validation: 5.102173
04/19 02:34:55 PM: Statistic: macro_avg
04/19 02:34:55 PM: 	validation: 164.378661
04/19 02:34:55 PM: Statistic: micro_avg
04/19 02:34:55 PM: 	validation: 164.378661
04/19 02:34:55 PM: Statistic: wsj_perplexity
04/19 02:34:55 PM: 	training: 234.293000
04/19 02:34:55 PM: 	validation: 164.378661
04/19 02:34:55 PM: global_lr: 0.003000
04/19 02:34:55 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 02:34:56 PM: Update 797: task toronto_lm, batch 796 (796): perplexity: 318.6688, toronto_lm_loss: 5.7642 ||
04/19 02:35:03 PM: Update 2012: task wsj, batch 12 (2012): perplexity: 194.9330, wsj_loss: 5.2727 ||
04/19 02:35:06 PM: Update 810: task toronto_lm, batch 809 (809): perplexity: 316.3264, toronto_lm_loss: 5.7568 ||
04/19 02:35:14 PM: Update 2028: task wsj, batch 28 (2028): perplexity: 198.5287, wsj_loss: 5.2909 ||
04/19 02:35:16 PM: Update 823: task toronto_lm, batch 822 (822): perplexity: 313.8435, toronto_lm_loss: 5.7489 ||
04/19 02:35:24 PM: Update 2044: task wsj, batch 44 (2044): perplexity: 196.2476, wsj_loss: 5.2794 ||
04/19 02:35:27 PM: Update 837: task toronto_lm, batch 836 (836): perplexity: 310.9188, toronto_lm_loss: 5.7395 ||
04/19 02:35:34 PM: Update 2052: task wsj, batch 52 (2052): perplexity: 197.8027, wsj_loss: 5.2873 ||
04/19 02:35:37 PM: Update 850: task toronto_lm, batch 849 (849): perplexity: 308.3951, toronto_lm_loss: 5.7314 ||
04/19 02:35:38 PM: Update 851: task wsj, batch 2 (2): perplexity: 29349.6232, wsj_loss: 10.2870 ||
04/19 02:35:45 PM: Update 2068: task wsj, batch 68 (2068): perplexity: 200.3950, wsj_loss: 5.3003 ||
04/19 02:35:47 PM: Update 863: task toronto_lm, batch 861 (861): perplexity: 306.2798, toronto_lm_loss: 5.7245 ||
04/19 02:35:55 PM: Update 2084: task wsj, batch 84 (2084): perplexity: 201.5534, wsj_loss: 5.3061 ||
04/19 02:35:58 PM: Update 876: task toronto_lm, batch 874 (874): perplexity: 304.2542, toronto_lm_loss: 5.7179 ||
04/19 02:36:06 PM: Update 2100: task wsj, batch 100 (2100): perplexity: 200.6358, wsj_loss: 5.3015 ||
04/19 02:36:08 PM: Update 889: task toronto_lm, batch 887 (887): perplexity: 302.0475, toronto_lm_loss: 5.7106 ||
04/19 02:36:16 PM: Update 2116: task wsj, batch 116 (2116): perplexity: 200.5605, wsj_loss: 5.3011 ||
04/19 02:36:18 PM: Update 902: task toronto_lm, batch 900 (900): perplexity: 300.0235, toronto_lm_loss: 5.7039 ||
04/19 02:36:26 PM: Update 2132: task wsj, batch 132 (2132): perplexity: 201.4109, wsj_loss: 5.3053 ||
04/19 02:36:28 PM: Update 915: task toronto_lm, batch 913 (913): perplexity: 297.7776, toronto_lm_loss: 5.6963 ||
04/19 02:36:37 PM: Update 2148: task wsj, batch 148 (2148): perplexity: 202.0111, wsj_loss: 5.3083 ||
04/19 02:36:38 PM: Update 928: task toronto_lm, batch 926 (926): perplexity: 295.6866, toronto_lm_loss: 5.6893 ||
04/19 02:36:47 PM: Update 2164: task wsj, batch 164 (2164): perplexity: 201.7827, wsj_loss: 5.3072 ||
04/19 02:36:48 PM: Update 941: task toronto_lm, batch 939 (939): perplexity: 293.5425, toronto_lm_loss: 5.6820 ||
04/19 02:36:58 PM: Update 2180: task wsj, batch 180 (2180): perplexity: 202.4650, wsj_loss: 5.3106 ||
04/19 02:36:58 PM: Update 954: task toronto_lm, batch 952 (952): perplexity: 291.2270, toronto_lm_loss: 5.6741 ||
04/19 02:37:08 PM: Update 2196: task wsj, batch 196 (2196): perplexity: 203.3124, wsj_loss: 5.3147 ||
04/19 02:37:08 PM: Update 967: task toronto_lm, batch 965 (965): perplexity: 289.4322, toronto_lm_loss: 5.6679 ||
04/19 02:37:18 PM: Update 2203: task wsj, batch 203 (2203): perplexity: 203.1654, wsj_loss: 5.3140 ||
04/19 02:37:19 PM: Update 980: task toronto_lm, batch 978 (978): perplexity: 287.4304, toronto_lm_loss: 5.6610 ||
04/19 02:37:29 PM: Update 2219: task wsj, batch 219 (2219): perplexity: 202.0492, wsj_loss: 5.3085 ||
04/19 02:37:29 PM: Update 993: task toronto_lm, batch 991 (991): perplexity: 285.6400, toronto_lm_loss: 5.6547 ||
04/19 02:37:34 PM: ***** Pass 1000 / Epoch 1 *****
04/19 02:37:34 PM: toronto_lm: trained on 998 batches, 0.005 epochs
04/19 02:37:34 PM: wsj: trained on 2 batches, 0.002 epochs
04/19 02:37:34 PM: Validating...
04/19 02:37:39 PM: Batch 17/140: perplexity: 185.0889, toronto_lm_loss: 5.2208 || , for evaluation data
04/19 02:37:39 PM: Update 2235: task wsj, batch 235 (2235): perplexity: 200.6351, wsj_loss: 5.3015 ||
04/19 02:37:49 PM: Batch 50/140: perplexity: 191.4533, toronto_lm_loss: 5.2546 || , for evaluation data
04/19 02:37:50 PM: Update 2251: task wsj, batch 251 (2251): perplexity: 200.4806, wsj_loss: 5.3007 ||
04/19 02:37:59 PM: Batch 88/140: perplexity: 177.8537, toronto_lm_loss: 5.1810 || , for evaluation data
04/19 02:38:00 PM: Update 2267: task wsj, batch 267 (2267): perplexity: 199.6211, wsj_loss: 5.2964 ||
04/19 02:38:09 PM: Batch 125/140: perplexity: 169.9205, toronto_lm_loss: 5.1353 || , for evaluation data
04/19 02:38:10 PM: Update 2283: task wsj, batch 283 (2283): perplexity: 199.2046, wsj_loss: 5.2943 ||
04/19 02:38:14 PM: Batch 1/66: perplexity: 12156.4229, wsj_loss: 9.4056 || , for evaluation data
04/19 02:38:21 PM: Update 2299: task wsj, batch 299 (2299): perplexity: 198.6859, wsj_loss: 5.2917 ||
04/19 02:38:24 PM: Batch 38/66: perplexity: 11600.2452, wsj_loss: 9.3588 || , for evaluation data
04/19 02:38:31 PM: Update 2315: task wsj, batch 315 (2315): perplexity: 198.4134, wsj_loss: 5.2904 ||
04/19 02:38:31 PM: Best model found for toronto_lm.
04/19 02:38:31 PM: Best model found for wsj.
04/19 02:38:31 PM: Best model found for micro.
04/19 02:38:31 PM: Best model found for macro.
04/19 02:38:31 PM: Advancing scheduler.
04/19 02:38:31 PM: 	Best macro_avg: -22.736
04/19 02:38:31 PM: 	# bad epochs: 0
04/19 02:38:31 PM: Statistic: toronto_lm_loss
04/19 02:38:31 PM: 	training: 5.651582
04/19 02:38:31 PM: 	validation: 5.112948
04/19 02:38:31 PM: Statistic: wsj_loss
04/19 02:38:31 PM: 	training: 10.287035
04/19 02:38:31 PM: 	validation: 9.363934
04/19 02:38:31 PM: Statistic: macro_avg
04/19 02:38:31 PM: 	validation: -22.736498
04/19 02:38:31 PM: Statistic: micro_avg
04/19 02:38:31 PM: 	validation: -14.629370
04/19 02:38:31 PM: Statistic: toronto_lm_perplexity
04/19 02:38:31 PM: 	training: 284.741467
04/19 02:38:31 PM: 	validation: 166.159470
04/19 02:38:31 PM: Statistic: wsj_perplexity
04/19 02:38:31 PM: 	training: 29349.623241
04/19 02:38:31 PM: 	validation: 11660.169501
04/19 02:38:31 PM: global_lr: 0.001000
04/19 02:38:32 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 02:38:32 PM: Update 1001: task toronto_lm, batch 1 (999): perplexity: 152.8421, toronto_lm_loss: 5.0294 ||
04/19 02:38:42 PM: Update 2331: task wsj, batch 331 (2331): perplexity: 197.9846, wsj_loss: 5.2882 ||
04/19 02:38:42 PM: Update 1014: task toronto_lm, batch 14 (1012): perplexity: 182.6650, toronto_lm_loss: 5.2077 ||
04/19 02:38:52 PM: Update 2339: task wsj, batch 339 (2339): perplexity: 197.8569, wsj_loss: 5.2875 ||
04/19 02:38:53 PM: Update 1027: task toronto_lm, batch 27 (1025): perplexity: 178.6078, toronto_lm_loss: 5.1852 ||
04/19 02:39:02 PM: Update 2355: task wsj, batch 355 (2355): perplexity: 197.8116, wsj_loss: 5.2873 ||
04/19 02:39:03 PM: Update 1040: task toronto_lm, batch 40 (1038): perplexity: 178.3372, toronto_lm_loss: 5.1837 ||
04/19 02:39:13 PM: Update 2371: task wsj, batch 371 (2371): perplexity: 197.5491, wsj_loss: 5.2860 ||
04/19 02:39:13 PM: Update 1053: task toronto_lm, batch 53 (1051): perplexity: 177.0769, toronto_lm_loss: 5.1766 ||
04/19 02:39:23 PM: Update 1066: task toronto_lm, batch 66 (1064): perplexity: 175.5610, toronto_lm_loss: 5.1680 ||
04/19 02:39:23 PM: Update 2387: task wsj, batch 387 (2387): perplexity: 197.4762, wsj_loss: 5.2856 ||
04/19 02:39:30 PM: Update 1075: task wsj, batch 1 (3): perplexity: 12327.2212, wsj_loss: 9.4196 ||
04/19 02:39:33 PM: Update 1079: task toronto_lm, batch 78 (1076): perplexity: 174.3232, toronto_lm_loss: 5.1609 ||
04/19 02:39:33 PM: Update 2403: task wsj, batch 403 (2403): perplexity: 197.7147, wsj_loss: 5.2868 ||
04/19 02:39:43 PM: Update 1092: task toronto_lm, batch 91 (1089): perplexity: 173.5243, toronto_lm_loss: 5.1563 ||
04/19 02:39:44 PM: Update 2419: task wsj, batch 419 (2419): perplexity: 197.7792, wsj_loss: 5.2872 ||
04/19 02:39:53 PM: Update 1105: task toronto_lm, batch 104 (1102): perplexity: 173.1552, toronto_lm_loss: 5.1542 ||
04/19 02:39:54 PM: Update 2435: task wsj, batch 435 (2435): perplexity: 197.4858, wsj_loss: 5.2857 ||
04/19 02:40:04 PM: Update 1119: task toronto_lm, batch 118 (1116): perplexity: 171.9077, toronto_lm_loss: 5.1470 ||
04/19 02:40:05 PM: Update 2451: task wsj, batch 451 (2451): perplexity: 197.2811, wsj_loss: 5.2846 ||
04/19 02:40:15 PM: Update 1133: task toronto_lm, batch 132 (1130): perplexity: 170.8082, toronto_lm_loss: 5.1405 ||
04/19 02:40:15 PM: Update 2467: task wsj, batch 467 (2467): perplexity: 197.0164, wsj_loss: 5.2833 ||
04/19 02:40:25 PM: Update 1147: task toronto_lm, batch 146 (1144): perplexity: 169.5944, toronto_lm_loss: 5.1334 ||
04/19 02:40:26 PM: Update 2483: task wsj, batch 483 (2483): perplexity: 196.8095, wsj_loss: 5.2822 ||
04/19 02:40:36 PM: Update 1161: task toronto_lm, batch 160 (1158): perplexity: 168.0846, toronto_lm_loss: 5.1245 ||
04/19 02:40:38 PM: Update 2494: task wsj, batch 494 (2494): perplexity: 196.9250, wsj_loss: 5.2828 ||
04/19 02:40:46 PM: Update 1174: task toronto_lm, batch 173 (1171): perplexity: 167.5757, toronto_lm_loss: 5.1214 ||
04/19 02:40:49 PM: Update 2510: task wsj, batch 510 (2510): perplexity: 196.5714, wsj_loss: 5.2810 ||
04/19 02:40:56 PM: Update 1187: task toronto_lm, batch 186 (1184): perplexity: 167.4074, toronto_lm_loss: 5.1204 ||
04/19 02:40:58 PM: Update 1190: task wsj, batch 2 (4): perplexity: 9039.5227, wsj_loss: 9.1094 ||
04/19 02:40:59 PM: Update 2526: task wsj, batch 526 (2526): perplexity: 196.0910, wsj_loss: 5.2786 ||
04/19 02:41:07 PM: Update 1201: task toronto_lm, batch 199 (1197): perplexity: 167.1168, toronto_lm_loss: 5.1187 ||
04/19 02:41:09 PM: Update 2542: task wsj, batch 542 (2542): perplexity: 195.3967, wsj_loss: 5.2750 ||
04/19 02:41:18 PM: Update 1215: task toronto_lm, batch 213 (1211): perplexity: 167.3418, toronto_lm_loss: 5.1200 ||
04/19 02:41:20 PM: Update 2558: task wsj, batch 558 (2558): perplexity: 195.0576, wsj_loss: 5.2733 ||
04/19 02:41:28 PM: Update 1228: task toronto_lm, batch 226 (1224): perplexity: 167.3722, toronto_lm_loss: 5.1202 ||
04/19 02:41:30 PM: Update 2574: task wsj, batch 574 (2574): perplexity: 194.5017, wsj_loss: 5.2704 ||
04/19 02:41:38 PM: Update 1241: task toronto_lm, batch 239 (1237): perplexity: 167.2964, toronto_lm_loss: 5.1198 ||
04/19 02:41:41 PM: Update 2590: task wsj, batch 590 (2590): perplexity: 194.0882, wsj_loss: 5.2683 ||
04/19 02:41:48 PM: Update 1254: task toronto_lm, batch 252 (1250): perplexity: 166.8963, toronto_lm_loss: 5.1174 ||
04/19 02:41:51 PM: Update 2606: task wsj, batch 606 (2606): perplexity: 193.7113, wsj_loss: 5.2664 ||
04/19 02:41:58 PM: Update 1257: task toronto_lm, batch 255 (1253): perplexity: 167.1964, toronto_lm_loss: 5.1192 ||
04/19 02:42:02 PM: Update 2622: task wsj, batch 622 (2622): perplexity: 193.3979, wsj_loss: 5.2647 ||
04/19 02:42:09 PM: Update 1270: task toronto_lm, batch 268 (1266): perplexity: 167.6437, toronto_lm_loss: 5.1218 ||
04/19 02:42:12 PM: Update 2630: task wsj, batch 630 (2630): perplexity: 193.1621, wsj_loss: 5.2635 ||
04/19 02:42:19 PM: Update 1283: task toronto_lm, batch 281 (1279): perplexity: 167.4535, toronto_lm_loss: 5.1207 ||
04/19 02:42:22 PM: Update 2646: task wsj, batch 646 (2646): perplexity: 192.9282, wsj_loss: 5.2623 ||
04/19 02:42:29 PM: Update 1297: task toronto_lm, batch 295 (1293): perplexity: 167.1971, toronto_lm_loss: 5.1192 ||
04/19 02:42:33 PM: Update 2662: task wsj, batch 662 (2662): perplexity: 192.8398, wsj_loss: 5.2619 ||
04/19 02:42:40 PM: Update 1311: task toronto_lm, batch 309 (1307): perplexity: 166.3878, toronto_lm_loss: 5.1143 ||
04/19 02:42:43 PM: Update 2678: task wsj, batch 678 (2678): perplexity: 192.8435, wsj_loss: 5.2619 ||
04/19 02:42:51 PM: Update 1325: task toronto_lm, batch 323 (1321): perplexity: 165.8357, toronto_lm_loss: 5.1110 ||
04/19 02:42:54 PM: Update 2694: task wsj, batch 694 (2694): perplexity: 192.7077, wsj_loss: 5.2612 ||
04/19 02:43:01 PM: Update 1339: task toronto_lm, batch 337 (1335): perplexity: 164.8640, toronto_lm_loss: 5.1051 ||
04/19 02:43:04 PM: Update 2710: task wsj, batch 710 (2710): perplexity: 192.4920, wsj_loss: 5.2601 ||
04/19 02:43:12 PM: Update 1353: task toronto_lm, batch 351 (1349): perplexity: 163.8439, toronto_lm_loss: 5.0989 ||
04/19 02:43:14 PM: Update 2726: task wsj, batch 726 (2726): perplexity: 192.1982, wsj_loss: 5.2585 ||
04/19 02:43:23 PM: Update 1367: task toronto_lm, batch 365 (1363): perplexity: 162.5423, toronto_lm_loss: 5.0909 ||
04/19 02:43:25 PM: Update 2742: task wsj, batch 742 (2742): perplexity: 192.0037, wsj_loss: 5.2575 ||
04/19 02:43:33 PM: Update 1381: task toronto_lm, batch 379 (1377): perplexity: 161.5059, toronto_lm_loss: 5.0845 ||
04/19 02:43:35 PM: Update 2758: task wsj, batch 758 (2758): perplexity: 191.9509, wsj_loss: 5.2572 ||
04/19 02:43:44 PM: Update 1395: task toronto_lm, batch 393 (1391): perplexity: 160.1353, toronto_lm_loss: 5.0760 ||
04/19 02:43:46 PM: Update 2774: task wsj, batch 774 (2774): perplexity: 191.6507, wsj_loss: 5.2557 ||
04/19 02:43:55 PM: Update 1409: task toronto_lm, batch 407 (1405): perplexity: 159.3265, toronto_lm_loss: 5.0710 ||
04/19 02:43:58 PM: Update 2786: task wsj, batch 786 (2786): perplexity: 191.5799, wsj_loss: 5.2553 ||
04/19 02:44:05 PM: Update 1423: task toronto_lm, batch 421 (1419): perplexity: 158.0714, toronto_lm_loss: 5.0630 ||
04/19 02:44:09 PM: Update 2802: task wsj, batch 802 (2802): perplexity: 191.3442, wsj_loss: 5.2541 ||
04/19 02:44:16 PM: Update 1437: task toronto_lm, batch 435 (1433): perplexity: 157.2575, toronto_lm_loss: 5.0579 ||
04/19 02:44:19 PM: Update 2818: task wsj, batch 818 (2818): perplexity: 190.9075, wsj_loss: 5.2518 ||
04/19 02:44:27 PM: Update 1451: task toronto_lm, batch 449 (1447): perplexity: 156.0289, toronto_lm_loss: 5.0500 ||
04/19 02:44:30 PM: Update 2834: task wsj, batch 834 (2834): perplexity: 190.5843, wsj_loss: 5.2501 ||
04/19 02:44:37 PM: Update 1465: task toronto_lm, batch 463 (1461): perplexity: 154.8859, toronto_lm_loss: 5.0427 ||
04/19 02:44:40 PM: Update 2850: task wsj, batch 850 (2850): perplexity: 190.2888, wsj_loss: 5.2485 ||
04/19 02:44:48 PM: Update 1479: task toronto_lm, batch 477 (1475): perplexity: 154.1826, toronto_lm_loss: 5.0381 ||
04/19 02:44:49 PM: Update 1480: task wsj, batch 3 (5): perplexity: 7121.3672, wsj_loss: 8.8709 ||
04/19 02:44:50 PM: Update 2866: task wsj, batch 866 (2866): perplexity: 189.9862, wsj_loss: 5.2470 ||
04/19 02:44:58 PM: Update 1493: task toronto_lm, batch 490 (1488): perplexity: 153.2914, toronto_lm_loss: 5.0323 ||
04/19 02:45:01 PM: Update 2882: task wsj, batch 882 (2882): perplexity: 189.6787, wsj_loss: 5.2453 ||
04/19 02:45:09 PM: Update 1507: task toronto_lm, batch 504 (1502): perplexity: 152.7338, toronto_lm_loss: 5.0287 ||
04/19 02:45:11 PM: Update 2898: task wsj, batch 898 (2898): perplexity: 189.2676, wsj_loss: 5.2432 ||
04/19 02:45:20 PM: Update 1521: task toronto_lm, batch 518 (1516): perplexity: 151.8007, toronto_lm_loss: 5.0226 ||
04/19 02:45:22 PM: Update 2914: task wsj, batch 914 (2914): perplexity: 188.9023, wsj_loss: 5.2412 ||
04/19 02:45:31 PM: Update 1535: task toronto_lm, batch 532 (1530): perplexity: 151.2254, toronto_lm_loss: 5.0188 ||
04/19 02:45:32 PM: Update 2922: task wsj, batch 922 (2922): perplexity: 188.6039, wsj_loss: 5.2396 ||
04/19 02:45:41 PM: Update 1549: task toronto_lm, batch 546 (1544): perplexity: 150.4481, toronto_lm_loss: 5.0136 ||
04/19 02:45:43 PM: Update 2938: task wsj, batch 938 (2938): perplexity: 188.5619, wsj_loss: 5.2394 ||
04/19 02:45:52 PM: Update 1563: task toronto_lm, batch 560 (1558): perplexity: 149.6939, toronto_lm_loss: 5.0086 ||
04/19 02:45:53 PM: Update 2954: task wsj, batch 954 (2954): perplexity: 188.3335, wsj_loss: 5.2382 ||
04/19 02:46:03 PM: Update 1577: task toronto_lm, batch 574 (1572): perplexity: 148.8102, toronto_lm_loss: 5.0027 ||
04/19 02:46:04 PM: Update 2970: task wsj, batch 970 (2970): perplexity: 188.3032, wsj_loss: 5.2381 ||
04/19 02:46:13 PM: Update 1591: task toronto_lm, batch 588 (1586): perplexity: 148.2305, toronto_lm_loss: 4.9988 ||
04/19 02:46:14 PM: Update 2986: task wsj, batch 986 (2986): perplexity: 188.0789, wsj_loss: 5.2369 ||
04/19 02:46:23 PM: ***** Pass 3000 / Epoch 3 *****
04/19 02:46:23 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 02:46:23 PM: Validating...
04/19 02:46:24 PM: Update 1605: task toronto_lm, batch 602 (1600): perplexity: 147.5027, toronto_lm_loss: 4.9938 ||
04/19 02:46:24 PM: Batch 4/24: perplexity: 200.3823, wsj_loss: 5.3002 || , for evaluation data
04/19 02:46:29 PM: Best model found for wsj.
04/19 02:46:29 PM: Best model found for micro.
04/19 02:46:29 PM: Best model found for macro.
04/19 02:46:29 PM: Advancing scheduler.
04/19 02:46:29 PM: 	Best macro_avg: 146.087
04/19 02:46:29 PM: 	# bad epochs: 0
04/19 02:46:29 PM: Statistic: wsj_loss
04/19 02:46:29 PM: 	training: 5.235754
04/19 02:46:29 PM: 	validation: 4.984205
04/19 02:46:29 PM: Statistic: macro_avg
04/19 02:46:29 PM: 	validation: 146.087370
04/19 02:46:29 PM: Statistic: micro_avg
04/19 02:46:29 PM: 	validation: 146.087370
04/19 02:46:29 PM: Statistic: wsj_perplexity
04/19 02:46:29 PM: 	training: 187.870774
04/19 02:46:29 PM: 	validation: 146.087370
04/19 02:46:29 PM: global_lr: 0.003000
04/19 02:46:30 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 02:46:34 PM: Update 1618: task toronto_lm, batch 615 (1613): perplexity: 146.8172, toronto_lm_loss: 4.9892 ||
04/19 02:46:35 PM: Update 3007: task wsj, batch 7 (3007): perplexity: 183.6919, wsj_loss: 5.2133 ||
04/19 02:46:45 PM: Update 1632: task toronto_lm, batch 629 (1627): perplexity: 146.2677, toronto_lm_loss: 4.9854 ||
04/19 02:46:45 PM: Update 3023: task wsj, batch 23 (3023): perplexity: 183.6895, wsj_loss: 5.2132 ||
04/19 02:46:55 PM: Update 1645: task toronto_lm, batch 642 (1640): perplexity: 145.6565, toronto_lm_loss: 4.9813 ||
04/19 02:46:55 PM: Update 3039: task wsj, batch 39 (3039): perplexity: 179.8904, wsj_loss: 5.1923 ||
04/19 02:47:06 PM: Update 1659: task toronto_lm, batch 656 (1654): perplexity: 144.9652, toronto_lm_loss: 4.9765 ||
04/19 02:47:06 PM: Update 3055: task wsj, batch 55 (3055): perplexity: 177.8438, wsj_loss: 5.1809 ||
04/19 02:47:16 PM: Update 1673: task toronto_lm, batch 670 (1668): perplexity: 144.3101, toronto_lm_loss: 4.9720 ||
04/19 02:47:16 PM: Update 3071: task wsj, batch 71 (3071): perplexity: 177.7983, wsj_loss: 5.1806 ||
04/19 02:47:27 PM: Update 1687: task toronto_lm, batch 684 (1682): perplexity: 143.6697, toronto_lm_loss: 4.9675 ||
04/19 02:47:27 PM: Update 3080: task wsj, batch 80 (3080): perplexity: 176.2424, wsj_loss: 5.1719 ||
04/19 02:47:37 PM: Update 3096: task wsj, batch 96 (3096): perplexity: 175.0572, wsj_loss: 5.1651 ||
04/19 02:47:38 PM: Update 1701: task toronto_lm, batch 698 (1696): perplexity: 142.9518, toronto_lm_loss: 4.9625 ||
04/19 02:47:48 PM: Update 3112: task wsj, batch 112 (3112): perplexity: 173.8555, wsj_loss: 5.1582 ||
04/19 02:47:48 PM: Update 1715: task toronto_lm, batch 712 (1710): perplexity: 142.3136, toronto_lm_loss: 4.9580 ||
04/19 02:47:58 PM: Update 3128: task wsj, batch 128 (3128): perplexity: 172.7594, wsj_loss: 5.1519 ||
04/19 02:47:59 PM: Update 1729: task toronto_lm, batch 726 (1724): perplexity: 141.7152, toronto_lm_loss: 4.9538 ||
04/19 02:48:03 PM: Update 1734: task wsj, batch 4 (6): perplexity: 5740.6942, wsj_loss: 8.6553 ||
04/19 02:48:09 PM: Update 3144: task wsj, batch 144 (3144): perplexity: 172.4193, wsj_loss: 5.1499 ||
04/19 02:48:09 PM: Update 1743: task toronto_lm, batch 739 (1737): perplexity: 141.0666, toronto_lm_loss: 4.9492 ||
04/19 02:48:19 PM: Update 1755: task wsj, batch 5 (7): perplexity: 4658.5192, wsj_loss: 8.4465 ||
04/19 02:48:19 PM: Update 3160: task wsj, batch 160 (3160): perplexity: 171.5322, wsj_loss: 5.1448 ||
04/19 02:48:20 PM: Update 1757: task toronto_lm, batch 752 (1750): perplexity: 140.5126, toronto_lm_loss: 4.9453 ||
04/19 02:48:30 PM: Update 3176: task wsj, batch 176 (3176): perplexity: 170.9426, wsj_loss: 5.1413 ||
04/19 02:48:31 PM: Update 1771: task toronto_lm, batch 766 (1764): perplexity: 140.0151, toronto_lm_loss: 4.9418 ||
04/19 02:48:40 PM: Update 3192: task wsj, batch 192 (3192): perplexity: 170.5761, wsj_loss: 5.1392 ||
04/19 02:48:41 PM: Update 1785: task toronto_lm, batch 780 (1778): perplexity: 139.5226, toronto_lm_loss: 4.9382 ||
04/19 02:48:51 PM: Update 3208: task wsj, batch 208 (3208): perplexity: 169.7666, wsj_loss: 5.1344 ||
04/19 02:48:52 PM: Update 1799: task toronto_lm, batch 794 (1792): perplexity: 138.8863, toronto_lm_loss: 4.9337 ||
04/19 02:49:01 PM: Update 3215: task wsj, batch 215 (3215): perplexity: 169.5992, wsj_loss: 5.1334 ||
04/19 02:49:03 PM: Update 1813: task toronto_lm, batch 808 (1806): perplexity: 138.4574, toronto_lm_loss: 4.9306 ||
04/19 02:49:11 PM: Update 3231: task wsj, batch 231 (3231): perplexity: 169.7392, wsj_loss: 5.1343 ||
04/19 02:49:13 PM: Update 1826: task toronto_lm, batch 821 (1819): perplexity: 137.9962, toronto_lm_loss: 4.9272 ||
04/19 02:49:21 PM: Update 3247: task wsj, batch 247 (3247): perplexity: 169.9507, wsj_loss: 5.1355 ||
04/19 02:49:23 PM: Update 1839: task toronto_lm, batch 834 (1832): perplexity: 137.5212, toronto_lm_loss: 4.9238 ||
04/19 02:49:32 PM: Update 3263: task wsj, batch 263 (3263): perplexity: 170.2202, wsj_loss: 5.1371 ||
04/19 02:49:33 PM: Update 1852: task toronto_lm, batch 847 (1845): perplexity: 137.0301, toronto_lm_loss: 4.9202 ||
04/19 02:49:42 PM: Update 3279: task wsj, batch 279 (3279): perplexity: 170.3459, wsj_loss: 5.1378 ||
04/19 02:49:43 PM: Update 1865: task toronto_lm, batch 860 (1858): perplexity: 136.5623, toronto_lm_loss: 4.9168 ||
04/19 02:49:53 PM: Update 3295: task wsj, batch 295 (3295): perplexity: 170.4280, wsj_loss: 5.1383 ||
04/19 02:49:54 PM: Update 1879: task toronto_lm, batch 874 (1872): perplexity: 136.1648, toronto_lm_loss: 4.9139 ||
04/19 02:50:03 PM: Update 3311: task wsj, batch 311 (3311): perplexity: 170.7647, wsj_loss: 5.1403 ||
04/19 02:50:04 PM: Update 1884: task toronto_lm, batch 879 (1877): perplexity: 136.1245, toronto_lm_loss: 4.9136 ||
04/19 02:50:14 PM: Update 3327: task wsj, batch 327 (3327): perplexity: 170.3210, wsj_loss: 5.1377 ||
04/19 02:50:15 PM: Update 1898: task toronto_lm, batch 893 (1891): perplexity: 136.2111, toronto_lm_loss: 4.9142 ||
04/19 02:50:24 PM: Update 3343: task wsj, batch 343 (3343): perplexity: 170.4675, wsj_loss: 5.1385 ||
04/19 02:50:26 PM: Update 1912: task toronto_lm, batch 907 (1905): perplexity: 136.3570, toronto_lm_loss: 4.9153 ||
04/19 02:50:35 PM: Update 3359: task wsj, batch 359 (3359): perplexity: 170.2950, wsj_loss: 5.1375 ||
04/19 02:50:36 PM: Update 1926: task wsj, batch 6 (8): perplexity: 3831.4542, wsj_loss: 8.2510 ||
04/19 02:50:37 PM: Update 1927: task toronto_lm, batch 921 (1919): perplexity: 136.3229, toronto_lm_loss: 4.9150 ||
04/19 02:50:47 PM: Update 1940: task toronto_lm, batch 934 (1932): perplexity: 136.2879, toronto_lm_loss: 4.9148 ||
04/19 02:50:47 PM: Update 3370: task wsj, batch 370 (3370): perplexity: 170.6213, wsj_loss: 5.1394 ||
04/19 02:50:57 PM: Update 1953: task toronto_lm, batch 947 (1945): perplexity: 136.0626, toronto_lm_loss: 4.9131 ||
04/19 02:50:58 PM: Update 3386: task wsj, batch 386 (3386): perplexity: 170.2272, wsj_loss: 5.1371 ||
04/19 02:51:08 PM: Update 1967: task toronto_lm, batch 961 (1959): perplexity: 135.8024, toronto_lm_loss: 4.9112 ||
04/19 02:51:08 PM: Update 3402: task wsj, batch 402 (3402): perplexity: 169.7408, wsj_loss: 5.1343 ||
04/19 02:51:19 PM: Update 1981: task toronto_lm, batch 975 (1973): perplexity: 135.5671, toronto_lm_loss: 4.9095 ||
04/19 02:51:19 PM: Update 3418: task wsj, batch 418 (3418): perplexity: 169.2856, wsj_loss: 5.1316 ||
04/19 02:51:29 PM: Update 3434: task wsj, batch 434 (3434): perplexity: 168.6863, wsj_loss: 5.1280 ||
04/19 02:51:29 PM: Update 1995: task toronto_lm, batch 989 (1987): perplexity: 135.1956, toronto_lm_loss: 4.9067 ||
04/19 02:51:33 PM: ***** Pass 2000 / Epoch 2 *****
04/19 02:51:33 PM: toronto_lm: trained on 994 batches, 0.005 epochs
04/19 02:51:33 PM: wsj: trained on 6 batches, 0.007 epochs
04/19 02:51:33 PM: Validating...
04/19 02:51:40 PM: Batch 24/140: perplexity: 152.7520, toronto_lm_loss: 5.0288 || , for evaluation data
04/19 02:51:40 PM: Update 3450: task wsj, batch 450 (3450): perplexity: 168.7184, wsj_loss: 5.1282 ||
04/19 02:51:50 PM: Batch 63/140: perplexity: 147.6777, toronto_lm_loss: 4.9950 || , for evaluation data
04/19 02:51:50 PM: Update 3466: task wsj, batch 466 (3466): perplexity: 168.5742, wsj_loss: 5.1274 ||
04/19 02:52:00 PM: Batch 102/140: perplexity: 141.1387, toronto_lm_loss: 4.9497 || , for evaluation data
04/19 02:52:00 PM: Update 3482: task wsj, batch 482 (3482): perplexity: 167.9417, wsj_loss: 5.1236 ||
04/19 02:52:10 PM: Batch 137/140: perplexity: 130.5917, toronto_lm_loss: 4.8721 || , for evaluation data
04/19 02:52:11 PM: Update 3498: task wsj, batch 498 (3498): perplexity: 167.7555, wsj_loss: 5.1225 ||
04/19 02:52:11 PM: Batch 1/66: perplexity: 1493.4798, wsj_loss: 7.3089 || , for evaluation data
04/19 02:52:21 PM: Update 3506: task wsj, batch 506 (3506): perplexity: 167.6617, wsj_loss: 5.1219 ||
04/19 02:52:21 PM: Batch 40/66: perplexity: 1214.2196, wsj_loss: 7.1019 || , for evaluation data
04/19 02:52:28 PM: Best model found for toronto_lm.
04/19 02:52:28 PM: Best model found for wsj.
04/19 02:52:28 PM: Best model found for micro.
04/19 02:52:28 PM: Best model found for macro.
04/19 02:52:28 PM: Advancing scheduler.
04/19 02:52:28 PM: 	Best macro_avg: -1.801
04/19 02:52:28 PM: 	# bad epochs: 0
04/19 02:52:28 PM: Statistic: toronto_lm_loss
04/19 02:52:28 PM: 	training: 4.905961
04/19 02:52:28 PM: 	validation: 4.872203
04/19 02:52:28 PM: Statistic: wsj_loss
04/19 02:52:28 PM: 	training: 8.251000
04/19 02:52:28 PM: 	validation: 7.098630
04/19 02:52:28 PM: Statistic: macro_avg
04/19 02:52:28 PM: 	validation: -1.801223
04/19 02:52:28 PM: Statistic: micro_avg
04/19 02:52:28 PM: 	validation: -1.231241
04/19 02:52:28 PM: Statistic: toronto_lm_perplexity
04/19 02:52:28 PM: 	training: 135.092693
04/19 02:52:28 PM: 	validation: 130.608322
04/19 02:52:28 PM: Statistic: wsj_perplexity
04/19 02:52:28 PM: 	training: 3831.454171
04/19 02:52:28 PM: 	validation: 1210.307251
04/19 02:52:28 PM: global_lr: 0.001000
04/19 02:52:29 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 02:52:29 PM: Update 2001: task toronto_lm, batch 1 (1993): perplexity: 94.9412, toronto_lm_loss: 4.5533 ||
04/19 02:52:32 PM: Update 3522: task wsj, batch 522 (3522): perplexity: 167.4858, wsj_loss: 5.1209 ||
04/19 02:52:40 PM: Update 2015: task toronto_lm, batch 15 (2007): perplexity: 116.8956, toronto_lm_loss: 4.7613 ||
04/19 02:52:42 PM: Update 3538: task wsj, batch 538 (3538): perplexity: 167.3677, wsj_loss: 5.1202 ||
04/19 02:52:51 PM: Update 2029: task toronto_lm, batch 29 (2021): perplexity: 117.6193, toronto_lm_loss: 4.7675 ||
04/19 02:52:52 PM: Update 3554: task wsj, batch 554 (3554): perplexity: 167.3459, wsj_loss: 5.1201 ||
04/19 02:53:01 PM: Update 2043: task toronto_lm, batch 43 (2035): perplexity: 115.5978, toronto_lm_loss: 4.7501 ||
04/19 02:53:03 PM: Update 3570: task wsj, batch 570 (3570): perplexity: 167.3218, wsj_loss: 5.1199 ||
04/19 02:53:12 PM: Update 2057: task toronto_lm, batch 57 (2049): perplexity: 115.9662, toronto_lm_loss: 4.7533 ||
04/19 02:53:13 PM: Update 3586: task wsj, batch 586 (3586): perplexity: 167.2593, wsj_loss: 5.1195 ||
04/19 02:53:23 PM: Update 2071: task toronto_lm, batch 71 (2063): perplexity: 115.3900, toronto_lm_loss: 4.7483 ||
04/19 02:53:24 PM: Update 3602: task wsj, batch 602 (3602): perplexity: 167.2473, wsj_loss: 5.1195 ||
04/19 02:53:33 PM: Update 2085: task toronto_lm, batch 85 (2077): perplexity: 114.2295, toronto_lm_loss: 4.7382 ||
04/19 02:53:34 PM: Update 2086: task wsj, batch 1 (9): perplexity: 1064.7519, wsj_loss: 6.9705 ||
04/19 02:53:34 PM: Update 3618: task wsj, batch 618 (3618): perplexity: 167.2593, wsj_loss: 5.1195 ||
04/19 02:53:44 PM: Update 2099: task toronto_lm, batch 98 (2090): perplexity: 113.7961, toronto_lm_loss: 4.7344 ||
04/19 02:53:45 PM: Update 3634: task wsj, batch 634 (3634): perplexity: 167.2474, wsj_loss: 5.1195 ||
04/19 02:53:55 PM: Update 2113: task toronto_lm, batch 112 (2104): perplexity: 113.4903, toronto_lm_loss: 4.7317 ||
04/19 02:53:55 PM: Update 3650: task wsj, batch 650 (3650): perplexity: 167.1536, wsj_loss: 5.1189 ||
04/19 02:54:05 PM: Update 2127: task toronto_lm, batch 126 (2118): perplexity: 113.5020, toronto_lm_loss: 4.7318 ||
04/19 02:54:08 PM: Update 3662: task wsj, batch 662 (3662): perplexity: 167.1496, wsj_loss: 5.1189 ||
04/19 02:54:16 PM: Update 2141: task toronto_lm, batch 140 (2132): perplexity: 112.6304, toronto_lm_loss: 4.7241 ||
04/19 02:54:18 PM: Update 3678: task wsj, batch 678 (3678): perplexity: 166.8594, wsj_loss: 5.1172 ||
04/19 02:54:27 PM: Update 2155: task toronto_lm, batch 154 (2146): perplexity: 112.1177, toronto_lm_loss: 4.7195 ||
04/19 02:54:29 PM: Update 3694: task wsj, batch 694 (3694): perplexity: 166.5216, wsj_loss: 5.1151 ||
04/19 02:54:30 PM: Update 2159: task wsj, batch 2 (10): perplexity: 1023.4418, wsj_loss: 6.9309 ||
04/19 02:54:37 PM: Update 2169: task toronto_lm, batch 167 (2159): perplexity: 111.1438, toronto_lm_loss: 4.7108 ||
04/19 02:54:39 PM: Update 3710: task wsj, batch 710 (3710): perplexity: 166.3245, wsj_loss: 5.1139 ||
04/19 02:54:48 PM: Update 2183: task toronto_lm, batch 181 (2173): perplexity: 110.5837, toronto_lm_loss: 4.7058 ||
04/19 02:54:49 PM: Update 3726: task wsj, batch 726 (3726): perplexity: 166.0578, wsj_loss: 5.1123 ||
04/19 02:54:59 PM: Update 2197: task toronto_lm, batch 195 (2187): perplexity: 110.6215, toronto_lm_loss: 4.7061 ||
04/19 02:55:00 PM: Update 3742: task wsj, batch 742 (3742): perplexity: 165.8386, wsj_loss: 5.1110 ||
04/19 02:55:09 PM: Update 2210: task toronto_lm, batch 208 (2200): perplexity: 109.9731, toronto_lm_loss: 4.7002 ||
04/19 02:55:10 PM: Update 3758: task wsj, batch 758 (3758): perplexity: 165.5427, wsj_loss: 5.1092 ||
04/19 02:55:19 PM: Update 2223: task toronto_lm, batch 221 (2213): perplexity: 109.4448, toronto_lm_loss: 4.6954 ||
04/19 02:55:21 PM: Update 3774: task wsj, batch 774 (3774): perplexity: 165.2366, wsj_loss: 5.1074 ||
04/19 02:55:25 PM: Update 2232: task wsj, batch 3 (11): perplexity: 958.1208, wsj_loss: 6.8650 ||
04/19 02:55:29 PM: Update 2237: task toronto_lm, batch 234 (2226): perplexity: 109.0601, toronto_lm_loss: 4.6919 ||
04/19 02:55:31 PM: Update 3790: task wsj, batch 790 (3790): perplexity: 165.0784, wsj_loss: 5.1064 ||
04/19 02:55:39 PM: Update 2250: task toronto_lm, batch 247 (2239): perplexity: 108.7425, toronto_lm_loss: 4.6890 ||
04/19 02:55:41 PM: Update 3797: task wsj, batch 797 (3797): perplexity: 164.9708, wsj_loss: 5.1058 ||
04/19 02:55:49 PM: Update 2263: task toronto_lm, batch 260 (2252): perplexity: 108.7237, toronto_lm_loss: 4.6888 ||
04/19 02:55:52 PM: Update 3813: task wsj, batch 813 (3813): perplexity: 164.7359, wsj_loss: 5.1043 ||
04/19 02:56:00 PM: Update 2277: task toronto_lm, batch 274 (2266): perplexity: 108.5991, toronto_lm_loss: 4.6877 ||
04/19 02:56:02 PM: Update 3829: task wsj, batch 829 (3829): perplexity: 164.7326, wsj_loss: 5.1043 ||
04/19 02:56:11 PM: Update 2291: task toronto_lm, batch 288 (2280): perplexity: 108.3145, toronto_lm_loss: 4.6850 ||
04/19 02:56:12 PM: Update 3845: task wsj, batch 845 (3845): perplexity: 164.6696, wsj_loss: 5.1039 ||
04/19 02:56:21 PM: Update 2304: task toronto_lm, batch 301 (2293): perplexity: 108.2112, toronto_lm_loss: 4.6841 ||
04/19 02:56:23 PM: Update 3861: task wsj, batch 861 (3861): perplexity: 164.5555, wsj_loss: 5.1032 ||
04/19 02:56:31 PM: Update 2317: task toronto_lm, batch 314 (2306): perplexity: 107.9075, toronto_lm_loss: 4.6813 ||
04/19 02:56:33 PM: Update 3877: task wsj, batch 877 (3877): perplexity: 164.5037, wsj_loss: 5.1029 ||
04/19 02:56:42 PM: Update 2331: task toronto_lm, batch 328 (2320): perplexity: 107.8025, toronto_lm_loss: 4.6803 ||
04/19 02:56:44 PM: Update 3893: task wsj, batch 893 (3893): perplexity: 164.3928, wsj_loss: 5.1023 ||
04/19 02:56:52 PM: Update 2344: task toronto_lm, batch 341 (2333): perplexity: 107.5900, toronto_lm_loss: 4.6783 ||
04/19 02:56:54 PM: Update 3909: task wsj, batch 909 (3909): perplexity: 164.3579, wsj_loss: 5.1020 ||
04/19 02:57:02 PM: Update 2357: task toronto_lm, batch 354 (2346): perplexity: 107.4349, toronto_lm_loss: 4.6769 ||
04/19 02:57:05 PM: Update 3925: task wsj, batch 925 (3925): perplexity: 164.3198, wsj_loss: 5.1018 ||
04/19 02:57:12 PM: Update 2371: task toronto_lm, batch 368 (2360): perplexity: 107.2224, toronto_lm_loss: 4.6749 ||
04/19 02:57:15 PM: Update 3941: task wsj, batch 941 (3941): perplexity: 164.2576, wsj_loss: 5.1014 ||
04/19 02:57:23 PM: Update 2385: task toronto_lm, batch 382 (2374): perplexity: 106.6776, toronto_lm_loss: 4.6698 ||
04/19 02:57:29 PM: Update 3954: task wsj, batch 954 (3954): perplexity: 164.2653, wsj_loss: 5.1015 ||
04/19 02:57:32 PM: Update 2397: task wsj, batch 4 (12): perplexity: 946.6876, wsj_loss: 6.8530 ||
04/19 02:57:34 PM: Update 2399: task toronto_lm, batch 395 (2387): perplexity: 106.5719, toronto_lm_loss: 4.6688 ||
04/19 02:57:40 PM: Update 3970: task wsj, batch 970 (3970): perplexity: 164.0061, wsj_loss: 5.0999 ||
04/19 02:57:44 PM: Update 2413: task toronto_lm, batch 409 (2401): perplexity: 106.3202, toronto_lm_loss: 4.6665 ||
04/19 02:57:50 PM: Update 3986: task wsj, batch 986 (3986): perplexity: 163.6324, wsj_loss: 5.0976 ||
04/19 02:57:55 PM: Update 2427: task toronto_lm, batch 423 (2415): perplexity: 106.0011, toronto_lm_loss: 4.6634 ||
04/19 02:57:59 PM: ***** Pass 4000 / Epoch 4 *****
04/19 02:58:00 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 02:58:00 PM: Validating...
04/19 02:58:00 PM: Batch 1/24: perplexity: 184.3494, wsj_loss: 5.2168 || , for evaluation data
04/19 02:58:05 PM: Best model found for wsj.
04/19 02:58:05 PM: Best model found for micro.
04/19 02:58:05 PM: Best model found for macro.
04/19 02:58:05 PM: Advancing scheduler.
04/19 02:58:05 PM: 	Best macro_avg: 133.338
04/19 02:58:05 PM: 	# bad epochs: 0
04/19 02:58:05 PM: Statistic: wsj_loss
04/19 02:58:05 PM: 	training: 5.096682
04/19 02:58:05 PM: 	validation: 4.892885
04/19 02:58:05 PM: Statistic: macro_avg
04/19 02:58:05 PM: 	validation: 133.337703
04/19 02:58:05 PM: Statistic: micro_avg
04/19 02:58:05 PM: 	validation: 133.337703
04/19 02:58:05 PM: Statistic: wsj_perplexity
04/19 02:58:05 PM: 	training: 163.478508
04/19 02:58:05 PM: 	validation: 133.337703
04/19 02:58:05 PM: global_lr: 0.003000
04/19 02:58:06 PM: Update 2441: task toronto_lm, batch 437 (2429): perplexity: 105.7037, toronto_lm_loss: 4.6606 ||
04/19 02:58:06 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 02:58:10 PM: Update 4007: task wsj, batch 7 (4007): perplexity: 158.9527, wsj_loss: 5.0686 ||
04/19 02:58:16 PM: Update 2455: task toronto_lm, batch 451 (2443): perplexity: 105.4126, toronto_lm_loss: 4.6579 ||
04/19 02:58:21 PM: Update 4023: task wsj, batch 23 (4023): perplexity: 153.8912, wsj_loss: 5.0362 ||
04/19 02:58:27 PM: Update 2469: task toronto_lm, batch 465 (2457): perplexity: 104.9127, toronto_lm_loss: 4.6531 ||
04/19 02:58:31 PM: Update 4039: task wsj, batch 39 (4039): perplexity: 156.0254, wsj_loss: 5.0500 ||
04/19 02:58:38 PM: Update 2483: task toronto_lm, batch 479 (2471): perplexity: 104.8806, toronto_lm_loss: 4.6528 ||
04/19 02:58:42 PM: Update 4055: task wsj, batch 55 (4055): perplexity: 152.2345, wsj_loss: 5.0254 ||
04/19 02:58:48 PM: Update 2497: task toronto_lm, batch 493 (2485): perplexity: 104.7976, toronto_lm_loss: 4.6520 ||
04/19 02:58:52 PM: Update 4071: task wsj, batch 71 (4071): perplexity: 151.4208, wsj_loss: 5.0201 ||
04/19 02:58:59 PM: Update 2511: task toronto_lm, batch 507 (2499): perplexity: 104.6244, toronto_lm_loss: 4.6504 ||
04/19 02:59:02 PM: Update 4087: task wsj, batch 87 (4087): perplexity: 150.8226, wsj_loss: 5.0161 ||
04/19 02:59:10 PM: Update 2516: task toronto_lm, batch 512 (2504): perplexity: 104.8865, toronto_lm_loss: 4.6529 ||
04/19 02:59:13 PM: Update 4095: task wsj, batch 95 (4095): perplexity: 151.3263, wsj_loss: 5.0194 ||
04/19 02:59:20 PM: Update 2529: task toronto_lm, batch 525 (2517): perplexity: 105.8686, toronto_lm_loss: 4.6622 ||
04/19 02:59:23 PM: Update 4111: task wsj, batch 111 (4111): perplexity: 151.1307, wsj_loss: 5.0181 ||
04/19 02:59:30 PM: Update 2542: task toronto_lm, batch 538 (2530): perplexity: 106.5717, toronto_lm_loss: 4.6688 ||
04/19 02:59:34 PM: Update 4127: task wsj, batch 127 (4127): perplexity: 151.9573, wsj_loss: 5.0236 ||
04/19 02:59:40 PM: Update 2555: task toronto_lm, batch 551 (2543): perplexity: 107.3246, toronto_lm_loss: 4.6759 ||
04/19 02:59:44 PM: Update 4143: task wsj, batch 143 (4143): perplexity: 152.4798, wsj_loss: 5.0270 ||
04/19 02:59:50 PM: Update 2568: task toronto_lm, batch 564 (2556): perplexity: 107.8876, toronto_lm_loss: 4.6811 ||
04/19 02:59:54 PM: Update 4159: task wsj, batch 159 (4159): perplexity: 152.6707, wsj_loss: 5.0283 ||
04/19 03:00:01 PM: Update 2582: task toronto_lm, batch 578 (2570): perplexity: 108.4970, toronto_lm_loss: 4.6867 ||
04/19 03:00:05 PM: Update 4175: task wsj, batch 175 (4175): perplexity: 153.6273, wsj_loss: 5.0345 ||
04/19 03:00:11 PM: Update 2596: task toronto_lm, batch 592 (2584): perplexity: 108.9947, toronto_lm_loss: 4.6913 ||
04/19 03:00:15 PM: Update 2601: task wsj, batch 5 (13): perplexity: 927.3809, wsj_loss: 6.8324 ||
04/19 03:00:15 PM: Update 4191: task wsj, batch 191 (4191): perplexity: 153.7472, wsj_loss: 5.0353 ||
04/19 03:00:21 PM: Update 2609: task toronto_lm, batch 604 (2596): perplexity: 109.3115, toronto_lm_loss: 4.6942 ||
04/19 03:00:26 PM: Update 4207: task wsj, batch 207 (4207): perplexity: 154.2964, wsj_loss: 5.0389 ||
04/19 03:00:28 PM: Update 2618: task wsj, batch 6 (14): perplexity: 874.8504, wsj_loss: 6.7741 ||
04/19 03:00:31 PM: Update 2622: task toronto_lm, batch 616 (2608): perplexity: 109.5697, toronto_lm_loss: 4.6966 ||
04/19 03:00:36 PM: Update 4223: task wsj, batch 223 (4223): perplexity: 154.0159, wsj_loss: 5.0371 ||
04/19 03:00:42 PM: Update 2636: task toronto_lm, batch 630 (2622): perplexity: 109.7706, toronto_lm_loss: 4.6984 ||
04/19 03:00:47 PM: Update 4239: task wsj, batch 239 (4239): perplexity: 154.0763, wsj_loss: 5.0374 ||
04/19 03:00:52 PM: Update 2649: task toronto_lm, batch 643 (2635): perplexity: 109.9427, toronto_lm_loss: 4.7000 ||
04/19 03:00:57 PM: Update 4247: task wsj, batch 247 (4247): perplexity: 154.0860, wsj_loss: 5.0375 ||
04/19 03:01:02 PM: Update 2662: task toronto_lm, batch 656 (2648): perplexity: 110.1763, toronto_lm_loss: 4.7021 ||
04/19 03:01:07 PM: Update 4263: task wsj, batch 263 (4263): perplexity: 153.6157, wsj_loss: 5.0345 ||
04/19 03:01:12 PM: Update 2675: task toronto_lm, batch 669 (2661): perplexity: 110.4042, toronto_lm_loss: 4.7041 ||
04/19 03:01:18 PM: Update 4279: task wsj, batch 279 (4279): perplexity: 153.5599, wsj_loss: 5.0341 ||
04/19 03:01:23 PM: Update 2689: task toronto_lm, batch 683 (2675): perplexity: 110.6810, toronto_lm_loss: 4.7067 ||
04/19 03:01:28 PM: Update 4295: task wsj, batch 295 (4295): perplexity: 153.3758, wsj_loss: 5.0329 ||
04/19 03:01:33 PM: Update 2702: task toronto_lm, batch 696 (2688): perplexity: 110.8965, toronto_lm_loss: 4.7086 ||
04/19 03:01:39 PM: Update 4311: task wsj, batch 311 (4311): perplexity: 152.8037, wsj_loss: 5.0292 ||
04/19 03:01:44 PM: Update 2716: task toronto_lm, batch 710 (2702): perplexity: 111.0638, toronto_lm_loss: 4.7101 ||
04/19 03:01:49 PM: Update 4327: task wsj, batch 327 (4327): perplexity: 152.2168, wsj_loss: 5.0253 ||
04/19 03:01:54 PM: Update 2730: task toronto_lm, batch 724 (2716): perplexity: 111.1906, toronto_lm_loss: 4.7112 ||
04/19 03:01:59 PM: Update 4343: task wsj, batch 343 (4343): perplexity: 151.9342, wsj_loss: 5.0234 ||
04/19 03:02:05 PM: Update 2744: task toronto_lm, batch 738 (2730): perplexity: 111.3289, toronto_lm_loss: 4.7125 ||
04/19 03:02:10 PM: Update 4359: task wsj, batch 359 (4359): perplexity: 151.5281, wsj_loss: 5.0208 ||
04/19 03:02:16 PM: Update 2758: task toronto_lm, batch 752 (2744): perplexity: 111.4900, toronto_lm_loss: 4.7139 ||
04/19 03:02:17 PM: Update 2760: task wsj, batch 7 (15): perplexity: 833.9887, wsj_loss: 6.7262 ||
04/19 03:02:20 PM: Update 4375: task wsj, batch 375 (4375): perplexity: 151.3180, wsj_loss: 5.0194 ||
04/19 03:02:26 PM: Update 2771: task toronto_lm, batch 764 (2756): perplexity: 111.6119, toronto_lm_loss: 4.7150 ||
04/19 03:02:31 PM: Update 4383: task wsj, batch 383 (4383): perplexity: 151.0317, wsj_loss: 5.0175 ||
04/19 03:02:36 PM: Update 2784: task toronto_lm, batch 777 (2769): perplexity: 111.7101, toronto_lm_loss: 4.7159 ||
04/19 03:02:41 PM: Update 4399: task wsj, batch 399 (4399): perplexity: 151.2453, wsj_loss: 5.0189 ||
04/19 03:02:47 PM: Update 2798: task toronto_lm, batch 791 (2783): perplexity: 111.8380, toronto_lm_loss: 4.7171 ||
04/19 03:02:52 PM: Update 4415: task wsj, batch 415 (4415): perplexity: 151.1342, wsj_loss: 5.0182 ||
04/19 03:02:58 PM: Update 2812: task toronto_lm, batch 805 (2797): perplexity: 111.9386, toronto_lm_loss: 4.7180 ||
04/19 03:03:02 PM: Update 4431: task wsj, batch 431 (4431): perplexity: 151.1501, wsj_loss: 5.0183 ||
04/19 03:03:09 PM: Update 2826: task toronto_lm, batch 819 (2811): perplexity: 111.9715, toronto_lm_loss: 4.7182 ||
04/19 03:03:12 PM: Update 4447: task wsj, batch 447 (4447): perplexity: 151.0460, wsj_loss: 5.0176 ||
04/19 03:03:19 PM: Update 2840: task toronto_lm, batch 833 (2825): perplexity: 112.1411, toronto_lm_loss: 4.7198 ||
04/19 03:03:23 PM: Update 4463: task wsj, batch 463 (4463): perplexity: 151.0579, wsj_loss: 5.0177 ||
04/19 03:03:30 PM: Update 2854: task toronto_lm, batch 847 (2839): perplexity: 112.2370, toronto_lm_loss: 4.7206 ||
04/19 03:03:33 PM: Update 4479: task wsj, batch 479 (4479): perplexity: 151.1416, wsj_loss: 5.0182 ||
04/19 03:03:41 PM: Update 2868: task toronto_lm, batch 861 (2853): perplexity: 112.3393, toronto_lm_loss: 4.7215 ||
04/19 03:03:44 PM: Update 4495: task wsj, batch 495 (4495): perplexity: 151.2530, wsj_loss: 5.0190 ||
04/19 03:03:51 PM: Update 2881: task toronto_lm, batch 874 (2866): perplexity: 112.3401, toronto_lm_loss: 4.7215 ||
04/19 03:03:54 PM: Update 4511: task wsj, batch 511 (4511): perplexity: 151.0193, wsj_loss: 5.0174 ||
04/19 03:04:02 PM: Update 2895: task toronto_lm, batch 888 (2880): perplexity: 112.2907, toronto_lm_loss: 4.7211 ||
04/19 03:04:05 PM: Update 4527: task wsj, batch 527 (4527): perplexity: 151.1202, wsj_loss: 5.0181 ||
04/19 03:04:12 PM: Update 2909: task toronto_lm, batch 902 (2894): perplexity: 112.2925, toronto_lm_loss: 4.7211 ||
04/19 03:04:17 PM: Update 4538: task wsj, batch 538 (4538): perplexity: 151.1791, wsj_loss: 5.0185 ||
04/19 03:04:23 PM: Update 2923: task toronto_lm, batch 916 (2908): perplexity: 112.2733, toronto_lm_loss: 4.7209 ||
04/19 03:04:24 PM: Update 2924: task wsj, batch 8 (16): perplexity: 813.9505, wsj_loss: 6.7019 ||
04/19 03:04:28 PM: Update 4554: task wsj, batch 554 (4554): perplexity: 150.7786, wsj_loss: 5.0158 ||
04/19 03:04:34 PM: Update 2937: task toronto_lm, batch 929 (2921): perplexity: 112.3434, toronto_lm_loss: 4.7216 ||
04/19 03:04:38 PM: Update 4570: task wsj, batch 570 (4570): perplexity: 150.5281, wsj_loss: 5.0141 ||
04/19 03:04:44 PM: Update 2951: task toronto_lm, batch 943 (2935): perplexity: 112.3109, toronto_lm_loss: 4.7213 ||
04/19 03:04:49 PM: Update 4586: task wsj, batch 586 (4586): perplexity: 150.2780, wsj_loss: 5.0125 ||
04/19 03:04:55 PM: Update 2965: task toronto_lm, batch 957 (2949): perplexity: 112.3066, toronto_lm_loss: 4.7212 ||
04/19 03:04:59 PM: Update 4602: task wsj, batch 602 (4602): perplexity: 150.0287, wsj_loss: 5.0108 ||
04/19 03:05:05 PM: Update 2978: task toronto_lm, batch 970 (2962): perplexity: 112.3449, toronto_lm_loss: 4.7216 ||
04/19 03:05:08 PM: Update 2982: task wsj, batch 9 (17): perplexity: 782.8080, wsj_loss: 6.6629 ||
04/19 03:05:10 PM: Update 4618: task wsj, batch 618 (4618): perplexity: 149.7345, wsj_loss: 5.0089 ||
04/19 03:05:16 PM: Update 2992: task toronto_lm, batch 983 (2975): perplexity: 112.3392, toronto_lm_loss: 4.7215 ||
04/19 03:05:20 PM: Update 4634: task wsj, batch 634 (4634): perplexity: 149.5055, wsj_loss: 5.0073 ||
04/19 03:05:22 PM: ***** Pass 3000 / Epoch 3 *****
04/19 03:05:22 PM: toronto_lm: trained on 991 batches, 0.005 epochs
04/19 03:05:22 PM: wsj: trained on 9 batches, 0.011 epochs
04/19 03:05:22 PM: Validating...
04/19 03:05:26 PM: Batch 15/140: perplexity: 143.8297, toronto_lm_loss: 4.9686 || , for evaluation data
04/19 03:05:30 PM: Update 4650: task wsj, batch 650 (4650): perplexity: 149.4224, wsj_loss: 5.0068 ||
04/19 03:05:36 PM: Batch 49/140: perplexity: 150.2668, toronto_lm_loss: 5.0124 || , for evaluation data
04/19 03:05:41 PM: Update 4666: task wsj, batch 666 (4666): perplexity: 149.3290, wsj_loss: 5.0062 ||
04/19 03:05:46 PM: Batch 88/140: perplexity: 138.6076, toronto_lm_loss: 4.9316 || , for evaluation data
04/19 03:05:51 PM: Update 4674: task wsj, batch 674 (4674): perplexity: 149.3200, wsj_loss: 5.0061 ||
04/19 03:05:57 PM: Batch 128/140: perplexity: 128.9955, toronto_lm_loss: 4.8598 || , for evaluation data
04/19 03:06:00 PM: Batch 1/66: perplexity: 670.8406, wsj_loss: 6.5085 || , for evaluation data
04/19 03:06:02 PM: Update 4690: task wsj, batch 690 (4690): perplexity: 149.1967, wsj_loss: 5.0053 ||
04/19 03:06:10 PM: Batch 40/66: perplexity: 503.7509, wsj_loss: 6.2221 || , for evaluation data
04/19 03:06:12 PM: Update 4706: task wsj, batch 706 (4706): perplexity: 149.1775, wsj_loss: 5.0051 ||
04/19 03:06:17 PM: Best model found for toronto_lm.
04/19 03:06:17 PM: Best model found for wsj.
04/19 03:06:17 PM: Best model found for micro.
04/19 03:06:17 PM: Best model found for macro.
04/19 03:06:17 PM: Advancing scheduler.
04/19 03:06:17 PM: 	Best macro_avg: -0.382
04/19 03:06:17 PM: 	# bad epochs: 0
04/19 03:06:17 PM: Statistic: toronto_lm_loss
04/19 03:06:17 PM: 	training: 4.720787
04/19 03:06:17 PM: 	validation: 4.833128
04/19 03:06:17 PM: Statistic: wsj_loss
04/19 03:06:17 PM: 	training: 6.662887
04/19 03:06:17 PM: 	validation: 6.220590
04/19 03:06:17 PM: Statistic: macro_avg
04/19 03:06:17 PM: 	validation: -0.381603
04/19 03:06:17 PM: Statistic: micro_avg
04/19 03:06:17 PM: 	validation: -0.324378
04/19 03:06:17 PM: Statistic: toronto_lm_perplexity
04/19 03:06:17 PM: 	training: 112.256602
04/19 03:06:17 PM: 	validation: 125.603190
04/19 03:06:17 PM: Statistic: wsj_perplexity
04/19 03:06:17 PM: 	training: 782.808009
04/19 03:06:17 PM: 	validation: 502.999903
04/19 03:06:17 PM: global_lr: 0.001000
04/19 03:06:17 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 03:06:18 PM: Update 3001: task toronto_lm, batch 1 (2984): perplexity: 111.8752, toronto_lm_loss: 4.7174 ||
04/19 03:06:23 PM: Update 4722: task wsj, batch 722 (4722): perplexity: 149.2688, wsj_loss: 5.0057 ||
04/19 03:06:29 PM: Update 3015: task toronto_lm, batch 15 (2998): perplexity: 108.9472, toronto_lm_loss: 4.6909 ||
04/19 03:06:33 PM: Update 4738: task wsj, batch 738 (4738): perplexity: 149.1496, wsj_loss: 5.0049 ||
04/19 03:06:39 PM: Update 3029: task toronto_lm, batch 29 (3012): perplexity: 107.5777, toronto_lm_loss: 4.6782 ||
04/19 03:06:44 PM: Update 4754: task wsj, batch 754 (4754): perplexity: 149.0891, wsj_loss: 5.0045 ||
04/19 03:06:50 PM: Update 3043: task toronto_lm, batch 43 (3026): perplexity: 111.2236, toronto_lm_loss: 4.7115 ||
04/19 03:06:54 PM: Update 4770: task wsj, batch 770 (4770): perplexity: 149.1191, wsj_loss: 5.0047 ||
04/19 03:06:56 PM: Update 3051: task wsj, batch 1 (18): perplexity: 498.3301, wsj_loss: 6.2113 ||
04/19 03:07:00 PM: Update 3056: task toronto_lm, batch 55 (3038): perplexity: 109.2884, toronto_lm_loss: 4.6940 ||
04/19 03:07:05 PM: Update 4786: task wsj, batch 786 (4786): perplexity: 149.0811, wsj_loss: 5.0045 ||
04/19 03:07:11 PM: Update 3070: task toronto_lm, batch 69 (3052): perplexity: 110.5504, toronto_lm_loss: 4.7055 ||
04/19 03:07:15 PM: Update 4802: task wsj, batch 802 (4802): perplexity: 149.0513, wsj_loss: 5.0043 ||
04/19 03:07:21 PM: Update 3084: task toronto_lm, batch 83 (3066): perplexity: 110.1008, toronto_lm_loss: 4.7014 ||
04/19 03:07:25 PM: Update 4818: task wsj, batch 818 (4818): perplexity: 149.0613, wsj_loss: 5.0044 ||
04/19 03:07:32 PM: Update 3098: task toronto_lm, batch 97 (3080): perplexity: 109.9877, toronto_lm_loss: 4.7004 ||
04/19 03:07:38 PM: Update 4830: task wsj, batch 830 (4830): perplexity: 149.0501, wsj_loss: 5.0043 ||
04/19 03:07:43 PM: Update 3112: task toronto_lm, batch 111 (3094): perplexity: 110.8082, toronto_lm_loss: 4.7078 ||
04/19 03:07:49 PM: Update 4846: task wsj, batch 846 (4846): perplexity: 148.8705, wsj_loss: 5.0031 ||
04/19 03:07:53 PM: Update 3126: task toronto_lm, batch 125 (3108): perplexity: 110.6038, toronto_lm_loss: 4.7060 ||
04/19 03:07:57 PM: Update 3131: task wsj, batch 2 (19): perplexity: 519.3732, wsj_loss: 6.2526 ||
04/19 03:07:59 PM: Update 4862: task wsj, batch 862 (4862): perplexity: 148.7825, wsj_loss: 5.0025 ||
04/19 03:08:04 PM: Update 3140: task toronto_lm, batch 138 (3121): perplexity: 109.5182, toronto_lm_loss: 4.6961 ||
04/19 03:08:09 PM: Update 4878: task wsj, batch 878 (4878): perplexity: 148.6327, wsj_loss: 5.0015 ||
04/19 03:08:16 PM: Update 3145: task toronto_lm, batch 143 (3126): perplexity: 109.6880, toronto_lm_loss: 4.6976 ||
04/19 03:08:20 PM: Update 4894: task wsj, batch 894 (4894): perplexity: 148.3754, wsj_loss: 4.9997 ||
04/19 03:08:27 PM: Update 3159: task toronto_lm, batch 157 (3140): perplexity: 111.9747, toronto_lm_loss: 4.7183 ||
04/19 03:08:30 PM: Update 4910: task wsj, batch 910 (4910): perplexity: 148.1782, wsj_loss: 4.9984 ||
04/19 03:08:38 PM: Update 3173: task toronto_lm, batch 171 (3154): perplexity: 113.2078, toronto_lm_loss: 4.7292 ||
04/19 03:08:41 PM: Update 4926: task wsj, batch 926 (4926): perplexity: 147.9329, wsj_loss: 4.9968 ||
04/19 03:08:48 PM: Update 3187: task toronto_lm, batch 185 (3168): perplexity: 114.4706, toronto_lm_loss: 4.7403 ||
04/19 03:08:51 PM: Update 4942: task wsj, batch 942 (4942): perplexity: 147.7863, wsj_loss: 4.9958 ||
04/19 03:08:58 PM: Update 3200: task toronto_lm, batch 198 (3181): perplexity: 115.0006, toronto_lm_loss: 4.7449 ||
04/19 03:09:02 PM: Update 4958: task wsj, batch 958 (4958): perplexity: 147.5846, wsj_loss: 4.9944 ||
04/19 03:09:09 PM: Update 3214: task toronto_lm, batch 212 (3195): perplexity: 115.3268, toronto_lm_loss: 4.7478 ||
04/19 03:09:12 PM: Update 4966: task wsj, batch 966 (4966): perplexity: 147.4512, wsj_loss: 4.9935 ||
04/19 03:09:20 PM: Update 3228: task toronto_lm, batch 226 (3209): perplexity: 115.7099, toronto_lm_loss: 4.7511 ||
04/19 03:09:23 PM: Update 4982: task wsj, batch 982 (4982): perplexity: 147.4163, wsj_loss: 4.9933 ||
04/19 03:09:30 PM: Update 3242: task toronto_lm, batch 240 (3223): perplexity: 115.4319, toronto_lm_loss: 4.7487 ||
04/19 03:09:33 PM: Update 4998: task wsj, batch 998 (4998): perplexity: 147.3083, wsj_loss: 4.9925 ||
04/19 03:09:34 PM: ***** Pass 5000 / Epoch 5 *****
04/19 03:09:34 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 03:09:34 PM: Validating...
04/19 03:09:40 PM: Best model found for wsj.
04/19 03:09:40 PM: Best model found for micro.
04/19 03:09:40 PM: Best model found for macro.
04/19 03:09:40 PM: Advancing scheduler.
04/19 03:09:40 PM: 	Best macro_avg: 126.515
04/19 03:09:40 PM: 	# bad epochs: 0
04/19 03:09:40 PM: Statistic: wsj_loss
04/19 03:09:40 PM: 	training: 4.992567
04/19 03:09:40 PM: 	validation: 4.840364
04/19 03:09:40 PM: Statistic: macro_avg
04/19 03:09:40 PM: 	validation: 126.515417
04/19 03:09:40 PM: Statistic: micro_avg
04/19 03:09:40 PM: 	validation: 126.515417
04/19 03:09:40 PM: Statistic: wsj_perplexity
04/19 03:09:40 PM: 	training: 147.314167
04/19 03:09:40 PM: 	validation: 126.515417
04/19 03:09:40 PM: global_lr: 0.003000
04/19 03:09:40 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 03:09:41 PM: Update 3256: task toronto_lm, batch 254 (3237): perplexity: 115.3997, toronto_lm_loss: 4.7484 ||
04/19 03:09:44 PM: Update 5005: task wsj, batch 5 (5005): perplexity: 149.0454, wsj_loss: 5.0043 ||
04/19 03:09:51 PM: Update 3270: task toronto_lm, batch 268 (3251): perplexity: 115.3022, toronto_lm_loss: 4.7476 ||
04/19 03:09:54 PM: Update 5021: task wsj, batch 21 (5021): perplexity: 148.8179, wsj_loss: 5.0027 ||
04/19 03:10:02 PM: Update 3284: task toronto_lm, batch 282 (3265): perplexity: 115.0752, toronto_lm_loss: 4.7456 ||
04/19 03:10:04 PM: Update 5037: task wsj, batch 37 (5037): perplexity: 145.7626, wsj_loss: 4.9820 ||
04/19 03:10:13 PM: Update 3298: task toronto_lm, batch 296 (3279): perplexity: 115.1180, toronto_lm_loss: 4.7460 ||
04/19 03:10:15 PM: Update 5053: task wsj, batch 53 (5053): perplexity: 144.3328, wsj_loss: 4.9721 ||
04/19 03:10:24 PM: Update 3312: task toronto_lm, batch 310 (3293): perplexity: 114.9518, toronto_lm_loss: 4.7445 ||
04/19 03:10:25 PM: Update 5069: task wsj, batch 69 (5069): perplexity: 144.2754, wsj_loss: 4.9717 ||
04/19 03:10:34 PM: Update 3326: task toronto_lm, batch 324 (3307): perplexity: 114.7286, toronto_lm_loss: 4.7426 ||
04/19 03:10:36 PM: Update 5085: task wsj, batch 85 (5085): perplexity: 144.4065, wsj_loss: 4.9726 ||
04/19 03:10:45 PM: Update 3340: task toronto_lm, batch 338 (3321): perplexity: 114.7099, toronto_lm_loss: 4.7424 ||
04/19 03:10:46 PM: Update 5101: task wsj, batch 101 (5101): perplexity: 144.1588, wsj_loss: 4.9709 ||
04/19 03:10:56 PM: Update 3354: task toronto_lm, batch 352 (3335): perplexity: 114.4789, toronto_lm_loss: 4.7404 ||
04/19 03:10:57 PM: Update 5117: task wsj, batch 117 (5117): perplexity: 143.8129, wsj_loss: 4.9685 ||
04/19 03:11:06 PM: Update 3368: task toronto_lm, batch 366 (3349): perplexity: 114.1439, toronto_lm_loss: 4.7375 ||
04/19 03:11:07 PM: Update 5124: task wsj, batch 124 (5124): perplexity: 144.8386, wsj_loss: 4.9756 ||
04/19 03:11:17 PM: Update 3382: task toronto_lm, batch 380 (3363): perplexity: 113.7968, toronto_lm_loss: 4.7344 ||
04/19 03:11:18 PM: Update 5140: task wsj, batch 140 (5140): perplexity: 143.1764, wsj_loss: 4.9641 ||
04/19 03:11:28 PM: Update 3396: task toronto_lm, batch 394 (3377): perplexity: 113.4573, toronto_lm_loss: 4.7314 ||
04/19 03:11:28 PM: Update 5156: task wsj, batch 156 (5156): perplexity: 142.1235, wsj_loss: 4.9567 ||
04/19 03:11:38 PM: Update 3410: task toronto_lm, batch 408 (3391): perplexity: 113.0093, toronto_lm_loss: 4.7275 ||
04/19 03:11:38 PM: Update 5172: task wsj, batch 172 (5172): perplexity: 140.8580, wsj_loss: 4.9478 ||
04/19 03:11:49 PM: Update 5188: task wsj, batch 188 (5188): perplexity: 140.2045, wsj_loss: 4.9431 ||
04/19 03:11:49 PM: Update 3424: task toronto_lm, batch 422 (3405): perplexity: 112.8282, toronto_lm_loss: 4.7259 ||
04/19 03:11:59 PM: Update 5204: task wsj, batch 204 (5204): perplexity: 139.6500, wsj_loss: 4.9391 ||
04/19 03:12:00 PM: Update 3438: task toronto_lm, batch 436 (3419): perplexity: 112.5392, toronto_lm_loss: 4.7233 ||
04/19 03:12:10 PM: Update 5220: task wsj, batch 220 (5220): perplexity: 139.5503, wsj_loss: 4.9384 ||
04/19 03:12:10 PM: Update 3452: task toronto_lm, batch 450 (3433): perplexity: 112.2757, toronto_lm_loss: 4.7210 ||
04/19 03:12:20 PM: Update 5236: task wsj, batch 236 (5236): perplexity: 139.2945, wsj_loss: 4.9366 ||
04/19 03:12:21 PM: Update 3466: task toronto_lm, batch 464 (3447): perplexity: 112.0059, toronto_lm_loss: 4.7186 ||
04/19 03:12:31 PM: Update 5252: task wsj, batch 252 (5252): perplexity: 139.3628, wsj_loss: 4.9371 ||
04/19 03:12:32 PM: Update 3480: task toronto_lm, batch 478 (3461): perplexity: 111.7346, toronto_lm_loss: 4.7161 ||
04/19 03:12:41 PM: Update 5261: task wsj, batch 261 (5261): perplexity: 139.6584, wsj_loss: 4.9392 ||
04/19 03:12:42 PM: Update 3494: task toronto_lm, batch 492 (3475): perplexity: 111.2049, toronto_lm_loss: 4.7114 ||
04/19 03:12:52 PM: Update 5277: task wsj, batch 277 (5277): perplexity: 139.7734, wsj_loss: 4.9400 ||
04/19 03:12:53 PM: Update 3508: task toronto_lm, batch 506 (3489): perplexity: 111.1134, toronto_lm_loss: 4.7106 ||
04/19 03:13:02 PM: Update 5293: task wsj, batch 293 (5293): perplexity: 139.7781, wsj_loss: 4.9401 ||
04/19 03:13:03 PM: Update 3522: task toronto_lm, batch 520 (3503): perplexity: 110.9453, toronto_lm_loss: 4.7090 ||
04/19 03:13:13 PM: Update 5309: task wsj, batch 309 (5309): perplexity: 140.0280, wsj_loss: 4.9418 ||
04/19 03:13:14 PM: Update 3536: task toronto_lm, batch 534 (3517): perplexity: 110.6489, toronto_lm_loss: 4.7064 ||
04/19 03:13:23 PM: Update 5325: task wsj, batch 325 (5325): perplexity: 139.9469, wsj_loss: 4.9413 ||
04/19 03:13:25 PM: Update 3550: task toronto_lm, batch 548 (3531): perplexity: 110.5590, toronto_lm_loss: 4.7055 ||
04/19 03:13:33 PM: Update 5341: task wsj, batch 341 (5341): perplexity: 140.0658, wsj_loss: 4.9421 ||
04/19 03:13:35 PM: Update 3564: task toronto_lm, batch 562 (3545): perplexity: 110.3787, toronto_lm_loss: 4.7039 ||
04/19 03:13:44 PM: Update 5357: task wsj, batch 357 (5357): perplexity: 139.8954, wsj_loss: 4.9409 ||
04/19 03:13:46 PM: Update 3578: task toronto_lm, batch 576 (3559): perplexity: 110.0984, toronto_lm_loss: 4.7014 ||
04/19 03:13:54 PM: Update 5373: task wsj, batch 373 (5373): perplexity: 139.8337, wsj_loss: 4.9405 ||
04/19 03:13:57 PM: Update 3592: task toronto_lm, batch 590 (3573): perplexity: 109.9661, toronto_lm_loss: 4.7002 ||
04/19 03:14:05 PM: Update 5389: task wsj, batch 389 (5389): perplexity: 139.9820, wsj_loss: 4.9415 ||
04/19 03:14:07 PM: Update 3606: task toronto_lm, batch 604 (3587): perplexity: 109.8176, toronto_lm_loss: 4.6988 ||
04/19 03:14:15 PM: Update 5405: task wsj, batch 405 (5405): perplexity: 140.0832, wsj_loss: 4.9422 ||
04/19 03:14:18 PM: Update 3620: task toronto_lm, batch 618 (3601): perplexity: 109.7265, toronto_lm_loss: 4.6980 ||
04/19 03:14:26 PM: Update 5414: task wsj, batch 414 (5414): perplexity: 140.0991, wsj_loss: 4.9423 ||
04/19 03:14:29 PM: Update 3634: task toronto_lm, batch 632 (3615): perplexity: 109.7767, toronto_lm_loss: 4.6984 ||
04/19 03:14:37 PM: Update 5430: task wsj, batch 430 (5430): perplexity: 139.8763, wsj_loss: 4.9408 ||
04/19 03:14:39 PM: Update 3648: task toronto_lm, batch 646 (3629): perplexity: 109.4732, toronto_lm_loss: 4.6957 ||
04/19 03:14:47 PM: Update 5446: task wsj, batch 446 (5446): perplexity: 139.7156, wsj_loss: 4.9396 ||
04/19 03:14:50 PM: Update 3662: task toronto_lm, batch 660 (3643): perplexity: 109.1189, toronto_lm_loss: 4.6924 ||
04/19 03:14:58 PM: Update 5462: task wsj, batch 462 (5462): perplexity: 139.2971, wsj_loss: 4.9366 ||
04/19 03:15:00 PM: Update 3676: task toronto_lm, batch 674 (3657): perplexity: 108.9415, toronto_lm_loss: 4.6908 ||
04/19 03:15:08 PM: Update 5478: task wsj, batch 478 (5478): perplexity: 139.0547, wsj_loss: 4.9349 ||
04/19 03:15:11 PM: Update 3690: task toronto_lm, batch 688 (3671): perplexity: 108.6144, toronto_lm_loss: 4.6878 ||
04/19 03:15:19 PM: Update 5494: task wsj, batch 494 (5494): perplexity: 138.7813, wsj_loss: 4.9329 ||
04/19 03:15:22 PM: Update 3704: task toronto_lm, batch 702 (3685): perplexity: 108.5536, toronto_lm_loss: 4.6872 ||
04/19 03:15:29 PM: Update 5510: task wsj, batch 510 (5510): perplexity: 138.5521, wsj_loss: 4.9312 ||
04/19 03:15:32 PM: Update 3718: task toronto_lm, batch 716 (3699): perplexity: 108.3893, toronto_lm_loss: 4.6857 ||
04/19 03:15:39 PM: Update 5526: task wsj, batch 526 (5526): perplexity: 138.5089, wsj_loss: 4.9309 ||
04/19 03:15:43 PM: Update 3732: task toronto_lm, batch 730 (3713): perplexity: 108.2523, toronto_lm_loss: 4.6845 ||
04/19 03:15:48 PM: Update 3738: task wsj, batch 3 (20): perplexity: 539.1892, wsj_loss: 6.2901 ||
04/19 03:15:50 PM: Update 5542: task wsj, batch 542 (5542): perplexity: 138.1286, wsj_loss: 4.9282 ||
04/19 03:15:54 PM: Update 3746: task toronto_lm, batch 743 (3726): perplexity: 108.0832, toronto_lm_loss: 4.6829 ||
04/19 03:16:00 PM: Update 5550: task wsj, batch 550 (5550): perplexity: 138.0939, wsj_loss: 4.9279 ||
04/19 03:16:05 PM: Update 3760: task toronto_lm, batch 757 (3740): perplexity: 107.8022, toronto_lm_loss: 4.6803 ||
04/19 03:16:11 PM: Update 5566: task wsj, batch 566 (5566): perplexity: 138.1190, wsj_loss: 4.9281 ||
04/19 03:16:20 PM: Update 3771: task toronto_lm, batch 768 (3751): perplexity: 107.7382, toronto_lm_loss: 4.6797 ||
04/19 03:16:21 PM: Update 5582: task wsj, batch 582 (5582): perplexity: 138.1021, wsj_loss: 4.9280 ||
04/19 03:16:31 PM: Update 3785: task toronto_lm, batch 782 (3765): perplexity: 108.2829, toronto_lm_loss: 4.6847 ||
04/19 03:16:31 PM: Update 5598: task wsj, batch 598 (5598): perplexity: 138.1316, wsj_loss: 4.9282 ||
04/19 03:16:41 PM: Update 3799: task toronto_lm, batch 796 (3779): perplexity: 108.6785, toronto_lm_loss: 4.6884 ||
04/19 03:16:42 PM: Update 5614: task wsj, batch 614 (5614): perplexity: 138.0722, wsj_loss: 4.9278 ||
04/19 03:16:52 PM: Update 3813: task toronto_lm, batch 810 (3793): perplexity: 108.8973, toronto_lm_loss: 4.6904 ||
04/19 03:16:52 PM: Update 5630: task wsj, batch 630 (5630): perplexity: 138.1019, wsj_loss: 4.9280 ||
04/19 03:17:03 PM: Update 3827: task toronto_lm, batch 824 (3807): perplexity: 109.0859, toronto_lm_loss: 4.6921 ||
04/19 03:17:03 PM: Update 5646: task wsj, batch 646 (5646): perplexity: 138.0420, wsj_loss: 4.9276 ||
04/19 03:17:13 PM: Update 5662: task wsj, batch 662 (5662): perplexity: 137.9482, wsj_loss: 4.9269 ||
04/19 03:17:13 PM: Update 3841: task toronto_lm, batch 838 (3821): perplexity: 109.2056, toronto_lm_loss: 4.6932 ||
04/19 03:17:24 PM: Update 5678: task wsj, batch 678 (5678): perplexity: 138.0231, wsj_loss: 4.9274 ||
04/19 03:17:24 PM: Update 3855: task toronto_lm, batch 852 (3835): perplexity: 109.2571, toronto_lm_loss: 4.6937 ||
04/19 03:17:29 PM: Update 3861: task wsj, batch 4 (21): perplexity: 511.1607, wsj_loss: 6.2367 ||
04/19 03:17:34 PM: Update 5694: task wsj, batch 694 (5694): perplexity: 138.0154, wsj_loss: 4.9274 ||
04/19 03:17:35 PM: Update 3869: task toronto_lm, batch 865 (3848): perplexity: 109.2895, toronto_lm_loss: 4.6940 ||
04/19 03:17:45 PM: Update 3883: task toronto_lm, batch 879 (3862): perplexity: 109.2118, toronto_lm_loss: 4.6933 ||
04/19 03:17:47 PM: Update 5706: task wsj, batch 706 (5706): perplexity: 137.9435, wsj_loss: 4.9268 ||
04/19 03:17:56 PM: Update 3897: task toronto_lm, batch 893 (3876): perplexity: 109.1477, toronto_lm_loss: 4.6927 ||
04/19 03:17:58 PM: Update 5722: task wsj, batch 722 (5722): perplexity: 137.7809, wsj_loss: 4.9257 ||
04/19 03:18:07 PM: Update 3911: task toronto_lm, batch 907 (3890): perplexity: 109.1780, toronto_lm_loss: 4.6930 ||
04/19 03:18:08 PM: Update 5738: task wsj, batch 738 (5738): perplexity: 137.5686, wsj_loss: 4.9241 ||
04/19 03:18:17 PM: Update 3925: task toronto_lm, batch 921 (3904): perplexity: 109.1870, toronto_lm_loss: 4.6931 ||
04/19 03:18:19 PM: Update 5754: task wsj, batch 754 (5754): perplexity: 137.4104, wsj_loss: 4.9230 ||
04/19 03:18:28 PM: Update 3939: task toronto_lm, batch 935 (3918): perplexity: 109.1855, toronto_lm_loss: 4.6930 ||
04/19 03:18:29 PM: Update 5770: task wsj, batch 770 (5770): perplexity: 137.1519, wsj_loss: 4.9211 ||
04/19 03:18:39 PM: Update 3953: task toronto_lm, batch 949 (3932): perplexity: 109.1339, toronto_lm_loss: 4.6926 ||
04/19 03:18:39 PM: Update 5786: task wsj, batch 786 (5786): perplexity: 136.9132, wsj_loss: 4.9193 ||
04/19 03:18:50 PM: Update 3967: task toronto_lm, batch 963 (3946): perplexity: 109.0399, toronto_lm_loss: 4.6917 ||
04/19 03:18:50 PM: Update 5802: task wsj, batch 802 (5802): perplexity: 136.7235, wsj_loss: 4.9180 ||
04/19 03:19:00 PM: Update 5818: task wsj, batch 818 (5818): perplexity: 136.5752, wsj_loss: 4.9169 ||
04/19 03:19:00 PM: Update 3981: task toronto_lm, batch 977 (3960): perplexity: 109.0228, toronto_lm_loss: 4.6916 ||
04/19 03:19:11 PM: Update 5834: task wsj, batch 834 (5834): perplexity: 136.5606, wsj_loss: 4.9168 ||
04/19 03:19:11 PM: Update 3995: task toronto_lm, batch 991 (3974): perplexity: 109.0252, toronto_lm_loss: 4.6916 ||
04/19 03:19:15 PM: ***** Pass 4000 / Epoch 4 *****
04/19 03:19:15 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 03:19:15 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 03:19:15 PM: Validating...
04/19 03:19:21 PM: Batch 24/140: perplexity: 133.9649, toronto_lm_loss: 4.8976 || , for evaluation data
04/19 03:19:21 PM: Update 5842: task wsj, batch 842 (5842): perplexity: 136.4858, wsj_loss: 4.9162 ||
04/19 03:19:31 PM: Batch 63/140: perplexity: 127.4019, toronto_lm_loss: 4.8473 || , for evaluation data
04/19 03:19:31 PM: Update 5858: task wsj, batch 858 (5858): perplexity: 136.4090, wsj_loss: 4.9157 ||
04/19 03:19:41 PM: Batch 97/140: perplexity: 122.7586, toronto_lm_loss: 4.8102 || , for evaluation data
04/19 03:19:42 PM: Update 5874: task wsj, batch 874 (5874): perplexity: 136.3928, wsj_loss: 4.9155 ||
04/19 03:19:51 PM: Batch 136/140: perplexity: 112.9055, toronto_lm_loss: 4.7266 || , for evaluation data
04/19 03:19:52 PM: Update 5890: task wsj, batch 890 (5890): perplexity: 136.3096, wsj_loss: 4.9149 ||
04/19 03:19:53 PM: Batch 1/66: perplexity: 611.8915, wsj_loss: 6.4166 || , for evaluation data
04/19 03:20:03 PM: Update 5906: task wsj, batch 906 (5906): perplexity: 136.2348, wsj_loss: 4.9144 ||
04/19 03:20:03 PM: Batch 40/66: perplexity: 466.3897, wsj_loss: 6.1450 || , for evaluation data
04/19 03:20:10 PM: Best model found for toronto_lm.
04/19 03:20:10 PM: Best model found for wsj.
04/19 03:20:10 PM: Best model found for micro.
04/19 03:20:10 PM: Best model found for macro.
04/19 03:20:10 PM: Advancing scheduler.
04/19 03:20:10 PM: 	Best macro_avg: -0.299
04/19 03:20:10 PM: 	# bad epochs: 0
04/19 03:20:10 PM: Statistic: toronto_lm_loss
04/19 03:20:10 PM: 	training: 4.691427
04/19 03:20:10 PM: 	validation: 4.722093
04/19 03:20:10 PM: Statistic: wsj_loss
04/19 03:20:10 PM: 	training: 6.236684
04/19 03:20:10 PM: 	validation: 6.149167
04/19 03:20:10 PM: Statistic: macro_avg
04/19 03:20:10 PM: 	validation: -0.299058
04/19 03:20:10 PM: Statistic: micro_avg
04/19 03:20:10 PM: 	validation: -0.279923
04/19 03:20:10 PM: Statistic: toronto_lm_perplexity
04/19 03:20:10 PM: 	training: 109.008599
04/19 03:20:10 PM: 	validation: 112.403310
04/19 03:20:10 PM: Statistic: wsj_perplexity
04/19 03:20:10 PM: 	training: 511.160732
04/19 03:20:10 PM: 	validation: 468.327326
04/19 03:20:10 PM: global_lr: 0.001000
04/19 03:20:10 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 03:20:10 PM: Update 4001: task toronto_lm, batch 1 (3980): perplexity: 87.8544, toronto_lm_loss: 4.4757 ||
04/19 03:20:13 PM: Update 5922: task wsj, batch 922 (5922): perplexity: 136.2645, wsj_loss: 4.9146 ||
04/19 03:20:21 PM: Update 4015: task toronto_lm, batch 15 (3994): perplexity: 104.3381, toronto_lm_loss: 4.6476 ||
04/19 03:20:24 PM: Update 5938: task wsj, batch 938 (5938): perplexity: 136.2726, wsj_loss: 4.9147 ||
04/19 03:20:32 PM: Update 4029: task toronto_lm, batch 29 (4008): perplexity: 102.8438, toronto_lm_loss: 4.6332 ||
04/19 03:20:34 PM: Update 5954: task wsj, batch 954 (5954): perplexity: 136.1645, wsj_loss: 4.9139 ||
04/19 03:20:42 PM: Update 4043: task toronto_lm, batch 43 (4022): perplexity: 101.8126, toronto_lm_loss: 4.6231 ||
04/19 03:20:44 PM: Update 5970: task wsj, batch 970 (5970): perplexity: 136.1483, wsj_loss: 4.9137 ||
04/19 03:20:53 PM: Update 4057: task toronto_lm, batch 57 (4036): perplexity: 102.9656, toronto_lm_loss: 4.6344 ||
04/19 03:20:55 PM: Update 5986: task wsj, batch 986 (5986): perplexity: 136.1139, wsj_loss: 4.9135 ||
04/19 03:21:04 PM: Update 4071: task toronto_lm, batch 71 (4050): perplexity: 102.1640, toronto_lm_loss: 4.6266 ||
04/19 03:21:07 PM: Update 5998: task wsj, batch 998 (5998): perplexity: 136.1124, wsj_loss: 4.9135 ||
04/19 03:21:09 PM: ***** Pass 6000 / Epoch 6 *****
04/19 03:21:09 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 03:21:09 PM: Validating...
04/19 03:21:14 PM: Best model found for wsj.
04/19 03:21:14 PM: Best model found for micro.
04/19 03:21:14 PM: Best model found for macro.
04/19 03:21:14 PM: Advancing scheduler.
04/19 03:21:14 PM: 	Best macro_avg: 120.808
04/19 03:21:14 PM: 	# bad epochs: 0
04/19 03:21:14 PM: Statistic: wsj_loss
04/19 03:21:14 PM: 	training: 4.913535
04/19 03:21:14 PM: 	validation: 4.794199
04/19 03:21:14 PM: Statistic: macro_avg
04/19 03:21:14 PM: 	validation: 120.807565
04/19 03:21:14 PM: Statistic: micro_avg
04/19 03:21:14 PM: 	validation: 120.807565
04/19 03:21:14 PM: Statistic: wsj_perplexity
04/19 03:21:14 PM: 	training: 136.119711
04/19 03:21:14 PM: 	validation: 120.807565
04/19 03:21:14 PM: global_lr: 0.003000
04/19 03:21:14 PM: Update 4085: task toronto_lm, batch 85 (4064): perplexity: 101.1192, toronto_lm_loss: 4.6163 ||
04/19 03:21:15 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 03:21:18 PM: Update 6005: task wsj, batch 5 (6005): perplexity: 134.7261, wsj_loss: 4.9032 ||
04/19 03:21:25 PM: Update 4099: task toronto_lm, batch 99 (4078): perplexity: 100.9710, toronto_lm_loss: 4.6148 ||
04/19 03:21:28 PM: Update 6021: task wsj, batch 21 (6021): perplexity: 125.7895, wsj_loss: 4.8346 ||
04/19 03:21:36 PM: Update 4113: task wsj, batch 1 (22): perplexity: 494.3679, wsj_loss: 6.2033 ||
04/19 03:21:36 PM: Update 4114: task toronto_lm, batch 113 (4092): perplexity: 100.6960, toronto_lm_loss: 4.6121 ||
04/19 03:21:39 PM: Update 6037: task wsj, batch 37 (6037): perplexity: 125.7865, wsj_loss: 4.8346 ||
04/19 03:21:47 PM: Update 4128: task toronto_lm, batch 127 (4106): perplexity: 100.6122, toronto_lm_loss: 4.6113 ||
04/19 03:21:49 PM: Update 6053: task wsj, batch 53 (6053): perplexity: 125.3183, wsj_loss: 4.8309 ||
04/19 03:21:58 PM: Update 4142: task toronto_lm, batch 141 (4120): perplexity: 100.8338, toronto_lm_loss: 4.6135 ||
04/19 03:22:00 PM: Update 6069: task wsj, batch 69 (6069): perplexity: 126.4101, wsj_loss: 4.8395 ||
04/19 03:22:08 PM: Update 4156: task toronto_lm, batch 155 (4134): perplexity: 100.2512, toronto_lm_loss: 4.6077 ||
04/19 03:22:10 PM: Update 6085: task wsj, batch 85 (6085): perplexity: 127.0046, wsj_loss: 4.8442 ||
04/19 03:22:19 PM: Update 4170: task toronto_lm, batch 169 (4148): perplexity: 99.6164, toronto_lm_loss: 4.6013 ||
04/19 03:22:20 PM: Update 6101: task wsj, batch 101 (6101): perplexity: 127.1000, wsj_loss: 4.8450 ||
04/19 03:22:30 PM: Update 4184: task toronto_lm, batch 183 (4162): perplexity: 99.1544, toronto_lm_loss: 4.5967 ||
04/19 03:22:31 PM: Update 6117: task wsj, batch 117 (6117): perplexity: 127.0670, wsj_loss: 4.8447 ||
04/19 03:22:40 PM: Update 4198: task toronto_lm, batch 197 (4176): perplexity: 98.9572, toronto_lm_loss: 4.5947 ||
04/19 03:22:47 PM: Update 6133: task wsj, batch 133 (6133): perplexity: 126.8090, wsj_loss: 4.8427 ||
04/19 03:22:51 PM: Update 4212: task toronto_lm, batch 211 (4190): perplexity: 98.5296, toronto_lm_loss: 4.5904 ||
04/19 03:22:57 PM: Update 6149: task wsj, batch 149 (6149): perplexity: 127.6570, wsj_loss: 4.8493 ||
04/19 03:23:01 PM: Update 4226: task toronto_lm, batch 225 (4204): perplexity: 98.3231, toronto_lm_loss: 4.5883 ||
04/19 03:23:07 PM: Update 6165: task wsj, batch 165 (6165): perplexity: 127.5942, wsj_loss: 4.8489 ||
04/19 03:23:12 PM: Update 4240: task toronto_lm, batch 239 (4218): perplexity: 98.0464, toronto_lm_loss: 4.5854 ||
04/19 03:23:18 PM: Update 6181: task wsj, batch 181 (6181): perplexity: 128.1782, wsj_loss: 4.8534 ||
04/19 03:23:23 PM: Update 4254: task toronto_lm, batch 253 (4232): perplexity: 97.8048, toronto_lm_loss: 4.5830 ||
04/19 03:23:28 PM: Update 6197: task wsj, batch 197 (6197): perplexity: 128.2144, wsj_loss: 4.8537 ||
04/19 03:23:33 PM: Update 4268: task toronto_lm, batch 267 (4246): perplexity: 97.7696, toronto_lm_loss: 4.5826 ||
04/19 03:23:39 PM: Update 6213: task wsj, batch 213 (6213): perplexity: 128.1886, wsj_loss: 4.8535 ||
04/19 03:23:43 PM: Update 4281: task toronto_lm, batch 280 (4259): perplexity: 97.8433, toronto_lm_loss: 4.5834 ||
04/19 03:23:49 PM: Update 6229: task wsj, batch 229 (6229): perplexity: 128.6106, wsj_loss: 4.8568 ||
04/19 03:23:54 PM: Update 4295: task toronto_lm, batch 294 (4273): perplexity: 97.9872, toronto_lm_loss: 4.5848 ||
04/19 03:23:59 PM: Update 6245: task wsj, batch 245 (6245): perplexity: 128.6484, wsj_loss: 4.8571 ||
04/19 03:24:05 PM: Update 4309: task toronto_lm, batch 308 (4287): perplexity: 97.9355, toronto_lm_loss: 4.5843 ||
04/19 03:24:10 PM: Update 6261: task wsj, batch 261 (6261): perplexity: 129.0149, wsj_loss: 4.8599 ||
04/19 03:24:16 PM: Update 4323: task toronto_lm, batch 322 (4301): perplexity: 97.5882, toronto_lm_loss: 4.5808 ||
04/19 03:24:20 PM: Update 6277: task wsj, batch 277 (6277): perplexity: 129.4101, wsj_loss: 4.8630 ||
04/19 03:24:26 PM: Update 4337: task toronto_lm, batch 336 (4315): perplexity: 97.5791, toronto_lm_loss: 4.5807 ||
04/19 03:24:34 PM: Update 6290: task wsj, batch 290 (6290): perplexity: 129.7487, wsj_loss: 4.8656 ||
04/19 03:24:37 PM: Update 4351: task toronto_lm, batch 350 (4329): perplexity: 97.3952, toronto_lm_loss: 4.5788 ||
04/19 03:24:44 PM: Update 6306: task wsj, batch 306 (6306): perplexity: 129.2280, wsj_loss: 4.8616 ||
04/19 03:24:48 PM: Update 4365: task toronto_lm, batch 364 (4343): perplexity: 97.4707, toronto_lm_loss: 4.5796 ||
04/19 03:24:55 PM: Update 6322: task wsj, batch 322 (6322): perplexity: 129.1088, wsj_loss: 4.8607 ||
04/19 03:24:58 PM: Update 4379: task toronto_lm, batch 378 (4357): perplexity: 97.1652, toronto_lm_loss: 4.5764 ||
04/19 03:25:05 PM: Update 6338: task wsj, batch 338 (6338): perplexity: 128.9986, wsj_loss: 4.8598 ||
04/19 03:25:09 PM: Update 4393: task toronto_lm, batch 392 (4371): perplexity: 97.0399, toronto_lm_loss: 4.5751 ||
04/19 03:25:15 PM: Update 6354: task wsj, batch 354 (6354): perplexity: 128.8203, wsj_loss: 4.8584 ||
04/19 03:25:21 PM: Update 4398: task toronto_lm, batch 397 (4376): perplexity: 97.0062, toronto_lm_loss: 4.5748 ||
04/19 03:25:26 PM: Update 6370: task wsj, batch 370 (6370): perplexity: 128.6404, wsj_loss: 4.8570 ||
04/19 03:25:32 PM: Update 4412: task toronto_lm, batch 411 (4390): perplexity: 98.5035, toronto_lm_loss: 4.5901 ||
04/19 03:25:36 PM: Update 6386: task wsj, batch 386 (6386): perplexity: 128.3474, wsj_loss: 4.8547 ||
04/19 03:25:43 PM: Update 4426: task toronto_lm, batch 425 (4404): perplexity: 99.6423, toronto_lm_loss: 4.6016 ||
04/19 03:25:47 PM: Update 6402: task wsj, batch 402 (6402): perplexity: 128.0835, wsj_loss: 4.8527 ||
04/19 03:25:53 PM: Update 4440: task toronto_lm, batch 439 (4418): perplexity: 100.3442, toronto_lm_loss: 4.6086 ||
04/19 03:25:57 PM: Update 6418: task wsj, batch 418 (6418): perplexity: 127.9604, wsj_loss: 4.8517 ||
04/19 03:26:04 PM: Update 4454: task toronto_lm, batch 453 (4432): perplexity: 100.9128, toronto_lm_loss: 4.6143 ||
04/19 03:26:07 PM: Update 6426: task wsj, batch 426 (6426): perplexity: 127.9938, wsj_loss: 4.8520 ||
04/19 03:26:15 PM: Update 4468: task toronto_lm, batch 467 (4446): perplexity: 101.3379, toronto_lm_loss: 4.6185 ||
04/19 03:26:17 PM: Update 6442: task wsj, batch 442 (6442): perplexity: 128.2063, wsj_loss: 4.8536 ||
04/19 03:26:25 PM: Update 4482: task toronto_lm, batch 481 (4460): perplexity: 101.6313, toronto_lm_loss: 4.6214 ||
04/19 03:26:28 PM: Update 6458: task wsj, batch 458 (6458): perplexity: 128.1427, wsj_loss: 4.8531 ||
04/19 03:26:36 PM: Update 4496: task toronto_lm, batch 495 (4474): perplexity: 101.7932, toronto_lm_loss: 4.6229 ||
04/19 03:26:38 PM: Update 6474: task wsj, batch 474 (6474): perplexity: 128.2794, wsj_loss: 4.8542 ||
04/19 03:26:47 PM: Update 4510: task toronto_lm, batch 509 (4488): perplexity: 101.9661, toronto_lm_loss: 4.6246 ||
04/19 03:26:48 PM: Update 6490: task wsj, batch 490 (6490): perplexity: 128.2162, wsj_loss: 4.8537 ||
04/19 03:26:57 PM: Update 4524: task toronto_lm, batch 523 (4502): perplexity: 102.0533, toronto_lm_loss: 4.6255 ||
04/19 03:26:59 PM: Update 6506: task wsj, batch 506 (6506): perplexity: 128.2318, wsj_loss: 4.8538 ||
04/19 03:27:08 PM: Update 4538: task toronto_lm, batch 537 (4516): perplexity: 102.1848, toronto_lm_loss: 4.6268 ||
04/19 03:27:09 PM: Update 6522: task wsj, batch 522 (6522): perplexity: 128.2348, wsj_loss: 4.8539 ||
04/19 03:27:19 PM: Update 4552: task toronto_lm, batch 551 (4530): perplexity: 102.2032, toronto_lm_loss: 4.6270 ||
04/19 03:27:20 PM: Update 6538: task wsj, batch 538 (6538): perplexity: 128.2931, wsj_loss: 4.8543 ||
04/19 03:27:29 PM: Update 4566: task toronto_lm, batch 565 (4544): perplexity: 102.2640, toronto_lm_loss: 4.6276 ||
04/19 03:27:30 PM: Update 6554: task wsj, batch 554 (6554): perplexity: 128.3638, wsj_loss: 4.8549 ||
04/19 03:27:40 PM: Update 4580: task toronto_lm, batch 579 (4558): perplexity: 102.4487, toronto_lm_loss: 4.6294 ||
04/19 03:27:41 PM: Update 6570: task wsj, batch 570 (6570): perplexity: 128.4149, wsj_loss: 4.8553 ||
04/19 03:27:42 PM: Update 4582: task wsj, batch 2 (23): perplexity: 506.6123, wsj_loss: 6.2277 ||
04/19 03:27:51 PM: Update 4594: task toronto_lm, batch 592 (4571): perplexity: 102.4209, toronto_lm_loss: 4.6291 ||
04/19 03:27:54 PM: Update 6582: task wsj, batch 582 (6582): perplexity: 128.4055, wsj_loss: 4.8552 ||
04/19 03:28:01 PM: Update 4608: task toronto_lm, batch 606 (4585): perplexity: 102.4904, toronto_lm_loss: 4.6298 ||
04/19 03:28:05 PM: Update 6598: task wsj, batch 598 (6598): perplexity: 128.3507, wsj_loss: 4.8548 ||
04/19 03:28:12 PM: Update 4622: task toronto_lm, batch 620 (4599): perplexity: 102.6113, toronto_lm_loss: 4.6309 ||
04/19 03:28:15 PM: Update 6614: task wsj, batch 614 (6614): perplexity: 128.2005, wsj_loss: 4.8536 ||
04/19 03:28:23 PM: Update 4636: task toronto_lm, batch 634 (4613): perplexity: 102.6588, toronto_lm_loss: 4.6314 ||
04/19 03:28:26 PM: Update 6630: task wsj, batch 630 (6630): perplexity: 128.0274, wsj_loss: 4.8522 ||
04/19 03:28:33 PM: Update 4650: task toronto_lm, batch 648 (4627): perplexity: 102.6341, toronto_lm_loss: 4.6312 ||
04/19 03:28:36 PM: Update 6646: task wsj, batch 646 (6646): perplexity: 127.9617, wsj_loss: 4.8517 ||
04/19 03:28:44 PM: Update 4664: task toronto_lm, batch 662 (4641): perplexity: 102.5751, toronto_lm_loss: 4.6306 ||
04/19 03:28:47 PM: Update 6662: task wsj, batch 662 (6662): perplexity: 127.8195, wsj_loss: 4.8506 ||
04/19 03:28:55 PM: Update 4678: task toronto_lm, batch 676 (4655): perplexity: 102.4984, toronto_lm_loss: 4.6298 ||
04/19 03:28:57 PM: Update 6678: task wsj, batch 678 (6678): perplexity: 127.6505, wsj_loss: 4.8493 ||
04/19 03:29:05 PM: Update 4692: task toronto_lm, batch 690 (4669): perplexity: 102.3951, toronto_lm_loss: 4.6288 ||
04/19 03:29:08 PM: Update 6694: task wsj, batch 694 (6694): perplexity: 127.4757, wsj_loss: 4.8479 ||
04/19 03:29:16 PM: Update 4706: task toronto_lm, batch 704 (4683): perplexity: 102.3624, toronto_lm_loss: 4.6285 ||
04/19 03:29:18 PM: Update 6710: task wsj, batch 710 (6710): perplexity: 127.2647, wsj_loss: 4.8463 ||
04/19 03:29:27 PM: Update 4720: task toronto_lm, batch 718 (4697): perplexity: 102.3256, toronto_lm_loss: 4.6282 ||
04/19 03:29:29 PM: Update 6718: task wsj, batch 718 (6718): perplexity: 127.2500, wsj_loss: 4.8462 ||
04/19 03:29:37 PM: Update 4734: task toronto_lm, batch 732 (4711): perplexity: 102.2309, toronto_lm_loss: 4.6272 ||
04/19 03:29:39 PM: Update 6734: task wsj, batch 734 (6734): perplexity: 127.1996, wsj_loss: 4.8458 ||
04/19 03:29:48 PM: Update 4748: task toronto_lm, batch 746 (4725): perplexity: 102.0934, toronto_lm_loss: 4.6259 ||
04/19 03:29:50 PM: Update 6750: task wsj, batch 750 (6750): perplexity: 127.1227, wsj_loss: 4.8452 ||
04/19 03:29:59 PM: Update 4762: task toronto_lm, batch 760 (4739): perplexity: 101.9360, toronto_lm_loss: 4.6243 ||
04/19 03:30:00 PM: Update 6766: task wsj, batch 766 (6766): perplexity: 127.0994, wsj_loss: 4.8450 ||
04/19 03:30:09 PM: Update 4776: task toronto_lm, batch 774 (4753): perplexity: 101.8849, toronto_lm_loss: 4.6238 ||
04/19 03:30:10 PM: Update 6782: task wsj, batch 782 (6782): perplexity: 127.0069, wsj_loss: 4.8442 ||
04/19 03:30:19 PM: Update 4789: task wsj, batch 3 (24): perplexity: 551.1283, wsj_loss: 6.3120 ||
04/19 03:30:20 PM: Update 4790: task toronto_lm, batch 787 (4766): perplexity: 101.8117, toronto_lm_loss: 4.6231 ||
04/19 03:30:21 PM: Update 6798: task wsj, batch 798 (6798): perplexity: 127.0588, wsj_loss: 4.8446 ||
04/19 03:30:31 PM: Update 4804: task toronto_lm, batch 801 (4780): perplexity: 101.6946, toronto_lm_loss: 4.6220 ||
04/19 03:30:31 PM: Update 6814: task wsj, batch 814 (6814): perplexity: 127.0904, wsj_loss: 4.8449 ||
04/19 03:30:42 PM: Update 4818: task toronto_lm, batch 815 (4794): perplexity: 101.6063, toronto_lm_loss: 4.6211 ||
04/19 03:30:42 PM: Update 6830: task wsj, batch 830 (6830): perplexity: 127.1696, wsj_loss: 4.8455 ||
04/19 03:30:52 PM: Update 4831: task toronto_lm, batch 828 (4807): perplexity: 101.4743, toronto_lm_loss: 4.6198 ||
04/19 03:30:52 PM: Update 6846: task wsj, batch 846 (6846): perplexity: 127.1877, wsj_loss: 4.8457 ||
04/19 03:31:02 PM: Update 4844: task toronto_lm, batch 841 (4820): perplexity: 101.4356, toronto_lm_loss: 4.6194 ||
04/19 03:31:03 PM: Update 6862: task wsj, batch 862 (6862): perplexity: 127.2667, wsj_loss: 4.8463 ||
04/19 03:31:12 PM: Update 4857: task toronto_lm, batch 854 (4833): perplexity: 101.2529, toronto_lm_loss: 4.6176 ||
04/19 03:31:15 PM: Update 6874: task wsj, batch 874 (6874): perplexity: 127.2852, wsj_loss: 4.8464 ||
04/19 03:31:22 PM: Update 4870: task toronto_lm, batch 867 (4846): perplexity: 101.1035, toronto_lm_loss: 4.6161 ||
04/19 03:31:26 PM: Update 6890: task wsj, batch 890 (6890): perplexity: 127.0596, wsj_loss: 4.8447 ||
04/19 03:31:32 PM: Update 4883: task toronto_lm, batch 880 (4859): perplexity: 101.0465, toronto_lm_loss: 4.6156 ||
04/19 03:31:36 PM: Update 6906: task wsj, batch 906 (6906): perplexity: 126.9959, wsj_loss: 4.8442 ||
04/19 03:31:43 PM: Update 4897: task toronto_lm, batch 894 (4873): perplexity: 100.9613, toronto_lm_loss: 4.6147 ||
04/19 03:31:47 PM: Update 6922: task wsj, batch 922 (6922): perplexity: 126.8505, wsj_loss: 4.8430 ||
04/19 03:31:53 PM: Update 4910: task toronto_lm, batch 907 (4886): perplexity: 100.8959, toronto_lm_loss: 4.6141 ||
04/19 03:31:57 PM: Update 6938: task wsj, batch 938 (6938): perplexity: 126.7406, wsj_loss: 4.8421 ||
04/19 03:32:04 PM: Update 4924: task toronto_lm, batch 921 (4900): perplexity: 100.8439, toronto_lm_loss: 4.6136 ||
04/19 03:32:05 PM: Update 4926: task wsj, batch 4 (25): perplexity: 521.9410, wsj_loss: 6.2576 ||
04/19 03:32:08 PM: Update 6954: task wsj, batch 954 (6954): perplexity: 126.6190, wsj_loss: 4.8412 ||
04/19 03:32:14 PM: Update 4938: task toronto_lm, batch 934 (4913): perplexity: 100.7288, toronto_lm_loss: 4.6124 ||
04/19 03:32:18 PM: Update 6970: task wsj, batch 970 (6970): perplexity: 126.5416, wsj_loss: 4.8406 ||
04/19 03:32:25 PM: Update 4952: task toronto_lm, batch 948 (4927): perplexity: 100.6230, toronto_lm_loss: 4.6114 ||
04/19 03:32:29 PM: Update 6986: task wsj, batch 986 (6986): perplexity: 126.4212, wsj_loss: 4.8396 ||
04/19 03:32:36 PM: Update 4966: task toronto_lm, batch 962 (4941): perplexity: 100.5333, toronto_lm_loss: 4.6105 ||
04/19 03:32:38 PM: ***** Pass 7000 / Epoch 7 *****
04/19 03:32:38 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 03:32:38 PM: Validating...
04/19 03:32:39 PM: Batch 4/24: perplexity: 166.8487, wsj_loss: 5.1171 || , for evaluation data
04/19 03:32:44 PM: Best model found for wsj.
04/19 03:32:44 PM: Best model found for micro.
04/19 03:32:44 PM: Best model found for macro.
04/19 03:32:44 PM: Advancing scheduler.
04/19 03:32:44 PM: 	Best macro_avg: 115.974
04/19 03:32:44 PM: 	# bad epochs: 0
04/19 03:32:44 PM: Statistic: wsj_loss
04/19 03:32:44 PM: 	training: 4.838807
04/19 03:32:44 PM: 	validation: 4.753367
04/19 03:32:44 PM: Statistic: macro_avg
04/19 03:32:44 PM: 	validation: 115.974070
04/19 03:32:44 PM: Statistic: micro_avg
04/19 03:32:44 PM: 	validation: 115.974070
04/19 03:32:44 PM: Statistic: wsj_perplexity
04/19 03:32:44 PM: 	training: 126.318620
04/19 03:32:44 PM: 	validation: 115.974070
04/19 03:32:44 PM: global_lr: 0.003000
04/19 03:32:44 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 03:32:46 PM: Update 4980: task toronto_lm, batch 976 (4955): perplexity: 100.3000, toronto_lm_loss: 4.6082 ||
04/19 03:32:49 PM: Update 7007: task wsj, batch 7 (7007): perplexity: 130.6712, wsj_loss: 4.8727 ||
04/19 03:32:52 PM: Update 4987: task wsj, batch 5 (26): perplexity: 482.0978, wsj_loss: 6.1781 ||
04/19 03:32:56 PM: Update 4993: task toronto_lm, batch 988 (4967): perplexity: 100.1772, toronto_lm_loss: 4.6069 ||
04/19 03:32:59 PM: Update 7014: task wsj, batch 14 (7014): perplexity: 127.7294, wsj_loss: 4.8499 ||
04/19 03:33:02 PM: ***** Pass 5000 / Epoch 5 *****
04/19 03:33:02 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 03:33:02 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 03:33:02 PM: Validating...
04/19 03:33:06 PM: Batch 18/140: perplexity: 148.1642, toronto_lm_loss: 4.9983 || , for evaluation data
04/19 03:33:10 PM: Update 7030: task wsj, batch 30 (7030): perplexity: 126.6248, wsj_loss: 4.8412 ||
04/19 03:33:17 PM: Batch 57/140: perplexity: 143.4284, toronto_lm_loss: 4.9658 || , for evaluation data
04/19 03:33:20 PM: Update 7046: task wsj, batch 46 (7046): perplexity: 128.1003, wsj_loss: 4.8528 ||
04/19 03:33:27 PM: Batch 95/140: perplexity: 132.0813, toronto_lm_loss: 4.8834 || , for evaluation data
04/19 03:33:30 PM: Update 7062: task wsj, batch 62 (7062): perplexity: 127.4169, wsj_loss: 4.8475 ||
04/19 03:33:37 PM: Batch 134/140: perplexity: 121.5301, toronto_lm_loss: 4.8002 || , for evaluation data
04/19 03:33:39 PM: Batch 1/66: perplexity: 617.0865, wsj_loss: 6.4250 || , for evaluation data
04/19 03:33:41 PM: Update 7078: task wsj, batch 78 (7078): perplexity: 125.9753, wsj_loss: 4.8361 ||
04/19 03:33:49 PM: Batch 39/66: perplexity: 438.5335, wsj_loss: 6.0834 || , for evaluation data
04/19 03:33:51 PM: Update 7094: task wsj, batch 94 (7094): perplexity: 125.3844, wsj_loss: 4.8314 ||
04/19 03:33:56 PM: Best model found for wsj.
04/19 03:33:56 PM: Best model found for micro.
04/19 03:33:56 PM: Best model found for macro.
04/19 03:33:56 PM: Advancing scheduler.
04/19 03:33:56 PM: 	Best macro_avg: -0.227
04/19 03:33:56 PM: 	# bad epochs: 0
04/19 03:33:56 PM: Statistic: toronto_lm_loss
04/19 03:33:56 PM: 	training: 4.606379
04/19 03:33:56 PM: 	validation: 4.790728
04/19 03:33:56 PM: Statistic: wsj_loss
04/19 03:33:56 PM: 	training: 6.178147
04/19 03:33:56 PM: 	validation: 6.059893
04/19 03:33:56 PM: Statistic: macro_avg
04/19 03:33:56 PM: 	validation: -0.227048
04/19 03:33:56 PM: Statistic: micro_avg
04/19 03:33:56 PM: 	validation: -0.228640
04/19 03:33:56 PM: Statistic: toronto_lm_perplexity
04/19 03:33:56 PM: 	training: 100.120963
04/19 03:33:56 PM: 	validation: 120.389024
04/19 03:33:56 PM: Statistic: wsj_perplexity
04/19 03:33:56 PM: 	training: 482.097769
04/19 03:33:56 PM: 	validation: 428.329409
04/19 03:33:56 PM: global_lr: 0.001000
04/19 03:33:56 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 03:33:57 PM: Update 5001: task toronto_lm, batch 1 (4975): perplexity: 99.6215, toronto_lm_loss: 4.6014 ||
04/19 03:34:02 PM: Update 7110: task wsj, batch 110 (7110): perplexity: 125.4325, wsj_loss: 4.8318 ||
04/19 03:34:08 PM: Update 5015: task toronto_lm, batch 15 (4989): perplexity: 99.6292, toronto_lm_loss: 4.6015 ||
04/19 03:34:12 PM: Update 7126: task wsj, batch 126 (7126): perplexity: 125.5127, wsj_loss: 4.8324 ||
04/19 03:34:23 PM: Update 7142: task wsj, batch 142 (7142): perplexity: 125.4834, wsj_loss: 4.8322 ||
04/19 03:34:26 PM: Update 5027: task toronto_lm, batch 27 (5001): perplexity: 98.1250, toronto_lm_loss: 4.5862 ||
04/19 03:34:36 PM: Update 7158: task wsj, batch 158 (7158): perplexity: 125.2382, wsj_loss: 4.8302 ||
04/19 03:34:36 PM: Update 5041: task toronto_lm, batch 41 (5015): perplexity: 102.4181, toronto_lm_loss: 4.6291 ||
04/19 03:34:46 PM: Update 7166: task wsj, batch 166 (7166): perplexity: 125.2661, wsj_loss: 4.8304 ||
04/19 03:34:47 PM: Update 5055: task toronto_lm, batch 55 (5029): perplexity: 103.2371, toronto_lm_loss: 4.6370 ||
04/19 03:34:57 PM: Update 7182: task wsj, batch 182 (7182): perplexity: 124.8338, wsj_loss: 4.8270 ||
04/19 03:34:58 PM: Update 5069: task toronto_lm, batch 69 (5043): perplexity: 103.2727, toronto_lm_loss: 4.6374 ||
04/19 03:35:07 PM: Update 7198: task wsj, batch 198 (7198): perplexity: 124.0725, wsj_loss: 4.8209 ||
04/19 03:35:09 PM: Update 5083: task toronto_lm, batch 83 (5057): perplexity: 102.4741, toronto_lm_loss: 4.6296 ||
04/19 03:35:09 PM: Update 5084: task wsj, batch 1 (27): perplexity: 368.5533, wsj_loss: 5.9096 ||
04/19 03:35:18 PM: Update 7214: task wsj, batch 214 (7214): perplexity: 123.8405, wsj_loss: 4.8190 ||
04/19 03:35:19 PM: Update 5097: task toronto_lm, batch 96 (5070): perplexity: 101.6645, toronto_lm_loss: 4.6217 ||
04/19 03:35:28 PM: Update 7230: task wsj, batch 230 (7230): perplexity: 123.3386, wsj_loss: 4.8149 ||
04/19 03:35:30 PM: Update 5111: task toronto_lm, batch 110 (5084): perplexity: 101.1901, toronto_lm_loss: 4.6170 ||
04/19 03:35:38 PM: Update 7246: task wsj, batch 246 (7246): perplexity: 122.6786, wsj_loss: 4.8096 ||
04/19 03:35:41 PM: Update 5125: task toronto_lm, batch 124 (5098): perplexity: 100.5567, toronto_lm_loss: 4.6107 ||
04/19 03:35:49 PM: Update 7262: task wsj, batch 262 (7262): perplexity: 122.3702, wsj_loss: 4.8071 ||
04/19 03:35:52 PM: Update 5139: task toronto_lm, batch 138 (5112): perplexity: 99.0425, toronto_lm_loss: 4.5955 ||
04/19 03:35:59 PM: Update 7278: task wsj, batch 278 (7278): perplexity: 122.3296, wsj_loss: 4.8067 ||
04/19 03:36:02 PM: Update 5153: task toronto_lm, batch 152 (5126): perplexity: 98.2942, toronto_lm_loss: 4.5880 ||
04/19 03:36:10 PM: Update 7294: task wsj, batch 294 (7294): perplexity: 122.0439, wsj_loss: 4.8044 ||
04/19 03:36:13 PM: Update 5167: task toronto_lm, batch 166 (5140): perplexity: 97.3550, toronto_lm_loss: 4.5784 ||
04/19 03:36:20 PM: Update 7302: task wsj, batch 302 (7302): perplexity: 121.9119, wsj_loss: 4.8033 ||
04/19 03:36:24 PM: Update 5181: task toronto_lm, batch 180 (5154): perplexity: 97.0536, toronto_lm_loss: 4.5753 ||
04/19 03:36:31 PM: Update 7318: task wsj, batch 318 (7318): perplexity: 122.0198, wsj_loss: 4.8042 ||
04/19 03:36:34 PM: Update 5195: task toronto_lm, batch 194 (5168): perplexity: 96.4636, toronto_lm_loss: 4.5692 ||
04/19 03:36:41 PM: Update 7334: task wsj, batch 334 (7334): perplexity: 122.2402, wsj_loss: 4.8060 ||
04/19 03:36:45 PM: Update 5209: task toronto_lm, batch 208 (5182): perplexity: 96.2058, toronto_lm_loss: 4.5665 ||
04/19 03:36:52 PM: Update 7350: task wsj, batch 350 (7350): perplexity: 122.0848, wsj_loss: 4.8047 ||
04/19 03:36:55 PM: Update 5222: task toronto_lm, batch 221 (5195): perplexity: 95.5864, toronto_lm_loss: 4.5600 ||
04/19 03:37:02 PM: Update 7366: task wsj, batch 366 (7366): perplexity: 122.1159, wsj_loss: 4.8050 ||
04/19 03:37:05 PM: Update 5235: task toronto_lm, batch 234 (5208): perplexity: 95.2849, toronto_lm_loss: 4.5569 ||
04/19 03:37:13 PM: Update 7382: task wsj, batch 382 (7382): perplexity: 122.2198, wsj_loss: 4.8058 ||
04/19 03:37:16 PM: Update 5249: task toronto_lm, batch 248 (5222): perplexity: 95.1406, toronto_lm_loss: 4.5554 ||
04/19 03:37:23 PM: Update 7398: task wsj, batch 398 (7398): perplexity: 122.2580, wsj_loss: 4.8061 ||
04/19 03:37:27 PM: Update 5263: task toronto_lm, batch 262 (5236): perplexity: 94.5597, toronto_lm_loss: 4.5492 ||
04/19 03:37:34 PM: Update 7414: task wsj, batch 414 (7414): perplexity: 122.4091, wsj_loss: 4.8074 ||
04/19 03:37:36 PM: Update 5275: task wsj, batch 2 (28): perplexity: 445.4701, wsj_loss: 6.0991 ||
04/19 03:37:37 PM: Update 5277: task toronto_lm, batch 275 (5249): perplexity: 93.8061, toronto_lm_loss: 4.5412 ||
04/19 03:37:44 PM: Update 7430: task wsj, batch 430 (7430): perplexity: 122.4254, wsj_loss: 4.8075 ||
04/19 03:37:48 PM: Update 5291: task toronto_lm, batch 289 (5263): perplexity: 93.4836, toronto_lm_loss: 4.5378 ||
04/19 03:37:55 PM: Update 7446: task wsj, batch 446 (7446): perplexity: 122.4509, wsj_loss: 4.8077 ||
04/19 03:37:59 PM: Update 5305: task toronto_lm, batch 303 (5277): perplexity: 92.8814, toronto_lm_loss: 4.5313 ||
04/19 03:38:08 PM: Update 7458: task wsj, batch 458 (7458): perplexity: 122.4236, wsj_loss: 4.8075 ||
04/19 03:38:10 PM: Update 5319: task toronto_lm, batch 317 (5291): perplexity: 92.5675, toronto_lm_loss: 4.5279 ||
04/19 03:38:19 PM: Update 7474: task wsj, batch 474 (7474): perplexity: 122.1261, wsj_loss: 4.8051 ||
04/19 03:38:20 PM: Update 5333: task toronto_lm, batch 331 (5305): perplexity: 92.2216, toronto_lm_loss: 4.5242 ||
04/19 03:38:29 PM: Update 7490: task wsj, batch 490 (7490): perplexity: 121.9301, wsj_loss: 4.8034 ||
04/19 03:38:31 PM: Update 5347: task toronto_lm, batch 345 (5319): perplexity: 92.0119, toronto_lm_loss: 4.5219 ||
04/19 03:38:39 PM: Update 7506: task wsj, batch 506 (7506): perplexity: 121.6756, wsj_loss: 4.8014 ||
04/19 03:38:42 PM: Update 5361: task toronto_lm, batch 359 (5333): perplexity: 91.8323, toronto_lm_loss: 4.5200 ||
04/19 03:38:50 PM: Update 7522: task wsj, batch 522 (7522): perplexity: 121.6286, wsj_loss: 4.8010 ||
04/19 03:38:52 PM: Update 5375: task toronto_lm, batch 373 (5347): perplexity: 91.5994, toronto_lm_loss: 4.5174 ||
04/19 03:39:00 PM: Update 7538: task wsj, batch 538 (7538): perplexity: 121.3968, wsj_loss: 4.7991 ||
04/19 03:39:03 PM: Update 5389: task toronto_lm, batch 387 (5361): perplexity: 91.1722, toronto_lm_loss: 4.5127 ||
04/19 03:39:11 PM: Update 7554: task wsj, batch 554 (7554): perplexity: 121.3008, wsj_loss: 4.7983 ||
04/19 03:39:14 PM: Update 5403: task toronto_lm, batch 401 (5375): perplexity: 91.0144, toronto_lm_loss: 4.5110 ||
04/19 03:39:21 PM: Update 7570: task wsj, batch 570 (7570): perplexity: 121.1445, wsj_loss: 4.7970 ||
04/19 03:39:25 PM: Update 5417: task toronto_lm, batch 415 (5389): perplexity: 90.8020, toronto_lm_loss: 4.5087 ||
04/19 03:39:32 PM: Update 7586: task wsj, batch 586 (7586): perplexity: 120.9816, wsj_loss: 4.7956 ||
04/19 03:39:35 PM: Update 5431: task toronto_lm, batch 429 (5403): perplexity: 90.3736, toronto_lm_loss: 4.5040 ||
04/19 03:39:42 PM: Update 7594: task wsj, batch 594 (7594): perplexity: 120.9438, wsj_loss: 4.7953 ||
04/19 03:39:46 PM: Update 5445: task toronto_lm, batch 443 (5417): perplexity: 90.2417, toronto_lm_loss: 4.5025 ||
04/19 03:39:52 PM: Update 7610: task wsj, batch 610 (7610): perplexity: 120.9832, wsj_loss: 4.7957 ||
04/19 03:39:57 PM: Update 5459: task toronto_lm, batch 457 (5431): perplexity: 89.9462, toronto_lm_loss: 4.4992 ||
04/19 03:40:03 PM: Update 7626: task wsj, batch 626 (7626): perplexity: 121.0160, wsj_loss: 4.7959 ||
04/19 03:40:07 PM: Update 5473: task toronto_lm, batch 471 (5445): perplexity: 89.7827, toronto_lm_loss: 4.4974 ||
04/19 03:40:13 PM: Update 7642: task wsj, batch 642 (7642): perplexity: 120.9901, wsj_loss: 4.7957 ||
04/19 03:40:18 PM: Update 5487: task toronto_lm, batch 485 (5459): perplexity: 89.4337, toronto_lm_loss: 4.4935 ||
04/19 03:40:24 PM: Update 7658: task wsj, batch 658 (7658): perplexity: 120.8863, wsj_loss: 4.7949 ||
04/19 03:40:29 PM: Update 5501: task toronto_lm, batch 499 (5473): perplexity: 89.2485, toronto_lm_loss: 4.4914 ||
04/19 03:40:34 PM: Update 7674: task wsj, batch 674 (7674): perplexity: 121.0091, wsj_loss: 4.7959 ||
04/19 03:40:38 PM: Update 5513: task wsj, batch 3 (29): perplexity: 409.7102, wsj_loss: 6.0155 ||
04/19 03:40:40 PM: Update 5515: task toronto_lm, batch 512 (5486): perplexity: 89.0881, toronto_lm_loss: 4.4896 ||
04/19 03:40:45 PM: Update 7690: task wsj, batch 690 (7690): perplexity: 120.9593, wsj_loss: 4.7955 ||
04/19 03:40:50 PM: Update 5528: task toronto_lm, batch 525 (5499): perplexity: 88.9299, toronto_lm_loss: 4.4878 ||
04/19 03:40:55 PM: Update 7706: task wsj, batch 706 (7706): perplexity: 121.0941, wsj_loss: 4.7966 ||
04/19 03:41:00 PM: Update 5542: task toronto_lm, batch 539 (5513): perplexity: 88.7927, toronto_lm_loss: 4.4863 ||
04/19 03:41:06 PM: Update 7722: task wsj, batch 722 (7722): perplexity: 121.0564, wsj_loss: 4.7963 ||
04/19 03:41:11 PM: Update 5556: task toronto_lm, batch 553 (5527): perplexity: 88.7128, toronto_lm_loss: 4.4854 ||
04/19 03:41:16 PM: Update 7738: task wsj, batch 738 (7738): perplexity: 121.0219, wsj_loss: 4.7960 ||
04/19 03:41:21 PM: Update 5569: task toronto_lm, batch 566 (5540): perplexity: 88.6014, toronto_lm_loss: 4.4841 ||
04/19 03:41:29 PM: Update 7750: task wsj, batch 750 (7750): perplexity: 120.9966, wsj_loss: 4.7958 ||
04/19 03:41:32 PM: Update 5583: task toronto_lm, batch 580 (5554): perplexity: 88.4060, toronto_lm_loss: 4.4819 ||
04/19 03:41:40 PM: Update 7766: task wsj, batch 766 (7766): perplexity: 120.8338, wsj_loss: 4.7944 ||
04/19 03:41:43 PM: Update 5597: task toronto_lm, batch 594 (5568): perplexity: 88.1683, toronto_lm_loss: 4.4792 ||
04/19 03:41:50 PM: Update 7782: task wsj, batch 782 (7782): perplexity: 120.6882, wsj_loss: 4.7932 ||
04/19 03:41:53 PM: Update 5610: task toronto_lm, batch 607 (5581): perplexity: 88.0398, toronto_lm_loss: 4.4778 ||
04/19 03:42:01 PM: Update 7798: task wsj, batch 798 (7798): perplexity: 120.4878, wsj_loss: 4.7915 ||
04/19 03:42:03 PM: Update 5624: task toronto_lm, batch 621 (5595): perplexity: 88.0049, toronto_lm_loss: 4.4774 ||
04/19 03:42:11 PM: Update 7814: task wsj, batch 814 (7814): perplexity: 120.3607, wsj_loss: 4.7905 ||
04/19 03:42:14 PM: Update 5638: task toronto_lm, batch 635 (5609): perplexity: 87.9345, toronto_lm_loss: 4.4766 ||
04/19 03:42:22 PM: Update 7830: task wsj, batch 830 (7830): perplexity: 120.1873, wsj_loss: 4.7891 ||
04/19 03:42:25 PM: Update 5652: task toronto_lm, batch 649 (5623): perplexity: 87.6380, toronto_lm_loss: 4.4732 ||
04/19 03:42:32 PM: Update 7846: task wsj, batch 846 (7846): perplexity: 120.1058, wsj_loss: 4.7884 ||
04/19 03:42:35 PM: Update 5656: task toronto_lm, batch 653 (5627): perplexity: 87.7177, toronto_lm_loss: 4.4741 ||
04/19 03:42:43 PM: Update 7862: task wsj, batch 862 (7862): perplexity: 120.0942, wsj_loss: 4.7883 ||
04/19 03:42:46 PM: Update 5670: task toronto_lm, batch 667 (5641): perplexity: 88.4579, toronto_lm_loss: 4.4825 ||
04/19 03:42:53 PM: Update 7878: task wsj, batch 878 (7878): perplexity: 119.9795, wsj_loss: 4.7873 ||
04/19 03:42:56 PM: Update 5684: task toronto_lm, batch 681 (5655): perplexity: 89.0459, toronto_lm_loss: 4.4892 ||
04/19 03:43:03 PM: Update 5693: task wsj, batch 4 (30): perplexity: 403.7699, wsj_loss: 6.0008 ||
04/19 03:43:03 PM: Update 7886: task wsj, batch 886 (7886): perplexity: 119.9722, wsj_loss: 4.7873 ||
04/19 03:43:07 PM: Update 5698: task toronto_lm, batch 694 (5668): perplexity: 89.5968, toronto_lm_loss: 4.4953 ||
04/19 03:43:14 PM: Update 7902: task wsj, batch 902 (7902): perplexity: 120.0266, wsj_loss: 4.7877 ||
04/19 03:43:18 PM: Update 5712: task toronto_lm, batch 708 (5682): perplexity: 90.1216, toronto_lm_loss: 4.5012 ||
04/19 03:43:24 PM: Update 7918: task wsj, batch 918 (7918): perplexity: 120.0072, wsj_loss: 4.7876 ||
04/19 03:43:28 PM: Update 5726: task toronto_lm, batch 722 (5696): perplexity: 90.4795, toronto_lm_loss: 4.5051 ||
04/19 03:43:35 PM: Update 7934: task wsj, batch 934 (7934): perplexity: 120.0018, wsj_loss: 4.7875 ||
04/19 03:43:39 PM: Update 5740: task toronto_lm, batch 736 (5710): perplexity: 90.8357, toronto_lm_loss: 4.5091 ||
04/19 03:43:45 PM: Update 7950: task wsj, batch 950 (7950): perplexity: 119.9905, wsj_loss: 4.7874 ||
04/19 03:43:50 PM: Update 5754: task toronto_lm, batch 750 (5724): perplexity: 91.2121, toronto_lm_loss: 4.5132 ||
04/19 03:43:55 PM: Update 7966: task wsj, batch 966 (7966): perplexity: 119.9620, wsj_loss: 4.7872 ||
04/19 03:43:59 PM: Update 5766: task wsj, batch 5 (31): perplexity: 397.6520, wsj_loss: 5.9856 ||
04/19 03:44:01 PM: Update 5768: task toronto_lm, batch 763 (5737): perplexity: 91.4852, toronto_lm_loss: 4.5162 ||
04/19 03:44:06 PM: Update 7982: task wsj, batch 982 (7982): perplexity: 120.0004, wsj_loss: 4.7875 ||
04/19 03:44:11 PM: Update 5782: task toronto_lm, batch 777 (5751): perplexity: 91.7817, toronto_lm_loss: 4.5194 ||
04/19 03:44:16 PM: Update 7998: task wsj, batch 998 (7998): perplexity: 120.0014, wsj_loss: 4.7875 ||
04/19 03:44:18 PM: ***** Pass 8000 / Epoch 8 *****
04/19 03:44:18 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 03:44:18 PM: Validating...
04/19 03:44:22 PM: Update 5796: task toronto_lm, batch 791 (5765): perplexity: 92.0277, toronto_lm_loss: 4.5221 ||
04/19 03:44:24 PM: Best model found for wsj.
04/19 03:44:24 PM: Best model found for micro.
04/19 03:44:24 PM: Best model found for macro.
04/19 03:44:24 PM: Advancing scheduler.
04/19 03:44:24 PM: 	Best macro_avg: 113.353
04/19 03:44:24 PM: 	# bad epochs: 0
04/19 03:44:24 PM: Statistic: wsj_loss
04/19 03:44:24 PM: 	training: 4.787659
04/19 03:44:24 PM: 	validation: 4.730510
04/19 03:44:24 PM: Statistic: macro_avg
04/19 03:44:24 PM: 	validation: 113.353344
04/19 03:44:24 PM: Statistic: micro_avg
04/19 03:44:24 PM: 	validation: 113.353344
04/19 03:44:24 PM: Statistic: wsj_perplexity
04/19 03:44:24 PM: 	training: 120.020073
04/19 03:44:24 PM: 	validation: 113.353344
04/19 03:44:24 PM: global_lr: 0.003000
04/19 03:44:24 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 03:44:27 PM: Update 8004: task wsj, batch 4 (8004): perplexity: 127.8966, wsj_loss: 4.8512 ||
04/19 03:44:32 PM: Update 5809: task toronto_lm, batch 804 (5778): perplexity: 92.2743, toronto_lm_loss: 4.5248 ||
04/19 03:44:37 PM: Update 8020: task wsj, batch 20 (8020): perplexity: 119.3898, wsj_loss: 4.7824 ||
04/19 03:44:43 PM: Update 5823: task toronto_lm, batch 818 (5792): perplexity: 92.3562, toronto_lm_loss: 4.5257 ||
04/19 03:44:48 PM: Update 8036: task wsj, batch 36 (8036): perplexity: 117.3117, wsj_loss: 4.7648 ||
04/19 03:44:53 PM: Update 5837: task toronto_lm, batch 832 (5806): perplexity: 92.5099, toronto_lm_loss: 4.5273 ||
04/19 03:44:58 PM: Update 8044: task wsj, batch 44 (8044): perplexity: 116.9768, wsj_loss: 4.7620 ||
04/19 03:45:03 PM: Update 5850: task toronto_lm, batch 845 (5819): perplexity: 92.6067, toronto_lm_loss: 4.5284 ||
04/19 03:45:08 PM: Update 8060: task wsj, batch 60 (8060): perplexity: 116.6168, wsj_loss: 4.7589 ||
04/19 03:45:14 PM: Update 5864: task toronto_lm, batch 859 (5833): perplexity: 92.8174, toronto_lm_loss: 4.5306 ||
04/19 03:45:19 PM: Update 8076: task wsj, batch 76 (8076): perplexity: 115.9894, wsj_loss: 4.7535 ||
04/19 03:45:24 PM: Update 5877: task toronto_lm, batch 872 (5846): perplexity: 92.9304, toronto_lm_loss: 4.5319 ||
04/19 03:45:29 PM: Update 8092: task wsj, batch 92 (8092): perplexity: 115.6864, wsj_loss: 4.7509 ||
04/19 03:45:35 PM: Update 5891: task toronto_lm, batch 886 (5860): perplexity: 93.0873, toronto_lm_loss: 4.5335 ||
04/19 03:45:40 PM: Update 8108: task wsj, batch 108 (8108): perplexity: 114.4391, wsj_loss: 4.7400 ||
04/19 03:45:45 PM: Update 5904: task toronto_lm, batch 899 (5873): perplexity: 93.2125, toronto_lm_loss: 4.5349 ||
04/19 03:45:50 PM: Update 8124: task wsj, batch 124 (8124): perplexity: 114.0241, wsj_loss: 4.7364 ||
04/19 03:45:55 PM: Update 5917: task toronto_lm, batch 912 (5886): perplexity: 93.3047, toronto_lm_loss: 4.5359 ||
04/19 03:46:00 PM: Update 8140: task wsj, batch 140 (8140): perplexity: 113.4987, wsj_loss: 4.7318 ||
04/19 03:46:05 PM: Update 5930: task toronto_lm, batch 925 (5899): perplexity: 93.4288, toronto_lm_loss: 4.5372 ||
04/19 03:46:11 PM: Update 8156: task wsj, batch 156 (8156): perplexity: 113.7492, wsj_loss: 4.7340 ||
04/19 03:46:15 PM: Update 5943: task toronto_lm, batch 938 (5912): perplexity: 93.5441, toronto_lm_loss: 4.5384 ||
04/19 03:46:21 PM: Update 8172: task wsj, batch 172 (8172): perplexity: 113.6721, wsj_loss: 4.7333 ||
04/19 03:46:26 PM: Update 5957: task toronto_lm, batch 952 (5926): perplexity: 93.6435, toronto_lm_loss: 4.5395 ||
04/19 03:46:31 PM: Update 8179: task wsj, batch 179 (8179): perplexity: 113.8754, wsj_loss: 4.7351 ||
04/19 03:46:36 PM: Update 5970: task toronto_lm, batch 965 (5939): perplexity: 93.7032, toronto_lm_loss: 4.5401 ||
04/19 03:46:42 PM: Update 8195: task wsj, batch 195 (8195): perplexity: 113.6692, wsj_loss: 4.7333 ||
04/19 03:46:46 PM: Update 5983: task toronto_lm, batch 978 (5952): perplexity: 93.7106, toronto_lm_loss: 4.5402 ||
04/19 03:46:52 PM: Update 8211: task wsj, batch 211 (8211): perplexity: 114.2443, wsj_loss: 4.7383 ||
04/19 03:46:56 PM: Update 5996: task toronto_lm, batch 991 (5965): perplexity: 93.7187, toronto_lm_loss: 4.5403 ||
04/19 03:46:59 PM: ***** Pass 6000 / Epoch 6 *****
04/19 03:46:59 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 03:46:59 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 03:46:59 PM: Validating...
04/19 03:47:02 PM: Update 8227: task wsj, batch 227 (8227): perplexity: 114.6819, wsj_loss: 4.7422 ||
04/19 03:47:06 PM: Batch 28/140: perplexity: 123.1642, toronto_lm_loss: 4.8135 || , for evaluation data
04/19 03:47:13 PM: Update 8243: task wsj, batch 243 (8243): perplexity: 114.6652, wsj_loss: 4.7420 ||
04/19 03:47:16 PM: Batch 67/140: perplexity: 119.7105, toronto_lm_loss: 4.7851 || , for evaluation data
04/19 03:47:23 PM: Update 8259: task wsj, batch 259 (8259): perplexity: 114.6743, wsj_loss: 4.7421 ||
04/19 03:47:26 PM: Batch 106/140: perplexity: 111.5167, toronto_lm_loss: 4.7142 || , for evaluation data
04/19 03:47:34 PM: Update 8275: task wsj, batch 275 (8275): perplexity: 115.1357, wsj_loss: 4.7461 ||
04/19 03:47:35 PM: Batch 1/66: perplexity: 565.8208, wsj_loss: 6.3383 || , for evaluation data
04/19 03:47:44 PM: Update 8291: task wsj, batch 291 (8291): perplexity: 115.4554, wsj_loss: 4.7489 ||
04/19 03:47:45 PM: Batch 40/66: perplexity: 410.1077, wsj_loss: 6.0164 || , for evaluation data
04/19 03:47:52 PM: Best model found for toronto_lm.
04/19 03:47:52 PM: Best model found for wsj.
04/19 03:47:52 PM: Best model found for micro.
04/19 03:47:52 PM: Best model found for macro.
04/19 03:47:52 PM: Advancing scheduler.
04/19 03:47:52 PM: 	Best macro_avg: -0.169
04/19 03:47:52 PM: 	# bad epochs: 0
04/19 03:47:52 PM: Statistic: toronto_lm_loss
04/19 03:47:52 PM: 	training: 4.540423
04/19 03:47:52 PM: 	validation: 4.630401
04/19 03:47:52 PM: Statistic: wsj_loss
04/19 03:47:52 PM: 	training: 5.985577
04/19 03:47:52 PM: 	validation: 6.012017
04/19 03:47:52 PM: Statistic: macro_avg
04/19 03:47:52 PM: 	validation: -0.169168
04/19 03:47:52 PM: Statistic: micro_avg
04/19 03:47:52 PM: 	validation: -0.202967
04/19 03:47:52 PM: Statistic: toronto_lm_perplexity
04/19 03:47:52 PM: 	training: 93.730420
04/19 03:47:52 PM: 	validation: 102.555198
04/19 03:47:52 PM: Statistic: wsj_perplexity
04/19 03:47:52 PM: 	training: 397.652018
04/19 03:47:52 PM: 	validation: 408.306205
04/19 03:47:52 PM: global_lr: 0.001000
04/19 03:47:52 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 03:47:53 PM: Update 6001: task toronto_lm, batch 1 (5970): perplexity: 106.1529, toronto_lm_loss: 4.6649 ||
04/19 03:47:55 PM: Update 8307: task wsj, batch 307 (8307): perplexity: 115.5993, wsj_loss: 4.7501 ||
04/19 03:48:04 PM: Update 6015: task toronto_lm, batch 15 (5984): perplexity: 95.9309, toronto_lm_loss: 4.5636 ||
04/19 03:48:05 PM: Update 8323: task wsj, batch 323 (8323): perplexity: 115.6937, wsj_loss: 4.7509 ||
04/19 03:48:14 PM: Update 6029: task toronto_lm, batch 29 (5998): perplexity: 97.5122, toronto_lm_loss: 4.5800 ||
04/19 03:48:18 PM: Update 8334: task wsj, batch 334 (8334): perplexity: 115.7704, wsj_loss: 4.7516 ||
04/19 03:48:24 PM: Update 6042: task toronto_lm, batch 42 (6011): perplexity: 97.8471, toronto_lm_loss: 4.5834 ||
04/19 03:48:28 PM: Update 8350: task wsj, batch 350 (8350): perplexity: 115.7661, wsj_loss: 4.7516 ||
04/19 03:48:35 PM: Update 6056: task toronto_lm, batch 56 (6025): perplexity: 97.9223, toronto_lm_loss: 4.5842 ||
04/19 03:48:39 PM: Update 8366: task wsj, batch 366 (8366): perplexity: 115.5687, wsj_loss: 4.7499 ||
04/19 03:48:46 PM: Update 6070: task toronto_lm, batch 70 (6039): perplexity: 97.7217, toronto_lm_loss: 4.5821 ||
04/19 03:48:49 PM: Update 8382: task wsj, batch 382 (8382): perplexity: 115.2316, wsj_loss: 4.7469 ||
04/19 03:48:56 PM: Update 6083: task toronto_lm, batch 83 (6052): perplexity: 97.2991, toronto_lm_loss: 4.5778 ||
04/19 03:49:00 PM: Update 8398: task wsj, batch 398 (8398): perplexity: 114.9957, wsj_loss: 4.7449 ||
04/19 03:49:07 PM: Update 6097: task toronto_lm, batch 97 (6066): perplexity: 96.5084, toronto_lm_loss: 4.5696 ||
04/19 03:49:10 PM: Update 8414: task wsj, batch 414 (8414): perplexity: 114.7380, wsj_loss: 4.7427 ||
04/19 03:49:17 PM: Update 6111: task toronto_lm, batch 111 (6080): perplexity: 96.8223, toronto_lm_loss: 4.5729 ||
04/19 03:49:21 PM: Update 8430: task wsj, batch 430 (8430): perplexity: 114.6533, wsj_loss: 4.7419 ||
04/19 03:49:28 PM: Update 6125: task toronto_lm, batch 125 (6094): perplexity: 96.7636, toronto_lm_loss: 4.5723 ||
04/19 03:49:31 PM: Update 8446: task wsj, batch 446 (8446): perplexity: 114.6349, wsj_loss: 4.7418 ||
04/19 03:49:39 PM: Update 6139: task toronto_lm, batch 139 (6108): perplexity: 96.5685, toronto_lm_loss: 4.5703 ||
04/19 03:49:42 PM: Update 8462: task wsj, batch 462 (8462): perplexity: 114.4903, wsj_loss: 4.7405 ||
04/19 03:49:49 PM: Update 6152: task toronto_lm, batch 152 (6121): perplexity: 96.7470, toronto_lm_loss: 4.5721 ||
04/19 03:49:52 PM: Update 8471: task wsj, batch 471 (8471): perplexity: 114.5350, wsj_loss: 4.7409 ||
04/19 03:49:59 PM: Update 6165: task toronto_lm, batch 165 (6134): perplexity: 96.8473, toronto_lm_loss: 4.5731 ||
04/19 03:50:03 PM: Update 8487: task wsj, batch 487 (8487): perplexity: 114.4183, wsj_loss: 4.7399 ||
04/19 03:50:10 PM: Update 6179: task toronto_lm, batch 179 (6148): perplexity: 96.4911, toronto_lm_loss: 4.5695 ||
04/19 03:50:13 PM: Update 8503: task wsj, batch 503 (8503): perplexity: 114.4453, wsj_loss: 4.7401 ||
04/19 03:50:20 PM: Update 6193: task toronto_lm, batch 193 (6162): perplexity: 96.3540, toronto_lm_loss: 4.5680 ||
04/19 03:50:24 PM: Update 8519: task wsj, batch 519 (8519): perplexity: 114.4335, wsj_loss: 4.7400 ||
04/19 03:50:31 PM: Update 6207: task toronto_lm, batch 207 (6176): perplexity: 96.1096, toronto_lm_loss: 4.5655 ||
04/19 03:50:34 PM: Update 8535: task wsj, batch 535 (8535): perplexity: 114.5495, wsj_loss: 4.7410 ||
04/19 03:50:42 PM: Update 6221: task toronto_lm, batch 221 (6190): perplexity: 95.9363, toronto_lm_loss: 4.5637 ||
04/19 03:50:45 PM: Update 8551: task wsj, batch 551 (8551): perplexity: 114.4405, wsj_loss: 4.7401 ||
04/19 03:50:52 PM: Update 6234: task toronto_lm, batch 234 (6203): perplexity: 95.5929, toronto_lm_loss: 4.5601 ||
04/19 03:50:54 PM: Update 6236: task wsj, batch 1 (32): perplexity: 415.2357, wsj_loss: 6.0288 ||
04/19 03:50:55 PM: Update 8567: task wsj, batch 567 (8567): perplexity: 114.5777, wsj_loss: 4.7413 ||
04/19 03:51:02 PM: Update 6247: task toronto_lm, batch 246 (6215): perplexity: 95.6485, toronto_lm_loss: 4.5607 ||
04/19 03:51:05 PM: Update 8583: task wsj, batch 583 (8583): perplexity: 114.7702, wsj_loss: 4.7429 ||
04/19 03:51:13 PM: Update 6261: task toronto_lm, batch 260 (6229): perplexity: 95.4634, toronto_lm_loss: 4.5587 ||
04/19 03:51:16 PM: Update 8599: task wsj, batch 599 (8599): perplexity: 114.7577, wsj_loss: 4.7428 ||
04/19 03:51:23 PM: Update 6275: task toronto_lm, batch 274 (6243): perplexity: 95.3828, toronto_lm_loss: 4.5579 ||
04/19 03:51:26 PM: Update 8615: task wsj, batch 615 (8615): perplexity: 114.9141, wsj_loss: 4.7442 ||
04/19 03:51:27 PM: Update 6280: task wsj, batch 2 (33): perplexity: 401.7669, wsj_loss: 5.9959 ||
04/19 03:51:39 PM: Update 8626: task wsj, batch 626 (8626): perplexity: 114.9853, wsj_loss: 4.7448 ||
04/19 03:51:39 PM: Update 6285: task toronto_lm, batch 282 (6251): perplexity: 95.4851, toronto_lm_loss: 4.5590 ||
04/19 03:51:43 PM: Update 6290: task wsj, batch 4 (35): perplexity: 368.2807, wsj_loss: 5.9088 ||
04/19 03:51:50 PM: Update 8642: task wsj, batch 642 (8642): perplexity: 114.9743, wsj_loss: 4.7447 ||
04/19 03:51:50 PM: Update 6299: task toronto_lm, batch 295 (6264): perplexity: 97.1063, toronto_lm_loss: 4.5758 ||
04/19 03:52:00 PM: Update 8658: task wsj, batch 658 (8658): perplexity: 114.7873, wsj_loss: 4.7431 ||
04/19 03:52:01 PM: Update 6313: task toronto_lm, batch 309 (6278): perplexity: 99.0049, toronto_lm_loss: 4.5952 ||
04/19 03:52:10 PM: Update 8674: task wsj, batch 674 (8674): perplexity: 114.7991, wsj_loss: 4.7432 ||
04/19 03:52:12 PM: Update 6327: task toronto_lm, batch 323 (6292): perplexity: 100.5803, toronto_lm_loss: 4.6110 ||
04/19 03:52:21 PM: Update 8690: task wsj, batch 690 (8690): perplexity: 114.6398, wsj_loss: 4.7418 ||
04/19 03:52:22 PM: Update 6341: task toronto_lm, batch 337 (6306): perplexity: 101.7562, toronto_lm_loss: 4.6226 ||
04/19 03:52:31 PM: Update 8706: task wsj, batch 706 (8706): perplexity: 114.5901, wsj_loss: 4.7414 ||
04/19 03:52:33 PM: Update 6355: task toronto_lm, batch 351 (6320): perplexity: 102.5396, toronto_lm_loss: 4.6302 ||
04/19 03:52:42 PM: Update 8722: task wsj, batch 722 (8722): perplexity: 114.4007, wsj_loss: 4.7397 ||
04/19 03:52:44 PM: Update 6369: task toronto_lm, batch 365 (6334): perplexity: 103.1948, toronto_lm_loss: 4.6366 ||
04/19 03:52:52 PM: Update 8738: task wsj, batch 738 (8738): perplexity: 114.2552, wsj_loss: 4.7384 ||
04/19 03:52:55 PM: Update 6383: task toronto_lm, batch 379 (6348): perplexity: 103.8018, toronto_lm_loss: 4.6425 ||
04/19 03:53:02 PM: Update 8754: task wsj, batch 754 (8754): perplexity: 114.1407, wsj_loss: 4.7374 ||
04/19 03:53:05 PM: Update 6397: task toronto_lm, batch 393 (6362): perplexity: 104.2701, toronto_lm_loss: 4.6470 ||
04/19 03:53:13 PM: Update 8762: task wsj, batch 762 (8762): perplexity: 114.1034, wsj_loss: 4.7371 ||
04/19 03:53:16 PM: Update 6411: task toronto_lm, batch 407 (6376): perplexity: 104.7982, toronto_lm_loss: 4.6520 ||
04/19 03:53:23 PM: Update 8778: task wsj, batch 778 (8778): perplexity: 114.1687, wsj_loss: 4.7377 ||
04/19 03:53:27 PM: Update 6425: task toronto_lm, batch 421 (6390): perplexity: 105.1779, toronto_lm_loss: 4.6557 ||
04/19 03:53:33 PM: Update 8794: task wsj, batch 794 (8794): perplexity: 114.1355, wsj_loss: 4.7374 ||
04/19 03:53:37 PM: Update 6438: task toronto_lm, batch 434 (6403): perplexity: 105.3629, toronto_lm_loss: 4.6574 ||
04/19 03:53:44 PM: Update 8810: task wsj, batch 810 (8810): perplexity: 114.2519, wsj_loss: 4.7384 ||
04/19 03:53:47 PM: Update 6452: task toronto_lm, batch 448 (6417): perplexity: 105.4533, toronto_lm_loss: 4.6583 ||
04/19 03:53:54 PM: Update 8826: task wsj, batch 826 (8826): perplexity: 114.2504, wsj_loss: 4.7384 ||
04/19 03:53:58 PM: Update 6466: task toronto_lm, batch 462 (6431): perplexity: 105.8502, toronto_lm_loss: 4.6620 ||
04/19 03:54:05 PM: Update 8842: task wsj, batch 842 (8842): perplexity: 114.2129, wsj_loss: 4.7381 ||
04/19 03:54:09 PM: Update 6480: task toronto_lm, batch 476 (6445): perplexity: 106.1496, toronto_lm_loss: 4.6648 ||
04/19 03:54:15 PM: Update 8858: task wsj, batch 858 (8858): perplexity: 114.2168, wsj_loss: 4.7381 ||
04/19 03:54:19 PM: Update 6493: task toronto_lm, batch 489 (6458): perplexity: 106.2275, toronto_lm_loss: 4.6656 ||
04/19 03:54:26 PM: Update 8874: task wsj, batch 874 (8874): perplexity: 114.2149, wsj_loss: 4.7381 ||
04/19 03:54:30 PM: Update 6507: task toronto_lm, batch 503 (6472): perplexity: 106.3891, toronto_lm_loss: 4.6671 ||
04/19 03:54:36 PM: Update 8890: task wsj, batch 890 (8890): perplexity: 114.1946, wsj_loss: 4.7379 ||
04/19 03:54:40 PM: Update 6521: task toronto_lm, batch 517 (6486): perplexity: 106.5154, toronto_lm_loss: 4.6683 ||
04/19 03:54:47 PM: Update 8906: task wsj, batch 906 (8906): perplexity: 114.2549, wsj_loss: 4.7384 ||
04/19 03:54:51 PM: Update 6535: task toronto_lm, batch 531 (6500): perplexity: 106.6942, toronto_lm_loss: 4.6700 ||
04/19 03:55:00 PM: Update 8918: task wsj, batch 918 (8918): perplexity: 114.1981, wsj_loss: 4.7379 ||
04/19 03:55:02 PM: Update 6549: task toronto_lm, batch 545 (6514): perplexity: 106.6512, toronto_lm_loss: 4.6696 ||
04/19 03:55:10 PM: Update 8934: task wsj, batch 934 (8934): perplexity: 114.0889, wsj_loss: 4.7370 ||
04/19 03:55:12 PM: Update 6563: task toronto_lm, batch 559 (6528): perplexity: 106.8029, toronto_lm_loss: 4.6710 ||
04/19 03:55:21 PM: Update 8950: task wsj, batch 950 (8950): perplexity: 114.0678, wsj_loss: 4.7368 ||
04/19 03:55:22 PM: Update 6576: task toronto_lm, batch 572 (6541): perplexity: 106.7973, toronto_lm_loss: 4.6709 ||
04/19 03:55:31 PM: Update 8966: task wsj, batch 966 (8966): perplexity: 113.9108, wsj_loss: 4.7354 ||
04/19 03:55:32 PM: Update 6589: task toronto_lm, batch 585 (6554): perplexity: 106.9658, toronto_lm_loss: 4.6725 ||
04/19 03:55:42 PM: Update 8982: task wsj, batch 982 (8982): perplexity: 113.7571, wsj_loss: 4.7341 ||
04/19 03:55:43 PM: Update 6603: task toronto_lm, batch 599 (6568): perplexity: 106.8631, toronto_lm_loss: 4.6715 ||
04/19 03:55:52 PM: Update 8998: task wsj, batch 998 (8998): perplexity: 113.6611, wsj_loss: 4.7332 ||
04/19 03:55:53 PM: Update 6616: task toronto_lm, batch 612 (6581): perplexity: 106.9563, toronto_lm_loss: 4.6724 ||
04/19 03:55:53 PM: ***** Pass 9000 / Epoch 9 *****
04/19 03:55:53 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 03:55:53 PM: Validating...
04/19 03:55:59 PM: Best model found for wsj.
04/19 03:55:59 PM: Best model found for micro.
04/19 03:55:59 PM: Best model found for macro.
04/19 03:55:59 PM: Advancing scheduler.
04/19 03:55:59 PM: 	Best macro_avg: 110.389
04/19 03:55:59 PM: 	# bad epochs: 0
04/19 03:55:59 PM: Statistic: wsj_loss
04/19 03:55:59 PM: 	training: 4.733145
04/19 03:55:59 PM: 	validation: 4.704012
04/19 03:55:59 PM: Statistic: macro_avg
04/19 03:55:59 PM: 	validation: 110.389114
04/19 03:55:59 PM: Statistic: micro_avg
04/19 03:55:59 PM: 	validation: 110.389114
04/19 03:55:59 PM: Statistic: wsj_perplexity
04/19 03:55:59 PM: 	training: 113.652384
04/19 03:55:59 PM: 	validation: 110.389114
04/19 03:55:59 PM: global_lr: 0.003000
04/19 03:55:59 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 03:56:02 PM: Update 9005: task wsj, batch 5 (9005): perplexity: 109.1675, wsj_loss: 4.6929 ||
04/19 03:56:04 PM: Update 6630: task toronto_lm, batch 626 (6595): perplexity: 107.0715, toronto_lm_loss: 4.6735 ||
04/19 03:56:13 PM: Update 9021: task wsj, batch 21 (9021): perplexity: 108.6906, wsj_loss: 4.6885 ||
04/19 03:56:14 PM: Update 6643: task toronto_lm, batch 639 (6608): perplexity: 107.1351, toronto_lm_loss: 4.6741 ||
04/19 03:56:23 PM: Update 9037: task wsj, batch 37 (9037): perplexity: 109.1046, wsj_loss: 4.6923 ||
04/19 03:56:24 PM: Update 6656: task toronto_lm, batch 652 (6621): perplexity: 107.1599, toronto_lm_loss: 4.6743 ||
04/19 03:56:35 PM: Update 6670: task toronto_lm, batch 666 (6635): perplexity: 107.0969, toronto_lm_loss: 4.6737 ||
04/19 03:56:39 PM: Update 9053: task wsj, batch 53 (9053): perplexity: 108.4954, wsj_loss: 4.6867 ||
04/19 03:56:45 PM: Update 6684: task toronto_lm, batch 680 (6649): perplexity: 107.2432, toronto_lm_loss: 4.6751 ||
04/19 03:56:50 PM: Update 9069: task wsj, batch 69 (9069): perplexity: 110.1188, wsj_loss: 4.7016 ||
04/19 03:56:56 PM: Update 6698: task toronto_lm, batch 694 (6663): perplexity: 107.1914, toronto_lm_loss: 4.6746 ||
04/19 03:57:00 PM: Update 9085: task wsj, batch 85 (9085): perplexity: 111.1414, wsj_loss: 4.7108 ||
04/19 03:57:07 PM: Update 6712: task toronto_lm, batch 708 (6677): perplexity: 107.1800, toronto_lm_loss: 4.6745 ||
04/19 03:57:10 PM: Update 9101: task wsj, batch 101 (9101): perplexity: 111.3992, wsj_loss: 4.7131 ||
04/19 03:57:14 PM: Update 6721: task wsj, batch 5 (36): perplexity: 349.9840, wsj_loss: 5.8579 ||
04/19 03:57:17 PM: Update 6725: task toronto_lm, batch 720 (6689): perplexity: 107.1205, toronto_lm_loss: 4.6740 ||
04/19 03:57:21 PM: Update 9117: task wsj, batch 117 (9117): perplexity: 111.5971, wsj_loss: 4.7149 ||
04/19 03:57:28 PM: Update 6739: task toronto_lm, batch 734 (6703): perplexity: 106.9805, toronto_lm_loss: 4.6726 ||
04/19 03:57:31 PM: Update 9133: task wsj, batch 133 (9133): perplexity: 110.9975, wsj_loss: 4.7095 ||
04/19 03:57:38 PM: Update 6753: task toronto_lm, batch 748 (6717): perplexity: 106.9083, toronto_lm_loss: 4.6720 ||
04/19 03:57:42 PM: Update 9149: task wsj, batch 149 (9149): perplexity: 111.3478, wsj_loss: 4.7127 ||
04/19 03:57:49 PM: Update 6767: task toronto_lm, batch 762 (6731): perplexity: 106.8872, toronto_lm_loss: 4.6718 ||
04/19 03:57:52 PM: Update 9165: task wsj, batch 165 (9165): perplexity: 111.4718, wsj_loss: 4.7138 ||
04/19 03:58:00 PM: Update 6781: task toronto_lm, batch 776 (6745): perplexity: 106.7988, toronto_lm_loss: 4.6709 ||
04/19 03:58:02 PM: Update 9181: task wsj, batch 181 (9181): perplexity: 111.8442, wsj_loss: 4.7171 ||
04/19 03:58:10 PM: Update 6795: task toronto_lm, batch 790 (6759): perplexity: 106.6569, toronto_lm_loss: 4.6696 ||
04/19 03:58:13 PM: Update 9197: task wsj, batch 197 (9197): perplexity: 111.9747, wsj_loss: 4.7183 ||
04/19 03:58:21 PM: Update 6809: task toronto_lm, batch 804 (6773): perplexity: 106.5244, toronto_lm_loss: 4.6684 ||
04/19 03:58:27 PM: Update 9210: task wsj, batch 210 (9210): perplexity: 112.0893, wsj_loss: 4.7193 ||
04/19 03:58:32 PM: Update 6823: task toronto_lm, batch 818 (6787): perplexity: 106.5237, toronto_lm_loss: 4.6684 ||
04/19 03:58:37 PM: Update 9226: task wsj, batch 226 (9226): perplexity: 111.7858, wsj_loss: 4.7166 ||
04/19 03:58:43 PM: Update 6837: task toronto_lm, batch 832 (6801): perplexity: 106.4269, toronto_lm_loss: 4.6675 ||
04/19 03:58:48 PM: Update 9242: task wsj, batch 242 (9242): perplexity: 111.4745, wsj_loss: 4.7138 ||
04/19 03:58:53 PM: Update 6851: task toronto_lm, batch 846 (6815): perplexity: 106.3215, toronto_lm_loss: 4.6665 ||
04/19 03:58:58 PM: Update 9258: task wsj, batch 258 (9258): perplexity: 110.9049, wsj_loss: 4.7087 ||
04/19 03:59:03 PM: Update 6864: task toronto_lm, batch 859 (6828): perplexity: 106.2643, toronto_lm_loss: 4.6659 ||
04/19 03:59:08 PM: Update 9274: task wsj, batch 274 (9274): perplexity: 110.5694, wsj_loss: 4.7056 ||
04/19 03:59:14 PM: Update 6878: task toronto_lm, batch 873 (6842): perplexity: 106.2148, toronto_lm_loss: 4.6655 ||
04/19 03:59:19 PM: Update 9290: task wsj, batch 290 (9290): perplexity: 110.4423, wsj_loss: 4.7045 ||
04/19 03:59:25 PM: Update 6892: task toronto_lm, batch 887 (6856): perplexity: 106.0870, toronto_lm_loss: 4.6643 ||
04/19 03:59:29 PM: Update 9306: task wsj, batch 306 (9306): perplexity: 110.3057, wsj_loss: 4.7033 ||
04/19 03:59:36 PM: Update 6906: task toronto_lm, batch 901 (6870): perplexity: 106.0596, toronto_lm_loss: 4.6640 ||
04/19 03:59:39 PM: Update 9322: task wsj, batch 322 (9322): perplexity: 110.1871, wsj_loss: 4.7022 ||
04/19 03:59:49 PM: Update 6912: task toronto_lm, batch 907 (6876): perplexity: 106.1119, toronto_lm_loss: 4.6645 ||
04/19 03:59:50 PM: Update 9338: task wsj, batch 338 (9338): perplexity: 110.1909, wsj_loss: 4.7022 ||
04/19 03:59:59 PM: Update 6926: task toronto_lm, batch 921 (6890): perplexity: 106.5342, toronto_lm_loss: 4.6685 ||
04/19 04:00:00 PM: Update 9347: task wsj, batch 347 (9347): perplexity: 110.0653, wsj_loss: 4.7011 ||
04/19 04:00:09 PM: Update 6939: task toronto_lm, batch 934 (6903): perplexity: 106.8023, toronto_lm_loss: 4.6710 ||
04/19 04:00:11 PM: Update 9363: task wsj, batch 363 (9363): perplexity: 109.9703, wsj_loss: 4.7002 ||
04/19 04:00:20 PM: Update 6953: task toronto_lm, batch 948 (6917): perplexity: 107.1878, toronto_lm_loss: 4.6746 ||
04/19 04:00:21 PM: Update 9379: task wsj, batch 379 (9379): perplexity: 109.9267, wsj_loss: 4.6998 ||
04/19 04:00:30 PM: Update 6966: task toronto_lm, batch 961 (6930): perplexity: 107.3464, toronto_lm_loss: 4.6761 ||
04/19 04:00:32 PM: Update 9395: task wsj, batch 395 (9395): perplexity: 110.0436, wsj_loss: 4.7009 ||
04/19 04:00:40 PM: Update 6979: task toronto_lm, batch 974 (6943): perplexity: 107.5654, toronto_lm_loss: 4.6781 ||
04/19 04:00:42 PM: Update 9411: task wsj, batch 411 (9411): perplexity: 110.2848, wsj_loss: 4.7031 ||
04/19 04:00:50 PM: Update 6992: task toronto_lm, batch 987 (6956): perplexity: 107.7987, toronto_lm_loss: 4.6803 ||
04/19 04:00:52 PM: Update 9427: task wsj, batch 427 (9427): perplexity: 110.3501, wsj_loss: 4.7037 ||
04/19 04:00:57 PM: ***** Pass 7000 / Epoch 7 *****
04/19 04:00:57 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 04:00:57 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 04:00:57 PM: Validating...
04/19 04:01:00 PM: Batch 15/140: perplexity: 116.4478, toronto_lm_loss: 4.7574 || , for evaluation data
04/19 04:01:03 PM: Update 9443: task wsj, batch 443 (9443): perplexity: 110.5431, wsj_loss: 4.7054 ||
04/19 04:01:11 PM: Batch 53/140: perplexity: 118.3036, toronto_lm_loss: 4.7733 || , for evaluation data
04/19 04:01:13 PM: Update 9459: task wsj, batch 459 (9459): perplexity: 110.5344, wsj_loss: 4.7053 ||
04/19 04:01:21 PM: Batch 91/140: perplexity: 109.9561, toronto_lm_loss: 4.7001 || , for evaluation data
04/19 04:01:23 PM: Update 9475: task wsj, batch 475 (9475): perplexity: 110.6914, wsj_loss: 4.7067 ||
04/19 04:01:31 PM: Batch 129/140: perplexity: 102.8399, toronto_lm_loss: 4.6332 || , for evaluation data
04/19 04:01:34 PM: Batch 1/66: perplexity: 519.9413, wsj_loss: 6.2537 || , for evaluation data
04/19 04:01:34 PM: Update 9491: task wsj, batch 491 (9491): perplexity: 110.7627, wsj_loss: 4.7074 ||
04/19 04:01:44 PM: Batch 40/66: perplexity: 390.7857, wsj_loss: 5.9682 || , for evaluation data
04/19 04:01:47 PM: Update 9502: task wsj, batch 502 (9502): perplexity: 110.6997, wsj_loss: 4.7068 ||
04/19 04:01:51 PM: Best model found for toronto_lm.
04/19 04:01:51 PM: Best model found for wsj.
04/19 04:01:51 PM: Best model found for micro.
04/19 04:01:51 PM: Best model found for macro.
04/19 04:01:51 PM: Advancing scheduler.
04/19 04:01:51 PM: 	Best macro_avg: -0.126
04/19 04:01:51 PM: 	# bad epochs: 0
04/19 04:01:51 PM: Statistic: toronto_lm_loss
04/19 04:01:51 PM: 	training: 4.680894
04/19 04:01:51 PM: 	validation: 4.609483
04/19 04:01:51 PM: Statistic: wsj_loss
04/19 04:01:51 PM: 	training: 5.857888
04/19 04:01:51 PM: 	validation: 5.960346
04/19 04:01:51 PM: Statistic: macro_avg
04/19 04:01:51 PM: 	validation: -0.125921
04/19 04:01:51 PM: Statistic: micro_avg
04/19 04:01:51 PM: 	validation: -0.176604
04/19 04:01:51 PM: Statistic: toronto_lm_perplexity
04/19 04:01:51 PM: 	training: 107.866451
04/19 04:01:51 PM: 	validation: 100.432244
04/19 04:01:51 PM: Statistic: wsj_perplexity
04/19 04:01:51 PM: 	training: 349.984040
04/19 04:01:51 PM: 	validation: 387.744190
04/19 04:01:51 PM: global_lr: 0.001000
04/19 04:01:51 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 04:01:52 PM: Update 7001: task toronto_lm, batch 1 (6965): perplexity: 142.3460, toronto_lm_loss: 4.9583 ||
04/19 04:01:57 PM: Update 9518: task wsj, batch 518 (9518): perplexity: 110.4407, wsj_loss: 4.7045 ||
04/19 04:02:02 PM: Update 7014: task toronto_lm, batch 14 (6978): perplexity: 115.2349, toronto_lm_loss: 4.7470 ||
04/19 04:02:07 PM: Update 9534: task wsj, batch 534 (9534): perplexity: 110.3785, wsj_loss: 4.7039 ||
04/19 04:02:12 PM: Update 7027: task toronto_lm, batch 27 (6991): perplexity: 117.8566, toronto_lm_loss: 4.7695 ||
04/19 04:02:18 PM: Update 9550: task wsj, batch 550 (9550): perplexity: 110.1401, wsj_loss: 4.7018 ||
04/19 04:02:22 PM: Update 7040: task toronto_lm, batch 40 (7004): perplexity: 117.0980, toronto_lm_loss: 4.7630 ||
04/19 04:02:28 PM: Update 9566: task wsj, batch 566 (9566): perplexity: 110.0827, wsj_loss: 4.7012 ||
04/19 04:02:32 PM: Update 7053: task toronto_lm, batch 53 (7017): perplexity: 118.9506, toronto_lm_loss: 4.7787 ||
04/19 04:02:38 PM: Update 9582: task wsj, batch 582 (9582): perplexity: 110.0271, wsj_loss: 4.7007 ||
04/19 04:02:43 PM: Update 7066: task toronto_lm, batch 66 (7030): perplexity: 120.1866, toronto_lm_loss: 4.7890 ||
04/19 04:02:46 PM: Update 7070: task wsj, batch 1 (37): perplexity: 420.1346, wsj_loss: 6.0406 ||
04/19 04:02:49 PM: Update 9598: task wsj, batch 598 (9598): perplexity: 109.9162, wsj_loss: 4.6997 ||
04/19 04:02:53 PM: Update 7079: task toronto_lm, batch 78 (7042): perplexity: 119.1840, toronto_lm_loss: 4.7807 ||
04/19 04:02:59 PM: Update 9614: task wsj, batch 614 (9614): perplexity: 109.8270, wsj_loss: 4.6989 ||
04/19 04:03:03 PM: Update 7092: task toronto_lm, batch 91 (7055): perplexity: 118.7172, toronto_lm_loss: 4.7767 ||
04/19 04:03:10 PM: Update 9630: task wsj, batch 630 (9630): perplexity: 109.6538, wsj_loss: 4.6973 ||
04/19 04:03:13 PM: Update 7105: task toronto_lm, batch 104 (7068): perplexity: 118.4860, toronto_lm_loss: 4.7748 ||
04/19 04:03:20 PM: Update 9638: task wsj, batch 638 (9638): perplexity: 109.6294, wsj_loss: 4.6971 ||
04/19 04:03:23 PM: Update 7118: task toronto_lm, batch 117 (7081): perplexity: 119.2362, toronto_lm_loss: 4.7811 ||
04/19 04:03:30 PM: Update 9654: task wsj, batch 654 (9654): perplexity: 109.6498, wsj_loss: 4.6973 ||
04/19 04:03:33 PM: Update 7131: task toronto_lm, batch 130 (7094): perplexity: 118.0046, toronto_lm_loss: 4.7707 ||
04/19 04:03:41 PM: Update 9670: task wsj, batch 670 (9670): perplexity: 109.7135, wsj_loss: 4.6979 ||
04/19 04:03:43 PM: Update 7144: task toronto_lm, batch 143 (7107): perplexity: 117.4593, toronto_lm_loss: 4.7661 ||
04/19 04:03:51 PM: Update 9686: task wsj, batch 686 (9686): perplexity: 109.7240, wsj_loss: 4.6980 ||
04/19 04:03:53 PM: Update 7157: task toronto_lm, batch 156 (7120): perplexity: 117.2231, toronto_lm_loss: 4.7641 ||
04/19 04:04:01 PM: Update 9702: task wsj, batch 702 (9702): perplexity: 109.6815, wsj_loss: 4.6976 ||
04/19 04:04:03 PM: Update 7170: task toronto_lm, batch 169 (7133): perplexity: 116.2801, toronto_lm_loss: 4.7560 ||
04/19 04:04:12 PM: Update 9718: task wsj, batch 718 (9718): perplexity: 109.7905, wsj_loss: 4.6986 ||
04/19 04:04:13 PM: Update 7183: task toronto_lm, batch 182 (7146): perplexity: 116.3787, toronto_lm_loss: 4.7568 ||
04/19 04:04:22 PM: Update 9734: task wsj, batch 734 (9734): perplexity: 109.7952, wsj_loss: 4.6986 ||
04/19 04:04:23 PM: Update 7196: task toronto_lm, batch 195 (7159): perplexity: 115.8401, toronto_lm_loss: 4.7522 ||
04/19 04:04:32 PM: Update 9750: task wsj, batch 750 (9750): perplexity: 109.7296, wsj_loss: 4.6980 ||
04/19 04:04:34 PM: Update 7210: task toronto_lm, batch 209 (7173): perplexity: 115.4493, toronto_lm_loss: 4.7488 ||
04/19 04:04:43 PM: Update 9766: task wsj, batch 766 (9766): perplexity: 109.7690, wsj_loss: 4.6984 ||
04/19 04:04:44 PM: Update 7223: task toronto_lm, batch 222 (7186): perplexity: 115.7481, toronto_lm_loss: 4.7514 ||
04/19 04:04:53 PM: Update 9782: task wsj, batch 782 (9782): perplexity: 109.6661, wsj_loss: 4.6974 ||
04/19 04:04:54 PM: Update 7236: task toronto_lm, batch 235 (7199): perplexity: 115.4103, toronto_lm_loss: 4.7485 ||
04/19 04:05:04 PM: Update 7249: task toronto_lm, batch 248 (7212): perplexity: 114.9447, toronto_lm_loss: 4.7445 ||
04/19 04:05:06 PM: Update 9794: task wsj, batch 794 (9794): perplexity: 109.7789, wsj_loss: 4.6985 ||
04/19 04:05:14 PM: Update 7262: task toronto_lm, batch 261 (7225): perplexity: 115.0910, toronto_lm_loss: 4.7457 ||
04/19 04:05:17 PM: Update 9810: task wsj, batch 810 (9810): perplexity: 109.6980, wsj_loss: 4.6977 ||
04/19 04:05:25 PM: Update 7276: task toronto_lm, batch 275 (7239): perplexity: 114.7762, toronto_lm_loss: 4.7430 ||
04/19 04:05:27 PM: Update 9826: task wsj, batch 826 (9826): perplexity: 109.7104, wsj_loss: 4.6978 ||
04/19 04:05:36 PM: Update 7290: task toronto_lm, batch 289 (7253): perplexity: 114.3575, toronto_lm_loss: 4.7393 ||
04/19 04:05:38 PM: Update 9842: task wsj, batch 842 (9842): perplexity: 109.6633, wsj_loss: 4.6974 ||
04/19 04:05:47 PM: Update 7304: task toronto_lm, batch 303 (7267): perplexity: 114.2204, toronto_lm_loss: 4.7381 ||
04/19 04:05:48 PM: Update 9858: task wsj, batch 858 (9858): perplexity: 109.5110, wsj_loss: 4.6960 ||
04/19 04:05:57 PM: Update 7318: task toronto_lm, batch 317 (7281): perplexity: 114.1451, toronto_lm_loss: 4.7375 ||
04/19 04:05:58 PM: Update 9874: task wsj, batch 874 (9874): perplexity: 109.3875, wsj_loss: 4.6949 ||
04/19 04:06:07 PM: Update 7331: task toronto_lm, batch 330 (7294): perplexity: 113.9067, toronto_lm_loss: 4.7354 ||
04/19 04:06:09 PM: Update 9890: task wsj, batch 890 (9890): perplexity: 109.2592, wsj_loss: 4.6937 ||
04/19 04:06:18 PM: Update 7345: task toronto_lm, batch 344 (7308): perplexity: 113.8975, toronto_lm_loss: 4.7353 ||
04/19 04:06:19 PM: Update 9906: task wsj, batch 906 (9906): perplexity: 109.1338, wsj_loss: 4.6926 ||
04/19 04:06:29 PM: Update 7359: task toronto_lm, batch 358 (7322): perplexity: 114.0896, toronto_lm_loss: 4.7370 ||
04/19 04:06:29 PM: Update 9922: task wsj, batch 922 (9922): perplexity: 108.9897, wsj_loss: 4.6913 ||
04/19 04:06:39 PM: Update 7373: task toronto_lm, batch 372 (7336): perplexity: 113.9443, toronto_lm_loss: 4.7357 ||
04/19 04:06:40 PM: Update 9930: task wsj, batch 930 (9930): perplexity: 108.9974, wsj_loss: 4.6913 ||
04/19 04:06:50 PM: Update 9946: task wsj, batch 946 (9946): perplexity: 108.9609, wsj_loss: 4.6910 ||
04/19 04:06:50 PM: Update 7387: task toronto_lm, batch 386 (7350): perplexity: 113.5428, toronto_lm_loss: 4.7322 ||
04/19 04:07:00 PM: Update 9962: task wsj, batch 962 (9962): perplexity: 108.9948, wsj_loss: 4.6913 ||
04/19 04:07:01 PM: Update 7401: task toronto_lm, batch 400 (7364): perplexity: 113.3923, toronto_lm_loss: 4.7309 ||
04/19 04:07:11 PM: Update 9978: task wsj, batch 978 (9978): perplexity: 108.9992, wsj_loss: 4.6913 ||
04/19 04:07:11 PM: Update 7414: task toronto_lm, batch 413 (7377): perplexity: 113.0660, toronto_lm_loss: 4.7280 ||
04/19 04:07:21 PM: Update 9994: task wsj, batch 994 (9994): perplexity: 109.0069, wsj_loss: 4.6914 ||
04/19 04:07:22 PM: Update 7428: task toronto_lm, batch 427 (7391): perplexity: 112.7806, toronto_lm_loss: 4.7254 ||
04/19 04:07:25 PM: ***** Pass 10000 / Epoch 10 *****
04/19 04:07:25 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 04:07:25 PM: Validating...
04/19 04:07:31 PM: Best model found for wsj.
04/19 04:07:31 PM: Best model found for micro.
04/19 04:07:31 PM: Best model found for macro.
04/19 04:07:31 PM: Advancing scheduler.
04/19 04:07:31 PM: 	Best macro_avg: 109.286
04/19 04:07:31 PM: 	# bad epochs: 0
04/19 04:07:31 PM: Statistic: wsj_loss
04/19 04:07:31 PM: 	training: 4.691474
04/19 04:07:31 PM: 	validation: 4.693966
04/19 04:07:31 PM: Statistic: macro_avg
04/19 04:07:31 PM: 	validation: 109.285713
04/19 04:07:31 PM: Statistic: micro_avg
04/19 04:07:31 PM: 	validation: 109.285713
04/19 04:07:31 PM: Statistic: wsj_perplexity
04/19 04:07:31 PM: 	training: 109.013715
04/19 04:07:31 PM: 	validation: 109.285713
04/19 04:07:31 PM: global_lr: 0.003000
04/19 04:07:31 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 04:07:32 PM: Update 10001: task wsj, batch 1 (10001): perplexity: 109.3726, wsj_loss: 4.6948 ||
04/19 04:07:32 PM: Update 7442: task toronto_lm, batch 441 (7405): perplexity: 112.3315, toronto_lm_loss: 4.7215 ||
04/19 04:07:42 PM: Update 10017: task wsj, batch 17 (10017): perplexity: 107.1920, wsj_loss: 4.6746 ||
04/19 04:07:42 PM: Update 7455: task toronto_lm, batch 454 (7418): perplexity: 112.2902, toronto_lm_loss: 4.7211 ||
04/19 04:07:52 PM: Update 7468: task toronto_lm, batch 467 (7431): perplexity: 112.0973, toronto_lm_loss: 4.7194 ||
04/19 04:07:53 PM: Update 10033: task wsj, batch 33 (10033): perplexity: 105.9095, wsj_loss: 4.6626 ||
04/19 04:08:02 PM: Update 7481: task toronto_lm, batch 480 (7444): perplexity: 111.9677, toronto_lm_loss: 4.7182 ||
04/19 04:08:03 PM: Update 10049: task wsj, batch 49 (10049): perplexity: 107.9409, wsj_loss: 4.6816 ||
04/19 04:08:13 PM: Update 7495: task toronto_lm, batch 494 (7458): perplexity: 111.7754, toronto_lm_loss: 4.7165 ||
04/19 04:08:13 PM: Update 10065: task wsj, batch 65 (10065): perplexity: 108.6463, wsj_loss: 4.6881 ||
04/19 04:08:24 PM: Update 10081: task wsj, batch 81 (10081): perplexity: 108.9820, wsj_loss: 4.6912 ||
04/19 04:08:24 PM: Update 7509: task toronto_lm, batch 508 (7472): perplexity: 111.7115, toronto_lm_loss: 4.7159 ||
04/19 04:08:34 PM: Update 10088: task wsj, batch 88 (10088): perplexity: 109.0441, wsj_loss: 4.6918 ||
04/19 04:08:35 PM: Update 7523: task toronto_lm, batch 522 (7486): perplexity: 111.6347, toronto_lm_loss: 4.7152 ||
04/19 04:08:44 PM: Update 10104: task wsj, batch 104 (10104): perplexity: 108.3998, wsj_loss: 4.6858 ||
04/19 04:08:45 PM: Update 7537: task toronto_lm, batch 536 (7500): perplexity: 111.5134, toronto_lm_loss: 4.7141 ||
04/19 04:08:55 PM: Update 10120: task wsj, batch 120 (10120): perplexity: 107.5552, wsj_loss: 4.6780 ||
04/19 04:08:56 PM: Update 7540: task toronto_lm, batch 539 (7503): perplexity: 111.6779, toronto_lm_loss: 4.7156 ||
04/19 04:09:05 PM: Update 10136: task wsj, batch 136 (10136): perplexity: 106.8282, wsj_loss: 4.6712 ||
04/19 04:09:07 PM: Update 7554: task toronto_lm, batch 553 (7517): perplexity: 111.8366, toronto_lm_loss: 4.7170 ||
04/19 04:09:15 PM: Update 10152: task wsj, batch 152 (10152): perplexity: 106.2201, wsj_loss: 4.6655 ||
04/19 04:09:18 PM: Update 7568: task toronto_lm, batch 567 (7531): perplexity: 111.8896, toronto_lm_loss: 4.7175 ||
04/19 04:09:26 PM: Update 10168: task wsj, batch 168 (10168): perplexity: 106.3195, wsj_loss: 4.6664 ||
04/19 04:09:28 PM: Update 7581: task toronto_lm, batch 580 (7544): perplexity: 111.9429, toronto_lm_loss: 4.7180 ||
04/19 04:09:36 PM: Update 10184: task wsj, batch 184 (10184): perplexity: 105.9491, wsj_loss: 4.6630 ||
04/19 04:09:38 PM: Update 7594: task toronto_lm, batch 593 (7557): perplexity: 111.9186, toronto_lm_loss: 4.7178 ||
04/19 04:09:46 PM: Update 10200: task wsj, batch 200 (10200): perplexity: 105.4973, wsj_loss: 4.6587 ||
04/19 04:09:49 PM: Update 7608: task toronto_lm, batch 607 (7571): perplexity: 111.7201, toronto_lm_loss: 4.7160 ||
04/19 04:09:57 PM: Update 10216: task wsj, batch 216 (10216): perplexity: 105.3198, wsj_loss: 4.6570 ||
04/19 04:09:59 PM: Update 7622: task toronto_lm, batch 621 (7585): perplexity: 111.4696, toronto_lm_loss: 4.7138 ||
04/19 04:10:07 PM: Update 10224: task wsj, batch 224 (10224): perplexity: 105.3958, wsj_loss: 4.6577 ||
04/19 04:10:09 PM: Update 7635: task toronto_lm, batch 634 (7598): perplexity: 111.1586, toronto_lm_loss: 4.7110 ||
04/19 04:10:17 PM: Update 10240: task wsj, batch 240 (10240): perplexity: 105.5132, wsj_loss: 4.6588 ||
04/19 04:10:19 PM: Update 7648: task toronto_lm, batch 647 (7611): perplexity: 111.0068, toronto_lm_loss: 4.7096 ||
04/19 04:10:28 PM: Update 10256: task wsj, batch 256 (10256): perplexity: 105.7036, wsj_loss: 4.6606 ||
04/19 04:10:29 PM: Update 7661: task toronto_lm, batch 660 (7624): perplexity: 110.7391, toronto_lm_loss: 4.7072 ||
04/19 04:10:38 PM: Update 10272: task wsj, batch 272 (10272): perplexity: 106.0518, wsj_loss: 4.6639 ||
04/19 04:10:39 PM: Update 7674: task toronto_lm, batch 673 (7637): perplexity: 110.5057, toronto_lm_loss: 4.7051 ||
04/19 04:10:44 PM: Update 7680: task wsj, batch 2 (38): perplexity: 393.8638, wsj_loss: 5.9760 ||
04/19 04:10:48 PM: Update 10288: task wsj, batch 288 (10288): perplexity: 106.0979, wsj_loss: 4.6644 ||
04/19 04:10:49 PM: Update 7687: task toronto_lm, batch 685 (7649): perplexity: 110.2735, toronto_lm_loss: 4.7030 ||
04/19 04:10:59 PM: Update 10304: task wsj, batch 304 (10304): perplexity: 106.1524, wsj_loss: 4.6649 ||
04/19 04:11:00 PM: Update 7701: task toronto_lm, batch 699 (7663): perplexity: 109.9092, toronto_lm_loss: 4.6997 ||
04/19 04:11:09 PM: Update 10320: task wsj, batch 320 (10320): perplexity: 106.3167, wsj_loss: 4.6664 ||
04/19 04:11:11 PM: Update 7715: task toronto_lm, batch 713 (7677): perplexity: 109.5686, toronto_lm_loss: 4.6966 ||
04/19 04:11:19 PM: Update 10336: task wsj, batch 336 (10336): perplexity: 106.2643, wsj_loss: 4.6659 ||
04/19 04:11:22 PM: Update 7729: task toronto_lm, batch 727 (7691): perplexity: 109.3710, toronto_lm_loss: 4.6947 ||
04/19 04:11:30 PM: Update 10352: task wsj, batch 352 (10352): perplexity: 106.3734, wsj_loss: 4.6670 ||
04/19 04:11:32 PM: Update 7743: task toronto_lm, batch 741 (7705): perplexity: 109.0198, toronto_lm_loss: 4.6915 ||
04/19 04:11:40 PM: Update 10368: task wsj, batch 368 (10368): perplexity: 106.2570, wsj_loss: 4.6659 ||
04/19 04:11:43 PM: Update 7757: task toronto_lm, batch 755 (7719): perplexity: 108.5995, toronto_lm_loss: 4.6877 ||
04/19 04:11:52 PM: Update 10378: task wsj, batch 378 (10378): perplexity: 106.6102, wsj_loss: 4.6692 ||
04/19 04:11:54 PM: Update 7771: task toronto_lm, batch 769 (7733): perplexity: 108.1508, toronto_lm_loss: 4.6835 ||
04/19 04:12:02 PM: Update 10394: task wsj, batch 394 (10394): perplexity: 106.5252, wsj_loss: 4.6684 ||
04/19 04:12:05 PM: Update 7785: task toronto_lm, batch 783 (7747): perplexity: 107.9431, toronto_lm_loss: 4.6816 ||
04/19 04:12:12 PM: Update 10410: task wsj, batch 410 (10410): perplexity: 106.2454, wsj_loss: 4.6658 ||
04/19 04:12:15 PM: Update 7798: task toronto_lm, batch 796 (7760): perplexity: 107.7500, toronto_lm_loss: 4.6798 ||
04/19 04:12:23 PM: Update 10426: task wsj, batch 426 (10426): perplexity: 106.1178, wsj_loss: 4.6646 ||
04/19 04:12:25 PM: Update 7812: task toronto_lm, batch 810 (7774): perplexity: 107.4244, toronto_lm_loss: 4.6768 ||
04/19 04:12:33 PM: Update 10442: task wsj, batch 442 (10442): perplexity: 106.0206, wsj_loss: 4.6636 ||
04/19 04:12:35 PM: Update 7825: task toronto_lm, batch 823 (7787): perplexity: 107.0929, toronto_lm_loss: 4.6737 ||
04/19 04:12:43 PM: Update 10458: task wsj, batch 458 (10458): perplexity: 105.8397, wsj_loss: 4.6619 ||
04/19 04:12:46 PM: Update 7839: task toronto_lm, batch 837 (7801): perplexity: 106.7977, toronto_lm_loss: 4.6709 ||
04/19 04:12:54 PM: Update 10474: task wsj, batch 474 (10474): perplexity: 105.6889, wsj_loss: 4.6605 ||
04/19 04:12:57 PM: Update 7853: task toronto_lm, batch 851 (7815): perplexity: 106.5814, toronto_lm_loss: 4.6689 ||
04/19 04:13:04 PM: Update 10490: task wsj, batch 490 (10490): perplexity: 105.5398, wsj_loss: 4.6591 ||
04/19 04:13:08 PM: Update 7867: task toronto_lm, batch 865 (7829): perplexity: 106.2808, toronto_lm_loss: 4.6661 ||
04/19 04:13:14 PM: Update 10506: task wsj, batch 506 (10506): perplexity: 105.4745, wsj_loss: 4.6585 ||
04/19 04:13:18 PM: Update 7881: task toronto_lm, batch 879 (7843): perplexity: 105.9053, toronto_lm_loss: 4.6625 ||
04/19 04:13:25 PM: Update 10513: task wsj, batch 513 (10513): perplexity: 105.5085, wsj_loss: 4.6588 ||
04/19 04:13:29 PM: Update 7895: task toronto_lm, batch 893 (7857): perplexity: 105.6679, toronto_lm_loss: 4.6603 ||
04/19 04:13:35 PM: Update 10529: task wsj, batch 529 (10529): perplexity: 105.5138, wsj_loss: 4.6588 ||
04/19 04:13:40 PM: Update 7909: task toronto_lm, batch 907 (7871): perplexity: 105.4937, toronto_lm_loss: 4.6587 ||
04/19 04:13:41 PM: Update 7910: task wsj, batch 3 (39): perplexity: 419.2021, wsj_loss: 6.0384 ||
04/19 04:13:45 PM: Update 10545: task wsj, batch 545 (10545): perplexity: 105.5707, wsj_loss: 4.6594 ||
04/19 04:13:51 PM: Update 7923: task toronto_lm, batch 920 (7884): perplexity: 105.3543, toronto_lm_loss: 4.6573 ||
04/19 04:13:56 PM: Update 10561: task wsj, batch 561 (10561): perplexity: 105.6169, wsj_loss: 4.6598 ||
04/19 04:14:01 PM: Update 7937: task toronto_lm, batch 934 (7898): perplexity: 105.0284, toronto_lm_loss: 4.6542 ||
04/19 04:14:06 PM: Update 10577: task wsj, batch 577 (10577): perplexity: 105.5729, wsj_loss: 4.6594 ||
04/19 04:14:12 PM: Update 7951: task toronto_lm, batch 948 (7912): perplexity: 104.7176, toronto_lm_loss: 4.6513 ||
04/19 04:14:16 PM: Update 10593: task wsj, batch 593 (10593): perplexity: 105.5881, wsj_loss: 4.6595 ||
04/19 04:14:23 PM: Update 7965: task toronto_lm, batch 962 (7926): perplexity: 104.4000, toronto_lm_loss: 4.6482 ||
04/19 04:14:27 PM: Update 10609: task wsj, batch 609 (10609): perplexity: 105.7038, wsj_loss: 4.6606 ||
04/19 04:14:33 PM: Update 7979: task toronto_lm, batch 976 (7940): perplexity: 104.1561, toronto_lm_loss: 4.6459 ||
04/19 04:14:37 PM: Update 10625: task wsj, batch 625 (10625): perplexity: 105.6920, wsj_loss: 4.6605 ||
04/19 04:14:44 PM: Update 7993: task toronto_lm, batch 990 (7954): perplexity: 103.9676, toronto_lm_loss: 4.6441 ||
04/19 04:14:48 PM: Update 10641: task wsj, batch 641 (10641): perplexity: 105.7453, wsj_loss: 4.6610 ||
04/19 04:14:49 PM: ***** Pass 8000 / Epoch 8 *****
04/19 04:14:49 PM: toronto_lm: trained on 997 batches, 0.005 epochs
04/19 04:14:49 PM: wsj: trained on 3 batches, 0.004 epochs
04/19 04:14:49 PM: Validating...
04/19 04:14:54 PM: Batch 18/140: perplexity: 125.6712, toronto_lm_loss: 4.8337 || , for evaluation data
04/19 04:14:58 PM: Update 10657: task wsj, batch 657 (10657): perplexity: 105.8384, wsj_loss: 4.6619 ||
04/19 04:15:04 PM: Batch 57/140: perplexity: 121.6640, toronto_lm_loss: 4.8013 || , for evaluation data
04/19 04:15:12 PM: Update 10670: task wsj, batch 670 (10670): perplexity: 105.8232, wsj_loss: 4.6618 ||
04/19 04:15:14 PM: Batch 96/140: perplexity: 111.8014, toronto_lm_loss: 4.7167 || , for evaluation data
04/19 04:15:22 PM: Update 10686: task wsj, batch 686 (10686): perplexity: 105.7668, wsj_loss: 4.6612 ||
04/19 04:15:24 PM: Batch 135/140: perplexity: 103.1637, toronto_lm_loss: 4.6363 || , for evaluation data
04/19 04:15:26 PM: Batch 1/66: perplexity: 512.9259, wsj_loss: 6.2401 || , for evaluation data
04/19 04:15:33 PM: Update 10702: task wsj, batch 702 (10702): perplexity: 105.7094, wsj_loss: 4.6607 ||
04/19 04:15:36 PM: Batch 40/66: perplexity: 375.4560, wsj_loss: 5.9281 || , for evaluation data
04/19 04:15:43 PM: Best model found for wsj.
04/19 04:15:43 PM: Best model found for micro.
04/19 04:15:43 PM: Best model found for macro.
04/19 04:15:43 PM: Advancing scheduler.
04/19 04:15:43 PM: 	Best macro_avg: -0.099
04/19 04:15:43 PM: 	# bad epochs: 0
04/19 04:15:43 PM: Statistic: toronto_lm_loss
04/19 04:15:43 PM: 	training: 4.643007
04/19 04:15:43 PM: 	validation: 4.627107
04/19 04:15:43 PM: Statistic: wsj_loss
04/19 04:15:43 PM: 	training: 6.038353
04/19 04:15:43 PM: 	validation: 5.922406
04/19 04:15:43 PM: Statistic: macro_avg
04/19 04:15:43 PM: 	validation: -0.098835
04/19 04:15:43 PM: Statistic: micro_avg
04/19 04:15:43 PM: 	validation: -0.158096
04/19 04:15:43 PM: Statistic: toronto_lm_perplexity
04/19 04:15:43 PM: 	training: 103.856157
04/19 04:15:43 PM: 	validation: 102.217899
04/19 04:15:43 PM: Statistic: wsj_perplexity
04/19 04:15:43 PM: 	training: 419.202093
04/19 04:15:43 PM: 	validation: 373.308719
04/19 04:15:43 PM: global_lr: 0.001000
04/19 04:15:43 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 04:15:43 PM: Update 10718: task wsj, batch 718 (10718): perplexity: 105.5474, wsj_loss: 4.6592 ||
04/19 04:15:44 PM: Update 8001: task toronto_lm, batch 1 (7962): perplexity: 100.4838, toronto_lm_loss: 4.6100 ||
04/19 04:15:53 PM: Update 10734: task wsj, batch 734 (10734): perplexity: 105.5493, wsj_loss: 4.6592 ||
04/19 04:15:54 PM: Update 8015: task toronto_lm, batch 15 (7976): perplexity: 88.0155, toronto_lm_loss: 4.4775 ||
04/19 04:16:04 PM: Update 10750: task wsj, batch 750 (10750): perplexity: 105.5045, wsj_loss: 4.6588 ||
04/19 04:16:04 PM: Update 8028: task toronto_lm, batch 28 (7989): perplexity: 86.3677, toronto_lm_loss: 4.4586 ||
04/19 04:16:14 PM: Update 10766: task wsj, batch 766 (10766): perplexity: 105.4044, wsj_loss: 4.6578 ||
04/19 04:16:14 PM: Update 8041: task toronto_lm, batch 41 (8002): perplexity: 86.5312, toronto_lm_loss: 4.4605 ||
04/19 04:16:25 PM: Update 10782: task wsj, batch 782 (10782): perplexity: 105.2826, wsj_loss: 4.6566 ||
04/19 04:16:25 PM: Update 8055: task toronto_lm, batch 55 (8016): perplexity: 85.4530, toronto_lm_loss: 4.4480 ||
04/19 04:16:35 PM: Update 10798: task wsj, batch 798 (10798): perplexity: 105.1454, wsj_loss: 4.6553 ||
04/19 04:16:36 PM: Update 8069: task toronto_lm, batch 69 (8030): perplexity: 85.8654, toronto_lm_loss: 4.4528 ||
04/19 04:16:46 PM: Update 10806: task wsj, batch 806 (10806): perplexity: 105.0920, wsj_loss: 4.6548 ||
04/19 04:16:47 PM: Update 8083: task toronto_lm, batch 83 (8044): perplexity: 85.9704, toronto_lm_loss: 4.4540 ||
04/19 04:16:56 PM: Update 10822: task wsj, batch 822 (10822): perplexity: 105.0823, wsj_loss: 4.6547 ||
04/19 04:16:57 PM: Update 8097: task toronto_lm, batch 97 (8058): perplexity: 85.3222, toronto_lm_loss: 4.4464 ||
04/19 04:17:06 PM: Update 10838: task wsj, batch 838 (10838): perplexity: 105.0556, wsj_loss: 4.6545 ||
04/19 04:17:07 PM: Update 8110: task toronto_lm, batch 110 (8071): perplexity: 85.5183, toronto_lm_loss: 4.4487 ||
04/19 04:17:17 PM: Update 10854: task wsj, batch 854 (10854): perplexity: 105.0494, wsj_loss: 4.6544 ||
04/19 04:17:17 PM: Update 8123: task toronto_lm, batch 123 (8084): perplexity: 86.0862, toronto_lm_loss: 4.4553 ||
04/19 04:17:27 PM: Update 10870: task wsj, batch 870 (10870): perplexity: 105.1005, wsj_loss: 4.6549 ||
04/19 04:17:28 PM: Update 8137: task toronto_lm, batch 137 (8098): perplexity: 86.2289, toronto_lm_loss: 4.4570 ||
04/19 04:17:37 PM: Update 10886: task wsj, batch 886 (10886): perplexity: 105.1121, wsj_loss: 4.6550 ||
04/19 04:17:38 PM: Update 8150: task toronto_lm, batch 150 (8111): perplexity: 86.1392, toronto_lm_loss: 4.4560 ||
04/19 04:17:48 PM: Update 10902: task wsj, batch 902 (10902): perplexity: 105.1865, wsj_loss: 4.6557 ||
04/19 04:17:48 PM: Update 8163: task toronto_lm, batch 163 (8124): perplexity: 85.9581, toronto_lm_loss: 4.4539 ||
04/19 04:17:58 PM: Update 10918: task wsj, batch 918 (10918): perplexity: 105.2601, wsj_loss: 4.6564 ||
04/19 04:17:59 PM: Update 8168: task toronto_lm, batch 168 (8129): perplexity: 86.7402, toronto_lm_loss: 4.4629 ||
04/19 04:18:08 PM: Update 10934: task wsj, batch 934 (10934): perplexity: 105.2467, wsj_loss: 4.6563 ||
04/19 04:18:10 PM: Update 8182: task toronto_lm, batch 182 (8143): perplexity: 89.4351, toronto_lm_loss: 4.4935 ||
04/19 04:18:19 PM: Update 10950: task wsj, batch 950 (10950): perplexity: 105.2965, wsj_loss: 4.6568 ||
04/19 04:18:20 PM: Update 8196: task toronto_lm, batch 196 (8157): perplexity: 91.3720, toronto_lm_loss: 4.5149 ||
04/19 04:18:31 PM: Update 8210: task toronto_lm, batch 210 (8171): perplexity: 92.8366, toronto_lm_loss: 4.5308 ||
04/19 04:18:31 PM: Update 10962: task wsj, batch 962 (10962): perplexity: 105.2275, wsj_loss: 4.6561 ||
04/19 04:18:41 PM: Update 8223: task toronto_lm, batch 223 (8184): perplexity: 93.9234, toronto_lm_loss: 4.5425 ||
04/19 04:18:42 PM: Update 10978: task wsj, batch 978 (10978): perplexity: 105.1795, wsj_loss: 4.6557 ||
04/19 04:18:52 PM: Update 8237: task toronto_lm, batch 237 (8198): perplexity: 95.0275, toronto_lm_loss: 4.5542 ||
04/19 04:18:52 PM: Update 10994: task wsj, batch 994 (10994): perplexity: 105.1657, wsj_loss: 4.6555 ||
04/19 04:18:56 PM: ***** Pass 11000 / Epoch 11 *****
04/19 04:18:56 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 04:18:56 PM: Validating...
04/19 04:19:02 PM: Best model found for wsj.
04/19 04:19:02 PM: Best model found for micro.
04/19 04:19:02 PM: Best model found for macro.
04/19 04:19:02 PM: Advancing scheduler.
04/19 04:19:02 PM: 	Best macro_avg: 107.467
04/19 04:19:02 PM: 	# bad epochs: 0
04/19 04:19:02 PM: Statistic: wsj_loss
04/19 04:19:02 PM: 	training: 4.655228
04/19 04:19:02 PM: 	validation: 4.677181
04/19 04:19:02 PM: Statistic: macro_avg
04/19 04:19:02 PM: 	validation: 107.466689
04/19 04:19:02 PM: Statistic: micro_avg
04/19 04:19:02 PM: 	validation: 107.466689
04/19 04:19:02 PM: Statistic: wsj_perplexity
04/19 04:19:02 PM: 	training: 105.133162
04/19 04:19:02 PM: 	validation: 107.466689
04/19 04:19:02 PM: global_lr: 0.003000
04/19 04:19:02 PM: Update 8250: task toronto_lm, batch 250 (8211): perplexity: 96.2263, toronto_lm_loss: 4.5667 ||
04/19 04:19:02 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 04:19:03 PM: Update 11001: task wsj, batch 1 (11001): perplexity: 96.8216, wsj_loss: 4.5729 ||
04/19 04:19:13 PM: Update 8264: task toronto_lm, batch 264 (8225): perplexity: 96.2547, toronto_lm_loss: 4.5670 ||
04/19 04:19:13 PM: Update 11017: task wsj, batch 17 (11017): perplexity: 94.2428, wsj_loss: 4.5459 ||
04/19 04:19:16 PM: Update 8268: task wsj, batch 1 (40): perplexity: 346.7547, wsj_loss: 5.8486 ||
04/19 04:19:23 PM: Update 8277: task toronto_lm, batch 276 (8237): perplexity: 96.4156, toronto_lm_loss: 4.5687 ||
04/19 04:19:23 PM: Update 11033: task wsj, batch 33 (11033): perplexity: 97.0062, wsj_loss: 4.5748 ||
04/19 04:19:33 PM: Update 8291: task toronto_lm, batch 290 (8251): perplexity: 96.9317, toronto_lm_loss: 4.5740 ||
04/19 04:19:34 PM: Update 11049: task wsj, batch 49 (11049): perplexity: 97.3987, wsj_loss: 4.5788 ||
04/19 04:19:43 PM: Update 8304: task toronto_lm, batch 303 (8264): perplexity: 96.9927, toronto_lm_loss: 4.5746 ||
04/19 04:19:44 PM: Update 11065: task wsj, batch 65 (11065): perplexity: 98.9587, wsj_loss: 4.5947 ||
04/19 04:19:54 PM: Update 8318: task toronto_lm, batch 317 (8278): perplexity: 97.1692, toronto_lm_loss: 4.5765 ||
04/19 04:19:54 PM: Update 11081: task wsj, batch 81 (11081): perplexity: 99.3859, wsj_loss: 4.5990 ||
04/19 04:20:05 PM: Update 8332: task toronto_lm, batch 331 (8292): perplexity: 97.4500, toronto_lm_loss: 4.5793 ||
04/19 04:20:10 PM: Update 11097: task wsj, batch 97 (11097): perplexity: 99.1628, wsj_loss: 4.5968 ||
04/19 04:20:16 PM: Update 8346: task toronto_lm, batch 345 (8306): perplexity: 97.4675, toronto_lm_loss: 4.5795 ||
04/19 04:20:20 PM: Update 11113: task wsj, batch 113 (11113): perplexity: 100.1443, wsj_loss: 4.6066 ||
04/19 04:20:26 PM: Update 8360: task toronto_lm, batch 359 (8320): perplexity: 97.3471, toronto_lm_loss: 4.5783 ||
04/19 04:20:31 PM: Update 11129: task wsj, batch 129 (11129): perplexity: 100.5130, wsj_loss: 4.6103 ||
04/19 04:20:36 PM: Update 8373: task toronto_lm, batch 372 (8333): perplexity: 97.4920, toronto_lm_loss: 4.5798 ||
04/19 04:20:41 PM: Update 11145: task wsj, batch 145 (11145): perplexity: 100.8040, wsj_loss: 4.6132 ||
04/19 04:20:47 PM: Update 8387: task toronto_lm, batch 386 (8347): perplexity: 97.3307, toronto_lm_loss: 4.5781 ||
04/19 04:20:51 PM: Update 11161: task wsj, batch 161 (11161): perplexity: 101.1559, wsj_loss: 4.6167 ||
04/19 04:20:58 PM: Update 8401: task toronto_lm, batch 400 (8361): perplexity: 97.5559, toronto_lm_loss: 4.5804 ||
04/19 04:21:02 PM: Update 11177: task wsj, batch 177 (11177): perplexity: 101.7186, wsj_loss: 4.6222 ||
04/19 04:21:08 PM: Update 8414: task toronto_lm, batch 413 (8374): perplexity: 97.5016, toronto_lm_loss: 4.5799 ||
04/19 04:21:12 PM: Update 11193: task wsj, batch 193 (11193): perplexity: 101.9208, wsj_loss: 4.6242 ||
04/19 04:21:12 PM: Update 8420: task wsj, batch 2 (41): perplexity: 330.5598, wsj_loss: 5.8008 ||
04/19 04:21:18 PM: Update 8428: task toronto_lm, batch 426 (8387): perplexity: 97.4077, toronto_lm_loss: 4.5789 ||
04/19 04:21:22 PM: Update 11209: task wsj, batch 209 (11209): perplexity: 102.0849, wsj_loss: 4.6258 ||
04/19 04:21:29 PM: Update 8442: task toronto_lm, batch 440 (8401): perplexity: 97.2089, toronto_lm_loss: 4.5769 ||
04/19 04:21:33 PM: Update 11225: task wsj, batch 225 (11225): perplexity: 102.2695, wsj_loss: 4.6276 ||
04/19 04:21:39 PM: Update 8455: task toronto_lm, batch 453 (8414): perplexity: 96.9869, toronto_lm_loss: 4.5746 ||
04/19 04:21:43 PM: Update 11241: task wsj, batch 241 (11241): perplexity: 102.4592, wsj_loss: 4.6295 ||
04/19 04:21:49 PM: Update 8468: task toronto_lm, batch 466 (8427): perplexity: 97.0645, toronto_lm_loss: 4.5754 ||
04/19 04:21:57 PM: Update 11254: task wsj, batch 254 (11254): perplexity: 102.6014, wsj_loss: 4.6309 ||
04/19 04:22:00 PM: Update 8482: task toronto_lm, batch 480 (8441): perplexity: 97.0198, toronto_lm_loss: 4.5749 ||
04/19 04:22:08 PM: Update 11270: task wsj, batch 270 (11270): perplexity: 102.5184, wsj_loss: 4.6300 ||
04/19 04:22:11 PM: Update 8496: task toronto_lm, batch 494 (8455): perplexity: 96.9575, toronto_lm_loss: 4.5743 ||
04/19 04:22:18 PM: Update 11286: task wsj, batch 286 (11286): perplexity: 102.2076, wsj_loss: 4.6270 ||
04/19 04:22:21 PM: Update 8510: task toronto_lm, batch 508 (8469): perplexity: 96.9186, toronto_lm_loss: 4.5739 ||
04/19 04:22:28 PM: Update 11302: task wsj, batch 302 (11302): perplexity: 102.2844, wsj_loss: 4.6278 ||
04/19 04:22:32 PM: Update 8524: task toronto_lm, batch 522 (8483): perplexity: 96.9105, toronto_lm_loss: 4.5738 ||
04/19 04:22:39 PM: Update 11318: task wsj, batch 318 (11318): perplexity: 102.0844, wsj_loss: 4.6258 ||
04/19 04:22:43 PM: Update 8538: task toronto_lm, batch 536 (8497): perplexity: 96.9269, toronto_lm_loss: 4.5740 ||
04/19 04:22:49 PM: Update 11334: task wsj, batch 334 (11334): perplexity: 101.7863, wsj_loss: 4.6229 ||
04/19 04:22:54 PM: Update 8552: task toronto_lm, batch 550 (8511): perplexity: 96.9326, toronto_lm_loss: 4.5740 ||
04/19 04:23:00 PM: Update 11350: task wsj, batch 350 (11350): perplexity: 101.6317, wsj_loss: 4.6214 ||
04/19 04:23:04 PM: Update 8565: task toronto_lm, batch 563 (8524): perplexity: 96.9740, toronto_lm_loss: 4.5744 ||
04/19 04:23:10 PM: Update 11366: task wsj, batch 366 (11366): perplexity: 101.5414, wsj_loss: 4.6205 ||
04/19 04:23:14 PM: Update 8578: task toronto_lm, batch 576 (8537): perplexity: 96.9675, toronto_lm_loss: 4.5744 ||
04/19 04:23:20 PM: Update 11382: task wsj, batch 382 (11382): perplexity: 101.4522, wsj_loss: 4.6196 ||
04/19 04:23:25 PM: Update 8592: task toronto_lm, batch 590 (8551): perplexity: 96.6448, toronto_lm_loss: 4.5710 ||
04/19 04:23:30 PM: Update 11390: task wsj, batch 390 (11390): perplexity: 101.4320, wsj_loss: 4.6194 ||
04/19 04:23:35 PM: Update 8605: task toronto_lm, batch 603 (8564): perplexity: 96.6169, toronto_lm_loss: 4.5708 ||
04/19 04:23:41 PM: Update 11406: task wsj, batch 406 (11406): perplexity: 101.7242, wsj_loss: 4.6223 ||
04/19 04:23:45 PM: Update 8619: task toronto_lm, batch 617 (8578): perplexity: 96.5910, toronto_lm_loss: 4.5705 ||
04/19 04:23:51 PM: Update 11422: task wsj, batch 422 (11422): perplexity: 101.9011, wsj_loss: 4.6240 ||
04/19 04:23:55 PM: Update 8632: task toronto_lm, batch 630 (8591): perplexity: 96.4071, toronto_lm_loss: 4.5686 ||
04/19 04:24:02 PM: Update 11438: task wsj, batch 438 (11438): perplexity: 101.9677, wsj_loss: 4.6247 ||
04/19 04:24:06 PM: Update 8646: task toronto_lm, batch 644 (8605): perplexity: 96.1877, toronto_lm_loss: 4.5663 ||
04/19 04:24:12 PM: Update 11454: task wsj, batch 454 (11454): perplexity: 101.9594, wsj_loss: 4.6246 ||
04/19 04:24:16 PM: Update 8659: task toronto_lm, batch 657 (8618): perplexity: 96.0657, toronto_lm_loss: 4.5650 ||
04/19 04:24:22 PM: Update 11470: task wsj, batch 470 (11470): perplexity: 101.9106, wsj_loss: 4.6241 ||
04/19 04:24:26 PM: Update 8672: task toronto_lm, batch 670 (8631): perplexity: 95.9518, toronto_lm_loss: 4.5638 ||
04/19 04:24:33 PM: Update 11486: task wsj, batch 486 (11486): perplexity: 102.0038, wsj_loss: 4.6250 ||
04/19 04:24:37 PM: Update 8686: task toronto_lm, batch 684 (8645): perplexity: 95.9162, toronto_lm_loss: 4.5635 ||
04/19 04:24:43 PM: Update 11502: task wsj, batch 502 (11502): perplexity: 102.0753, wsj_loss: 4.6257 ||
04/19 04:24:48 PM: Update 8700: task wsj, batch 3 (42): perplexity: 329.8479, wsj_loss: 5.7986 ||
04/19 04:24:48 PM: Update 8701: task toronto_lm, batch 698 (8659): perplexity: 95.8555, toronto_lm_loss: 4.5628 ||
04/19 04:24:54 PM: Update 11518: task wsj, batch 518 (11518): perplexity: 102.0360, wsj_loss: 4.6253 ||
04/19 04:24:58 PM: Update 8714: task toronto_lm, batch 711 (8672): perplexity: 95.6824, toronto_lm_loss: 4.5610 ||
04/19 04:25:04 PM: Update 11534: task wsj, batch 534 (11534): perplexity: 102.0264, wsj_loss: 4.6252 ||
04/19 04:25:09 PM: Update 8728: task toronto_lm, batch 725 (8686): perplexity: 95.5639, toronto_lm_loss: 4.5598 ||
04/19 04:25:17 PM: Update 11546: task wsj, batch 546 (11546): perplexity: 102.1337, wsj_loss: 4.6263 ||
04/19 04:25:20 PM: Update 8742: task toronto_lm, batch 739 (8700): perplexity: 95.4106, toronto_lm_loss: 4.5582 ||
04/19 04:25:27 PM: Update 11562: task wsj, batch 562 (11562): perplexity: 102.0307, wsj_loss: 4.6253 ||
04/19 04:25:31 PM: Update 8756: task toronto_lm, batch 753 (8714): perplexity: 95.2664, toronto_lm_loss: 4.5567 ||
04/19 04:25:37 PM: Update 11578: task wsj, batch 578 (11578): perplexity: 101.7555, wsj_loss: 4.6226 ||
04/19 04:25:41 PM: Update 8770: task toronto_lm, batch 767 (8728): perplexity: 95.1909, toronto_lm_loss: 4.5559 ||
04/19 04:25:48 PM: Update 11594: task wsj, batch 594 (11594): perplexity: 101.6564, wsj_loss: 4.6216 ||
04/19 04:25:51 PM: Update 8783: task toronto_lm, batch 780 (8741): perplexity: 95.0960, toronto_lm_loss: 4.5549 ||
04/19 04:25:58 PM: Update 11610: task wsj, batch 610 (11610): perplexity: 101.6656, wsj_loss: 4.6217 ||
04/19 04:26:07 PM: Update 8793: task toronto_lm, batch 790 (8751): perplexity: 95.0519, toronto_lm_loss: 4.5544 ||
04/19 04:26:09 PM: Update 11626: task wsj, batch 626 (11626): perplexity: 101.5455, wsj_loss: 4.6205 ||
04/19 04:26:17 PM: Update 8806: task toronto_lm, batch 803 (8764): perplexity: 95.4065, toronto_lm_loss: 4.5581 ||
04/19 04:26:19 PM: Update 11642: task wsj, batch 642 (11642): perplexity: 101.5608, wsj_loss: 4.6207 ||
04/19 04:26:28 PM: Update 8820: task toronto_lm, batch 817 (8778): perplexity: 95.5308, toronto_lm_loss: 4.5594 ||
04/19 04:26:29 PM: Update 11658: task wsj, batch 658 (11658): perplexity: 101.5052, wsj_loss: 4.6201 ||
04/19 04:26:38 PM: Update 8833: task toronto_lm, batch 830 (8791): perplexity: 95.6686, toronto_lm_loss: 4.5609 ||
04/19 04:26:40 PM: Update 11674: task wsj, batch 674 (11674): perplexity: 101.4048, wsj_loss: 4.6191 ||
04/19 04:26:49 PM: Update 8847: task toronto_lm, batch 844 (8805): perplexity: 95.8544, toronto_lm_loss: 4.5628 ||
04/19 04:26:50 PM: Update 11681: task wsj, batch 681 (11681): perplexity: 101.3750, wsj_loss: 4.6188 ||
04/19 04:26:59 PM: Update 8860: task toronto_lm, batch 857 (8818): perplexity: 95.9196, toronto_lm_loss: 4.5635 ||
04/19 04:27:00 PM: Update 11697: task wsj, batch 697 (11697): perplexity: 101.3261, wsj_loss: 4.6183 ||
04/19 04:27:10 PM: Update 8874: task toronto_lm, batch 871 (8832): perplexity: 95.9225, toronto_lm_loss: 4.5635 ||
04/19 04:27:11 PM: Update 11713: task wsj, batch 713 (11713): perplexity: 101.3322, wsj_loss: 4.6184 ||
04/19 04:27:20 PM: Update 8887: task toronto_lm, batch 884 (8845): perplexity: 95.9826, toronto_lm_loss: 4.5642 ||
04/19 04:27:21 PM: Update 11729: task wsj, batch 729 (11729): perplexity: 101.3655, wsj_loss: 4.6187 ||
04/19 04:27:30 PM: Update 8901: task toronto_lm, batch 898 (8859): perplexity: 96.0332, toronto_lm_loss: 4.5647 ||
04/19 04:27:32 PM: Update 11745: task wsj, batch 745 (11745): perplexity: 101.4359, wsj_loss: 4.6194 ||
04/19 04:27:41 PM: Update 8915: task toronto_lm, batch 912 (8873): perplexity: 95.9673, toronto_lm_loss: 4.5640 ||
04/19 04:27:42 PM: Update 11761: task wsj, batch 761 (11761): perplexity: 101.4575, wsj_loss: 4.6196 ||
04/19 04:27:52 PM: Update 8929: task toronto_lm, batch 926 (8887): perplexity: 95.8480, toronto_lm_loss: 4.5628 ||
04/19 04:27:53 PM: Update 11777: task wsj, batch 777 (11777): perplexity: 101.5448, wsj_loss: 4.6205 ||
04/19 04:28:02 PM: Update 8942: task toronto_lm, batch 939 (8900): perplexity: 95.8148, toronto_lm_loss: 4.5624 ||
04/19 04:28:03 PM: Update 11793: task wsj, batch 793 (11793): perplexity: 101.5418, wsj_loss: 4.6205 ||
04/19 04:28:12 PM: Update 8955: task toronto_lm, batch 952 (8913): perplexity: 95.8019, toronto_lm_loss: 4.5623 ||
04/19 04:28:14 PM: Update 11809: task wsj, batch 809 (11809): perplexity: 101.6841, wsj_loss: 4.6219 ||
04/19 04:28:23 PM: Update 8969: task toronto_lm, batch 966 (8927): perplexity: 95.7133, toronto_lm_loss: 4.5614 ||
04/19 04:28:24 PM: Update 11825: task wsj, batch 825 (11825): perplexity: 101.6435, wsj_loss: 4.6215 ||
04/19 04:28:33 PM: Update 8983: task toronto_lm, batch 980 (8941): perplexity: 95.6274, toronto_lm_loss: 4.5605 ||
04/19 04:28:38 PM: Update 11838: task wsj, batch 838 (11838): perplexity: 101.6326, wsj_loss: 4.6214 ||
04/19 04:28:43 PM: Update 8996: task toronto_lm, batch 993 (8954): perplexity: 95.6174, toronto_lm_loss: 4.5604 ||
04/19 04:28:46 PM: ***** Pass 9000 / Epoch 9 *****
04/19 04:28:46 PM: toronto_lm: trained on 997 batches, 0.005 epochs
04/19 04:28:46 PM: wsj: trained on 3 batches, 0.004 epochs
04/19 04:28:46 PM: Validating...
04/19 04:28:49 PM: Update 11854: task wsj, batch 854 (11854): perplexity: 101.5925, wsj_loss: 4.6210 ||
04/19 04:28:54 PM: Batch 27/140: perplexity: 114.9302, toronto_lm_loss: 4.7443 || , for evaluation data
04/19 04:28:59 PM: Update 11870: task wsj, batch 870 (11870): perplexity: 101.4962, wsj_loss: 4.6200 ||
04/19 04:29:04 PM: Batch 66/140: perplexity: 112.2100, toronto_lm_loss: 4.7204 || , for evaluation data
04/19 04:29:10 PM: Update 11886: task wsj, batch 886 (11886): perplexity: 101.3522, wsj_loss: 4.6186 ||
04/19 04:29:14 PM: Batch 105/140: perplexity: 105.1161, toronto_lm_loss: 4.6551 || , for evaluation data
04/19 04:29:20 PM: Update 11902: task wsj, batch 902 (11902): perplexity: 101.2209, wsj_loss: 4.6173 ||
04/19 04:29:24 PM: Batch 138/140: perplexity: 98.1839, toronto_lm_loss: 4.5868 || , for evaluation data
04/19 04:29:25 PM: Batch 1/66: perplexity: 485.5139, wsj_loss: 6.1852 || , for evaluation data
04/19 04:29:30 PM: Update 11918: task wsj, batch 918 (11918): perplexity: 101.2192, wsj_loss: 4.6173 ||
04/19 04:29:35 PM: Batch 40/66: perplexity: 361.1963, wsj_loss: 5.8894 || , for evaluation data
04/19 04:29:41 PM: Update 11934: task wsj, batch 934 (11934): perplexity: 101.1491, wsj_loss: 4.6166 ||
04/19 04:29:42 PM: Best model found for toronto_lm.
04/19 04:29:42 PM: Best model found for wsj.
04/19 04:29:42 PM: Best model found for micro.
04/19 04:29:42 PM: Best model found for macro.
04/19 04:29:42 PM: Advancing scheduler.
04/19 04:29:42 PM: 	Best macro_avg: -0.070
04/19 04:29:42 PM: 	# bad epochs: 0
04/19 04:29:42 PM: Statistic: toronto_lm_loss
04/19 04:29:42 PM: 	training: 4.560658
04/19 04:29:42 PM: 	validation: 4.589425
04/19 04:29:42 PM: Statistic: wsj_loss
04/19 04:29:42 PM: 	training: 5.798632
04/19 04:29:42 PM: 	validation: 5.887945
04/19 04:29:42 PM: Statistic: macro_avg
04/19 04:29:42 PM: 	validation: -0.069764
04/19 04:29:42 PM: Statistic: micro_avg
04/19 04:29:42 PM: 	validation: -0.141882
04/19 04:29:42 PM: Statistic: toronto_lm_perplexity
04/19 04:29:42 PM: 	training: 95.646398
04/19 04:29:42 PM: 	validation: 98.437821
04/19 04:29:42 PM: Statistic: wsj_perplexity
04/19 04:29:42 PM: 	training: 329.847910
04/19 04:29:42 PM: 	validation: 360.663222
04/19 04:29:42 PM: global_lr: 0.001000
04/19 04:29:42 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 04:29:43 PM: Update 9001: task toronto_lm, batch 1 (8959): perplexity: 100.2554, toronto_lm_loss: 4.6077 ||
04/19 04:29:51 PM: Update 11950: task wsj, batch 950 (11950): perplexity: 101.1079, wsj_loss: 4.6162 ||
04/19 04:29:53 PM: Update 9014: task toronto_lm, batch 14 (8972): perplexity: 87.1858, toronto_lm_loss: 4.4680 ||
04/19 04:30:02 PM: Update 11966: task wsj, batch 966 (11966): perplexity: 101.0097, wsj_loss: 4.6152 ||
04/19 04:30:03 PM: Update 9027: task toronto_lm, batch 27 (8985): perplexity: 86.2947, toronto_lm_loss: 4.4578 ||
04/19 04:30:12 PM: Update 11975: task wsj, batch 975 (11975): perplexity: 100.9997, wsj_loss: 4.6151 ||
04/19 04:30:14 PM: Update 9041: task toronto_lm, batch 41 (8999): perplexity: 88.4518, toronto_lm_loss: 4.4825 ||
04/19 04:30:23 PM: Update 11991: task wsj, batch 991 (11991): perplexity: 100.9856, wsj_loss: 4.6150 ||
04/19 04:30:24 PM: Update 9054: task toronto_lm, batch 54 (9012): perplexity: 86.3193, toronto_lm_loss: 4.4581 ||
04/19 04:30:29 PM: ***** Pass 12000 / Epoch 12 *****
04/19 04:30:29 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 04:30:29 PM: Validating...
04/19 04:30:33 PM: Batch 16/24: perplexity: 122.1520, wsj_loss: 4.8053 || , for evaluation data
04/19 04:30:35 PM: Update 9068: task toronto_lm, batch 68 (9026): perplexity: 86.7446, toronto_lm_loss: 4.4630 ||
04/19 04:30:35 PM: Best model found for wsj.
04/19 04:30:35 PM: Best model found for micro.
04/19 04:30:35 PM: Best model found for macro.
04/19 04:30:35 PM: Advancing scheduler.
04/19 04:30:35 PM: 	Best macro_avg: 106.761
04/19 04:30:35 PM: 	# bad epochs: 0
04/19 04:30:35 PM: Statistic: wsj_loss
04/19 04:30:35 PM: 	training: 4.614851
04/19 04:30:35 PM: 	validation: 4.670590
04/19 04:30:35 PM: Statistic: macro_avg
04/19 04:30:35 PM: 	validation: 106.760755
04/19 04:30:35 PM: Statistic: micro_avg
04/19 04:30:35 PM: 	validation: 106.760755
04/19 04:30:35 PM: Statistic: wsj_perplexity
04/19 04:30:35 PM: 	training: 100.972824
04/19 04:30:35 PM: 	validation: 106.760755
04/19 04:30:35 PM: global_lr: 0.003000
04/19 04:30:35 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 04:30:43 PM: Update 12012: task wsj, batch 12 (12012): perplexity: 104.3454, wsj_loss: 4.6477 ||
04/19 04:30:45 PM: Update 9081: task toronto_lm, batch 81 (9039): perplexity: 87.0712, toronto_lm_loss: 4.4667 ||
04/19 04:30:53 PM: Update 12028: task wsj, batch 28 (12028): perplexity: 104.8149, wsj_loss: 4.6522 ||
04/19 04:30:55 PM: Update 9094: task toronto_lm, batch 94 (9052): perplexity: 87.5156, toronto_lm_loss: 4.4718 ||
04/19 04:31:04 PM: Update 12044: task wsj, batch 44 (12044): perplexity: 103.1519, wsj_loss: 4.6362 ||
04/19 04:31:05 PM: Update 9107: task toronto_lm, batch 107 (9065): perplexity: 87.3808, toronto_lm_loss: 4.4703 ||
04/19 04:31:14 PM: Update 12060: task wsj, batch 60 (12060): perplexity: 103.0358, wsj_loss: 4.6351 ||
04/19 04:31:15 PM: Update 9120: task toronto_lm, batch 120 (9078): perplexity: 87.0590, toronto_lm_loss: 4.4666 ||
04/19 04:31:25 PM: Update 12076: task wsj, batch 76 (12076): perplexity: 102.4970, wsj_loss: 4.6298 ||
04/19 04:31:25 PM: Update 9133: task toronto_lm, batch 133 (9091): perplexity: 87.5401, toronto_lm_loss: 4.4721 ||
04/19 04:31:35 PM: Update 9146: task toronto_lm, batch 146 (9104): perplexity: 87.3895, toronto_lm_loss: 4.4704 ||
04/19 04:31:35 PM: Update 12092: task wsj, batch 92 (12092): perplexity: 102.6474, wsj_loss: 4.6313 ||
04/19 04:31:45 PM: Update 9159: task toronto_lm, batch 159 (9117): perplexity: 87.5854, toronto_lm_loss: 4.4726 ||
04/19 04:31:46 PM: Update 12108: task wsj, batch 108 (12108): perplexity: 102.9573, wsj_loss: 4.6343 ||
04/19 04:31:55 PM: Update 9172: task toronto_lm, batch 172 (9130): perplexity: 87.5545, toronto_lm_loss: 4.4723 ||
04/19 04:31:56 PM: Update 12124: task wsj, batch 124 (12124): perplexity: 102.7095, wsj_loss: 4.6319 ||
04/19 04:32:06 PM: Update 9186: task toronto_lm, batch 186 (9144): perplexity: 86.9288, toronto_lm_loss: 4.4651 ||
04/19 04:32:06 PM: Update 12132: task wsj, batch 132 (12132): perplexity: 102.8472, wsj_loss: 4.6332 ||
04/19 04:32:16 PM: Update 12148: task wsj, batch 148 (12148): perplexity: 101.7755, wsj_loss: 4.6228 ||
04/19 04:32:17 PM: Update 9200: task toronto_lm, batch 200 (9158): perplexity: 87.0652, toronto_lm_loss: 4.4667 ||
04/19 04:32:27 PM: Update 9213: task toronto_lm, batch 213 (9171): perplexity: 86.9453, toronto_lm_loss: 4.4653 ||
04/19 04:32:27 PM: Update 12164: task wsj, batch 164 (12164): perplexity: 101.5379, wsj_loss: 4.6204 ||
04/19 04:32:37 PM: Update 9226: task toronto_lm, batch 226 (9184): perplexity: 87.0394, toronto_lm_loss: 4.4664 ||
04/19 04:32:37 PM: Update 12180: task wsj, batch 180 (12180): perplexity: 100.9404, wsj_loss: 4.6145 ||
04/19 04:32:47 PM: Update 9240: task toronto_lm, batch 240 (9198): perplexity: 86.6475, toronto_lm_loss: 4.4618 ||
04/19 04:32:48 PM: Update 12196: task wsj, batch 196 (12196): perplexity: 100.4483, wsj_loss: 4.6096 ||
04/19 04:32:58 PM: Update 12212: task wsj, batch 212 (12212): perplexity: 100.1387, wsj_loss: 4.6066 ||
04/19 04:32:58 PM: Update 9254: task toronto_lm, batch 254 (9212): perplexity: 86.2985, toronto_lm_loss: 4.4578 ||
04/19 04:33:09 PM: Update 12228: task wsj, batch 228 (12228): perplexity: 100.0476, wsj_loss: 4.6056 ||
04/19 04:33:09 PM: Update 9268: task toronto_lm, batch 268 (9226): perplexity: 86.0052, toronto_lm_loss: 4.4544 ||
04/19 04:33:19 PM: Update 9281: task toronto_lm, batch 281 (9239): perplexity: 86.1493, toronto_lm_loss: 4.4561 ||
04/19 04:33:19 PM: Update 12244: task wsj, batch 244 (12244): perplexity: 99.8499, wsj_loss: 4.6037 ||
04/19 04:33:29 PM: Update 9294: task toronto_lm, batch 294 (9252): perplexity: 85.9725, toronto_lm_loss: 4.4540 ||
04/19 04:33:30 PM: Update 12260: task wsj, batch 260 (12260): perplexity: 99.8646, wsj_loss: 4.6038 ||
04/19 04:33:39 PM: Update 9307: task toronto_lm, batch 307 (9265): perplexity: 85.8575, toronto_lm_loss: 4.4527 ||
04/19 04:33:40 PM: Update 12267: task wsj, batch 267 (12267): perplexity: 99.6181, wsj_loss: 4.6013 ||
04/19 04:33:49 PM: Update 9320: task toronto_lm, batch 320 (9278): perplexity: 85.6594, toronto_lm_loss: 4.4504 ||
04/19 04:33:50 PM: Update 12283: task wsj, batch 283 (12283): perplexity: 99.6806, wsj_loss: 4.6020 ||
04/19 04:33:59 PM: Update 9333: task toronto_lm, batch 333 (9291): perplexity: 85.5610, toronto_lm_loss: 4.4492 ||
04/19 04:34:00 PM: Update 12299: task wsj, batch 299 (12299): perplexity: 99.8277, wsj_loss: 4.6034 ||
04/19 04:34:09 PM: Update 9346: task toronto_lm, batch 346 (9304): perplexity: 85.5880, toronto_lm_loss: 4.4495 ||
04/19 04:34:11 PM: Update 12315: task wsj, batch 315 (12315): perplexity: 99.7438, wsj_loss: 4.6026 ||
04/19 04:34:19 PM: Update 9359: task toronto_lm, batch 359 (9317): perplexity: 85.5094, toronto_lm_loss: 4.4486 ||
04/19 04:34:21 PM: Update 12331: task wsj, batch 331 (12331): perplexity: 99.8381, wsj_loss: 4.6035 ||
04/19 04:34:29 PM: Update 9372: task toronto_lm, batch 372 (9330): perplexity: 85.2684, toronto_lm_loss: 4.4458 ||
04/19 04:34:32 PM: Update 12347: task wsj, batch 347 (12347): perplexity: 99.8855, wsj_loss: 4.6040 ||
04/19 04:34:40 PM: Update 9386: task toronto_lm, batch 386 (9344): perplexity: 84.9640, toronto_lm_loss: 4.4422 ||
04/19 04:34:42 PM: Update 12363: task wsj, batch 363 (12363): perplexity: 100.0302, wsj_loss: 4.6055 ||
04/19 04:34:50 PM: Update 9399: task toronto_lm, batch 399 (9357): perplexity: 84.9924, toronto_lm_loss: 4.4426 ||
04/19 04:34:53 PM: Update 12379: task wsj, batch 379 (12379): perplexity: 99.9093, wsj_loss: 4.6043 ||
04/19 04:35:01 PM: Update 9413: task toronto_lm, batch 413 (9371): perplexity: 85.0215, toronto_lm_loss: 4.4429 ||
04/19 04:35:03 PM: Update 12395: task wsj, batch 395 (12395): perplexity: 100.1030, wsj_loss: 4.6062 ||
04/19 04:35:12 PM: Update 9418: task toronto_lm, batch 418 (9376): perplexity: 85.0879, toronto_lm_loss: 4.4437 ||
04/19 04:35:14 PM: Update 12411: task wsj, batch 411 (12411): perplexity: 100.1522, wsj_loss: 4.6067 ||
04/19 04:35:22 PM: Update 9432: task toronto_lm, batch 432 (9390): perplexity: 85.8652, toronto_lm_loss: 4.4528 ||
04/19 04:35:26 PM: Update 12422: task wsj, batch 422 (12422): perplexity: 100.2321, wsj_loss: 4.6075 ||
04/19 04:35:33 PM: Update 9446: task toronto_lm, batch 446 (9404): perplexity: 86.5138, toronto_lm_loss: 4.4603 ||
04/19 04:35:36 PM: Update 12438: task wsj, batch 438 (12438): perplexity: 100.2294, wsj_loss: 4.6075 ||
04/19 04:35:43 PM: Update 9459: task toronto_lm, batch 459 (9417): perplexity: 86.8339, toronto_lm_loss: 4.4640 ||
04/19 04:35:47 PM: Update 12454: task wsj, batch 454 (12454): perplexity: 99.9434, wsj_loss: 4.6046 ||
04/19 04:35:54 PM: Update 9473: task toronto_lm, batch 473 (9431): perplexity: 87.3012, toronto_lm_loss: 4.4694 ||
04/19 04:35:57 PM: Update 12470: task wsj, batch 470 (12470): perplexity: 99.6385, wsj_loss: 4.6015 ||
04/19 04:36:04 PM: Update 9487: task toronto_lm, batch 487 (9445): perplexity: 87.6252, toronto_lm_loss: 4.4731 ||
04/19 04:36:08 PM: Update 12486: task wsj, batch 486 (12486): perplexity: 99.6263, wsj_loss: 4.6014 ||
04/19 04:36:15 PM: Update 9501: task toronto_lm, batch 501 (9459): perplexity: 87.8552, toronto_lm_loss: 4.4757 ||
04/19 04:36:18 PM: Update 12502: task wsj, batch 502 (12502): perplexity: 99.4061, wsj_loss: 4.5992 ||
04/19 04:36:26 PM: Update 9515: task toronto_lm, batch 515 (9473): perplexity: 88.0750, toronto_lm_loss: 4.4782 ||
04/19 04:36:28 PM: Update 12518: task wsj, batch 518 (12518): perplexity: 99.1525, wsj_loss: 4.5967 ||
04/19 04:36:37 PM: Update 9529: task toronto_lm, batch 529 (9487): perplexity: 88.2600, toronto_lm_loss: 4.4803 ||
04/19 04:36:39 PM: Update 12534: task wsj, batch 534 (12534): perplexity: 99.2366, wsj_loss: 4.5975 ||
04/19 04:36:47 PM: Update 9542: task toronto_lm, batch 542 (9500): perplexity: 88.1635, toronto_lm_loss: 4.4792 ||
04/19 04:36:49 PM: Update 12550: task wsj, batch 550 (12550): perplexity: 99.1731, wsj_loss: 4.5969 ||
04/19 04:36:57 PM: Update 9556: task toronto_lm, batch 556 (9514): perplexity: 88.1668, toronto_lm_loss: 4.4792 ||
04/19 04:37:00 PM: Update 12558: task wsj, batch 558 (12558): perplexity: 99.0207, wsj_loss: 4.5953 ||
04/19 04:37:07 PM: Update 9569: task toronto_lm, batch 569 (9527): perplexity: 88.2397, toronto_lm_loss: 4.4801 ||
04/19 04:37:10 PM: Update 12574: task wsj, batch 574 (12574): perplexity: 99.0198, wsj_loss: 4.5953 ||
04/19 04:37:17 PM: Update 9582: task toronto_lm, batch 582 (9540): perplexity: 88.2558, toronto_lm_loss: 4.4802 ||
04/19 04:37:21 PM: Update 12590: task wsj, batch 590 (12590): perplexity: 99.0141, wsj_loss: 4.5953 ||
04/19 04:37:28 PM: Update 9596: task toronto_lm, batch 596 (9554): perplexity: 88.2498, toronto_lm_loss: 4.4802 ||
04/19 04:37:31 PM: Update 12606: task wsj, batch 606 (12606): perplexity: 99.1330, wsj_loss: 4.5965 ||
04/19 04:37:38 PM: Update 9609: task toronto_lm, batch 609 (9567): perplexity: 88.3001, toronto_lm_loss: 4.4807 ||
04/19 04:37:42 PM: Update 12622: task wsj, batch 622 (12622): perplexity: 99.2015, wsj_loss: 4.5972 ||
04/19 04:37:49 PM: Update 9623: task toronto_lm, batch 623 (9581): perplexity: 88.4862, toronto_lm_loss: 4.4828 ||
04/19 04:37:52 PM: Update 12638: task wsj, batch 638 (12638): perplexity: 99.2178, wsj_loss: 4.5973 ||
04/19 04:37:59 PM: Update 9636: task toronto_lm, batch 636 (9594): perplexity: 88.5529, toronto_lm_loss: 4.4836 ||
04/19 04:38:02 PM: Update 12654: task wsj, batch 654 (12654): perplexity: 99.3170, wsj_loss: 4.5983 ||
04/19 04:38:10 PM: Update 9650: task toronto_lm, batch 650 (9608): perplexity: 88.5304, toronto_lm_loss: 4.4833 ||
04/19 04:38:13 PM: Update 12670: task wsj, batch 670 (12670): perplexity: 99.3034, wsj_loss: 4.5982 ||
04/19 04:38:20 PM: Update 9664: task toronto_lm, batch 664 (9622): perplexity: 88.5852, toronto_lm_loss: 4.4840 ||
04/19 04:38:23 PM: Update 12686: task wsj, batch 686 (12686): perplexity: 99.3194, wsj_loss: 4.5983 ||
04/19 04:38:30 PM: Update 9677: task wsj, batch 1 (43): perplexity: 289.6640, wsj_loss: 5.6687 ||
04/19 04:38:31 PM: Update 9678: task toronto_lm, batch 677 (9635): perplexity: 88.5615, toronto_lm_loss: 4.4837 ||
04/19 04:38:34 PM: Update 12702: task wsj, batch 702 (12702): perplexity: 99.3099, wsj_loss: 4.5982 ||
04/19 04:38:42 PM: Update 9692: task toronto_lm, batch 691 (9649): perplexity: 88.4607, toronto_lm_loss: 4.4826 ||
04/19 04:38:47 PM: Update 12714: task wsj, batch 714 (12714): perplexity: 99.2640, wsj_loss: 4.5978 ||
04/19 04:38:51 PM: Update 9705: task wsj, batch 2 (44): perplexity: 335.0741, wsj_loss: 5.8144 ||
04/19 04:38:52 PM: Update 9706: task toronto_lm, batch 704 (9662): perplexity: 88.4140, toronto_lm_loss: 4.4820 ||
04/19 04:38:57 PM: Update 12730: task wsj, batch 730 (12730): perplexity: 99.1395, wsj_loss: 4.5965 ||
04/19 04:39:03 PM: Update 9720: task toronto_lm, batch 718 (9676): perplexity: 88.3395, toronto_lm_loss: 4.4812 ||
04/19 04:39:08 PM: Update 12746: task wsj, batch 746 (12746): perplexity: 98.9844, wsj_loss: 4.5950 ||
04/19 04:39:14 PM: Update 9734: task toronto_lm, batch 732 (9690): perplexity: 88.3430, toronto_lm_loss: 4.4812 ||
04/19 04:39:18 PM: Update 12762: task wsj, batch 762 (12762): perplexity: 98.9152, wsj_loss: 4.5943 ||
04/19 04:39:24 PM: Update 9748: task toronto_lm, batch 746 (9704): perplexity: 88.2834, toronto_lm_loss: 4.4806 ||
04/19 04:39:29 PM: Update 12778: task wsj, batch 778 (12778): perplexity: 98.9272, wsj_loss: 4.5944 ||
04/19 04:39:34 PM: Update 9761: task toronto_lm, batch 759 (9717): perplexity: 88.2551, toronto_lm_loss: 4.4802 ||
04/19 04:39:37 PM: Update 9764: task wsj, batch 3 (45): perplexity: 346.3762, wsj_loss: 5.8475 ||
04/19 04:39:39 PM: Update 12794: task wsj, batch 794 (12794): perplexity: 98.8470, wsj_loss: 4.5936 ||
04/19 04:39:45 PM: Update 9775: task toronto_lm, batch 772 (9730): perplexity: 88.2127, toronto_lm_loss: 4.4798 ||
04/19 04:39:50 PM: Update 12810: task wsj, batch 810 (12810): perplexity: 98.8088, wsj_loss: 4.5932 ||
04/19 04:39:56 PM: Update 9789: task toronto_lm, batch 786 (9744): perplexity: 88.2601, toronto_lm_loss: 4.4803 ||
04/19 04:40:00 PM: Update 12826: task wsj, batch 826 (12826): perplexity: 98.6752, wsj_loss: 4.5918 ||
04/19 04:40:06 PM: Update 9803: task toronto_lm, batch 800 (9758): perplexity: 88.1613, toronto_lm_loss: 4.4792 ||
04/19 04:40:10 PM: Update 12842: task wsj, batch 842 (12842): perplexity: 98.5260, wsj_loss: 4.5903 ||
04/19 04:40:17 PM: Update 9817: task toronto_lm, batch 814 (9772): perplexity: 88.1204, toronto_lm_loss: 4.4787 ||
04/19 04:40:21 PM: Update 12850: task wsj, batch 850 (12850): perplexity: 98.5553, wsj_loss: 4.5906 ||
04/19 04:40:28 PM: Update 9831: task toronto_lm, batch 828 (9786): perplexity: 88.0092, toronto_lm_loss: 4.4774 ||
04/19 04:40:31 PM: Update 12866: task wsj, batch 866 (12866): perplexity: 98.5427, wsj_loss: 4.5905 ||
04/19 04:40:38 PM: Update 9845: task toronto_lm, batch 842 (9800): perplexity: 87.8961, toronto_lm_loss: 4.4762 ||
04/19 04:40:42 PM: Update 12882: task wsj, batch 882 (12882): perplexity: 98.5768, wsj_loss: 4.5908 ||
04/19 04:40:48 PM: Update 9858: task toronto_lm, batch 855 (9813): perplexity: 87.8736, toronto_lm_loss: 4.4759 ||
04/19 04:40:52 PM: Update 12898: task wsj, batch 898 (12898): perplexity: 98.5343, wsj_loss: 4.5904 ||
04/19 04:40:59 PM: Update 9872: task toronto_lm, batch 869 (9827): perplexity: 87.8273, toronto_lm_loss: 4.4754 ||
04/19 04:41:03 PM: Update 12914: task wsj, batch 914 (12914): perplexity: 98.5647, wsj_loss: 4.5907 ||
04/19 04:41:10 PM: Update 9886: task toronto_lm, batch 883 (9841): perplexity: 87.7329, toronto_lm_loss: 4.4743 ||
04/19 04:41:13 PM: Update 12930: task wsj, batch 930 (12930): perplexity: 98.6330, wsj_loss: 4.5914 ||
04/19 04:41:20 PM: Update 9900: task toronto_lm, batch 897 (9855): perplexity: 87.7189, toronto_lm_loss: 4.4741 ||
04/19 04:41:23 PM: Update 12946: task wsj, batch 946 (12946): perplexity: 98.6904, wsj_loss: 4.5920 ||
04/19 04:41:31 PM: Update 9914: task wsj, batch 4 (46): perplexity: 346.5303, wsj_loss: 5.8480 ||
04/19 04:41:32 PM: Update 9915: task toronto_lm, batch 911 (9869): perplexity: 87.6681, toronto_lm_loss: 4.4736 ||
04/19 04:41:34 PM: Update 12962: task wsj, batch 962 (12962): perplexity: 98.6614, wsj_loss: 4.5917 ||
04/19 04:41:42 PM: Update 9929: task toronto_lm, batch 925 (9883): perplexity: 87.6402, toronto_lm_loss: 4.4732 ||
04/19 04:41:44 PM: Update 12978: task wsj, batch 978 (12978): perplexity: 98.6505, wsj_loss: 4.5916 ||
04/19 04:41:53 PM: Update 9943: task toronto_lm, batch 939 (9897): perplexity: 87.6316, toronto_lm_loss: 4.4731 ||
04/19 04:41:55 PM: Update 12994: task wsj, batch 994 (12994): perplexity: 98.6039, wsj_loss: 4.5911 ||
04/19 04:41:59 PM: ***** Pass 13000 / Epoch 13 *****
04/19 04:41:59 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 04:41:59 PM: Validating...
04/19 04:42:04 PM: Update 9957: task toronto_lm, batch 953 (9911): perplexity: 87.5671, toronto_lm_loss: 4.4724 ||
04/19 04:42:04 PM: Best model found for wsj.
04/19 04:42:04 PM: Best model found for micro.
04/19 04:42:04 PM: Best model found for macro.
04/19 04:42:04 PM: Advancing scheduler.
04/19 04:42:04 PM: 	Best macro_avg: 105.738
04/19 04:42:04 PM: 	# bad epochs: 0
04/19 04:42:04 PM: Statistic: wsj_loss
04/19 04:42:04 PM: 	training: 4.591567
04/19 04:42:04 PM: 	validation: 4.660965
04/19 04:42:04 PM: Statistic: macro_avg
04/19 04:42:04 PM: 	validation: 105.738053
04/19 04:42:04 PM: Statistic: micro_avg
04/19 04:42:04 PM: 	validation: 105.738053
04/19 04:42:04 PM: Statistic: wsj_perplexity
04/19 04:42:04 PM: 	training: 98.648892
04/19 04:42:04 PM: 	validation: 105.738053
04/19 04:42:04 PM: global_lr: 0.003000
04/19 04:42:05 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 04:42:05 PM: Update 13001: task wsj, batch 1 (13001): perplexity: 90.5276, wsj_loss: 4.5057 ||
04/19 04:42:15 PM: Update 9971: task toronto_lm, batch 967 (9925): perplexity: 87.4559, toronto_lm_loss: 4.4711 ||
04/19 04:42:16 PM: Update 13008: task wsj, batch 8 (13008): perplexity: 100.6349, wsj_loss: 4.6115 ||
04/19 04:42:25 PM: Update 9984: task toronto_lm, batch 980 (9938): perplexity: 87.3823, toronto_lm_loss: 4.4703 ||
04/19 04:42:26 PM: Update 13024: task wsj, batch 24 (13024): perplexity: 96.7394, wsj_loss: 4.5720 ||
04/19 04:42:35 PM: Update 9998: task toronto_lm, batch 994 (9952): perplexity: 87.3287, toronto_lm_loss: 4.4697 ||
04/19 04:42:37 PM: Update 13040: task wsj, batch 40 (13040): perplexity: 96.1190, wsj_loss: 4.5656 ||
04/19 04:42:37 PM: ***** Pass 10000 / Epoch 10 *****
04/19 04:42:37 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 04:42:37 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 04:42:37 PM: Validating...
04/19 04:42:46 PM: Batch 27/140: perplexity: 109.8197, toronto_lm_loss: 4.6988 || , for evaluation data
04/19 04:42:47 PM: Update 13056: task wsj, batch 56 (13056): perplexity: 95.6412, wsj_loss: 4.5606 ||
04/19 04:42:56 PM: Batch 65/140: perplexity: 107.5654, toronto_lm_loss: 4.6781 || , for evaluation data
04/19 04:42:58 PM: Update 13072: task wsj, batch 72 (13072): perplexity: 95.4389, wsj_loss: 4.5585 ||
04/19 04:43:06 PM: Batch 104/140: perplexity: 101.9227, toronto_lm_loss: 4.6242 || , for evaluation data
04/19 04:43:08 PM: Update 13088: task wsj, batch 88 (13088): perplexity: 95.3102, wsj_loss: 4.5571 ||
04/19 04:43:16 PM: Batch 1/66: perplexity: 436.1687, wsj_loss: 6.0780 || , for evaluation data
04/19 04:43:18 PM: Update 13104: task wsj, batch 104 (13104): perplexity: 94.6040, wsj_loss: 4.5497 ||
04/19 04:43:26 PM: Batch 39/66: perplexity: 315.2506, wsj_loss: 5.7534 || , for evaluation data
04/19 04:43:29 PM: Update 13120: task wsj, batch 120 (13120): perplexity: 94.3313, wsj_loss: 4.5468 ||
04/19 04:43:33 PM: Best model found for toronto_lm.
04/19 04:43:33 PM: Best model found for wsj.
04/19 04:43:33 PM: Best model found for micro.
04/19 04:43:33 PM: Best model found for macro.
04/19 04:43:33 PM: Advancing scheduler.
04/19 04:43:33 PM: 	Best macro_avg: 0.037
04/19 04:43:33 PM: 	# bad epochs: 0
04/19 04:43:33 PM: Statistic: toronto_lm_loss
04/19 04:43:33 PM: 	training: 4.469315
04/19 04:43:33 PM: 	validation: 4.548112
04/19 04:43:33 PM: Statistic: wsj_loss
04/19 04:43:33 PM: 	training: 5.847970
04/19 04:43:33 PM: 	validation: 5.734922
04/19 04:43:33 PM: Statistic: macro_avg
04/19 04:43:33 PM: 	validation: 0.036568
04/19 04:43:33 PM: Statistic: micro_avg
04/19 04:43:33 PM: 	validation: -0.076270
04/19 04:43:33 PM: Statistic: toronto_lm_perplexity
04/19 04:43:33 PM: 	training: 87.296885
04/19 04:43:33 PM: 	validation: 94.453919
04/19 04:43:33 PM: Statistic: wsj_perplexity
04/19 04:43:33 PM: 	training: 346.530254
04/19 04:43:33 PM: 	validation: 309.488795
04/19 04:43:33 PM: global_lr: 0.001000
04/19 04:43:33 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 04:43:34 PM: Update 10001: task toronto_lm, batch 1 (9955): perplexity: 72.8393, toronto_lm_loss: 4.2883 ||
04/19 04:43:39 PM: Update 13136: task wsj, batch 136 (13136): perplexity: 94.4820, wsj_loss: 4.5484 ||
04/19 04:43:44 PM: Update 10014: task toronto_lm, batch 14 (9968): perplexity: 81.6606, toronto_lm_loss: 4.4026 ||
04/19 04:43:50 PM: Update 13144: task wsj, batch 144 (13144): perplexity: 94.6034, wsj_loss: 4.5497 ||
04/19 04:43:55 PM: Update 10028: task toronto_lm, batch 28 (9982): perplexity: 82.7162, toronto_lm_loss: 4.4154 ||
04/19 04:44:00 PM: Update 13160: task wsj, batch 160 (13160): perplexity: 94.9680, wsj_loss: 4.5535 ||
04/19 04:44:05 PM: Update 10041: task toronto_lm, batch 41 (9995): perplexity: 82.2178, toronto_lm_loss: 4.4094 ||
04/19 04:44:11 PM: Update 13176: task wsj, batch 176 (13176): perplexity: 94.8750, wsj_loss: 4.5526 ||
04/19 04:44:18 PM: Update 10047: task toronto_lm, batch 47 (10001): perplexity: 82.7815, toronto_lm_loss: 4.4162 ||
04/19 04:44:21 PM: Update 13192: task wsj, batch 192 (13192): perplexity: 95.2080, wsj_loss: 4.5561 ||
04/19 04:44:28 PM: Update 10060: task toronto_lm, batch 60 (10014): perplexity: 87.4114, toronto_lm_loss: 4.4706 ||
04/19 04:44:31 PM: Update 13208: task wsj, batch 208 (13208): perplexity: 95.5405, wsj_loss: 4.5595 ||
04/19 04:44:38 PM: Update 10073: task toronto_lm, batch 73 (10027): perplexity: 91.5138, toronto_lm_loss: 4.5165 ||
04/19 04:44:39 PM: Update 10074: task wsj, batch 1 (47): perplexity: 317.7492, wsj_loss: 5.7613 ||
04/19 04:44:42 PM: Update 13224: task wsj, batch 224 (13224): perplexity: 95.9525, wsj_loss: 4.5639 ||
04/19 04:44:48 PM: Update 10086: task toronto_lm, batch 85 (10039): perplexity: 94.4322, toronto_lm_loss: 4.5479 ||
04/19 04:44:52 PM: Update 13240: task wsj, batch 240 (13240): perplexity: 96.2232, wsj_loss: 4.5667 ||
04/19 04:44:58 PM: Update 10099: task toronto_lm, batch 98 (10052): perplexity: 95.7698, toronto_lm_loss: 4.5619 ||
04/19 04:45:03 PM: Update 13256: task wsj, batch 256 (13256): perplexity: 96.3369, wsj_loss: 4.5679 ||
04/19 04:45:08 PM: Update 10112: task toronto_lm, batch 111 (10065): perplexity: 95.8729, toronto_lm_loss: 4.5630 ||
04/19 04:45:13 PM: Update 13272: task wsj, batch 272 (13272): perplexity: 96.2848, wsj_loss: 4.5673 ||
04/19 04:45:18 PM: Update 10125: task toronto_lm, batch 124 (10078): perplexity: 96.0640, toronto_lm_loss: 4.5650 ||
04/19 04:45:24 PM: Update 13288: task wsj, batch 288 (13288): perplexity: 96.3545, wsj_loss: 4.5680 ||
04/19 04:45:28 PM: Update 10138: task toronto_lm, batch 137 (10091): perplexity: 95.9017, toronto_lm_loss: 4.5633 ||
04/19 04:45:35 PM: Update 13298: task wsj, batch 298 (13298): perplexity: 96.6570, wsj_loss: 4.5712 ||
04/19 04:45:38 PM: Update 10151: task toronto_lm, batch 150 (10104): perplexity: 95.8971, toronto_lm_loss: 4.5633 ||
04/19 04:45:45 PM: Update 13314: task wsj, batch 314 (13314): perplexity: 96.5729, wsj_loss: 4.5703 ||
04/19 04:45:48 PM: Update 10164: task toronto_lm, batch 163 (10117): perplexity: 95.8594, toronto_lm_loss: 4.5629 ||
04/19 04:45:56 PM: Update 13330: task wsj, batch 330 (13330): perplexity: 96.5271, wsj_loss: 4.5698 ||
04/19 04:45:58 PM: Update 10177: task toronto_lm, batch 176 (10130): perplexity: 95.5712, toronto_lm_loss: 4.5599 ||
04/19 04:46:06 PM: Update 13346: task wsj, batch 346 (13346): perplexity: 96.2992, wsj_loss: 4.5675 ||
04/19 04:46:08 PM: Update 10190: task toronto_lm, batch 189 (10143): perplexity: 95.2928, toronto_lm_loss: 4.5570 ||
04/19 04:46:17 PM: Update 13362: task wsj, batch 362 (13362): perplexity: 96.1266, wsj_loss: 4.5657 ||
04/19 04:46:18 PM: Update 10203: task toronto_lm, batch 202 (10156): perplexity: 94.7855, toronto_lm_loss: 4.5516 ||
04/19 04:46:27 PM: Update 13378: task wsj, batch 378 (13378): perplexity: 96.0868, wsj_loss: 4.5653 ||
04/19 04:46:29 PM: Update 10216: task toronto_lm, batch 215 (10169): perplexity: 94.2335, toronto_lm_loss: 4.5458 ||
04/19 04:46:37 PM: Update 13394: task wsj, batch 394 (13394): perplexity: 96.0112, wsj_loss: 4.5645 ||
04/19 04:46:39 PM: Update 10229: task toronto_lm, batch 228 (10182): perplexity: 93.8900, toronto_lm_loss: 4.5421 ||
04/19 04:46:48 PM: Update 13410: task wsj, batch 410 (13410): perplexity: 95.9325, wsj_loss: 4.5636 ||
04/19 04:46:49 PM: Update 10242: task toronto_lm, batch 241 (10195): perplexity: 93.7540, toronto_lm_loss: 4.5407 ||
04/19 04:46:58 PM: Update 13426: task wsj, batch 426 (13426): perplexity: 95.7414, wsj_loss: 4.5617 ||
04/19 04:46:59 PM: Update 10255: task toronto_lm, batch 254 (10208): perplexity: 93.3551, toronto_lm_loss: 4.5364 ||
04/19 04:47:09 PM: Update 13433: task wsj, batch 433 (13433): perplexity: 95.7061, wsj_loss: 4.5613 ||
04/19 04:47:10 PM: Update 10269: task toronto_lm, batch 268 (10222): perplexity: 92.9650, toronto_lm_loss: 4.5322 ||
04/19 04:47:19 PM: Update 13449: task wsj, batch 449 (13449): perplexity: 95.7576, wsj_loss: 4.5618 ||
04/19 04:47:20 PM: Update 10282: task toronto_lm, batch 281 (10235): perplexity: 92.7544, toronto_lm_loss: 4.5300 ||
04/19 04:47:21 PM: Update 10284: task wsj, batch 2 (48): perplexity: 305.0424, wsj_loss: 5.7205 ||
04/19 04:47:29 PM: Update 13465: task wsj, batch 465 (13465): perplexity: 95.8388, wsj_loss: 4.5627 ||
04/19 04:47:30 PM: Update 10295: task toronto_lm, batch 293 (10247): perplexity: 92.7349, toronto_lm_loss: 4.5297 ||
04/19 04:47:40 PM: Update 10308: task toronto_lm, batch 306 (10260): perplexity: 92.3967, toronto_lm_loss: 4.5261 ||
04/19 04:47:40 PM: Update 13481: task wsj, batch 481 (13481): perplexity: 95.8680, wsj_loss: 4.5630 ||
04/19 04:47:50 PM: Update 10321: task toronto_lm, batch 319 (10273): perplexity: 92.0803, toronto_lm_loss: 4.5227 ||
04/19 04:47:50 PM: Update 13497: task wsj, batch 497 (13497): perplexity: 95.7897, wsj_loss: 4.5622 ||
04/19 04:48:00 PM: Update 10334: task toronto_lm, batch 332 (10286): perplexity: 91.8863, toronto_lm_loss: 4.5206 ||
04/19 04:48:01 PM: Update 13513: task wsj, batch 513 (13513): perplexity: 96.0076, wsj_loss: 4.5644 ||
04/19 04:48:10 PM: Update 10347: task toronto_lm, batch 345 (10299): perplexity: 91.6433, toronto_lm_loss: 4.5179 ||
04/19 04:48:11 PM: Update 13529: task wsj, batch 529 (13529): perplexity: 96.1056, wsj_loss: 4.5654 ||
04/19 04:48:21 PM: Update 10361: task toronto_lm, batch 359 (10313): perplexity: 91.0750, toronto_lm_loss: 4.5117 ||
04/19 04:48:22 PM: Update 13545: task wsj, batch 545 (13545): perplexity: 96.0554, wsj_loss: 4.5649 ||
04/19 04:48:31 PM: Update 10374: task toronto_lm, batch 372 (10326): perplexity: 90.7151, toronto_lm_loss: 4.5077 ||
04/19 04:48:32 PM: Update 13561: task wsj, batch 561 (13561): perplexity: 96.1156, wsj_loss: 4.5656 ||
04/19 04:48:38 PM: Update 10383: task wsj, batch 3 (49): perplexity: 297.8116, wsj_loss: 5.6965 ||
04/19 04:48:41 PM: Update 10387: task toronto_lm, batch 384 (10338): perplexity: 90.6734, toronto_lm_loss: 4.5073 ||
04/19 04:48:43 PM: Update 13577: task wsj, batch 577 (13577): perplexity: 96.2650, wsj_loss: 4.5671 ||
04/19 04:48:51 PM: Update 10400: task toronto_lm, batch 397 (10351): perplexity: 90.5387, toronto_lm_loss: 4.5058 ||
04/19 04:48:56 PM: Update 13590: task wsj, batch 590 (13590): perplexity: 96.2629, wsj_loss: 4.5671 ||
04/19 04:49:01 PM: Update 10413: task toronto_lm, batch 410 (10364): perplexity: 90.4854, toronto_lm_loss: 4.5052 ||
04/19 04:49:06 PM: Update 13606: task wsj, batch 606 (13606): perplexity: 96.1837, wsj_loss: 4.5663 ||
04/19 04:49:11 PM: Update 10427: task toronto_lm, batch 424 (10378): perplexity: 90.2667, toronto_lm_loss: 4.5028 ||
04/19 04:49:17 PM: Update 13622: task wsj, batch 622 (13622): perplexity: 96.1246, wsj_loss: 4.5656 ||
04/19 04:49:21 PM: Update 10440: task toronto_lm, batch 437 (10391): perplexity: 90.1626, toronto_lm_loss: 4.5016 ||
04/19 04:49:27 PM: Update 13638: task wsj, batch 638 (13638): perplexity: 96.0427, wsj_loss: 4.5648 ||
04/19 04:49:32 PM: Update 10453: task toronto_lm, batch 450 (10404): perplexity: 89.8156, toronto_lm_loss: 4.4978 ||
04/19 04:49:38 PM: Update 13654: task wsj, batch 654 (13654): perplexity: 95.8992, wsj_loss: 4.5633 ||
04/19 04:49:42 PM: Update 10466: task toronto_lm, batch 463 (10417): perplexity: 89.7186, toronto_lm_loss: 4.4967 ||
04/19 04:49:48 PM: Update 13670: task wsj, batch 670 (13670): perplexity: 95.8444, wsj_loss: 4.5627 ||
04/19 04:49:52 PM: Update 10479: task toronto_lm, batch 476 (10430): perplexity: 89.6164, toronto_lm_loss: 4.4955 ||
04/19 04:49:59 PM: Update 13686: task wsj, batch 686 (13686): perplexity: 95.8154, wsj_loss: 4.5624 ||
04/19 04:50:02 PM: Update 10492: task toronto_lm, batch 489 (10443): perplexity: 89.4218, toronto_lm_loss: 4.4934 ||
04/19 04:50:09 PM: Update 13702: task wsj, batch 702 (13702): perplexity: 95.7251, wsj_loss: 4.5615 ||
04/19 04:50:12 PM: Update 10505: task toronto_lm, batch 502 (10456): perplexity: 89.2155, toronto_lm_loss: 4.4911 ||
04/19 04:50:14 PM: Update 10507: task wsj, batch 4 (50): perplexity: 306.6052, wsj_loss: 5.7256 ||
04/19 04:50:19 PM: Update 13718: task wsj, batch 718 (13718): perplexity: 95.5888, wsj_loss: 4.5601 ||
04/19 04:50:22 PM: Update 10518: task toronto_lm, batch 514 (10468): perplexity: 89.1859, toronto_lm_loss: 4.4907 ||
04/19 04:50:30 PM: Update 13726: task wsj, batch 726 (13726): perplexity: 95.6113, wsj_loss: 4.5603 ||
04/19 04:50:32 PM: Update 10531: task toronto_lm, batch 527 (10481): perplexity: 89.1494, toronto_lm_loss: 4.4903 ||
04/19 04:50:40 PM: Update 13742: task wsj, batch 742 (13742): perplexity: 95.6411, wsj_loss: 4.5606 ||
04/19 04:50:43 PM: Update 10544: task toronto_lm, batch 540 (10494): perplexity: 89.0135, toronto_lm_loss: 4.4888 ||
04/19 04:50:51 PM: Update 13758: task wsj, batch 758 (13758): perplexity: 95.6633, wsj_loss: 4.5608 ||
04/19 04:50:53 PM: Update 10557: task toronto_lm, batch 553 (10507): perplexity: 88.9216, toronto_lm_loss: 4.4878 ||
04/19 04:51:01 PM: Update 13774: task wsj, batch 774 (13774): perplexity: 95.7172, wsj_loss: 4.5614 ||
04/19 04:51:03 PM: Update 10570: task toronto_lm, batch 566 (10520): perplexity: 88.8615, toronto_lm_loss: 4.4871 ||
04/19 04:51:12 PM: Update 13790: task wsj, batch 790 (13790): perplexity: 95.7323, wsj_loss: 4.5616 ||
04/19 04:51:13 PM: Update 10583: task toronto_lm, batch 579 (10533): perplexity: 88.6937, toronto_lm_loss: 4.4852 ||
04/19 04:51:22 PM: Update 13806: task wsj, batch 806 (13806): perplexity: 95.6976, wsj_loss: 4.5612 ||
04/19 04:51:23 PM: Update 10596: task toronto_lm, batch 592 (10546): perplexity: 88.5428, toronto_lm_loss: 4.4835 ||
04/19 04:51:33 PM: Update 13822: task wsj, batch 822 (13822): perplexity: 95.7379, wsj_loss: 4.5616 ||
04/19 04:51:33 PM: Update 10609: task toronto_lm, batch 605 (10559): perplexity: 88.3535, toronto_lm_loss: 4.4813 ||
04/19 04:51:43 PM: Update 13838: task wsj, batch 838 (13838): perplexity: 95.7608, wsj_loss: 4.5619 ||
04/19 04:51:43 PM: Update 10622: task toronto_lm, batch 618 (10572): perplexity: 88.1883, toronto_lm_loss: 4.4795 ||
04/19 04:51:53 PM: Update 10635: task toronto_lm, batch 631 (10585): perplexity: 87.9689, toronto_lm_loss: 4.4770 ||
04/19 04:51:53 PM: Update 13854: task wsj, batch 854 (13854): perplexity: 95.8965, wsj_loss: 4.5633 ||
04/19 04:52:03 PM: Update 10648: task toronto_lm, batch 644 (10598): perplexity: 87.7986, toronto_lm_loss: 4.4750 ||
04/19 04:52:04 PM: Update 13870: task wsj, batch 870 (13870): perplexity: 95.9284, wsj_loss: 4.5636 ||
04/19 04:52:14 PM: Update 10661: task toronto_lm, batch 657 (10611): perplexity: 87.7467, toronto_lm_loss: 4.4745 ||
04/19 04:52:17 PM: Update 13882: task wsj, batch 882 (13882): perplexity: 95.9604, wsj_loss: 4.5639 ||
04/19 04:52:23 PM: Update 10673: task wsj, batch 5 (51): perplexity: 296.4435, wsj_loss: 5.6919 ||
04/19 04:52:24 PM: Update 10674: task toronto_lm, batch 669 (10623): perplexity: 87.6049, toronto_lm_loss: 4.4728 ||
04/19 04:52:28 PM: Update 13898: task wsj, batch 898 (13898): perplexity: 95.9714, wsj_loss: 4.5641 ||
04/19 04:52:34 PM: Update 10678: task toronto_lm, batch 673 (10627): perplexity: 87.6215, toronto_lm_loss: 4.4730 ||
04/19 04:52:38 PM: Update 13914: task wsj, batch 914 (13914): perplexity: 95.9044, wsj_loss: 4.5634 ||
04/19 04:52:44 PM: Update 10691: task toronto_lm, batch 686 (10640): perplexity: 87.7712, toronto_lm_loss: 4.4747 ||
04/19 04:52:49 PM: Update 13930: task wsj, batch 930 (13930): perplexity: 95.8087, wsj_loss: 4.5624 ||
04/19 04:52:54 PM: Update 10704: task toronto_lm, batch 699 (10653): perplexity: 87.9538, toronto_lm_loss: 4.4768 ||
04/19 04:52:59 PM: Update 13946: task wsj, batch 946 (13946): perplexity: 95.7051, wsj_loss: 4.5613 ||
04/19 04:53:04 PM: Update 10717: task toronto_lm, batch 712 (10666): perplexity: 88.0222, toronto_lm_loss: 4.4776 ||
04/19 04:53:10 PM: Update 13962: task wsj, batch 962 (13962): perplexity: 95.5974, wsj_loss: 4.5601 ||
04/19 04:53:14 PM: Update 10730: task toronto_lm, batch 725 (10679): perplexity: 88.1547, toronto_lm_loss: 4.4791 ||
04/19 04:53:20 PM: Update 13978: task wsj, batch 978 (13978): perplexity: 95.5729, wsj_loss: 4.5599 ||
04/19 04:53:24 PM: Update 10743: task toronto_lm, batch 738 (10692): perplexity: 88.1967, toronto_lm_loss: 4.4796 ||
04/19 04:53:30 PM: Update 13994: task wsj, batch 994 (13994): perplexity: 95.4943, wsj_loss: 4.5591 ||
04/19 04:53:34 PM: ***** Pass 14000 / Epoch 14 *****
04/19 04:53:34 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 04:53:34 PM: Validating...
04/19 04:53:34 PM: Update 10756: task toronto_lm, batch 751 (10705): perplexity: 88.1206, toronto_lm_loss: 4.4787 ||
04/19 04:53:40 PM: Best model found for wsj.
04/19 04:53:40 PM: Best model found for micro.
04/19 04:53:40 PM: Best model found for macro.
04/19 04:53:40 PM: Advancing scheduler.
04/19 04:53:40 PM: 	Best macro_avg: 103.550
04/19 04:53:40 PM: 	# bad epochs: 0
04/19 04:53:40 PM: Statistic: wsj_loss
04/19 04:53:40 PM: 	training: 4.559169
04/19 04:53:40 PM: 	validation: 4.640059
04/19 04:53:40 PM: Statistic: macro_avg
04/19 04:53:40 PM: 	validation: 103.550451
04/19 04:53:40 PM: Statistic: micro_avg
04/19 04:53:40 PM: 	validation: 103.550451
04/19 04:53:40 PM: Statistic: wsj_perplexity
04/19 04:53:40 PM: 	training: 95.504077
04/19 04:53:40 PM: 	validation: 103.550451
04/19 04:53:40 PM: global_lr: 0.003000
04/19 04:53:40 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 04:53:41 PM: Update 14001: task wsj, batch 1 (14001): perplexity: 88.7392, wsj_loss: 4.4857 ||
04/19 04:53:44 PM: Update 10769: task toronto_lm, batch 764 (10718): perplexity: 88.0442, toronto_lm_loss: 4.4778 ||
04/19 04:53:55 PM: Update 10782: task toronto_lm, batch 777 (10731): perplexity: 88.0422, toronto_lm_loss: 4.4778 ||
04/19 04:53:56 PM: Update 14017: task wsj, batch 17 (14017): perplexity: 91.6567, wsj_loss: 4.5181 ||
04/19 04:54:05 PM: Update 10795: task toronto_lm, batch 790 (10744): perplexity: 87.9373, toronto_lm_loss: 4.4766 ||
04/19 04:54:07 PM: Update 14033: task wsj, batch 33 (14033): perplexity: 92.5945, wsj_loss: 4.5282 ||
04/19 04:54:15 PM: Update 10808: task toronto_lm, batch 803 (10757): perplexity: 87.9391, toronto_lm_loss: 4.4766 ||
04/19 04:54:17 PM: Update 14049: task wsj, batch 49 (14049): perplexity: 94.3951, wsj_loss: 4.5475 ||
04/19 04:54:25 PM: Update 10821: task toronto_lm, batch 816 (10770): perplexity: 87.8237, toronto_lm_loss: 4.4753 ||
04/19 04:54:27 PM: Update 14065: task wsj, batch 65 (14065): perplexity: 94.1025, wsj_loss: 4.5444 ||
04/19 04:54:32 PM: Update 10830: task wsj, batch 6 (52): perplexity: 292.0073, wsj_loss: 5.6768 ||
04/19 04:54:35 PM: Update 10834: task toronto_lm, batch 828 (10782): perplexity: 87.8094, toronto_lm_loss: 4.4752 ||
04/19 04:54:38 PM: Update 14081: task wsj, batch 81 (14081): perplexity: 94.5545, wsj_loss: 4.5492 ||
04/19 04:54:45 PM: Update 10847: task toronto_lm, batch 841 (10795): perplexity: 87.7057, toronto_lm_loss: 4.4740 ||
04/19 04:54:48 PM: Update 14097: task wsj, batch 97 (14097): perplexity: 94.9758, wsj_loss: 4.5536 ||
04/19 04:54:55 PM: Update 10860: task toronto_lm, batch 854 (10808): perplexity: 87.5720, toronto_lm_loss: 4.4725 ||
04/19 04:54:59 PM: Update 14113: task wsj, batch 113 (14113): perplexity: 95.2287, wsj_loss: 4.5563 ||
04/19 04:55:05 PM: Update 10873: task toronto_lm, batch 867 (10821): perplexity: 87.5189, toronto_lm_loss: 4.4719 ||
04/19 04:55:09 PM: Update 14129: task wsj, batch 129 (14129): perplexity: 95.4671, wsj_loss: 4.5588 ||
04/19 04:55:15 PM: Update 10886: task toronto_lm, batch 880 (10834): perplexity: 87.3998, toronto_lm_loss: 4.4705 ||
04/19 04:55:20 PM: Update 14145: task wsj, batch 145 (14145): perplexity: 95.7277, wsj_loss: 4.5615 ||
04/19 04:55:26 PM: Update 10900: task wsj, batch 7 (53): perplexity: 290.3577, wsj_loss: 5.6711 ||
04/19 04:55:27 PM: Update 10901: task toronto_lm, batch 894 (10848): perplexity: 87.3191, toronto_lm_loss: 4.4696 ||
04/19 04:55:30 PM: Update 14161: task wsj, batch 161 (14161): perplexity: 95.6720, wsj_loss: 4.5609 ||
04/19 04:55:38 PM: Update 10915: task toronto_lm, batch 908 (10862): perplexity: 87.2862, toronto_lm_loss: 4.4692 ||
04/19 04:55:44 PM: Update 14174: task wsj, batch 174 (14174): perplexity: 95.6156, wsj_loss: 4.5603 ||
04/19 04:55:48 PM: Update 10929: task toronto_lm, batch 922 (10876): perplexity: 87.2085, toronto_lm_loss: 4.4683 ||
04/19 04:55:54 PM: Update 14190: task wsj, batch 190 (14190): perplexity: 94.9371, wsj_loss: 4.5532 ||
04/19 04:55:58 PM: Update 10942: task toronto_lm, batch 935 (10889): perplexity: 87.1502, toronto_lm_loss: 4.4676 ||
04/19 04:56:05 PM: Update 14206: task wsj, batch 206 (14206): perplexity: 94.7263, wsj_loss: 4.5510 ||
04/19 04:56:08 PM: Update 10955: task toronto_lm, batch 948 (10902): perplexity: 87.0412, toronto_lm_loss: 4.4664 ||
04/19 04:56:15 PM: Update 14222: task wsj, batch 222 (14222): perplexity: 94.8246, wsj_loss: 4.5520 ||
04/19 04:56:19 PM: Update 10969: task toronto_lm, batch 962 (10916): perplexity: 86.9413, toronto_lm_loss: 4.4652 ||
04/19 04:56:26 PM: Update 14238: task wsj, batch 238 (14238): perplexity: 94.5514, wsj_loss: 4.5491 ||
04/19 04:56:29 PM: Update 10982: task toronto_lm, batch 975 (10929): perplexity: 86.8307, toronto_lm_loss: 4.4640 ||
04/19 04:56:36 PM: Update 14254: task wsj, batch 254 (14254): perplexity: 94.2475, wsj_loss: 4.5459 ||
04/19 04:56:39 PM: Update 10995: task toronto_lm, batch 988 (10942): perplexity: 86.7495, toronto_lm_loss: 4.4630 ||
04/19 04:56:43 PM: ***** Pass 11000 / Epoch 11 *****
04/19 04:56:43 PM: toronto_lm: trained on 993 batches, 0.005 epochs
04/19 04:56:43 PM: wsj: trained on 7 batches, 0.008 epochs
04/19 04:56:43 PM: Validating...
04/19 04:56:47 PM: Update 14270: task wsj, batch 270 (14270): perplexity: 93.9404, wsj_loss: 4.5427 ||
04/19 04:56:49 PM: Batch 24/140: perplexity: 114.4118, toronto_lm_loss: 4.7398 || , for evaluation data
04/19 04:56:57 PM: Update 14286: task wsj, batch 286 (14286): perplexity: 93.8553, wsj_loss: 4.5418 ||
04/19 04:56:59 PM: Batch 63/140: perplexity: 109.2723, toronto_lm_loss: 4.6938 || , for evaluation data
04/19 04:57:07 PM: Update 14302: task wsj, batch 302 (14302): perplexity: 93.8342, wsj_loss: 4.5415 ||
04/19 04:57:09 PM: Batch 97/140: perplexity: 103.6919, toronto_lm_loss: 4.6414 || , for evaluation data
04/19 04:57:17 PM: Update 14310: task wsj, batch 310 (14310): perplexity: 93.6948, wsj_loss: 4.5400 ||
04/19 04:57:19 PM: Batch 136/140: perplexity: 96.2935, toronto_lm_loss: 4.5674 || , for evaluation data
04/19 04:57:21 PM: Batch 1/66: perplexity: 419.7641, wsj_loss: 6.0397 || , for evaluation data
04/19 04:57:28 PM: Update 14326: task wsj, batch 326 (14326): perplexity: 93.8700, wsj_loss: 4.5419 ||
04/19 04:57:31 PM: Batch 40/66: perplexity: 299.1401, wsj_loss: 5.7009 || , for evaluation data
04/19 04:57:38 PM: Best model found for wsj.
04/19 04:57:38 PM: Best model found for micro.
04/19 04:57:38 PM: Best model found for macro.
04/19 04:57:38 PM: Advancing scheduler.
04/19 04:57:38 PM: 	Best macro_avg: 0.061
04/19 04:57:38 PM: 	# bad epochs: 0
04/19 04:57:38 PM: Statistic: toronto_lm_loss
04/19 04:57:38 PM: 	training: 4.462417
04/19 04:57:38 PM: 	validation: 4.563936
04/19 04:57:38 PM: Statistic: wsj_loss
04/19 04:57:38 PM: 	training: 5.671113
04/19 04:57:38 PM: 	validation: 5.691927
04/19 04:57:38 PM: Statistic: macro_avg
04/19 04:57:38 PM: 	validation: 0.061111
04/19 04:57:38 PM: Statistic: micro_avg
04/19 04:57:38 PM: 	validation: -0.059571
04/19 04:57:38 PM: Statistic: toronto_lm_perplexity
04/19 04:57:38 PM: 	training: 86.696765
04/19 04:57:38 PM: 	validation: 95.960444
04/19 04:57:38 PM: Statistic: wsj_perplexity
04/19 04:57:38 PM: 	training: 290.357665
04/19 04:57:38 PM: 	validation: 296.464327
04/19 04:57:38 PM: global_lr: 0.001000
04/19 04:57:38 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 04:57:38 PM: Update 14342: task wsj, batch 342 (14342): perplexity: 93.8811, wsj_loss: 4.5420 ||
04/19 04:57:39 PM: Update 11001: task toronto_lm, batch 1 (10948): perplexity: 84.9863, toronto_lm_loss: 4.4425 ||
04/19 04:57:49 PM: Update 11014: task toronto_lm, batch 14 (10961): perplexity: 82.5516, toronto_lm_loss: 4.4134 ||
04/19 04:57:49 PM: Update 14358: task wsj, batch 358 (14358): perplexity: 93.9841, wsj_loss: 4.5431 ||
04/19 04:57:59 PM: Update 14374: task wsj, batch 374 (14374): perplexity: 94.0658, wsj_loss: 4.5440 ||
04/19 04:57:59 PM: Update 11028: task toronto_lm, batch 28 (10975): perplexity: 79.1543, toronto_lm_loss: 4.3714 ||
04/19 04:58:10 PM: Update 14390: task wsj, batch 390 (14390): perplexity: 93.9834, wsj_loss: 4.5431 ||
04/19 04:58:10 PM: Update 11042: task toronto_lm, batch 42 (10989): perplexity: 78.3370, toronto_lm_loss: 4.3610 ||
04/19 04:58:20 PM: Update 14406: task wsj, batch 406 (14406): perplexity: 94.1026, wsj_loss: 4.5444 ||
04/19 04:58:21 PM: Update 11056: task toronto_lm, batch 56 (11003): perplexity: 79.0934, toronto_lm_loss: 4.3706 ||
04/19 04:58:31 PM: Update 14422: task wsj, batch 422 (14422): perplexity: 94.0733, wsj_loss: 4.5441 ||
04/19 04:58:31 PM: Update 11070: task toronto_lm, batch 70 (11017): perplexity: 78.0464, toronto_lm_loss: 4.3573 ||
04/19 04:58:41 PM: Update 14438: task wsj, batch 438 (14438): perplexity: 94.1982, wsj_loss: 4.5454 ||
04/19 04:58:42 PM: Update 11084: task toronto_lm, batch 84 (11031): perplexity: 77.8774, toronto_lm_loss: 4.3551 ||
04/19 04:58:51 PM: Update 14454: task wsj, batch 454 (14454): perplexity: 94.2495, wsj_loss: 4.5459 ||
04/19 04:58:53 PM: Update 11098: task toronto_lm, batch 98 (11045): perplexity: 78.1616, toronto_lm_loss: 4.3588 ||
04/19 04:59:04 PM: Update 11112: task toronto_lm, batch 112 (11059): perplexity: 78.4195, toronto_lm_loss: 4.3621 ||
04/19 04:59:05 PM: Update 14466: task wsj, batch 466 (14466): perplexity: 94.3136, wsj_loss: 4.5466 ||
04/19 04:59:14 PM: Update 11126: task toronto_lm, batch 126 (11073): perplexity: 78.1458, toronto_lm_loss: 4.3586 ||
04/19 04:59:15 PM: Update 14482: task wsj, batch 482 (14482): perplexity: 93.9816, wsj_loss: 4.5431 ||
04/19 04:59:25 PM: Update 11140: task toronto_lm, batch 140 (11087): perplexity: 77.9677, toronto_lm_loss: 4.3563 ||
04/19 04:59:26 PM: Update 14498: task wsj, batch 498 (14498): perplexity: 94.0001, wsj_loss: 4.5433 ||
04/19 04:59:36 PM: Update 11154: task toronto_lm, batch 154 (11101): perplexity: 77.8779, toronto_lm_loss: 4.3551 ||
04/19 04:59:36 PM: Update 14514: task wsj, batch 514 (14514): perplexity: 93.9138, wsj_loss: 4.5424 ||
04/19 04:59:46 PM: Update 11168: task toronto_lm, batch 168 (11115): perplexity: 77.4954, toronto_lm_loss: 4.3502 ||
04/19 04:59:47 PM: Update 14530: task wsj, batch 530 (14530): perplexity: 93.7644, wsj_loss: 4.5408 ||
04/19 04:59:57 PM: Update 11182: task wsj, batch 1 (54): perplexity: 343.2750, wsj_loss: 5.8385 ||
04/19 04:59:57 PM: Update 14546: task wsj, batch 546 (14546): perplexity: 93.6561, wsj_loss: 4.5396 ||
04/19 04:59:58 PM: Update 11183: task toronto_lm, batch 182 (11129): perplexity: 77.4193, toronto_lm_loss: 4.3492 ||
04/19 05:00:08 PM: Update 14562: task wsj, batch 562 (14562): perplexity: 93.5715, wsj_loss: 4.5387 ||
04/19 05:00:08 PM: Update 11196: task toronto_lm, batch 195 (11142): perplexity: 77.2042, toronto_lm_loss: 4.3465 ||
04/19 05:00:18 PM: Update 11209: task toronto_lm, batch 208 (11155): perplexity: 77.2326, toronto_lm_loss: 4.3468 ||
04/19 05:00:18 PM: Update 14578: task wsj, batch 578 (14578): perplexity: 93.5360, wsj_loss: 4.5383 ||
04/19 05:00:28 PM: Update 11222: task toronto_lm, batch 221 (11168): perplexity: 77.1575, toronto_lm_loss: 4.3458 ||
04/19 05:00:28 PM: Update 14594: task wsj, batch 594 (14594): perplexity: 93.4407, wsj_loss: 4.5373 ||
04/19 05:00:38 PM: Update 11235: task toronto_lm, batch 234 (11181): perplexity: 77.2438, toronto_lm_loss: 4.3470 ||
04/19 05:00:39 PM: Update 14602: task wsj, batch 602 (14602): perplexity: 93.4662, wsj_loss: 4.5376 ||
04/19 05:00:48 PM: Update 11248: task toronto_lm, batch 247 (11194): perplexity: 77.0621, toronto_lm_loss: 4.3446 ||
04/19 05:00:49 PM: Update 11249: task wsj, batch 2 (55): perplexity: 328.9874, wsj_loss: 5.7960 ||
04/19 05:00:49 PM: Update 14618: task wsj, batch 618 (14618): perplexity: 93.5121, wsj_loss: 4.5381 ||
04/19 05:00:58 PM: Update 11261: task toronto_lm, batch 259 (11206): perplexity: 76.9782, toronto_lm_loss: 4.3435 ||
04/19 05:01:00 PM: Update 14634: task wsj, batch 634 (14634): perplexity: 93.4789, wsj_loss: 4.5377 ||
04/19 05:01:08 PM: Update 11274: task toronto_lm, batch 272 (11219): perplexity: 76.8766, toronto_lm_loss: 4.3422 ||
04/19 05:01:10 PM: Update 14650: task wsj, batch 650 (14650): perplexity: 93.4885, wsj_loss: 4.5378 ||
04/19 05:01:19 PM: Update 11288: task toronto_lm, batch 286 (11233): perplexity: 76.8199, toronto_lm_loss: 4.3415 ||
04/19 05:01:21 PM: Update 14666: task wsj, batch 666 (14666): perplexity: 93.4838, wsj_loss: 4.5378 ||
04/19 05:01:30 PM: Update 11302: task toronto_lm, batch 300 (11247): perplexity: 76.7686, toronto_lm_loss: 4.3408 ||
04/19 05:01:31 PM: Update 14682: task wsj, batch 682 (14682): perplexity: 93.5503, wsj_loss: 4.5385 ||
04/19 05:01:41 PM: Update 11306: task toronto_lm, batch 304 (11251): perplexity: 76.8340, toronto_lm_loss: 4.3416 ||
04/19 05:01:41 PM: Update 14698: task wsj, batch 698 (14698): perplexity: 93.6351, wsj_loss: 4.5394 ||
04/19 05:01:51 PM: Update 11319: task toronto_lm, batch 317 (11264): perplexity: 78.5495, toronto_lm_loss: 4.3637 ||
04/19 05:01:52 PM: Update 14714: task wsj, batch 714 (14714): perplexity: 93.7285, wsj_loss: 4.5404 ||
04/19 05:02:02 PM: Update 11333: task toronto_lm, batch 331 (11278): perplexity: 79.9566, toronto_lm_loss: 4.3815 ||
04/19 05:02:02 PM: Update 14730: task wsj, batch 730 (14730): perplexity: 93.8183, wsj_loss: 4.5414 ||
04/19 05:02:13 PM: Update 14746: task wsj, batch 746 (14746): perplexity: 93.8022, wsj_loss: 4.5412 ||
04/19 05:02:13 PM: Update 11347: task toronto_lm, batch 345 (11292): perplexity: 81.2373, toronto_lm_loss: 4.3974 ||
04/19 05:02:24 PM: Update 11361: task toronto_lm, batch 359 (11306): perplexity: 82.5056, toronto_lm_loss: 4.4129 ||
04/19 05:02:26 PM: Update 14758: task wsj, batch 758 (14758): perplexity: 93.7213, wsj_loss: 4.5403 ||
04/19 05:02:34 PM: Update 11374: task toronto_lm, batch 372 (11319): perplexity: 83.2733, toronto_lm_loss: 4.4221 ||
04/19 05:02:36 PM: Update 14774: task wsj, batch 774 (14774): perplexity: 93.6323, wsj_loss: 4.5394 ||
04/19 05:02:44 PM: Update 11388: task toronto_lm, batch 386 (11333): perplexity: 83.7609, toronto_lm_loss: 4.4280 ||
04/19 05:02:46 PM: Update 14790: task wsj, batch 790 (14790): perplexity: 93.5533, wsj_loss: 4.5385 ||
04/19 05:02:54 PM: Update 11401: task toronto_lm, batch 399 (11346): perplexity: 84.4783, toronto_lm_loss: 4.4365 ||
04/19 05:02:57 PM: Update 14806: task wsj, batch 806 (14806): perplexity: 93.4981, wsj_loss: 4.5379 ||
04/19 05:03:04 PM: Update 11414: task toronto_lm, batch 412 (11359): perplexity: 85.0512, toronto_lm_loss: 4.4433 ||
04/19 05:03:07 PM: Update 14822: task wsj, batch 822 (14822): perplexity: 93.3424, wsj_loss: 4.5363 ||
04/19 05:03:15 PM: Update 11428: task toronto_lm, batch 426 (11373): perplexity: 85.6393, toronto_lm_loss: 4.4501 ||
04/19 05:03:18 PM: Update 14838: task wsj, batch 838 (14838): perplexity: 93.3358, wsj_loss: 4.5362 ||
04/19 05:03:26 PM: Update 11442: task toronto_lm, batch 440 (11387): perplexity: 86.0435, toronto_lm_loss: 4.4549 ||
04/19 05:03:28 PM: Update 14854: task wsj, batch 854 (14854): perplexity: 93.2372, wsj_loss: 4.5351 ||
04/19 05:03:37 PM: Update 11456: task toronto_lm, batch 454 (11401): perplexity: 86.5158, toronto_lm_loss: 4.4603 ||
04/19 05:03:39 PM: Update 14870: task wsj, batch 870 (14870): perplexity: 93.1567, wsj_loss: 4.5343 ||
04/19 05:03:40 PM: Update 11460: task wsj, batch 3 (56): perplexity: 315.0401, wsj_loss: 5.7527 ||
04/19 05:03:47 PM: Update 11469: task toronto_lm, batch 466 (11413): perplexity: 87.0203, toronto_lm_loss: 4.4661 ||
04/19 05:03:49 PM: Update 14886: task wsj, batch 886 (14886): perplexity: 93.1231, wsj_loss: 4.5339 ||
04/19 05:03:58 PM: Update 11483: task toronto_lm, batch 480 (11427): perplexity: 87.3651, toronto_lm_loss: 4.4701 ||
04/19 05:04:00 PM: Update 14894: task wsj, batch 894 (14894): perplexity: 93.1819, wsj_loss: 4.5346 ||
04/19 05:04:08 PM: Update 11496: task toronto_lm, batch 493 (11440): perplexity: 87.5818, toronto_lm_loss: 4.4726 ||
04/19 05:04:10 PM: Update 14910: task wsj, batch 910 (14910): perplexity: 93.1763, wsj_loss: 4.5345 ||
04/19 05:04:18 PM: Update 11510: task toronto_lm, batch 507 (11454): perplexity: 87.8328, toronto_lm_loss: 4.4754 ||
04/19 05:04:20 PM: Update 14926: task wsj, batch 926 (14926): perplexity: 93.2350, wsj_loss: 4.5351 ||
04/19 05:04:26 PM: Update 11520: task wsj, batch 4 (57): perplexity: 318.6062, wsj_loss: 5.7640 ||
04/19 05:04:28 PM: Update 11523: task toronto_lm, batch 519 (11466): perplexity: 87.9500, toronto_lm_loss: 4.4768 ||
04/19 05:04:31 PM: Update 14942: task wsj, batch 942 (14942): perplexity: 93.2180, wsj_loss: 4.5349 ||
04/19 05:04:38 PM: Update 11536: task toronto_lm, batch 532 (11479): perplexity: 88.1949, toronto_lm_loss: 4.4795 ||
04/19 05:04:41 PM: Update 14958: task wsj, batch 958 (14958): perplexity: 93.2444, wsj_loss: 4.5352 ||
04/19 05:04:49 PM: Update 11549: task toronto_lm, batch 545 (11492): perplexity: 88.4786, toronto_lm_loss: 4.4828 ||
04/19 05:04:52 PM: Update 14974: task wsj, batch 974 (14974): perplexity: 93.2353, wsj_loss: 4.5351 ||
04/19 05:04:59 PM: Update 11562: task toronto_lm, batch 558 (11505): perplexity: 88.7775, toronto_lm_loss: 4.4861 ||
04/19 05:05:02 PM: Update 14990: task wsj, batch 990 (14990): perplexity: 93.3064, wsj_loss: 4.5359 ||
04/19 05:05:09 PM: ***** Pass 15000 / Epoch 15 *****
04/19 05:05:09 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 05:05:09 PM: Validating...
04/19 05:05:09 PM: Update 11575: task toronto_lm, batch 571 (11518): perplexity: 89.0804, toronto_lm_loss: 4.4895 ||
04/19 05:05:12 PM: Batch 16/24: perplexity: 120.1346, wsj_loss: 4.7886 || , for evaluation data
04/19 05:05:14 PM: Advancing scheduler.
04/19 05:05:14 PM: 	Best macro_avg: 103.550
04/19 05:05:14 PM: 	# bad epochs: 1
04/19 05:05:14 PM: Statistic: wsj_loss
04/19 05:05:14 PM: 	training: 4.535907
04/19 05:05:14 PM: 	validation: 4.652221
04/19 05:05:14 PM: Statistic: macro_avg
04/19 05:05:14 PM: 	validation: 104.817515
04/19 05:05:14 PM: Statistic: micro_avg
04/19 05:05:14 PM: 	validation: 104.817515
04/19 05:05:14 PM: Statistic: wsj_perplexity
04/19 05:05:14 PM: 	training: 93.308087
04/19 05:05:14 PM: 	validation: 104.817515
04/19 05:05:14 PM: global_lr: 0.003000
04/19 05:05:14 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 05:05:19 PM: Update 11589: task toronto_lm, batch 585 (11532): perplexity: 89.2413, toronto_lm_loss: 4.4913 ||
04/19 05:05:22 PM: Update 15012: task wsj, batch 12 (15012): perplexity: 94.3049, wsj_loss: 4.5465 ||
04/19 05:05:29 PM: Update 11602: task toronto_lm, batch 598 (11545): perplexity: 89.3244, toronto_lm_loss: 4.4923 ||
04/19 05:05:33 PM: Update 15028: task wsj, batch 28 (15028): perplexity: 92.4616, wsj_loss: 4.5268 ||
04/19 05:05:39 PM: Update 11615: task toronto_lm, batch 611 (11558): perplexity: 89.3503, toronto_lm_loss: 4.4926 ||
04/19 05:05:43 PM: Update 15044: task wsj, batch 44 (15044): perplexity: 93.8453, wsj_loss: 4.5416 ||
04/19 05:05:50 PM: Update 11628: task toronto_lm, batch 624 (11571): perplexity: 89.4999, toronto_lm_loss: 4.4942 ||
04/19 05:05:53 PM: Update 15051: task wsj, batch 51 (15051): perplexity: 94.9761, wsj_loss: 4.5536 ||
04/19 05:06:00 PM: Update 11641: task toronto_lm, batch 637 (11584): perplexity: 89.6130, toronto_lm_loss: 4.4955 ||
04/19 05:06:04 PM: Update 15067: task wsj, batch 67 (15067): perplexity: 93.4974, wsj_loss: 4.5379 ||
04/19 05:06:10 PM: Update 11654: task toronto_lm, batch 650 (11597): perplexity: 89.7566, toronto_lm_loss: 4.4971 ||
04/19 05:06:14 PM: Update 15083: task wsj, batch 83 (15083): perplexity: 92.9143, wsj_loss: 4.5317 ||
04/19 05:06:20 PM: Update 11667: task toronto_lm, batch 663 (11610): perplexity: 89.7591, toronto_lm_loss: 4.4971 ||
04/19 05:06:24 PM: Update 15099: task wsj, batch 99 (15099): perplexity: 92.3362, wsj_loss: 4.5254 ||
04/19 05:06:30 PM: Update 11680: task toronto_lm, batch 676 (11623): perplexity: 89.8289, toronto_lm_loss: 4.4979 ||
04/19 05:06:35 PM: Update 15115: task wsj, batch 115 (15115): perplexity: 92.0529, wsj_loss: 4.5224 ||
04/19 05:06:40 PM: Update 11693: task toronto_lm, batch 689 (11636): perplexity: 89.9336, toronto_lm_loss: 4.4991 ||
04/19 05:06:45 PM: Update 15131: task wsj, batch 131 (15131): perplexity: 92.2092, wsj_loss: 4.5241 ||
04/19 05:06:50 PM: Update 11706: task toronto_lm, batch 702 (11649): perplexity: 90.0070, toronto_lm_loss: 4.4999 ||
04/19 05:06:56 PM: Update 15147: task wsj, batch 147 (15147): perplexity: 91.7823, wsj_loss: 4.5194 ||
04/19 05:07:00 PM: Update 11719: task toronto_lm, batch 715 (11662): perplexity: 89.9753, toronto_lm_loss: 4.4995 ||
04/19 05:07:06 PM: Update 15163: task wsj, batch 163 (15163): perplexity: 90.6948, wsj_loss: 4.5075 ||
04/19 05:07:11 PM: Update 11733: task toronto_lm, batch 729 (11676): perplexity: 90.0915, toronto_lm_loss: 4.5008 ||
04/19 05:07:16 PM: Update 15179: task wsj, batch 179 (15179): perplexity: 90.6746, wsj_loss: 4.5073 ||
04/19 05:07:21 PM: Update 11747: task toronto_lm, batch 743 (11690): perplexity: 90.1546, toronto_lm_loss: 4.5015 ||
04/19 05:07:27 PM: Update 15187: task wsj, batch 187 (15187): perplexity: 90.7360, wsj_loss: 4.5080 ||
04/19 05:07:31 PM: Update 11760: task toronto_lm, batch 756 (11703): perplexity: 90.1809, toronto_lm_loss: 4.5018 ||
04/19 05:07:37 PM: Update 15203: task wsj, batch 203 (15203): perplexity: 91.1008, wsj_loss: 4.5120 ||
04/19 05:07:42 PM: Update 11774: task toronto_lm, batch 770 (11717): perplexity: 90.2442, toronto_lm_loss: 4.5025 ||
04/19 05:07:48 PM: Update 15219: task wsj, batch 219 (15219): perplexity: 91.1166, wsj_loss: 4.5121 ||
04/19 05:07:52 PM: Update 11787: task toronto_lm, batch 783 (11730): perplexity: 90.3264, toronto_lm_loss: 4.5034 ||
04/19 05:07:58 PM: Update 15235: task wsj, batch 235 (15235): perplexity: 91.3074, wsj_loss: 4.5142 ||
04/19 05:08:02 PM: Update 11800: task toronto_lm, batch 796 (11743): perplexity: 90.3279, toronto_lm_loss: 4.5034 ||
04/19 05:08:09 PM: Update 15251: task wsj, batch 251 (15251): perplexity: 91.4059, wsj_loss: 4.5153 ||
04/19 05:08:13 PM: Update 11814: task toronto_lm, batch 810 (11757): perplexity: 90.3513, toronto_lm_loss: 4.5037 ||
04/19 05:08:19 PM: Update 15267: task wsj, batch 267 (15267): perplexity: 91.6690, wsj_loss: 4.5182 ||
04/19 05:08:24 PM: Update 11828: task toronto_lm, batch 824 (11771): perplexity: 90.3621, toronto_lm_loss: 4.5038 ||
04/19 05:08:29 PM: Update 15283: task wsj, batch 283 (15283): perplexity: 92.0832, wsj_loss: 4.5227 ||
04/19 05:08:34 PM: Update 11841: task toronto_lm, batch 837 (11784): perplexity: 90.4672, toronto_lm_loss: 4.5050 ||
04/19 05:08:40 PM: Update 15299: task wsj, batch 299 (15299): perplexity: 92.1049, wsj_loss: 4.5229 ||
04/19 05:08:44 PM: Update 11854: task toronto_lm, batch 850 (11797): perplexity: 90.5544, toronto_lm_loss: 4.5060 ||
04/19 05:08:50 PM: Update 15315: task wsj, batch 315 (15315): perplexity: 92.1738, wsj_loss: 4.5237 ||
04/19 05:08:54 PM: Update 11867: task toronto_lm, batch 863 (11810): perplexity: 90.6047, toronto_lm_loss: 4.5065 ||
04/19 05:09:01 PM: Update 15331: task wsj, batch 331 (15331): perplexity: 92.0681, wsj_loss: 4.5225 ||
04/19 05:09:04 PM: Update 11880: task toronto_lm, batch 876 (11823): perplexity: 90.6461, toronto_lm_loss: 4.5070 ||
04/19 05:09:13 PM: Update 15342: task wsj, batch 342 (15342): perplexity: 92.1253, wsj_loss: 4.5231 ||
04/19 05:09:14 PM: Update 11893: task toronto_lm, batch 889 (11836): perplexity: 90.6235, toronto_lm_loss: 4.5067 ||
04/19 05:09:24 PM: Update 15358: task wsj, batch 358 (15358): perplexity: 91.8914, wsj_loss: 4.5206 ||
04/19 05:09:24 PM: Update 11906: task toronto_lm, batch 902 (11849): perplexity: 90.6148, toronto_lm_loss: 4.5066 ||
04/19 05:09:34 PM: Update 15374: task wsj, batch 374 (15374): perplexity: 91.7304, wsj_loss: 4.5189 ||
04/19 05:09:34 PM: Update 11919: task toronto_lm, batch 915 (11862): perplexity: 90.6636, toronto_lm_loss: 4.5072 ||
04/19 05:09:44 PM: Update 11932: task toronto_lm, batch 928 (11875): perplexity: 90.7023, toronto_lm_loss: 4.5076 ||
04/19 05:09:45 PM: Update 15390: task wsj, batch 390 (15390): perplexity: 91.5591, wsj_loss: 4.5170 ||
04/19 05:09:55 PM: Update 11936: task toronto_lm, batch 932 (11879): perplexity: 90.8120, toronto_lm_loss: 4.5088 ||
04/19 05:09:55 PM: Update 15406: task wsj, batch 406 (15406): perplexity: 91.3977, wsj_loss: 4.5152 ||
04/19 05:10:05 PM: Update 11949: task toronto_lm, batch 945 (11892): perplexity: 91.0366, toronto_lm_loss: 4.5113 ||
04/19 05:10:05 PM: Update 15422: task wsj, batch 422 (15422): perplexity: 91.1757, wsj_loss: 4.5128 ||
04/19 05:10:15 PM: Update 11962: task toronto_lm, batch 958 (11905): perplexity: 91.1620, toronto_lm_loss: 4.5126 ||
04/19 05:10:16 PM: Update 15438: task wsj, batch 438 (15438): perplexity: 91.1410, wsj_loss: 4.5124 ||
04/19 05:10:25 PM: Update 11976: task toronto_lm, batch 972 (11919): perplexity: 91.2698, toronto_lm_loss: 4.5138 ||
04/19 05:10:26 PM: Update 15454: task wsj, batch 454 (15454): perplexity: 91.1073, wsj_loss: 4.5120 ||
04/19 05:10:35 PM: Update 11989: task toronto_lm, batch 985 (11932): perplexity: 91.3009, toronto_lm_loss: 4.5142 ||
04/19 05:10:37 PM: Update 15470: task wsj, batch 470 (15470): perplexity: 91.0708, wsj_loss: 4.5116 ||
04/19 05:10:42 PM: Update 11997: task wsj, batch 5 (58): perplexity: 313.9135, wsj_loss: 5.7491 ||
04/19 05:10:44 PM: ***** Pass 12000 / Epoch 12 *****
04/19 05:10:44 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 05:10:44 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 05:10:44 PM: Validating...
04/19 05:10:46 PM: Batch 6/140: perplexity: 109.3459, toronto_lm_loss: 4.6945 || , for evaluation data
04/19 05:10:47 PM: Update 15478: task wsj, batch 478 (15478): perplexity: 91.1189, wsj_loss: 4.5122 ||
04/19 05:10:56 PM: Batch 45/140: perplexity: 109.4627, toronto_lm_loss: 4.6956 || , for evaluation data
04/19 05:10:57 PM: Update 15494: task wsj, batch 494 (15494): perplexity: 91.1839, wsj_loss: 4.5129 ||
04/19 05:11:06 PM: Batch 83/140: perplexity: 102.3703, toronto_lm_loss: 4.6286 || , for evaluation data
04/19 05:11:08 PM: Update 15510: task wsj, batch 510 (15510): perplexity: 91.2576, wsj_loss: 4.5137 ||
04/19 05:11:16 PM: Batch 121/140: perplexity: 94.4304, toronto_lm_loss: 4.5479 || , for evaluation data
04/19 05:11:18 PM: Update 15526: task wsj, batch 526 (15526): perplexity: 91.2842, wsj_loss: 4.5140 ||
04/19 05:11:21 PM: Batch 1/66: perplexity: 420.5007, wsj_loss: 6.0414 || , for evaluation data
04/19 05:11:29 PM: Update 15542: task wsj, batch 542 (15542): perplexity: 91.3040, wsj_loss: 4.5142 ||
04/19 05:11:31 PM: Batch 39/66: perplexity: 314.6573, wsj_loss: 5.7515 || , for evaluation data
04/19 05:11:38 PM: Best model found for toronto_lm.
04/19 05:11:38 PM: Advancing scheduler.
04/19 05:11:38 PM: 	Best macro_avg: 0.061
04/19 05:11:38 PM: 	# bad epochs: 1
04/19 05:11:38 PM: Statistic: toronto_lm_loss
04/19 05:11:38 PM: 	training: 4.513931
04/19 05:11:38 PM: 	validation: 4.511689
04/19 05:11:38 PM: Statistic: wsj_loss
04/19 05:11:38 PM: 	training: 5.749117
04/19 05:11:38 PM: 	validation: 5.729750
04/19 05:11:38 PM: Statistic: macro_avg
04/19 05:11:38 PM: 	validation: 0.043140
04/19 05:11:38 PM: Statistic: micro_avg
04/19 05:11:38 PM: 	validation: -0.074223
04/19 05:11:38 PM: Statistic: toronto_lm_perplexity
04/19 05:11:38 PM: 	training: 91.279916
04/19 05:11:38 PM: 	validation: 91.075478
04/19 05:11:38 PM: Statistic: wsj_perplexity
04/19 05:11:38 PM: 	training: 313.913500
04/19 05:11:38 PM: 	validation: 307.892165
04/19 05:11:38 PM: global_lr: 0.001000
04/19 05:11:39 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 05:11:39 PM: Update 15558: task wsj, batch 558 (15558): perplexity: 91.2590, wsj_loss: 4.5137 ||
04/19 05:11:39 PM: Update 12001: task toronto_lm, batch 1 (11943): perplexity: 83.6360, toronto_lm_loss: 4.4265 ||
04/19 05:11:49 PM: Update 15574: task wsj, batch 574 (15574): perplexity: 91.3986, wsj_loss: 4.5152 ||
04/19 05:11:49 PM: Update 12014: task toronto_lm, batch 13 (11955): perplexity: 84.8669, toronto_lm_loss: 4.4411 ||
04/19 05:12:00 PM: Update 12027: task toronto_lm, batch 26 (11968): perplexity: 85.8467, toronto_lm_loss: 4.4526 ||
04/19 05:12:00 PM: Update 15590: task wsj, batch 590 (15590): perplexity: 91.4781, wsj_loss: 4.5161 ||
04/19 05:12:03 PM: Update 12032: task wsj, batch 2 (60): perplexity: 262.5665, wsj_loss: 5.5705 ||
04/19 05:12:10 PM: Update 12041: task toronto_lm, batch 39 (11981): perplexity: 85.5725, toronto_lm_loss: 4.4494 ||
04/19 05:12:10 PM: Update 15606: task wsj, batch 606 (15606): perplexity: 91.5224, wsj_loss: 4.5166 ||
04/19 05:12:21 PM: Update 15622: task wsj, batch 622 (15622): perplexity: 91.5533, wsj_loss: 4.5169 ||
04/19 05:12:21 PM: Update 12055: task toronto_lm, batch 53 (11995): perplexity: 84.8061, toronto_lm_loss: 4.4404 ||
04/19 05:12:31 PM: Update 12068: task toronto_lm, batch 66 (12008): perplexity: 85.1932, toronto_lm_loss: 4.4449 ||
04/19 05:12:33 PM: Update 15634: task wsj, batch 634 (15634): perplexity: 91.5963, wsj_loss: 4.5174 ||
04/19 05:12:41 PM: Update 12081: task toronto_lm, batch 79 (12021): perplexity: 85.5865, toronto_lm_loss: 4.4495 ||
04/19 05:12:44 PM: Update 15650: task wsj, batch 650 (15650): perplexity: 91.5430, wsj_loss: 4.5168 ||
04/19 05:12:52 PM: Update 12095: task toronto_lm, batch 93 (12035): perplexity: 84.8559, toronto_lm_loss: 4.4410 ||
04/19 05:12:54 PM: Update 15666: task wsj, batch 666 (15666): perplexity: 91.4356, wsj_loss: 4.5156 ||
04/19 05:13:03 PM: Update 12109: task toronto_lm, batch 107 (12049): perplexity: 84.6740, toronto_lm_loss: 4.4388 ||
04/19 05:13:05 PM: Update 15682: task wsj, batch 682 (15682): perplexity: 91.3757, wsj_loss: 4.5150 ||
04/19 05:13:13 PM: Update 12123: task toronto_lm, batch 121 (12063): perplexity: 83.9777, toronto_lm_loss: 4.4306 ||
04/19 05:13:15 PM: Update 15698: task wsj, batch 698 (15698): perplexity: 91.2709, wsj_loss: 4.5138 ||
04/19 05:13:24 PM: Update 12137: task toronto_lm, batch 135 (12077): perplexity: 84.0083, toronto_lm_loss: 4.4309 ||
04/19 05:13:26 PM: Update 15714: task wsj, batch 714 (15714): perplexity: 91.1126, wsj_loss: 4.5121 ||
04/19 05:13:35 PM: Update 12151: task toronto_lm, batch 149 (12091): perplexity: 83.9647, toronto_lm_loss: 4.4304 ||
04/19 05:13:36 PM: Update 15730: task wsj, batch 730 (15730): perplexity: 91.0730, wsj_loss: 4.5117 ||
04/19 05:13:45 PM: Update 12165: task toronto_lm, batch 163 (12105): perplexity: 83.8568, toronto_lm_loss: 4.4291 ||
04/19 05:13:46 PM: Update 15746: task wsj, batch 746 (15746): perplexity: 91.0354, wsj_loss: 4.5112 ||
04/19 05:13:56 PM: Update 12179: task toronto_lm, batch 177 (12119): perplexity: 83.6295, toronto_lm_loss: 4.4264 ||
04/19 05:13:57 PM: Update 15762: task wsj, batch 762 (15762): perplexity: 90.9652, wsj_loss: 4.5105 ||
04/19 05:14:07 PM: Update 12193: task toronto_lm, batch 191 (12133): perplexity: 82.9974, toronto_lm_loss: 4.4188 ||
04/19 05:14:08 PM: Update 15770: task wsj, batch 770 (15770): perplexity: 90.9697, wsj_loss: 4.5105 ||
04/19 05:14:17 PM: Update 12207: task toronto_lm, batch 205 (12147): perplexity: 82.8192, toronto_lm_loss: 4.4167 ||
04/19 05:14:18 PM: Update 15786: task wsj, batch 786 (15786): perplexity: 91.0095, wsj_loss: 4.5110 ||
04/19 05:14:28 PM: Update 12221: task toronto_lm, batch 219 (12161): perplexity: 82.5522, toronto_lm_loss: 4.4134 ||
04/19 05:14:28 PM: Update 15802: task wsj, batch 802 (15802): perplexity: 91.0801, wsj_loss: 4.5117 ||
04/19 05:14:39 PM: Update 12235: task toronto_lm, batch 233 (12175): perplexity: 82.2191, toronto_lm_loss: 4.4094 ||
04/19 05:14:39 PM: Update 15818: task wsj, batch 818 (15818): perplexity: 91.0464, wsj_loss: 4.5114 ||
04/19 05:14:49 PM: Update 15834: task wsj, batch 834 (15834): perplexity: 91.0349, wsj_loss: 4.5112 ||
04/19 05:14:50 PM: Update 12249: task toronto_lm, batch 247 (12189): perplexity: 81.8209, toronto_lm_loss: 4.4045 ||
04/19 05:15:00 PM: Update 15850: task wsj, batch 850 (15850): perplexity: 91.0448, wsj_loss: 4.5114 ||
04/19 05:15:00 PM: Update 12263: task toronto_lm, batch 261 (12203): perplexity: 81.6048, toronto_lm_loss: 4.4019 ||
04/19 05:15:10 PM: Update 15866: task wsj, batch 866 (15866): perplexity: 91.0376, wsj_loss: 4.5113 ||
04/19 05:15:11 PM: Update 12277: task toronto_lm, batch 275 (12217): perplexity: 81.3605, toronto_lm_loss: 4.3989 ||
04/19 05:15:21 PM: Update 15882: task wsj, batch 882 (15882): perplexity: 91.1126, wsj_loss: 4.5121 ||
04/19 05:15:22 PM: Update 12291: task toronto_lm, batch 289 (12231): perplexity: 81.1930, toronto_lm_loss: 4.3968 ||
04/19 05:15:31 PM: Update 15898: task wsj, batch 898 (15898): perplexity: 91.1580, wsj_loss: 4.5126 ||
04/19 05:15:33 PM: Update 12305: task toronto_lm, batch 303 (12245): perplexity: 80.9021, toronto_lm_loss: 4.3932 ||
04/19 05:15:41 PM: Update 15914: task wsj, batch 914 (15914): perplexity: 91.2227, wsj_loss: 4.5133 ||
04/19 05:15:43 PM: Update 12318: task toronto_lm, batch 316 (12258): perplexity: 80.6775, toronto_lm_loss: 4.3905 ||
04/19 05:15:53 PM: Update 12332: task toronto_lm, batch 330 (12272): perplexity: 80.5929, toronto_lm_loss: 4.3894 ||
04/19 05:15:55 PM: Update 15926: task wsj, batch 926 (15926): perplexity: 91.2852, wsj_loss: 4.5140 ||
04/19 05:16:04 PM: Update 12346: task toronto_lm, batch 344 (12286): perplexity: 80.6242, toronto_lm_loss: 4.3898 ||
04/19 05:16:05 PM: Update 15942: task wsj, batch 942 (15942): perplexity: 91.2951, wsj_loss: 4.5141 ||
04/19 05:16:15 PM: Update 12360: task toronto_lm, batch 358 (12300): perplexity: 80.2111, toronto_lm_loss: 4.3847 ||
04/19 05:16:16 PM: Update 15958: task wsj, batch 958 (15958): perplexity: 91.2130, wsj_loss: 4.5132 ||
04/19 05:16:26 PM: Update 12374: task toronto_lm, batch 372 (12314): perplexity: 80.1445, toronto_lm_loss: 4.3838 ||
04/19 05:16:26 PM: Update 15974: task wsj, batch 974 (15974): perplexity: 91.1638, wsj_loss: 4.5127 ||
04/19 05:16:36 PM: Update 12388: task toronto_lm, batch 386 (12328): perplexity: 79.9611, toronto_lm_loss: 4.3815 ||
04/19 05:16:36 PM: Update 15990: task wsj, batch 990 (15990): perplexity: 91.0393, wsj_loss: 4.5113 ||
04/19 05:16:43 PM: ***** Pass 16000 / Epoch 16 *****
04/19 05:16:43 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 05:16:43 PM: Validating...
04/19 05:16:46 PM: Batch 16/24: perplexity: 117.9181, wsj_loss: 4.7700 || , for evaluation data
04/19 05:16:47 PM: Update 12402: task toronto_lm, batch 400 (12342): perplexity: 79.8502, toronto_lm_loss: 4.3802 ||
04/19 05:16:48 PM: Best model found for wsj.
04/19 05:16:48 PM: Best model found for micro.
04/19 05:16:48 PM: Best model found for macro.
04/19 05:16:48 PM: Advancing scheduler.
04/19 05:16:48 PM: 	Best macro_avg: 103.030
04/19 05:16:48 PM: 	# bad epochs: 0
04/19 05:16:48 PM: Statistic: wsj_loss
04/19 05:16:48 PM: 	training: 4.510832
04/19 05:16:48 PM: 	validation: 4.635021
04/19 05:16:48 PM: Statistic: macro_avg
04/19 05:16:48 PM: 	validation: 103.030041
04/19 05:16:48 PM: Statistic: micro_avg
04/19 05:16:48 PM: 	validation: 103.030041
04/19 05:16:48 PM: Statistic: wsj_perplexity
04/19 05:16:48 PM: 	training: 90.997498
04/19 05:16:48 PM: 	validation: 103.030041
04/19 05:16:48 PM: global_lr: 0.003000
04/19 05:16:49 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 05:16:57 PM: Update 16012: task wsj, batch 12 (16012): perplexity: 85.7869, wsj_loss: 4.4519 ||
04/19 05:16:58 PM: Update 12416: task toronto_lm, batch 414 (12356): perplexity: 79.7123, toronto_lm_loss: 4.3784 ||
04/19 05:17:07 PM: Update 16028: task wsj, batch 28 (16028): perplexity: 86.7831, wsj_loss: 4.4634 ||
04/19 05:17:08 PM: Update 12430: task toronto_lm, batch 428 (12370): perplexity: 79.3710, toronto_lm_loss: 4.3741 ||
04/19 05:17:17 PM: Update 16044: task wsj, batch 44 (16044): perplexity: 85.9458, wsj_loss: 4.4537 ||
04/19 05:17:19 PM: Update 12443: task toronto_lm, batch 441 (12383): perplexity: 79.1107, toronto_lm_loss: 4.3708 ||
04/19 05:17:28 PM: Update 16060: task wsj, batch 60 (16060): perplexity: 87.4480, wsj_loss: 4.4710 ||
04/19 05:17:30 PM: Update 12457: task toronto_lm, batch 455 (12397): perplexity: 78.9895, toronto_lm_loss: 4.3693 ||
04/19 05:17:38 PM: Update 16067: task wsj, batch 67 (16067): perplexity: 87.9306, wsj_loss: 4.4765 ||
04/19 05:17:40 PM: Update 12470: task toronto_lm, batch 468 (12410): perplexity: 78.8309, toronto_lm_loss: 4.3673 ||
04/19 05:17:49 PM: Update 16083: task wsj, batch 83 (16083): perplexity: 88.7844, wsj_loss: 4.4862 ||
04/19 05:17:50 PM: Update 12483: task toronto_lm, batch 481 (12423): perplexity: 78.6440, toronto_lm_loss: 4.3649 ||
04/19 05:17:59 PM: Update 16099: task wsj, batch 99 (16099): perplexity: 89.2930, wsj_loss: 4.4919 ||
04/19 05:18:00 PM: Update 12497: task toronto_lm, batch 495 (12437): perplexity: 78.5789, toronto_lm_loss: 4.3641 ||
04/19 05:18:10 PM: Update 16115: task wsj, batch 115 (16115): perplexity: 89.3755, wsj_loss: 4.4928 ||
04/19 05:18:11 PM: Update 12511: task toronto_lm, batch 509 (12451): perplexity: 78.4186, toronto_lm_loss: 4.3621 ||
04/19 05:18:20 PM: Update 16131: task wsj, batch 131 (16131): perplexity: 89.5889, wsj_loss: 4.4952 ||
04/19 05:18:22 PM: Update 12525: task toronto_lm, batch 523 (12465): perplexity: 78.1893, toronto_lm_loss: 4.3591 ||
04/19 05:18:30 PM: Update 16147: task wsj, batch 147 (16147): perplexity: 90.2390, wsj_loss: 4.5025 ||
04/19 05:18:33 PM: Update 12539: task toronto_lm, batch 537 (12479): perplexity: 78.0929, toronto_lm_loss: 4.3579 ||
04/19 05:18:41 PM: Update 16163: task wsj, batch 163 (16163): perplexity: 90.3975, wsj_loss: 4.5042 ||
04/19 05:18:43 PM: Update 12553: task toronto_lm, batch 551 (12493): perplexity: 77.8692, toronto_lm_loss: 4.3550 ||
04/19 05:18:51 PM: Update 16179: task wsj, batch 179 (16179): perplexity: 90.3335, wsj_loss: 4.5035 ||
04/19 05:18:58 PM: Update 12561: task toronto_lm, batch 559 (12501): perplexity: 77.8843, toronto_lm_loss: 4.3552 ||
04/19 05:19:02 PM: Update 16195: task wsj, batch 195 (16195): perplexity: 90.5411, wsj_loss: 4.5058 ||
04/19 05:19:08 PM: Update 12574: task toronto_lm, batch 572 (12514): perplexity: 78.4642, toronto_lm_loss: 4.3626 ||
04/19 05:19:12 PM: Update 16211: task wsj, batch 211 (16211): perplexity: 90.6333, wsj_loss: 4.5068 ||
04/19 05:19:18 PM: Update 12588: task toronto_lm, batch 586 (12528): perplexity: 78.9618, toronto_lm_loss: 4.3690 ||
04/19 05:19:22 PM: Update 16219: task wsj, batch 219 (16219): perplexity: 90.6433, wsj_loss: 4.5069 ||
04/19 05:19:29 PM: Update 12602: task toronto_lm, batch 600 (12542): perplexity: 79.4150, toronto_lm_loss: 4.3747 ||
04/19 05:19:33 PM: Update 16235: task wsj, batch 235 (16235): perplexity: 90.3387, wsj_loss: 4.5036 ||
04/19 05:19:40 PM: Update 12616: task toronto_lm, batch 614 (12556): perplexity: 79.8158, toronto_lm_loss: 4.3797 ||
04/19 05:19:43 PM: Update 16251: task wsj, batch 251 (16251): perplexity: 90.3239, wsj_loss: 4.5034 ||
04/19 05:19:50 PM: Update 12629: task toronto_lm, batch 627 (12569): perplexity: 80.0687, toronto_lm_loss: 4.3829 ||
04/19 05:19:52 PM: Update 12632: task wsj, batch 3 (61): perplexity: 268.2623, wsj_loss: 5.5920 ||
04/19 05:19:54 PM: Update 16267: task wsj, batch 267 (16267): perplexity: 90.2734, wsj_loss: 4.5028 ||
04/19 05:20:00 PM: Update 12642: task toronto_lm, batch 639 (12581): perplexity: 80.4514, toronto_lm_loss: 4.3877 ||
04/19 05:20:04 PM: Update 16283: task wsj, batch 283 (16283): perplexity: 89.9620, wsj_loss: 4.4994 ||
04/19 05:20:10 PM: Update 12655: task toronto_lm, batch 652 (12594): perplexity: 80.6534, toronto_lm_loss: 4.3902 ||
04/19 05:20:15 PM: Update 16299: task wsj, batch 299 (16299): perplexity: 89.7703, wsj_loss: 4.4973 ||
04/19 05:20:20 PM: Update 12668: task toronto_lm, batch 665 (12607): perplexity: 80.8575, toronto_lm_loss: 4.3927 ||
04/19 05:20:25 PM: Update 16315: task wsj, batch 315 (16315): perplexity: 89.6471, wsj_loss: 4.4959 ||
04/19 05:20:31 PM: Update 12681: task toronto_lm, batch 678 (12620): perplexity: 81.0213, toronto_lm_loss: 4.3947 ||
04/19 05:20:35 PM: Update 16331: task wsj, batch 331 (16331): perplexity: 89.6026, wsj_loss: 4.4954 ||
04/19 05:20:41 PM: Update 12694: task toronto_lm, batch 691 (12633): perplexity: 81.1226, toronto_lm_loss: 4.3960 ||
04/19 05:20:42 PM: Update 12696: task wsj, batch 4 (62): perplexity: 273.2953, wsj_loss: 5.6106 ||
04/19 05:20:46 PM: Update 16347: task wsj, batch 347 (16347): perplexity: 89.4362, wsj_loss: 4.4935 ||
04/19 05:20:52 PM: Update 12708: task toronto_lm, batch 704 (12646): perplexity: 81.3567, toronto_lm_loss: 4.3988 ||
04/19 05:20:56 PM: Update 16355: task wsj, batch 355 (16355): perplexity: 89.3286, wsj_loss: 4.4923 ||
04/19 05:21:02 PM: Update 12722: task toronto_lm, batch 718 (12660): perplexity: 81.3560, toronto_lm_loss: 4.3988 ||
04/19 05:21:05 PM: Update 12725: task wsj, batch 5 (63): perplexity: 269.1700, wsj_loss: 5.5953 ||
04/19 05:21:06 PM: Update 16371: task wsj, batch 371 (16371): perplexity: 89.3625, wsj_loss: 4.4927 ||
04/19 05:21:12 PM: Update 12735: task toronto_lm, batch 730 (12672): perplexity: 81.4994, toronto_lm_loss: 4.4006 ||
04/19 05:21:17 PM: Update 16387: task wsj, batch 387 (16387): perplexity: 89.5016, wsj_loss: 4.4943 ||
04/19 05:21:23 PM: Update 12748: task toronto_lm, batch 743 (12685): perplexity: 81.5235, toronto_lm_loss: 4.4009 ||
04/19 05:21:27 PM: Update 16403: task wsj, batch 403 (16403): perplexity: 89.6206, wsj_loss: 4.4956 ||
04/19 05:21:33 PM: Update 12761: task toronto_lm, batch 756 (12698): perplexity: 81.6014, toronto_lm_loss: 4.4018 ||
04/19 05:21:38 PM: Update 16419: task wsj, batch 419 (16419): perplexity: 89.6332, wsj_loss: 4.4957 ||
04/19 05:21:43 PM: Update 12774: task toronto_lm, batch 769 (12711): perplexity: 81.7065, toronto_lm_loss: 4.4031 ||
04/19 05:21:48 PM: Update 16435: task wsj, batch 435 (16435): perplexity: 89.6314, wsj_loss: 4.4957 ||
04/19 05:21:53 PM: Update 12787: task toronto_lm, batch 782 (12724): perplexity: 81.7765, toronto_lm_loss: 4.4040 ||
04/19 05:21:59 PM: Update 16451: task wsj, batch 451 (16451): perplexity: 89.6121, wsj_loss: 4.4955 ||
04/19 05:22:03 PM: Update 12800: task toronto_lm, batch 795 (12737): perplexity: 81.7707, toronto_lm_loss: 4.4039 ||
04/19 05:22:09 PM: Update 16467: task wsj, batch 467 (16467): perplexity: 89.7244, wsj_loss: 4.4967 ||
04/19 05:22:13 PM: Update 12813: task toronto_lm, batch 808 (12750): perplexity: 81.7774, toronto_lm_loss: 4.4040 ||
04/19 05:22:20 PM: Update 16483: task wsj, batch 483 (16483): perplexity: 89.8189, wsj_loss: 4.4978 ||
04/19 05:22:24 PM: Update 12827: task toronto_lm, batch 822 (12764): perplexity: 81.7174, toronto_lm_loss: 4.4033 ||
04/19 05:22:30 PM: Update 16499: task wsj, batch 499 (16499): perplexity: 89.8503, wsj_loss: 4.4981 ||
04/19 05:22:34 PM: Update 12840: task toronto_lm, batch 835 (12777): perplexity: 81.7849, toronto_lm_loss: 4.4041 ||
04/19 05:22:43 PM: Update 16510: task wsj, batch 510 (16510): perplexity: 90.0002, wsj_loss: 4.4998 ||
04/19 05:22:44 PM: Update 12853: task toronto_lm, batch 848 (12790): perplexity: 81.8836, toronto_lm_loss: 4.4053 ||
04/19 05:22:54 PM: Update 16526: task wsj, batch 526 (16526): perplexity: 89.8537, wsj_loss: 4.4982 ||
04/19 05:22:54 PM: Update 12866: task toronto_lm, batch 861 (12803): perplexity: 81.9389, toronto_lm_loss: 4.4060 ||
04/19 05:23:04 PM: Update 16542: task wsj, batch 542 (16542): perplexity: 89.8552, wsj_loss: 4.4982 ||
04/19 05:23:04 PM: Update 12879: task toronto_lm, batch 874 (12816): perplexity: 81.9297, toronto_lm_loss: 4.4059 ||
04/19 05:23:14 PM: Update 12892: task toronto_lm, batch 887 (12829): perplexity: 81.8845, toronto_lm_loss: 4.4053 ||
04/19 05:23:14 PM: Update 16558: task wsj, batch 558 (16558): perplexity: 89.7326, wsj_loss: 4.4968 ||
04/19 05:23:24 PM: Update 12905: task toronto_lm, batch 900 (12842): perplexity: 81.8874, toronto_lm_loss: 4.4053 ||
04/19 05:23:25 PM: Update 16574: task wsj, batch 574 (16574): perplexity: 89.5602, wsj_loss: 4.4949 ||
04/19 05:23:34 PM: Update 12918: task toronto_lm, batch 913 (12855): perplexity: 81.8594, toronto_lm_loss: 4.4050 ||
04/19 05:23:35 PM: Update 16590: task wsj, batch 590 (16590): perplexity: 89.5595, wsj_loss: 4.4949 ||
04/19 05:23:45 PM: Update 12931: task toronto_lm, batch 926 (12868): perplexity: 81.8346, toronto_lm_loss: 4.4047 ||
04/19 05:23:46 PM: Update 16606: task wsj, batch 606 (16606): perplexity: 89.4651, wsj_loss: 4.4938 ||
04/19 05:23:55 PM: Update 12944: task toronto_lm, batch 939 (12881): perplexity: 81.7940, toronto_lm_loss: 4.4042 ||
04/19 05:23:56 PM: Update 16622: task wsj, batch 622 (16622): perplexity: 89.4065, wsj_loss: 4.4932 ||
04/19 05:24:05 PM: Update 12957: task toronto_lm, batch 952 (12894): perplexity: 81.7735, toronto_lm_loss: 4.4040 ||
04/19 05:24:07 PM: Update 16638: task wsj, batch 638 (16638): perplexity: 89.3538, wsj_loss: 4.4926 ||
04/19 05:24:15 PM: Update 12970: task toronto_lm, batch 965 (12907): perplexity: 81.7538, toronto_lm_loss: 4.4037 ||
04/19 05:24:17 PM: Update 16646: task wsj, batch 646 (16646): perplexity: 89.3024, wsj_loss: 4.4920 ||
04/19 05:24:25 PM: Update 12983: task toronto_lm, batch 978 (12920): perplexity: 81.7776, toronto_lm_loss: 4.4040 ||
04/19 05:24:27 PM: Update 16662: task wsj, batch 662 (16662): perplexity: 89.4769, wsj_loss: 4.4940 ||
04/19 05:24:35 PM: Update 12996: task toronto_lm, batch 991 (12933): perplexity: 81.7253, toronto_lm_loss: 4.4034 ||
04/19 05:24:38 PM: Update 16678: task wsj, batch 678 (16678): perplexity: 89.5532, wsj_loss: 4.4948 ||
04/19 05:24:38 PM: ***** Pass 13000 / Epoch 13 *****
04/19 05:24:38 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 05:24:38 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 05:24:38 PM: Validating...
04/19 05:24:45 PM: Batch 27/140: perplexity: 104.6520, toronto_lm_loss: 4.6506 || , for evaluation data
04/19 05:24:48 PM: Update 16694: task wsj, batch 694 (16694): perplexity: 89.5854, wsj_loss: 4.4952 ||
04/19 05:24:56 PM: Batch 66/140: perplexity: 103.0282, toronto_lm_loss: 4.6350 || , for evaluation data
04/19 05:24:59 PM: Update 16710: task wsj, batch 710 (16710): perplexity: 89.5884, wsj_loss: 4.4952 ||
04/19 05:25:06 PM: Batch 105/140: perplexity: 96.7003, toronto_lm_loss: 4.5716 || , for evaluation data
04/19 05:25:09 PM: Update 16726: task wsj, batch 726 (16726): perplexity: 89.5432, wsj_loss: 4.4947 ||
04/19 05:25:15 PM: Batch 1/66: perplexity: 422.9839, wsj_loss: 6.0473 || , for evaluation data
04/19 05:25:19 PM: Update 16742: task wsj, batch 742 (16742): perplexity: 89.5252, wsj_loss: 4.4945 ||
04/19 05:25:25 PM: Batch 34/66: perplexity: 306.7986, wsj_loss: 5.7262 || , for evaluation data
04/19 05:25:30 PM: Update 16758: task wsj, batch 758 (16758): perplexity: 89.5677, wsj_loss: 4.4950 ||
04/19 05:25:34 PM: Best model found for toronto_lm.
04/19 05:25:34 PM: Advancing scheduler.
04/19 05:25:34 PM: 	Best macro_avg: 0.061
04/19 05:25:34 PM: 	# bad epochs: 2
04/19 05:25:34 PM: Statistic: toronto_lm_loss
04/19 05:25:34 PM: 	training: 4.403241
04/19 05:25:34 PM: 	validation: 4.502425
04/19 05:25:34 PM: Statistic: wsj_loss
04/19 05:25:34 PM: 	training: 5.595343
04/19 05:25:34 PM: 	validation: 5.702119
04/19 05:25:34 PM: Statistic: macro_avg
04/19 05:25:34 PM: 	validation: 0.060762
04/19 05:25:34 PM: Statistic: micro_avg
04/19 05:25:34 PM: 	validation: -0.063464
04/19 05:25:34 PM: Statistic: toronto_lm_perplexity
04/19 05:25:34 PM: 	training: 81.715277
04/19 05:25:34 PM: 	validation: 90.235702
04/19 05:25:34 PM: Statistic: wsj_perplexity
04/19 05:25:34 PM: 	training: 269.169964
04/19 05:25:34 PM: 	validation: 299.501235
04/19 05:25:34 PM: global_lr: 0.001000
04/19 05:25:34 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 05:25:35 PM: Update 13001: task toronto_lm, batch 1 (12938): perplexity: 66.7746, toronto_lm_loss: 4.2013 ||
04/19 05:25:40 PM: Update 16774: task wsj, batch 774 (16774): perplexity: 89.5909, wsj_loss: 4.4953 ||
04/19 05:25:45 PM: Update 13014: task toronto_lm, batch 14 (12951): perplexity: 70.1255, toronto_lm_loss: 4.2503 ||
04/19 05:25:51 PM: Update 16790: task wsj, batch 790 (16790): perplexity: 89.5760, wsj_loss: 4.4951 ||
04/19 05:25:55 PM: Update 13027: task toronto_lm, batch 27 (12964): perplexity: 73.4890, toronto_lm_loss: 4.2971 ||
04/19 05:26:03 PM: Update 16802: task wsj, batch 802 (16802): perplexity: 89.5963, wsj_loss: 4.4953 ||
04/19 05:26:05 PM: Update 13040: task toronto_lm, batch 40 (12977): perplexity: 76.1755, toronto_lm_loss: 4.3330 ||
04/19 05:26:14 PM: Update 16818: task wsj, batch 818 (16818): perplexity: 89.5789, wsj_loss: 4.4951 ||
04/19 05:26:15 PM: Update 13053: task toronto_lm, batch 53 (12990): perplexity: 76.7799, toronto_lm_loss: 4.3409 ||
04/19 05:26:24 PM: Update 16834: task wsj, batch 834 (16834): perplexity: 89.5205, wsj_loss: 4.4945 ||
04/19 05:26:25 PM: Update 13066: task toronto_lm, batch 66 (13003): perplexity: 76.5048, toronto_lm_loss: 4.3374 ||
04/19 05:26:31 PM: Update 13073: task wsj, batch 1 (64): perplexity: 299.7452, wsj_loss: 5.7029 ||
04/19 05:26:35 PM: Update 16850: task wsj, batch 850 (16850): perplexity: 89.4136, wsj_loss: 4.4933 ||
04/19 05:26:35 PM: Update 13079: task toronto_lm, batch 78 (13015): perplexity: 76.7641, toronto_lm_loss: 4.3407 ||
04/19 05:26:45 PM: Update 16866: task wsj, batch 866 (16866): perplexity: 89.3720, wsj_loss: 4.4928 ||
04/19 05:26:45 PM: Update 13092: task toronto_lm, batch 91 (13028): perplexity: 76.6610, toronto_lm_loss: 4.3394 ||
04/19 05:26:56 PM: Update 16882: task wsj, batch 882 (16882): perplexity: 89.2828, wsj_loss: 4.4918 ||
04/19 05:26:56 PM: Update 13106: task toronto_lm, batch 105 (13042): perplexity: 76.7911, toronto_lm_loss: 4.3411 ||
04/19 05:27:06 PM: Update 16898: task wsj, batch 898 (16898): perplexity: 89.2467, wsj_loss: 4.4914 ||
04/19 05:27:07 PM: Update 13120: task toronto_lm, batch 119 (13056): perplexity: 76.7999, toronto_lm_loss: 4.3412 ||
04/19 05:27:17 PM: Update 16914: task wsj, batch 914 (16914): perplexity: 89.1274, wsj_loss: 4.4901 ||
04/19 05:27:17 PM: Update 13133: task toronto_lm, batch 132 (13069): perplexity: 77.1123, toronto_lm_loss: 4.3453 ||
04/19 05:27:27 PM: Update 13146: task toronto_lm, batch 145 (13082): perplexity: 77.3233, toronto_lm_loss: 4.3480 ||
04/19 05:27:27 PM: Update 16930: task wsj, batch 930 (16930): perplexity: 89.1030, wsj_loss: 4.4898 ||
04/19 05:27:37 PM: Update 13159: task toronto_lm, batch 158 (13095): perplexity: 77.2568, toronto_lm_loss: 4.3471 ||
04/19 05:27:37 PM: Update 16937: task wsj, batch 937 (16937): perplexity: 89.0680, wsj_loss: 4.4894 ||
04/19 05:27:47 PM: Update 13172: task toronto_lm, batch 171 (13108): perplexity: 77.2384, toronto_lm_loss: 4.3469 ||
04/19 05:27:47 PM: Update 16953: task wsj, batch 953 (16953): perplexity: 89.0965, wsj_loss: 4.4897 ||
04/19 05:27:52 PM: Update 13179: task wsj, batch 2 (65): perplexity: 304.5284, wsj_loss: 5.7188 ||
04/19 05:27:57 PM: Update 13185: task toronto_lm, batch 183 (13120): perplexity: 76.9684, toronto_lm_loss: 4.3434 ||
04/19 05:27:58 PM: Update 16969: task wsj, batch 969 (16969): perplexity: 89.0971, wsj_loss: 4.4897 ||
04/19 05:28:08 PM: Update 16985: task wsj, batch 985 (16985): perplexity: 89.0998, wsj_loss: 4.4898 ||
04/19 05:28:09 PM: Update 13191: task toronto_lm, batch 189 (13126): perplexity: 77.0904, toronto_lm_loss: 4.3450 ||
04/19 05:28:18 PM: ***** Pass 17000 / Epoch 17 *****
04/19 05:28:18 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 05:28:18 PM: Validating...
04/19 05:28:18 PM: Batch 1/24: perplexity: 134.5573, wsj_loss: 4.9020 || , for evaluation data
04/19 05:28:20 PM: Update 13205: task toronto_lm, batch 203 (13140): perplexity: 80.1605, toronto_lm_loss: 4.3840 ||
04/19 05:28:24 PM: Advancing scheduler.
04/19 05:28:24 PM: 	Best macro_avg: 103.030
04/19 05:28:24 PM: 	# bad epochs: 1
04/19 05:28:24 PM: Statistic: wsj_loss
04/19 05:28:24 PM: 	training: 4.489845
04/19 05:28:24 PM: 	validation: 4.641202
04/19 05:28:24 PM: Statistic: macro_avg
04/19 05:28:24 PM: 	validation: 103.668906
04/19 05:28:24 PM: Statistic: micro_avg
04/19 05:28:24 PM: 	validation: 103.668906
04/19 05:28:24 PM: Statistic: wsj_perplexity
04/19 05:28:24 PM: 	training: 89.107639
04/19 05:28:24 PM: 	validation: 103.668906
04/19 05:28:24 PM: global_lr: 0.003000
04/19 05:28:24 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 05:28:29 PM: Update 17007: task wsj, batch 7 (17007): perplexity: 93.1421, wsj_loss: 4.5341 ||
04/19 05:28:30 PM: Update 13218: task toronto_lm, batch 216 (13153): perplexity: 82.5032, toronto_lm_loss: 4.4128 ||
04/19 05:28:39 PM: Update 17023: task wsj, batch 23 (17023): perplexity: 91.2041, wsj_loss: 4.5131 ||
04/19 05:28:40 PM: Update 13232: task toronto_lm, batch 230 (13167): perplexity: 84.5849, toronto_lm_loss: 4.4378 ||
04/19 05:28:50 PM: Update 17039: task wsj, batch 39 (17039): perplexity: 90.0481, wsj_loss: 4.5003 ||
04/19 05:28:51 PM: Update 13246: task toronto_lm, batch 244 (13181): perplexity: 86.2424, toronto_lm_loss: 4.4572 ||
04/19 05:29:00 PM: Update 17055: task wsj, batch 55 (17055): perplexity: 90.5648, wsj_loss: 4.5061 ||
04/19 05:29:02 PM: Update 13260: task toronto_lm, batch 258 (13195): perplexity: 87.4364, toronto_lm_loss: 4.4709 ||
04/19 05:29:10 PM: Update 17071: task wsj, batch 71 (17071): perplexity: 90.6893, wsj_loss: 4.5074 ||
04/19 05:29:13 PM: Update 13274: task toronto_lm, batch 272 (13209): perplexity: 88.8725, toronto_lm_loss: 4.4872 ||
04/19 05:29:21 PM: Update 17087: task wsj, batch 87 (17087): perplexity: 90.8298, wsj_loss: 4.5090 ||
04/19 05:29:23 PM: Update 13287: task toronto_lm, batch 285 (13222): perplexity: 89.5567, toronto_lm_loss: 4.4949 ||
04/19 05:29:31 PM: Update 17095: task wsj, batch 95 (17095): perplexity: 90.7714, wsj_loss: 4.5083 ||
04/19 05:29:33 PM: Update 13301: task toronto_lm, batch 299 (13236): perplexity: 90.1844, toronto_lm_loss: 4.5019 ||
04/19 05:29:42 PM: Update 17111: task wsj, batch 111 (17111): perplexity: 89.4848, wsj_loss: 4.4941 ||
04/19 05:29:44 PM: Update 13315: task toronto_lm, batch 313 (13250): perplexity: 90.7858, toronto_lm_loss: 4.5085 ||
04/19 05:29:52 PM: Update 17127: task wsj, batch 127 (17127): perplexity: 88.5843, wsj_loss: 4.4840 ||
04/19 05:29:54 PM: Update 13328: task toronto_lm, batch 326 (13263): perplexity: 91.2398, toronto_lm_loss: 4.5135 ||
04/19 05:30:03 PM: Update 17143: task wsj, batch 143 (17143): perplexity: 88.3238, wsj_loss: 4.4810 ||
04/19 05:30:04 PM: Update 13341: task toronto_lm, batch 339 (13276): perplexity: 92.0532, toronto_lm_loss: 4.5224 ||
04/19 05:30:13 PM: Update 17159: task wsj, batch 159 (17159): perplexity: 88.3004, wsj_loss: 4.4807 ||
04/19 05:30:15 PM: Update 13354: task toronto_lm, batch 352 (13289): perplexity: 92.3584, toronto_lm_loss: 4.5257 ||
04/19 05:30:24 PM: Update 17175: task wsj, batch 175 (17175): perplexity: 88.4612, wsj_loss: 4.4826 ||
04/19 05:30:25 PM: Update 13367: task toronto_lm, batch 365 (13302): perplexity: 92.7100, toronto_lm_loss: 4.5295 ||
04/19 05:30:34 PM: Update 17191: task wsj, batch 191 (17191): perplexity: 88.3483, wsj_loss: 4.4813 ||
04/19 05:30:35 PM: Update 13380: task toronto_lm, batch 378 (13315): perplexity: 93.2765, toronto_lm_loss: 4.5356 ||
04/19 05:30:45 PM: Update 17207: task wsj, batch 207 (17207): perplexity: 87.6142, wsj_loss: 4.4729 ||
04/19 05:30:45 PM: Update 13393: task toronto_lm, batch 391 (13328): perplexity: 93.5731, toronto_lm_loss: 4.5387 ||
04/19 05:30:55 PM: Update 17223: task wsj, batch 223 (17223): perplexity: 87.5800, wsj_loss: 4.4726 ||
04/19 05:30:55 PM: Update 13406: task toronto_lm, batch 404 (13341): perplexity: 93.9953, toronto_lm_loss: 4.5432 ||
04/19 05:31:05 PM: Update 17231: task wsj, batch 231 (17231): perplexity: 87.6158, wsj_loss: 4.4730 ||
04/19 05:31:05 PM: Update 13419: task toronto_lm, batch 417 (13354): perplexity: 94.3607, toronto_lm_loss: 4.5471 ||
04/19 05:31:16 PM: Update 13432: task toronto_lm, batch 430 (13367): perplexity: 94.6263, toronto_lm_loss: 4.5499 ||
04/19 05:31:16 PM: Update 17247: task wsj, batch 247 (17247): perplexity: 87.7613, wsj_loss: 4.4746 ||
04/19 05:31:26 PM: Update 13445: task toronto_lm, batch 443 (13380): perplexity: 95.0047, toronto_lm_loss: 4.5539 ||
04/19 05:31:26 PM: Update 17263: task wsj, batch 263 (17263): perplexity: 87.8907, wsj_loss: 4.4761 ||
04/19 05:31:36 PM: Update 13458: task toronto_lm, batch 456 (13393): perplexity: 95.0827, toronto_lm_loss: 4.5547 ||
04/19 05:31:37 PM: Update 17279: task wsj, batch 279 (17279): perplexity: 87.5632, wsj_loss: 4.4724 ||
04/19 05:31:46 PM: Update 13471: task toronto_lm, batch 469 (13406): perplexity: 95.4360, toronto_lm_loss: 4.5585 ||
04/19 05:31:47 PM: Update 17295: task wsj, batch 295 (17295): perplexity: 87.6970, wsj_loss: 4.4739 ||
04/19 05:31:52 PM: Update 13478: task wsj, batch 3 (66): perplexity: 294.6254, wsj_loss: 5.6857 ||
04/19 05:31:56 PM: Update 13484: task toronto_lm, batch 481 (13418): perplexity: 95.3121, toronto_lm_loss: 4.5572 ||
04/19 05:31:58 PM: Update 17311: task wsj, batch 311 (17311): perplexity: 87.8732, wsj_loss: 4.4759 ||
04/19 05:32:06 PM: Update 13497: task toronto_lm, batch 494 (13431): perplexity: 95.4045, toronto_lm_loss: 4.5581 ||
04/19 05:32:08 PM: Update 17327: task wsj, batch 327 (17327): perplexity: 88.2159, wsj_loss: 4.4798 ||
04/19 05:32:17 PM: Update 13510: task toronto_lm, batch 507 (13444): perplexity: 95.6659, toronto_lm_loss: 4.5609 ||
04/19 05:32:19 PM: Update 17343: task wsj, batch 343 (17343): perplexity: 88.2055, wsj_loss: 4.4797 ||
04/19 05:32:27 PM: Update 13523: task toronto_lm, batch 520 (13457): perplexity: 95.8722, toronto_lm_loss: 4.5630 ||
04/19 05:32:29 PM: Update 17359: task wsj, batch 359 (17359): perplexity: 88.2369, wsj_loss: 4.4800 ||
04/19 05:32:37 PM: Update 13536: task toronto_lm, batch 533 (13470): perplexity: 96.0605, toronto_lm_loss: 4.5650 ||
04/19 05:32:39 PM: Update 17375: task wsj, batch 375 (17375): perplexity: 88.5351, wsj_loss: 4.4834 ||
04/19 05:32:47 PM: Update 13549: task toronto_lm, batch 546 (13483): perplexity: 96.1972, toronto_lm_loss: 4.5664 ||
04/19 05:32:52 PM: Update 17386: task wsj, batch 386 (17386): perplexity: 88.5609, wsj_loss: 4.4837 ||
04/19 05:32:57 PM: Update 13562: task toronto_lm, batch 559 (13496): perplexity: 96.4321, toronto_lm_loss: 4.5688 ||
04/19 05:33:03 PM: Update 17402: task wsj, batch 402 (17402): perplexity: 88.3085, wsj_loss: 4.4808 ||
04/19 05:33:07 PM: Update 13575: task toronto_lm, batch 572 (13509): perplexity: 96.5602, toronto_lm_loss: 4.5702 ||
04/19 05:33:08 PM: Update 13577: task wsj, batch 4 (67): perplexity: 282.0636, wsj_loss: 5.6421 ||
04/19 05:33:13 PM: Update 17418: task wsj, batch 418 (17418): perplexity: 88.2285, wsj_loss: 4.4799 ||
04/19 05:33:17 PM: Update 13588: task toronto_lm, batch 584 (13521): perplexity: 96.6402, toronto_lm_loss: 4.5710 ||
04/19 05:33:24 PM: Update 17434: task wsj, batch 434 (17434): perplexity: 88.1324, wsj_loss: 4.4788 ||
04/19 05:33:27 PM: Update 13601: task toronto_lm, batch 596 (13533): perplexity: 96.7398, toronto_lm_loss: 4.5720 ||
04/19 05:33:34 PM: Update 17450: task wsj, batch 450 (17450): perplexity: 87.9375, wsj_loss: 4.4766 ||
04/19 05:33:37 PM: Update 13614: task toronto_lm, batch 609 (13546): perplexity: 96.9096, toronto_lm_loss: 4.5738 ||
04/19 05:33:44 PM: Update 17466: task wsj, batch 466 (17466): perplexity: 87.9014, wsj_loss: 4.4762 ||
04/19 05:33:48 PM: Update 13628: task toronto_lm, batch 623 (13560): perplexity: 97.0652, toronto_lm_loss: 4.5754 ||
04/19 05:33:55 PM: Update 17482: task wsj, batch 482 (17482): perplexity: 87.7726, wsj_loss: 4.4747 ||
04/19 05:33:58 PM: Update 13641: task toronto_lm, batch 636 (13573): perplexity: 97.0141, toronto_lm_loss: 4.5749 ||
04/19 05:34:05 PM: Update 17498: task wsj, batch 498 (17498): perplexity: 87.7626, wsj_loss: 4.4746 ||
04/19 05:34:08 PM: Update 13654: task toronto_lm, batch 649 (13586): perplexity: 97.1497, toronto_lm_loss: 4.5763 ||
04/19 05:34:16 PM: Update 17514: task wsj, batch 514 (17514): perplexity: 87.6876, wsj_loss: 4.4738 ||
04/19 05:34:18 PM: Update 13667: task toronto_lm, batch 662 (13599): perplexity: 97.4167, toronto_lm_loss: 4.5790 ||
04/19 05:34:26 PM: Update 17522: task wsj, batch 522 (17522): perplexity: 87.7315, wsj_loss: 4.4743 ||
04/19 05:34:28 PM: Update 13680: task toronto_lm, batch 675 (13612): perplexity: 97.4492, toronto_lm_loss: 4.5793 ||
04/19 05:34:37 PM: Update 17538: task wsj, batch 538 (17538): perplexity: 87.7847, wsj_loss: 4.4749 ||
04/19 05:34:39 PM: Update 13694: task toronto_lm, batch 689 (13626): perplexity: 97.4850, toronto_lm_loss: 4.5797 ||
04/19 05:34:47 PM: Update 17554: task wsj, batch 554 (17554): perplexity: 87.8365, wsj_loss: 4.4755 ||
04/19 05:34:49 PM: Update 13707: task toronto_lm, batch 702 (13639): perplexity: 97.5035, toronto_lm_loss: 4.5799 ||
04/19 05:34:58 PM: Update 17570: task wsj, batch 570 (17570): perplexity: 87.8491, wsj_loss: 4.4756 ||
04/19 05:34:59 PM: Update 13720: task toronto_lm, batch 715 (13652): perplexity: 97.5691, toronto_lm_loss: 4.5806 ||
04/19 05:35:08 PM: Update 17586: task wsj, batch 586 (17586): perplexity: 87.8777, wsj_loss: 4.4759 ||
04/19 05:35:09 PM: Update 13733: task toronto_lm, batch 728 (13665): perplexity: 97.5863, toronto_lm_loss: 4.5807 ||
04/19 05:35:19 PM: Update 17602: task wsj, batch 602 (17602): perplexity: 87.9078, wsj_loss: 4.4763 ||
04/19 05:35:20 PM: Update 13747: task toronto_lm, batch 742 (13679): perplexity: 97.6584, toronto_lm_loss: 4.5815 ||
04/19 05:35:29 PM: Update 17618: task wsj, batch 618 (17618): perplexity: 87.9673, wsj_loss: 4.4770 ||
04/19 05:35:30 PM: Update 13760: task toronto_lm, batch 755 (13692): perplexity: 97.6283, toronto_lm_loss: 4.5812 ||
04/19 05:35:39 PM: Update 17634: task wsj, batch 634 (17634): perplexity: 88.0892, wsj_loss: 4.4783 ||
04/19 05:35:40 PM: Update 13773: task toronto_lm, batch 768 (13705): perplexity: 97.6927, toronto_lm_loss: 4.5818 ||
04/19 05:35:50 PM: Update 17650: task wsj, batch 650 (17650): perplexity: 88.1625, wsj_loss: 4.4792 ||
04/19 05:35:50 PM: Update 13786: task toronto_lm, batch 781 (13718): perplexity: 97.7275, toronto_lm_loss: 4.5822 ||
04/19 05:36:00 PM: Update 13799: task toronto_lm, batch 794 (13731): perplexity: 97.6047, toronto_lm_loss: 4.5809 ||
04/19 05:36:00 PM: Update 17666: task wsj, batch 666 (17666): perplexity: 88.1688, wsj_loss: 4.4793 ||
04/19 05:36:11 PM: Update 13813: task toronto_lm, batch 808 (13745): perplexity: 97.6394, toronto_lm_loss: 4.5813 ||
04/19 05:36:13 PM: Update 17678: task wsj, batch 678 (17678): perplexity: 88.1649, wsj_loss: 4.4792 ||
04/19 05:36:23 PM: Update 17694: task wsj, batch 694 (17694): perplexity: 88.0304, wsj_loss: 4.4777 ||
04/19 05:36:23 PM: Update 13819: task toronto_lm, batch 814 (13751): perplexity: 97.6950, toronto_lm_loss: 4.5819 ||
04/19 05:36:34 PM: Update 13832: task toronto_lm, batch 827 (13764): perplexity: 98.4387, toronto_lm_loss: 4.5894 ||
04/19 05:36:34 PM: Update 17710: task wsj, batch 710 (17710): perplexity: 87.9581, wsj_loss: 4.4769 ||
04/19 05:36:44 PM: Update 13845: task toronto_lm, batch 840 (13777): perplexity: 99.1790, toronto_lm_loss: 4.5969 ||
04/19 05:36:44 PM: Update 17726: task wsj, batch 726 (17726): perplexity: 87.8468, wsj_loss: 4.4756 ||
04/19 05:36:54 PM: Update 13859: task toronto_lm, batch 854 (13791): perplexity: 99.7176, toronto_lm_loss: 4.6023 ||
04/19 05:36:55 PM: Update 17742: task wsj, batch 742 (17742): perplexity: 87.6957, wsj_loss: 4.4739 ||
04/19 05:37:05 PM: Update 13873: task toronto_lm, batch 868 (13805): perplexity: 100.1493, toronto_lm_loss: 4.6067 ||
04/19 05:37:05 PM: Update 17758: task wsj, batch 758 (17758): perplexity: 87.6351, wsj_loss: 4.4732 ||
04/19 05:37:15 PM: Update 13886: task toronto_lm, batch 881 (13818): perplexity: 100.5050, toronto_lm_loss: 4.6102 ||
04/19 05:37:16 PM: Update 17774: task wsj, batch 774 (17774): perplexity: 87.6435, wsj_loss: 4.4733 ||
04/19 05:37:26 PM: Update 13900: task toronto_lm, batch 895 (13832): perplexity: 100.7950, toronto_lm_loss: 4.6131 ||
04/19 05:37:26 PM: Update 17790: task wsj, batch 790 (17790): perplexity: 87.5742, wsj_loss: 4.4725 ||
04/19 05:37:37 PM: Update 13914: task toronto_lm, batch 909 (13846): perplexity: 101.1091, toronto_lm_loss: 4.6162 ||
04/19 05:37:37 PM: Update 17806: task wsj, batch 806 (17806): perplexity: 87.5292, wsj_loss: 4.4720 ||
04/19 05:37:47 PM: Update 17814: task wsj, batch 814 (17814): perplexity: 87.5675, wsj_loss: 4.4724 ||
04/19 05:37:47 PM: Update 13928: task toronto_lm, batch 923 (13860): perplexity: 101.4156, toronto_lm_loss: 4.6192 ||
04/19 05:37:58 PM: Update 17830: task wsj, batch 830 (17830): perplexity: 87.5673, wsj_loss: 4.4724 ||
04/19 05:37:58 PM: Update 13942: task toronto_lm, batch 937 (13874): perplexity: 101.7329, toronto_lm_loss: 4.6224 ||
04/19 05:38:08 PM: Update 17846: task wsj, batch 846 (17846): perplexity: 87.6054, wsj_loss: 4.4728 ||
04/19 05:38:09 PM: Update 13956: task toronto_lm, batch 951 (13888): perplexity: 101.9043, toronto_lm_loss: 4.6240 ||
04/19 05:38:19 PM: Update 17862: task wsj, batch 862 (17862): perplexity: 87.6489, wsj_loss: 4.4733 ||
04/19 05:38:19 PM: Update 13970: task toronto_lm, batch 965 (13902): perplexity: 102.1020, toronto_lm_loss: 4.6260 ||
04/19 05:38:29 PM: Update 17878: task wsj, batch 878 (17878): perplexity: 87.6714, wsj_loss: 4.4736 ||
04/19 05:38:30 PM: Update 13983: task toronto_lm, batch 978 (13915): perplexity: 102.2548, toronto_lm_loss: 4.6275 ||
04/19 05:38:40 PM: Update 13996: task toronto_lm, batch 991 (13928): perplexity: 102.4029, toronto_lm_loss: 4.6289 ||
04/19 05:38:40 PM: Update 17894: task wsj, batch 894 (17894): perplexity: 87.6986, wsj_loss: 4.4739 ||
04/19 05:38:43 PM: ***** Pass 14000 / Epoch 14 *****
04/19 05:38:43 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 05:38:43 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 05:38:43 PM: Validating...
04/19 05:38:50 PM: Batch 28/140: perplexity: 105.3858, toronto_lm_loss: 4.6576 || , for evaluation data
04/19 05:38:50 PM: Update 17910: task wsj, batch 910 (17910): perplexity: 87.7197, wsj_loss: 4.4741 ||
04/19 05:39:00 PM: Batch 67/140: perplexity: 104.3352, toronto_lm_loss: 4.6476 || , for evaluation data
04/19 05:39:01 PM: Update 17926: task wsj, batch 926 (17926): perplexity: 87.7670, wsj_loss: 4.4747 ||
04/19 05:39:10 PM: Batch 106/140: perplexity: 98.2242, toronto_lm_loss: 4.5873 || , for evaluation data
04/19 05:39:11 PM: Update 17942: task wsj, batch 942 (17942): perplexity: 87.7976, wsj_loss: 4.4750 ||
04/19 05:39:19 PM: Batch 1/66: perplexity: 431.1797, wsj_loss: 6.0665 || , for evaluation data
04/19 05:39:21 PM: Update 17958: task wsj, batch 958 (17958): perplexity: 87.8330, wsj_loss: 4.4754 ||
04/19 05:39:29 PM: Batch 40/66: perplexity: 305.7197, wsj_loss: 5.7227 || , for evaluation data
04/19 05:39:34 PM: Update 17970: task wsj, batch 970 (17970): perplexity: 87.8006, wsj_loss: 4.4751 ||
04/19 05:39:37 PM: Advancing scheduler.
04/19 05:39:37 PM: 	Best macro_avg: 0.061
04/19 05:39:37 PM: 	# bad epochs: 3
04/19 05:39:37 PM: Statistic: toronto_lm_loss
04/19 05:39:37 PM: 	training: 4.629040
04/19 05:39:37 PM: 	validation: 4.526968
04/19 05:39:37 PM: Statistic: wsj_loss
04/19 05:39:37 PM: 	training: 5.631602
04/19 05:39:37 PM: 	validation: 5.725747
04/19 05:39:37 PM: Statistic: macro_avg
04/19 05:39:37 PM: 	validation: 0.044198
04/19 05:39:37 PM: Statistic: micro_avg
04/19 05:39:37 PM: 	validation: -0.072646
04/19 05:39:37 PM: Statistic: toronto_lm_perplexity
04/19 05:39:37 PM: 	training: 102.415677
04/19 05:39:37 PM: 	validation: 92.477764
04/19 05:39:37 PM: Statistic: wsj_perplexity
04/19 05:39:37 PM: 	training: 279.108919
04/19 05:39:37 PM: 	validation: 306.662168
04/19 05:39:37 PM: global_lr: 0.001000
04/19 05:39:37 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 05:39:38 PM: Update 14001: task toronto_lm, batch 1 (13933): perplexity: 113.1155, toronto_lm_loss: 4.7284 ||
04/19 05:39:45 PM: Update 17986: task wsj, batch 986 (17986): perplexity: 87.7026, wsj_loss: 4.4740 ||
04/19 05:39:49 PM: Update 14015: task toronto_lm, batch 15 (13947): perplexity: 109.2801, toronto_lm_loss: 4.6939 ||
04/19 05:39:54 PM: ***** Pass 18000 / Epoch 18 *****
04/19 05:39:54 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 05:39:54 PM: Validating...
04/19 05:39:55 PM: Batch 3/24: perplexity: 147.7423, wsj_loss: 4.9955 || , for evaluation data
04/19 05:39:59 PM: Update 14029: task toronto_lm, batch 29 (13961): perplexity: 108.7000, toronto_lm_loss: 4.6886 ||
04/19 05:40:00 PM: Best model found for wsj.
04/19 05:40:00 PM: Best model found for micro.
04/19 05:40:00 PM: Best model found for macro.
04/19 05:40:00 PM: Advancing scheduler.
04/19 05:40:00 PM: 	Best macro_avg: 102.954
04/19 05:40:00 PM: 	# bad epochs: 0
04/19 05:40:00 PM: Statistic: wsj_loss
04/19 05:40:00 PM: 	training: 4.473025
04/19 05:40:00 PM: 	validation: 4.634282
04/19 05:40:00 PM: Statistic: macro_avg
04/19 05:40:00 PM: 	validation: 102.953983
04/19 05:40:00 PM: Statistic: micro_avg
04/19 05:40:00 PM: 	validation: 102.953983
04/19 05:40:00 PM: Statistic: wsj_perplexity
04/19 05:40:00 PM: 	training: 87.621352
04/19 05:40:00 PM: 	validation: 102.953983
04/19 05:40:00 PM: global_lr: 0.003000
04/19 05:40:01 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 05:40:06 PM: Update 18008: task wsj, batch 8 (18008): perplexity: 88.0977, wsj_loss: 4.4784 ||
04/19 05:40:10 PM: Update 14043: task toronto_lm, batch 43 (13975): perplexity: 110.1739, toronto_lm_loss: 4.7021 ||
04/19 05:40:16 PM: Update 18024: task wsj, batch 24 (18024): perplexity: 85.3799, wsj_loss: 4.4471 ||
04/19 05:40:21 PM: Update 14057: task toronto_lm, batch 57 (13989): perplexity: 109.3065, toronto_lm_loss: 4.6942 ||
04/19 05:40:27 PM: Update 18040: task wsj, batch 40 (18040): perplexity: 85.7763, wsj_loss: 4.4517 ||
04/19 05:40:31 PM: Update 14071: task toronto_lm, batch 71 (14003): perplexity: 108.5327, toronto_lm_loss: 4.6871 ||
04/19 05:40:37 PM: Update 18056: task wsj, batch 56 (18056): perplexity: 84.4196, wsj_loss: 4.4358 ||
04/19 05:40:42 PM: Update 14085: task toronto_lm, batch 85 (14017): perplexity: 107.7502, toronto_lm_loss: 4.6798 ||
04/19 05:40:47 PM: Update 18072: task wsj, batch 72 (18072): perplexity: 84.7054, wsj_loss: 4.4392 ||
04/19 05:40:53 PM: Update 14099: task toronto_lm, batch 99 (14031): perplexity: 108.5751, toronto_lm_loss: 4.6874 ||
04/19 05:40:58 PM: Update 18088: task wsj, batch 88 (18088): perplexity: 84.8650, wsj_loss: 4.4411 ||
04/19 05:41:03 PM: Update 14113: task toronto_lm, batch 113 (14045): perplexity: 108.0242, toronto_lm_loss: 4.6824 ||
04/19 05:41:08 PM: Update 18104: task wsj, batch 104 (18104): perplexity: 84.8085, wsj_loss: 4.4404 ||
04/19 05:41:14 PM: Update 14127: task toronto_lm, batch 127 (14059): perplexity: 107.4503, toronto_lm_loss: 4.6770 ||
04/19 05:41:19 PM: Update 18112: task wsj, batch 112 (18112): perplexity: 85.2896, wsj_loss: 4.4461 ||
04/19 05:41:25 PM: Update 14141: task toronto_lm, batch 141 (14073): perplexity: 107.3347, toronto_lm_loss: 4.6760 ||
04/19 05:41:29 PM: Update 18128: task wsj, batch 128 (18128): perplexity: 85.8706, wsj_loss: 4.4528 ||
04/19 05:41:36 PM: Update 14155: task toronto_lm, batch 155 (14087): perplexity: 107.2334, toronto_lm_loss: 4.6750 ||
04/19 05:41:40 PM: Update 18144: task wsj, batch 144 (18144): perplexity: 85.8451, wsj_loss: 4.4525 ||
04/19 05:41:46 PM: Update 14168: task toronto_lm, batch 168 (14100): perplexity: 106.9253, toronto_lm_loss: 4.6721 ||
04/19 05:41:50 PM: Update 18160: task wsj, batch 160 (18160): perplexity: 86.1247, wsj_loss: 4.4558 ||
04/19 05:41:56 PM: Update 14181: task toronto_lm, batch 181 (14113): perplexity: 106.5445, toronto_lm_loss: 4.6686 ||
04/19 05:42:00 PM: Update 18176: task wsj, batch 176 (18176): perplexity: 86.3164, wsj_loss: 4.4580 ||
04/19 05:42:06 PM: Update 14194: task toronto_lm, batch 194 (14126): perplexity: 105.9528, toronto_lm_loss: 4.6630 ||
04/19 05:42:11 PM: Update 18192: task wsj, batch 192 (18192): perplexity: 86.2293, wsj_loss: 4.4570 ||
04/19 05:42:16 PM: Update 14207: task toronto_lm, batch 207 (14139): perplexity: 105.8132, toronto_lm_loss: 4.6617 ||
04/19 05:42:21 PM: Update 18208: task wsj, batch 208 (18208): perplexity: 86.4598, wsj_loss: 4.4597 ||
04/19 05:42:26 PM: Update 14220: task toronto_lm, batch 220 (14152): perplexity: 105.6856, toronto_lm_loss: 4.6605 ||
04/19 05:42:31 PM: Update 18224: task wsj, batch 224 (18224): perplexity: 86.6642, wsj_loss: 4.4620 ||
04/19 05:42:37 PM: Update 14234: task toronto_lm, batch 234 (14166): perplexity: 105.5857, toronto_lm_loss: 4.6595 ||
04/19 05:42:42 PM: Update 18240: task wsj, batch 240 (18240): perplexity: 87.0728, wsj_loss: 4.4667 ||
04/19 05:42:47 PM: Update 14248: task toronto_lm, batch 248 (14180): perplexity: 105.4809, toronto_lm_loss: 4.6585 ||
04/19 05:42:52 PM: Update 18256: task wsj, batch 256 (18256): perplexity: 87.2666, wsj_loss: 4.4690 ||
04/19 05:42:58 PM: Update 14262: task toronto_lm, batch 262 (14194): perplexity: 105.2674, toronto_lm_loss: 4.6565 ||
04/19 05:43:02 PM: Update 18264: task wsj, batch 264 (18264): perplexity: 87.2401, wsj_loss: 4.4687 ||
04/19 05:43:08 PM: Update 14275: task toronto_lm, batch 275 (14207): perplexity: 104.8068, toronto_lm_loss: 4.6521 ||
04/19 05:43:13 PM: Update 18280: task wsj, batch 280 (18280): perplexity: 86.8490, wsj_loss: 4.4642 ||
04/19 05:43:19 PM: Update 14289: task toronto_lm, batch 289 (14221): perplexity: 104.7434, toronto_lm_loss: 4.6515 ||
04/19 05:43:23 PM: Update 18296: task wsj, batch 296 (18296): perplexity: 86.6616, wsj_loss: 4.4620 ||
04/19 05:43:29 PM: Update 14303: task toronto_lm, batch 303 (14235): perplexity: 104.2043, toronto_lm_loss: 4.6464 ||
04/19 05:43:33 PM: Update 18312: task wsj, batch 312 (18312): perplexity: 86.5671, wsj_loss: 4.4609 ||
04/19 05:43:40 PM: Update 14316: task toronto_lm, batch 316 (14248): perplexity: 104.0077, toronto_lm_loss: 4.6445 ||
04/19 05:43:44 PM: Update 18328: task wsj, batch 328 (18328): perplexity: 86.6324, wsj_loss: 4.4617 ||
04/19 05:43:50 PM: Update 14330: task toronto_lm, batch 330 (14262): perplexity: 103.8907, toronto_lm_loss: 4.6433 ||
04/19 05:43:54 PM: Update 18344: task wsj, batch 344 (18344): perplexity: 86.6161, wsj_loss: 4.4615 ||
04/19 05:44:00 PM: Update 14343: task toronto_lm, batch 343 (14275): perplexity: 103.7228, toronto_lm_loss: 4.6417 ||
04/19 05:44:04 PM: Update 18360: task wsj, batch 360 (18360): perplexity: 86.4958, wsj_loss: 4.4601 ||
04/19 05:44:11 PM: Update 14357: task toronto_lm, batch 357 (14289): perplexity: 103.6970, toronto_lm_loss: 4.6415 ||
04/19 05:44:15 PM: Update 18376: task wsj, batch 376 (18376): perplexity: 86.2702, wsj_loss: 4.4575 ||
04/19 05:44:22 PM: Update 14371: task toronto_lm, batch 371 (14303): perplexity: 103.5582, toronto_lm_loss: 4.6401 ||
04/19 05:44:25 PM: Update 18392: task wsj, batch 392 (18392): perplexity: 86.1247, wsj_loss: 4.4558 ||
04/19 05:44:32 PM: Update 14384: task toronto_lm, batch 384 (14316): perplexity: 103.2237, toronto_lm_loss: 4.6369 ||
04/19 05:44:36 PM: Update 18399: task wsj, batch 399 (18399): perplexity: 86.0738, wsj_loss: 4.4552 ||
04/19 05:44:43 PM: Update 14398: task toronto_lm, batch 398 (14330): perplexity: 103.0859, toronto_lm_loss: 4.6356 ||
04/19 05:44:46 PM: Update 18415: task wsj, batch 415 (18415): perplexity: 86.1752, wsj_loss: 4.4564 ||
04/19 05:44:53 PM: Update 14412: task toronto_lm, batch 412 (14344): perplexity: 102.9395, toronto_lm_loss: 4.6341 ||
04/19 05:44:56 PM: Update 18431: task wsj, batch 431 (18431): perplexity: 86.2832, wsj_loss: 4.4576 ||
04/19 05:45:03 PM: Update 14425: task toronto_lm, batch 425 (14357): perplexity: 102.8786, toronto_lm_loss: 4.6335 ||
04/19 05:45:07 PM: Update 18447: task wsj, batch 447 (18447): perplexity: 86.5868, wsj_loss: 4.4611 ||
04/19 05:45:14 PM: Update 14439: task toronto_lm, batch 439 (14371): perplexity: 102.6799, toronto_lm_loss: 4.6316 ||
04/19 05:45:17 PM: Update 18463: task wsj, batch 463 (18463): perplexity: 86.4821, wsj_loss: 4.4599 ||
04/19 05:45:25 PM: Update 14444: task toronto_lm, batch 444 (14376): perplexity: 102.4694, toronto_lm_loss: 4.6296 ||
04/19 05:45:27 PM: Update 18479: task wsj, batch 479 (18479): perplexity: 86.5757, wsj_loss: 4.4610 ||
04/19 05:45:36 PM: Update 14458: task toronto_lm, batch 458 (14390): perplexity: 102.3518, toronto_lm_loss: 4.6284 ||
04/19 05:45:38 PM: Update 18495: task wsj, batch 495 (18495): perplexity: 86.4590, wsj_loss: 4.4597 ||
04/19 05:45:46 PM: Update 14471: task toronto_lm, batch 471 (14403): perplexity: 102.0653, toronto_lm_loss: 4.6256 ||
04/19 05:45:48 PM: Update 18511: task wsj, batch 511 (18511): perplexity: 86.5109, wsj_loss: 4.4603 ||
04/19 05:45:56 PM: Update 14484: task toronto_lm, batch 484 (14416): perplexity: 101.5252, toronto_lm_loss: 4.6203 ||
04/19 05:45:59 PM: Update 18527: task wsj, batch 527 (18527): perplexity: 86.6191, wsj_loss: 4.4615 ||
04/19 05:46:06 PM: Update 14497: task toronto_lm, batch 497 (14429): perplexity: 101.1962, toronto_lm_loss: 4.6171 ||
04/19 05:46:08 PM: Update 14500: task wsj, batch 1 (69): perplexity: 355.3346, wsj_loss: 5.8731 ||
04/19 05:46:09 PM: Update 18543: task wsj, batch 543 (18543): perplexity: 86.6565, wsj_loss: 4.4620 ||
04/19 05:46:17 PM: Update 14511: task toronto_lm, batch 510 (14442): perplexity: 100.7680, toronto_lm_loss: 4.6128 ||
04/19 05:46:22 PM: Update 18554: task wsj, batch 554 (18554): perplexity: 86.5766, wsj_loss: 4.4610 ||
04/19 05:46:28 PM: Update 14525: task toronto_lm, batch 524 (14456): perplexity: 100.3632, toronto_lm_loss: 4.6088 ||
04/19 05:46:32 PM: Update 18570: task wsj, batch 570 (18570): perplexity: 86.5050, wsj_loss: 4.4602 ||
04/19 05:46:38 PM: Update 14538: task toronto_lm, batch 537 (14469): perplexity: 99.7687, toronto_lm_loss: 4.6029 ||
04/19 05:46:42 PM: Update 18586: task wsj, batch 586 (18586): perplexity: 86.3633, wsj_loss: 4.4586 ||
04/19 05:46:48 PM: Update 14552: task toronto_lm, batch 551 (14483): perplexity: 99.2914, toronto_lm_loss: 4.5981 ||
04/19 05:46:53 PM: Update 18602: task wsj, batch 602 (18602): perplexity: 86.2530, wsj_loss: 4.4573 ||
04/19 05:46:59 PM: Update 14566: task toronto_lm, batch 565 (14497): perplexity: 98.6841, toronto_lm_loss: 4.5919 ||
04/19 05:47:03 PM: Update 18618: task wsj, batch 618 (18618): perplexity: 86.1336, wsj_loss: 4.4559 ||
04/19 05:47:10 PM: Update 14580: task toronto_lm, batch 579 (14511): perplexity: 98.1252, toronto_lm_loss: 4.5862 ||
04/19 05:47:14 PM: Update 18634: task wsj, batch 634 (18634): perplexity: 86.1534, wsj_loss: 4.4561 ||
04/19 05:47:20 PM: Update 14594: task toronto_lm, batch 593 (14525): perplexity: 97.6203, toronto_lm_loss: 4.5811 ||
04/19 05:47:24 PM: Update 18650: task wsj, batch 650 (18650): perplexity: 86.0940, wsj_loss: 4.4554 ||
04/19 05:47:31 PM: Update 14608: task toronto_lm, batch 607 (14539): perplexity: 97.0792, toronto_lm_loss: 4.5755 ||
04/19 05:47:34 PM: Update 18666: task wsj, batch 666 (18666): perplexity: 86.0208, wsj_loss: 4.4546 ||
04/19 05:47:42 PM: Update 14622: task toronto_lm, batch 621 (14553): perplexity: 96.5534, toronto_lm_loss: 4.5701 ||
04/19 05:47:45 PM: Update 18682: task wsj, batch 682 (18682): perplexity: 85.9234, wsj_loss: 4.4535 ||
04/19 05:47:53 PM: Update 14636: task toronto_lm, batch 635 (14567): perplexity: 96.0742, toronto_lm_loss: 4.5651 ||
04/19 05:47:55 PM: Update 18690: task wsj, batch 690 (18690): perplexity: 85.9305, wsj_loss: 4.4535 ||
04/19 05:48:03 PM: Update 14650: task toronto_lm, batch 649 (14581): perplexity: 95.6431, toronto_lm_loss: 4.5606 ||
04/19 05:48:06 PM: Update 18706: task wsj, batch 706 (18706): perplexity: 85.9860, wsj_loss: 4.4542 ||
04/19 05:48:14 PM: Update 14664: task toronto_lm, batch 663 (14595): perplexity: 95.2041, toronto_lm_loss: 4.5560 ||
04/19 05:48:16 PM: Update 18722: task wsj, batch 722 (18722): perplexity: 86.0625, wsj_loss: 4.4551 ||
04/19 05:48:25 PM: Update 14678: task toronto_lm, batch 677 (14609): perplexity: 94.8200, toronto_lm_loss: 4.5520 ||
04/19 05:48:27 PM: Update 18738: task wsj, batch 738 (18738): perplexity: 86.0899, wsj_loss: 4.4554 ||
04/19 05:48:35 PM: Update 14692: task toronto_lm, batch 691 (14623): perplexity: 94.4410, toronto_lm_loss: 4.5480 ||
04/19 05:48:37 PM: Update 18754: task wsj, batch 754 (18754): perplexity: 86.1814, wsj_loss: 4.4565 ||
04/19 05:48:46 PM: Update 14706: task toronto_lm, batch 705 (14637): perplexity: 93.9219, toronto_lm_loss: 4.5425 ||
04/19 05:48:47 PM: Update 18770: task wsj, batch 770 (18770): perplexity: 86.1165, wsj_loss: 4.4557 ||
04/19 05:48:57 PM: Update 14720: task toronto_lm, batch 719 (14651): perplexity: 93.5634, toronto_lm_loss: 4.5386 ||
04/19 05:48:58 PM: Update 18786: task wsj, batch 786 (18786): perplexity: 86.0528, wsj_loss: 4.4550 ||
04/19 05:49:08 PM: Update 14734: task toronto_lm, batch 733 (14665): perplexity: 93.1038, toronto_lm_loss: 4.5337 ||
04/19 05:49:08 PM: Update 18802: task wsj, batch 802 (18802): perplexity: 86.1270, wsj_loss: 4.4558 ||
04/19 05:49:12 PM: Update 14740: task wsj, batch 2 (70): perplexity: 354.3440, wsj_loss: 5.8703 ||
04/19 05:49:18 PM: Update 14748: task toronto_lm, batch 746 (14678): perplexity: 92.8458, toronto_lm_loss: 4.5309 ||
04/19 05:49:19 PM: Update 18818: task wsj, batch 818 (18818): perplexity: 86.1701, wsj_loss: 4.4563 ||
04/19 05:49:29 PM: Update 18834: task wsj, batch 834 (18834): perplexity: 86.2044, wsj_loss: 4.4567 ||
04/19 05:49:29 PM: Update 14762: task toronto_lm, batch 760 (14692): perplexity: 92.4349, toronto_lm_loss: 4.5265 ||
04/19 05:49:40 PM: Update 14776: task toronto_lm, batch 774 (14706): perplexity: 92.0323, toronto_lm_loss: 4.5221 ||
04/19 05:49:42 PM: Update 18846: task wsj, batch 846 (18846): perplexity: 86.1928, wsj_loss: 4.4566 ||
04/19 05:49:50 PM: Update 14790: task toronto_lm, batch 788 (14720): perplexity: 91.6120, toronto_lm_loss: 4.5176 ||
04/19 05:49:52 PM: Update 18862: task wsj, batch 862 (18862): perplexity: 86.1482, wsj_loss: 4.4561 ||
04/19 05:49:54 PM: Update 14795: task wsj, batch 3 (71): perplexity: 302.9020, wsj_loss: 5.7134 ||
04/19 05:50:01 PM: Update 14804: task toronto_lm, batch 801 (14733): perplexity: 91.2589, toronto_lm_loss: 4.5137 ||
04/19 05:50:02 PM: Update 18878: task wsj, batch 878 (18878): perplexity: 86.0640, wsj_loss: 4.4551 ||
04/19 05:50:11 PM: Update 14817: task toronto_lm, batch 814 (14746): perplexity: 90.9664, toronto_lm_loss: 4.5105 ||
04/19 05:50:13 PM: Update 18894: task wsj, batch 894 (18894): perplexity: 86.0120, wsj_loss: 4.4545 ||
04/19 05:50:14 PM: Update 14820: task wsj, batch 4 (72): perplexity: 274.3363, wsj_loss: 5.6144 ||
04/19 05:50:22 PM: Update 14831: task toronto_lm, batch 826 (14758): perplexity: 90.6762, toronto_lm_loss: 4.5073 ||
04/19 05:50:23 PM: Update 18910: task wsj, batch 910 (18910): perplexity: 85.9471, wsj_loss: 4.4537 ||
04/19 05:50:33 PM: Update 14845: task toronto_lm, batch 840 (14772): perplexity: 90.2809, toronto_lm_loss: 4.5029 ||
04/19 05:50:34 PM: Update 18926: task wsj, batch 926 (18926): perplexity: 85.8993, wsj_loss: 4.4532 ||
04/19 05:50:43 PM: Update 14858: task toronto_lm, batch 853 (14785): perplexity: 90.0390, toronto_lm_loss: 4.5002 ||
04/19 05:50:44 PM: Update 18942: task wsj, batch 942 (18942): perplexity: 85.8536, wsj_loss: 4.4526 ||
04/19 05:50:53 PM: Update 14872: task toronto_lm, batch 867 (14799): perplexity: 89.6691, toronto_lm_loss: 4.4961 ||
04/19 05:50:54 PM: Update 18958: task wsj, batch 958 (18958): perplexity: 85.7762, wsj_loss: 4.4517 ||
04/19 05:51:03 PM: Update 14885: task toronto_lm, batch 880 (14812): perplexity: 89.3498, toronto_lm_loss: 4.4926 ||
04/19 05:51:05 PM: Update 18974: task wsj, batch 974 (18974): perplexity: 85.7352, wsj_loss: 4.4513 ||
04/19 05:51:13 PM: Update 14898: task wsj, batch 6 (74): perplexity: 272.1519, wsj_loss: 5.6064 ||
04/19 05:51:14 PM: Update 14899: task toronto_lm, batch 893 (14825): perplexity: 89.0579, toronto_lm_loss: 4.4893 ||
04/19 05:51:15 PM: Update 18981: task wsj, batch 981 (18981): perplexity: 85.7543, wsj_loss: 4.4515 ||
04/19 05:51:24 PM: Update 14912: task toronto_lm, batch 906 (14838): perplexity: 88.7024, toronto_lm_loss: 4.4853 ||
04/19 05:51:26 PM: Update 18997: task wsj, batch 997 (18997): perplexity: 85.7717, wsj_loss: 4.4517 ||
04/19 05:51:28 PM: ***** Pass 19000 / Epoch 19 *****
04/19 05:51:28 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 05:51:28 PM: Validating...
04/19 05:51:33 PM: Advancing scheduler.
04/19 05:51:33 PM: 	Best macro_avg: 102.954
04/19 05:51:33 PM: 	# bad epochs: 1
04/19 05:51:33 PM: Statistic: wsj_loss
04/19 05:51:33 PM: 	training: 4.451763
04/19 05:51:33 PM: 	validation: 4.644598
04/19 05:51:33 PM: Statistic: macro_avg
04/19 05:51:33 PM: 	validation: 104.021537
04/19 05:51:33 PM: Statistic: micro_avg
04/19 05:51:33 PM: 	validation: 104.021537
04/19 05:51:33 PM: Statistic: wsj_perplexity
04/19 05:51:33 PM: 	training: 85.778006
04/19 05:51:33 PM: 	validation: 104.021537
04/19 05:51:33 PM: global_lr: 0.003000
04/19 05:51:33 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 05:51:35 PM: Update 14926: task toronto_lm, batch 920 (14852): perplexity: 88.2996, toronto_lm_loss: 4.4807 ||
04/19 05:51:36 PM: Update 19004: task wsj, batch 4 (19004): perplexity: 90.7710, wsj_loss: 4.5083 ||
04/19 05:51:46 PM: Update 14940: task toronto_lm, batch 934 (14866): perplexity: 87.9930, toronto_lm_loss: 4.4773 ||
04/19 05:51:46 PM: Update 19020: task wsj, batch 20 (19020): perplexity: 91.3128, wsj_loss: 4.5143 ||
04/19 05:51:56 PM: Update 14953: task toronto_lm, batch 947 (14879): perplexity: 87.7702, toronto_lm_loss: 4.4747 ||
04/19 05:51:57 PM: Update 19036: task wsj, batch 36 (19036): perplexity: 89.2175, wsj_loss: 4.4911 ||
04/19 05:52:06 PM: Update 14966: task toronto_lm, batch 960 (14892): perplexity: 87.4496, toronto_lm_loss: 4.4711 ||
04/19 05:52:07 PM: Update 19052: task wsj, batch 52 (19052): perplexity: 88.6466, wsj_loss: 4.4847 ||
04/19 05:52:17 PM: Update 14980: task toronto_lm, batch 974 (14906): perplexity: 87.1735, toronto_lm_loss: 4.4679 ||
04/19 05:52:18 PM: Update 19068: task wsj, batch 68 (19068): perplexity: 88.2426, wsj_loss: 4.4801 ||
04/19 05:52:27 PM: Update 14993: task toronto_lm, batch 987 (14919): perplexity: 86.9106, toronto_lm_loss: 4.4649 ||
04/19 05:52:28 PM: Update 19084: task wsj, batch 84 (19084): perplexity: 87.7018, wsj_loss: 4.4739 ||
04/19 05:52:32 PM: ***** Pass 15000 / Epoch 15 *****
04/19 05:52:32 PM: toronto_lm: trained on 994 batches, 0.005 epochs
04/19 05:52:32 PM: wsj: trained on 6 batches, 0.007 epochs
04/19 05:52:32 PM: Validating...
04/19 05:52:37 PM: Batch 18/140: perplexity: 106.1334, toronto_lm_loss: 4.6647 || , for evaluation data
04/19 05:52:38 PM: Update 19100: task wsj, batch 100 (19100): perplexity: 87.2146, wsj_loss: 4.4684 ||
04/19 05:52:47 PM: Batch 56/140: perplexity: 103.4566, toronto_lm_loss: 4.6392 || , for evaluation data
04/19 05:52:49 PM: Update 19116: task wsj, batch 116 (19116): perplexity: 87.1815, wsj_loss: 4.4680 ||
04/19 05:52:57 PM: Batch 89/140: perplexity: 95.7009, toronto_lm_loss: 4.5612 || , for evaluation data
04/19 05:52:59 PM: Update 19132: task wsj, batch 132 (19132): perplexity: 87.2650, wsj_loss: 4.4689 ||
04/19 05:53:07 PM: Batch 127/140: perplexity: 89.6353, toronto_lm_loss: 4.4957 || , for evaluation data
04/19 05:53:09 PM: Update 19139: task wsj, batch 139 (19139): perplexity: 87.3811, wsj_loss: 4.4703 ||
04/19 05:53:11 PM: Batch 1/66: perplexity: 367.7430, wsj_loss: 5.9074 || , for evaluation data
04/19 05:53:20 PM: Update 19155: task wsj, batch 155 (19155): perplexity: 87.1279, wsj_loss: 4.4674 ||
04/19 05:53:21 PM: Batch 39/66: perplexity: 266.1148, wsj_loss: 5.5839 || , for evaluation data
04/19 05:53:28 PM: Best model found for toronto_lm.
04/19 05:53:28 PM: Best model found for wsj.
04/19 05:53:28 PM: Best model found for micro.
04/19 05:53:28 PM: Best model found for macro.
04/19 05:53:28 PM: Advancing scheduler.
04/19 05:53:28 PM: 	Best macro_avg: 0.143
04/19 05:53:28 PM: 	# bad epochs: 0
04/19 05:53:28 PM: Statistic: toronto_lm_loss
04/19 05:53:28 PM: 	training: 4.463427
04/19 05:53:28 PM: 	validation: 4.472294
04/19 05:53:28 PM: Statistic: wsj_loss
04/19 05:53:28 PM: 	training: 5.606360
04/19 05:53:28 PM: 	validation: 5.558712
04/19 05:53:28 PM: Statistic: macro_avg
04/19 05:53:28 PM: 	validation: 0.143466
04/19 05:53:28 PM: Statistic: micro_avg
04/19 05:53:28 PM: 	validation: -0.012163
04/19 05:53:28 PM: Statistic: toronto_lm_perplexity
04/19 05:53:28 PM: 	training: 86.784377
04/19 05:53:28 PM: 	validation: 87.557326
04/19 05:53:28 PM: Statistic: wsj_perplexity
04/19 05:53:28 PM: 	training: 272.151919
04/19 05:53:28 PM: 	validation: 259.488424
04/19 05:53:28 PM: global_lr: 0.001000
04/19 05:53:28 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 05:53:29 PM: Update 15001: task toronto_lm, batch 1 (14927): perplexity: 63.3298, toronto_lm_loss: 4.1484 ||
04/19 05:53:30 PM: Update 19171: task wsj, batch 171 (19171): perplexity: 86.5695, wsj_loss: 4.4609 ||
04/19 05:53:40 PM: Update 15015: task toronto_lm, batch 15 (14941): perplexity: 69.7857, toronto_lm_loss: 4.2454 ||
04/19 05:53:41 PM: Update 19187: task wsj, batch 187 (19187): perplexity: 86.0947, wsj_loss: 4.4554 ||
04/19 05:53:50 PM: Update 15028: task toronto_lm, batch 28 (14954): perplexity: 69.8424, toronto_lm_loss: 4.2462 ||
04/19 05:53:51 PM: Update 19203: task wsj, batch 203 (19203): perplexity: 85.7100, wsj_loss: 4.4510 ||
04/19 05:54:01 PM: Update 15042: task toronto_lm, batch 42 (14968): perplexity: 69.9886, toronto_lm_loss: 4.2483 ||
04/19 05:54:01 PM: Update 19219: task wsj, batch 219 (19219): perplexity: 85.3222, wsj_loss: 4.4464 ||
04/19 05:54:11 PM: Update 15055: task toronto_lm, batch 55 (14981): perplexity: 70.2519, toronto_lm_loss: 4.2521 ||
04/19 05:54:12 PM: Update 19235: task wsj, batch 235 (19235): perplexity: 85.2936, wsj_loss: 4.4461 ||
04/19 05:54:21 PM: Update 15069: task toronto_lm, batch 69 (14995): perplexity: 69.4943, toronto_lm_loss: 4.2412 ||
04/19 05:54:22 PM: Update 19251: task wsj, batch 251 (19251): perplexity: 85.0856, wsj_loss: 4.4437 ||
04/19 05:54:33 PM: Update 19267: task wsj, batch 267 (19267): perplexity: 85.0991, wsj_loss: 4.4438 ||
04/19 05:54:34 PM: Update 15075: task toronto_lm, batch 75 (15001): perplexity: 70.2821, toronto_lm_loss: 4.2525 ||
04/19 05:54:43 PM: Update 19275: task wsj, batch 275 (19275): perplexity: 85.0038, wsj_loss: 4.4427 ||
04/19 05:54:44 PM: Update 15088: task toronto_lm, batch 88 (15014): perplexity: 75.3961, toronto_lm_loss: 4.3228 ||
04/19 05:54:53 PM: Update 19291: task wsj, batch 291 (19291): perplexity: 85.1528, wsj_loss: 4.4444 ||
04/19 05:54:55 PM: Update 15102: task toronto_lm, batch 102 (15028): perplexity: 78.6464, toronto_lm_loss: 4.3650 ||
04/19 05:55:04 PM: Update 19307: task wsj, batch 307 (19307): perplexity: 85.2790, wsj_loss: 4.4459 ||
04/19 05:55:05 PM: Update 15115: task toronto_lm, batch 115 (15041): perplexity: 80.7244, toronto_lm_loss: 4.3910 ||
04/19 05:55:14 PM: Update 19323: task wsj, batch 323 (19323): perplexity: 85.3477, wsj_loss: 4.4467 ||
04/19 05:55:15 PM: Update 15128: task toronto_lm, batch 128 (15054): perplexity: 81.6470, toronto_lm_loss: 4.4024 ||
04/19 05:55:25 PM: Update 19339: task wsj, batch 339 (19339): perplexity: 85.3370, wsj_loss: 4.4466 ||
04/19 05:55:25 PM: Update 15141: task toronto_lm, batch 141 (15067): perplexity: 82.3738, toronto_lm_loss: 4.4113 ||
04/19 05:55:35 PM: Update 19355: task wsj, batch 355 (19355): perplexity: 85.0610, wsj_loss: 4.4434 ||
04/19 05:55:36 PM: Update 15154: task toronto_lm, batch 154 (15080): perplexity: 83.1335, toronto_lm_loss: 4.4204 ||
04/19 05:55:46 PM: Update 19371: task wsj, batch 371 (19371): perplexity: 85.2207, wsj_loss: 4.4452 ||
04/19 05:55:46 PM: Update 15167: task toronto_lm, batch 167 (15093): perplexity: 83.4917, toronto_lm_loss: 4.4247 ||
04/19 05:55:56 PM: Update 15180: task toronto_lm, batch 180 (15106): perplexity: 83.4048, toronto_lm_loss: 4.4237 ||
04/19 05:55:56 PM: Update 19387: task wsj, batch 387 (19387): perplexity: 85.3359, wsj_loss: 4.4466 ||
04/19 05:56:06 PM: Update 15193: task toronto_lm, batch 193 (15119): perplexity: 83.4900, toronto_lm_loss: 4.4247 ||
04/19 05:56:06 PM: Update 19403: task wsj, batch 403 (19403): perplexity: 85.4492, wsj_loss: 4.4479 ||
04/19 05:56:16 PM: Update 15206: task toronto_lm, batch 206 (15132): perplexity: 83.1739, toronto_lm_loss: 4.4209 ||
04/19 05:56:17 PM: Update 19419: task wsj, batch 419 (19419): perplexity: 85.4490, wsj_loss: 4.4479 ||
04/19 05:56:26 PM: Update 15219: task toronto_lm, batch 219 (15145): perplexity: 83.0888, toronto_lm_loss: 4.4199 ||
04/19 05:56:29 PM: Update 19430: task wsj, batch 430 (19430): perplexity: 85.6243, wsj_loss: 4.4500 ||
04/19 05:56:36 PM: Update 15232: task toronto_lm, batch 232 (15158): perplexity: 82.8831, toronto_lm_loss: 4.4174 ||
04/19 05:56:39 PM: Update 19446: task wsj, batch 446 (19446): perplexity: 85.5640, wsj_loss: 4.4493 ||
04/19 05:56:46 PM: Update 15245: task toronto_lm, batch 245 (15171): perplexity: 82.4465, toronto_lm_loss: 4.4121 ||
04/19 05:56:50 PM: Update 19462: task wsj, batch 462 (19462): perplexity: 85.4877, wsj_loss: 4.4484 ||
04/19 05:56:57 PM: Update 15258: task toronto_lm, batch 258 (15184): perplexity: 82.5012, toronto_lm_loss: 4.4128 ||
04/19 05:57:00 PM: Update 19478: task wsj, batch 478 (19478): perplexity: 85.2364, wsj_loss: 4.4454 ||
04/19 05:57:07 PM: Update 15271: task toronto_lm, batch 271 (15197): perplexity: 82.4588, toronto_lm_loss: 4.4123 ||
04/19 05:57:10 PM: Update 19494: task wsj, batch 494 (19494): perplexity: 85.0076, wsj_loss: 4.4427 ||
04/19 05:57:17 PM: Update 15284: task toronto_lm, batch 284 (15210): perplexity: 82.3745, toronto_lm_loss: 4.4113 ||
04/19 05:57:21 PM: Update 19510: task wsj, batch 510 (19510): perplexity: 84.8802, wsj_loss: 4.4412 ||
04/19 05:57:27 PM: Update 15297: task toronto_lm, batch 297 (15223): perplexity: 82.0834, toronto_lm_loss: 4.4077 ||
04/19 05:57:31 PM: Update 19526: task wsj, batch 526 (19526): perplexity: 84.8776, wsj_loss: 4.4412 ||
04/19 05:57:37 PM: Update 15310: task toronto_lm, batch 310 (15236): perplexity: 81.9097, toronto_lm_loss: 4.4056 ||
04/19 05:57:42 PM: Update 19542: task wsj, batch 542 (19542): perplexity: 84.8287, wsj_loss: 4.4406 ||
04/19 05:57:47 PM: Update 15323: task toronto_lm, batch 323 (15249): perplexity: 81.6961, toronto_lm_loss: 4.4030 ||
04/19 05:57:52 PM: Update 19558: task wsj, batch 558 (19558): perplexity: 84.7721, wsj_loss: 4.4400 ||
04/19 05:57:57 PM: Update 15336: task toronto_lm, batch 336 (15262): perplexity: 81.4605, toronto_lm_loss: 4.4001 ||
04/19 05:58:02 PM: Update 19565: task wsj, batch 565 (19565): perplexity: 84.7730, wsj_loss: 4.4400 ||
04/19 05:58:07 PM: Update 15349: task toronto_lm, batch 349 (15275): perplexity: 81.2937, toronto_lm_loss: 4.3981 ||
04/19 05:58:12 PM: Update 19581: task wsj, batch 581 (19581): perplexity: 84.8121, wsj_loss: 4.4404 ||
04/19 05:58:17 PM: Update 15362: task toronto_lm, batch 362 (15288): perplexity: 81.3867, toronto_lm_loss: 4.3992 ||
04/19 05:58:23 PM: Update 19597: task wsj, batch 597 (19597): perplexity: 84.8287, wsj_loss: 4.4406 ||
04/19 05:58:28 PM: Update 15375: task toronto_lm, batch 375 (15301): perplexity: 81.0457, toronto_lm_loss: 4.3950 ||
04/19 05:58:33 PM: Update 19613: task wsj, batch 613 (19613): perplexity: 84.8221, wsj_loss: 4.4406 ||
04/19 05:58:38 PM: Update 15388: task toronto_lm, batch 388 (15314): perplexity: 80.8127, toronto_lm_loss: 4.3921 ||
04/19 05:58:44 PM: Update 19629: task wsj, batch 629 (19629): perplexity: 84.8854, wsj_loss: 4.4413 ||
04/19 05:58:48 PM: Update 15401: task toronto_lm, batch 401 (15327): perplexity: 80.4932, toronto_lm_loss: 4.3882 ||
04/19 05:58:54 PM: Update 19645: task wsj, batch 645 (19645): perplexity: 84.9301, wsj_loss: 4.4418 ||
04/19 05:58:57 PM: Update 15413: task wsj, batch 1 (75): perplexity: 255.9956, wsj_loss: 5.5452 ||
04/19 05:58:58 PM: Update 15414: task toronto_lm, batch 413 (15339): perplexity: 80.3657, toronto_lm_loss: 4.3866 ||
04/19 05:59:04 PM: Update 19661: task wsj, batch 661 (19661): perplexity: 85.0445, wsj_loss: 4.4432 ||
04/19 05:59:08 PM: Update 15427: task toronto_lm, batch 426 (15352): perplexity: 80.2173, toronto_lm_loss: 4.3847 ||
04/19 05:59:15 PM: Update 19677: task wsj, batch 677 (19677): perplexity: 85.0223, wsj_loss: 4.4429 ||
04/19 05:59:18 PM: Update 15440: task toronto_lm, batch 439 (15365): perplexity: 80.1183, toronto_lm_loss: 4.3835 ||
04/19 05:59:25 PM: Update 19693: task wsj, batch 693 (19693): perplexity: 85.0806, wsj_loss: 4.4436 ||
04/19 05:59:28 PM: Update 15453: task toronto_lm, batch 452 (15378): perplexity: 79.8221, toronto_lm_loss: 4.3798 ||
04/19 05:59:36 PM: Update 19709: task wsj, batch 709 (19709): perplexity: 85.0963, wsj_loss: 4.4438 ||
04/19 05:59:38 PM: Update 15466: task toronto_lm, batch 465 (15391): perplexity: 79.6012, toronto_lm_loss: 4.3770 ||
04/19 05:59:48 PM: Update 15479: task toronto_lm, batch 478 (15404): perplexity: 79.4693, toronto_lm_loss: 4.3754 ||
04/19 05:59:49 PM: Update 19722: task wsj, batch 722 (19722): perplexity: 85.0460, wsj_loss: 4.4432 ||
04/19 05:59:58 PM: Update 15492: task toronto_lm, batch 491 (15417): perplexity: 79.3128, toronto_lm_loss: 4.3734 ||
04/19 05:59:59 PM: Update 19738: task wsj, batch 738 (19738): perplexity: 84.9488, wsj_loss: 4.4420 ||
04/19 06:00:08 PM: Update 15505: task toronto_lm, batch 504 (15430): perplexity: 79.1488, toronto_lm_loss: 4.3713 ||
04/19 06:00:10 PM: Update 19754: task wsj, batch 754 (19754): perplexity: 84.8717, wsj_loss: 4.4411 ||
04/19 06:00:18 PM: Update 15518: task toronto_lm, batch 517 (15443): perplexity: 78.9357, toronto_lm_loss: 4.3686 ||
04/19 06:00:20 PM: Update 19770: task wsj, batch 770 (19770): perplexity: 84.8385, wsj_loss: 4.4407 ||
04/19 06:00:29 PM: Update 15531: task toronto_lm, batch 530 (15456): perplexity: 78.7995, toronto_lm_loss: 4.3669 ||
04/19 06:00:30 PM: Update 19786: task wsj, batch 786 (19786): perplexity: 84.7514, wsj_loss: 4.4397 ||
04/19 06:00:39 PM: Update 15544: task toronto_lm, batch 543 (15469): perplexity: 78.7339, toronto_lm_loss: 4.3661 ||
04/19 06:00:41 PM: Update 19802: task wsj, batch 802 (19802): perplexity: 84.6908, wsj_loss: 4.4390 ||
04/19 06:00:49 PM: Update 15557: task toronto_lm, batch 556 (15482): perplexity: 78.5928, toronto_lm_loss: 4.3643 ||
04/19 06:00:51 PM: Update 19818: task wsj, batch 818 (19818): perplexity: 84.6307, wsj_loss: 4.4383 ||
04/19 06:00:59 PM: Update 15570: task toronto_lm, batch 569 (15495): perplexity: 78.4192, toronto_lm_loss: 4.3621 ||
04/19 06:01:02 PM: Update 19834: task wsj, batch 834 (19834): perplexity: 84.5815, wsj_loss: 4.4377 ||
04/19 06:01:09 PM: Update 15583: task toronto_lm, batch 582 (15508): perplexity: 78.1898, toronto_lm_loss: 4.3591 ||
04/19 06:01:12 PM: Update 19850: task wsj, batch 850 (19850): perplexity: 84.5179, wsj_loss: 4.4370 ||
04/19 06:01:19 PM: Update 15596: task toronto_lm, batch 595 (15521): perplexity: 78.0221, toronto_lm_loss: 4.3570 ||
04/19 06:01:22 PM: Update 19858: task wsj, batch 858 (19858): perplexity: 84.5101, wsj_loss: 4.4369 ||
04/19 06:01:29 PM: Update 15609: task toronto_lm, batch 608 (15534): perplexity: 77.9093, toronto_lm_loss: 4.3555 ||
04/19 06:01:33 PM: Update 19874: task wsj, batch 874 (19874): perplexity: 84.5323, wsj_loss: 4.4371 ||
04/19 06:01:40 PM: Update 15622: task toronto_lm, batch 621 (15547): perplexity: 77.8001, toronto_lm_loss: 4.3541 ||
04/19 06:01:43 PM: Update 19890: task wsj, batch 890 (19890): perplexity: 84.5798, wsj_loss: 4.4377 ||
04/19 06:01:43 PM: Update 15627: task wsj, batch 2 (76): perplexity: 264.6057, wsj_loss: 5.5782 ||
04/19 06:01:50 PM: Update 15635: task toronto_lm, batch 633 (15559): perplexity: 77.6802, toronto_lm_loss: 4.3526 ||
04/19 06:01:54 PM: Update 19906: task wsj, batch 906 (19906): perplexity: 84.6451, wsj_loss: 4.4385 ||
04/19 06:02:00 PM: Update 15648: task toronto_lm, batch 646 (15572): perplexity: 77.6729, toronto_lm_loss: 4.3525 ||
04/19 06:02:04 PM: Update 19922: task wsj, batch 922 (19922): perplexity: 84.6578, wsj_loss: 4.4386 ||
04/19 06:02:10 PM: Update 15661: task toronto_lm, batch 659 (15585): perplexity: 77.6366, toronto_lm_loss: 4.3520 ||
04/19 06:02:14 PM: Update 19938: task wsj, batch 938 (19938): perplexity: 84.6516, wsj_loss: 4.4385 ||
04/19 06:02:20 PM: Update 15674: task toronto_lm, batch 672 (15598): perplexity: 77.5106, toronto_lm_loss: 4.3504 ||
04/19 06:02:25 PM: Update 19954: task wsj, batch 954 (19954): perplexity: 84.6721, wsj_loss: 4.4388 ||
04/19 06:02:30 PM: Update 15687: task toronto_lm, batch 685 (15611): perplexity: 77.3847, toronto_lm_loss: 4.3488 ||
04/19 06:02:35 PM: Update 19970: task wsj, batch 970 (19970): perplexity: 84.6507, wsj_loss: 4.4385 ||
04/19 06:02:40 PM: Update 15700: task toronto_lm, batch 698 (15624): perplexity: 77.1558, toronto_lm_loss: 4.3458 ||
04/19 06:02:46 PM: Update 19986: task wsj, batch 986 (19986): perplexity: 84.6542, wsj_loss: 4.4386 ||
04/19 06:02:50 PM: Update 15704: task toronto_lm, batch 702 (15628): perplexity: 77.2947, toronto_lm_loss: 4.3476 ||
04/19 06:02:55 PM: ***** Pass 20000 / Epoch 20 *****
04/19 06:02:55 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 06:02:55 PM: Validating...
04/19 06:02:56 PM: Batch 4/24: perplexity: 154.3066, wsj_loss: 5.0389 || , for evaluation data
04/19 06:03:00 PM: Update 15717: task toronto_lm, batch 715 (15641): perplexity: 77.7658, toronto_lm_loss: 4.3537 ||
04/19 06:03:01 PM: Best model found for wsj.
04/19 06:03:01 PM: Best model found for micro.
04/19 06:03:01 PM: Best model found for macro.
04/19 06:03:01 PM: Advancing scheduler.
04/19 06:03:01 PM: 	Best macro_avg: 102.628
04/19 06:03:01 PM: 	# bad epochs: 0
04/19 06:03:01 PM: Statistic: wsj_loss
04/19 06:03:01 PM: 	training: 4.438856
04/19 06:03:01 PM: 	validation: 4.631111
04/19 06:03:01 PM: Statistic: macro_avg
04/19 06:03:01 PM: 	validation: 102.628061
04/19 06:03:01 PM: Statistic: micro_avg
04/19 06:03:01 PM: 	validation: 102.628061
04/19 06:03:01 PM: Statistic: wsj_perplexity
04/19 06:03:01 PM: 	training: 84.677989
04/19 06:03:01 PM: 	validation: 102.628061
04/19 06:03:01 PM: global_lr: 0.003000
04/19 06:03:01 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 06:03:06 PM: Update 20007: task wsj, batch 7 (20007): perplexity: 88.5242, wsj_loss: 4.4833 ||
04/19 06:03:10 PM: Update 15729: task wsj, batch 3 (77): perplexity: 267.0483, wsj_loss: 5.5874 ||
04/19 06:03:10 PM: Update 15730: task toronto_lm, batch 727 (15653): perplexity: 78.1328, toronto_lm_loss: 4.3584 ||
04/19 06:03:16 PM: Update 20014: task wsj, batch 14 (20014): perplexity: 88.0595, wsj_loss: 4.4780 ||
04/19 06:03:21 PM: Update 15743: task toronto_lm, batch 740 (15666): perplexity: 78.4991, toronto_lm_loss: 4.3631 ||
04/19 06:03:26 PM: Update 20030: task wsj, batch 30 (20030): perplexity: 84.1864, wsj_loss: 4.4330 ||
04/19 06:03:31 PM: Update 15756: task toronto_lm, batch 753 (15679): perplexity: 78.7535, toronto_lm_loss: 4.3663 ||
04/19 06:03:37 PM: Update 20046: task wsj, batch 46 (20046): perplexity: 82.8191, wsj_loss: 4.4167 ||
04/19 06:03:41 PM: Update 15769: task toronto_lm, batch 766 (15692): perplexity: 79.0588, toronto_lm_loss: 4.3702 ||
04/19 06:03:47 PM: Update 20062: task wsj, batch 62 (20062): perplexity: 82.4394, wsj_loss: 4.4121 ||
04/19 06:03:51 PM: Update 15782: task toronto_lm, batch 779 (15705): perplexity: 79.3367, toronto_lm_loss: 4.3737 ||
04/19 06:03:58 PM: Update 20078: task wsj, batch 78 (20078): perplexity: 81.3765, wsj_loss: 4.3991 ||
04/19 06:04:01 PM: Update 15795: task toronto_lm, batch 792 (15718): perplexity: 79.5792, toronto_lm_loss: 4.3768 ||
04/19 06:04:08 PM: Update 20094: task wsj, batch 94 (20094): perplexity: 81.2459, wsj_loss: 4.3975 ||
04/19 06:04:11 PM: Update 15808: task toronto_lm, batch 805 (15731): perplexity: 79.7982, toronto_lm_loss: 4.3795 ||
04/19 06:04:18 PM: Update 20110: task wsj, batch 110 (20110): perplexity: 81.4715, wsj_loss: 4.4003 ||
04/19 06:04:21 PM: Update 15821: task toronto_lm, batch 818 (15744): perplexity: 79.9509, toronto_lm_loss: 4.3814 ||
04/19 06:04:29 PM: Update 20126: task wsj, batch 126 (20126): perplexity: 81.6222, wsj_loss: 4.4021 ||
04/19 06:04:31 PM: Update 15834: task toronto_lm, batch 831 (15757): perplexity: 80.1052, toronto_lm_loss: 4.3833 ||
04/19 06:04:39 PM: Update 20142: task wsj, batch 142 (20142): perplexity: 81.7209, wsj_loss: 4.4033 ||
04/19 06:04:42 PM: Update 15848: task toronto_lm, batch 845 (15771): perplexity: 80.2616, toronto_lm_loss: 4.3853 ||
04/19 06:04:50 PM: Update 20151: task wsj, batch 151 (20151): perplexity: 81.8131, wsj_loss: 4.4044 ||
04/19 06:04:53 PM: Update 15862: task toronto_lm, batch 859 (15785): perplexity: 80.4134, toronto_lm_loss: 4.3872 ||
04/19 06:05:00 PM: Update 20167: task wsj, batch 167 (20167): perplexity: 81.9873, wsj_loss: 4.4066 ||
04/19 06:05:03 PM: Update 15876: task toronto_lm, batch 873 (15799): perplexity: 80.5432, toronto_lm_loss: 4.3888 ||
04/19 06:05:10 PM: Update 20183: task wsj, batch 183 (20183): perplexity: 82.2787, wsj_loss: 4.4101 ||
04/19 06:05:13 PM: Update 15889: task toronto_lm, batch 886 (15812): perplexity: 80.6016, toronto_lm_loss: 4.3895 ||
04/19 06:05:21 PM: Update 20199: task wsj, batch 199 (20199): perplexity: 82.8132, wsj_loss: 4.4166 ||
04/19 06:05:23 PM: Update 15902: task toronto_lm, batch 899 (15825): perplexity: 80.6318, toronto_lm_loss: 4.3899 ||
04/19 06:05:31 PM: Update 20215: task wsj, batch 215 (20215): perplexity: 82.7310, wsj_loss: 4.4156 ||
04/19 06:05:34 PM: Update 15916: task toronto_lm, batch 913 (15839): perplexity: 80.6788, toronto_lm_loss: 4.3905 ||
04/19 06:05:42 PM: Update 20231: task wsj, batch 231 (20231): perplexity: 82.7214, wsj_loss: 4.4155 ||
04/19 06:05:44 PM: Update 15929: task toronto_lm, batch 926 (15852): perplexity: 80.6607, toronto_lm_loss: 4.3903 ||
04/19 06:05:52 PM: Update 20247: task wsj, batch 247 (20247): perplexity: 82.9865, wsj_loss: 4.4187 ||
04/19 06:05:55 PM: Update 15943: task toronto_lm, batch 940 (15866): perplexity: 80.6757, toronto_lm_loss: 4.3904 ||
04/19 06:06:02 PM: Update 20263: task wsj, batch 263 (20263): perplexity: 83.1201, wsj_loss: 4.4203 ||
04/19 06:06:05 PM: Update 15956: task toronto_lm, batch 953 (15879): perplexity: 80.7283, toronto_lm_loss: 4.3911 ||
04/19 06:06:13 PM: Update 20279: task wsj, batch 279 (20279): perplexity: 83.4372, wsj_loss: 4.4241 ||
04/19 06:06:16 PM: Update 15970: task toronto_lm, batch 967 (15893): perplexity: 80.7387, toronto_lm_loss: 4.3912 ||
04/19 06:06:23 PM: Update 20295: task wsj, batch 295 (20295): perplexity: 83.4803, wsj_loss: 4.4246 ||
04/19 06:06:26 PM: Update 15983: task toronto_lm, batch 980 (15906): perplexity: 80.7653, toronto_lm_loss: 4.3915 ||
04/19 06:06:34 PM: Update 15994: task wsj, batch 4 (78): perplexity: 260.3624, wsj_loss: 5.5621 ||
04/19 06:06:36 PM: Update 20306: task wsj, batch 306 (20306): perplexity: 83.6273, wsj_loss: 4.4264 ||
04/19 06:06:36 PM: Update 15996: task toronto_lm, batch 992 (15918): perplexity: 80.7824, toronto_lm_loss: 4.3918 ||
04/19 06:06:39 PM: ***** Pass 16000 / Epoch 16 *****
04/19 06:06:39 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 06:06:39 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 06:06:39 PM: Validating...
04/19 06:06:46 PM: Batch 27/140: perplexity: 102.9967, toronto_lm_loss: 4.6347 || , for evaluation data
04/19 06:06:46 PM: Update 20322: task wsj, batch 322 (20322): perplexity: 83.4172, wsj_loss: 4.4239 ||
04/19 06:06:56 PM: Batch 66/140: perplexity: 101.8022, toronto_lm_loss: 4.6230 || , for evaluation data
04/19 06:06:57 PM: Update 20338: task wsj, batch 338 (20338): perplexity: 83.2178, wsj_loss: 4.4215 ||
04/19 06:07:06 PM: Batch 104/140: perplexity: 95.6850, toronto_lm_loss: 4.5611 || , for evaluation data
04/19 06:07:07 PM: Update 20354: task wsj, batch 354 (20354): perplexity: 83.1560, wsj_loss: 4.4207 ||
04/19 06:07:16 PM: Batch 1/66: perplexity: 375.4545, wsj_loss: 5.9281 || , for evaluation data
04/19 06:07:17 PM: Update 20370: task wsj, batch 370 (20370): perplexity: 83.1708, wsj_loss: 4.4209 ||
04/19 06:07:26 PM: Batch 40/66: perplexity: 261.2113, wsj_loss: 5.5653 || , for evaluation data
04/19 06:07:28 PM: Update 20386: task wsj, batch 386 (20386): perplexity: 83.0167, wsj_loss: 4.4190 ||
04/19 06:07:32 PM: Advancing scheduler.
04/19 06:07:32 PM: 	Best macro_avg: 0.143
04/19 06:07:32 PM: 	# bad epochs: 1
04/19 06:07:32 PM: Statistic: toronto_lm_loss
04/19 06:07:32 PM: 	training: 4.392234
04/19 06:07:32 PM: 	validation: 4.490163
04/19 06:07:32 PM: Statistic: wsj_loss
04/19 06:07:32 PM: 	training: 5.562074
04/19 06:07:32 PM: 	validation: 5.561753
04/19 06:07:32 PM: Statistic: macro_avg
04/19 06:07:32 PM: 	validation: 0.140306
04/19 06:07:32 PM: Statistic: micro_avg
04/19 06:07:32 PM: 	validation: -0.013176
04/19 06:07:32 PM: Statistic: toronto_lm_perplexity
04/19 06:07:32 PM: 	training: 80.820757
04/19 06:07:32 PM: 	validation: 89.135973
04/19 06:07:32 PM: Statistic: wsj_perplexity
04/19 06:07:32 PM: 	training: 260.362378
04/19 06:07:32 PM: 	validation: 260.278778
04/19 06:07:32 PM: global_lr: 0.001000
04/19 06:07:33 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 06:07:33 PM: Update 16001: task toronto_lm, batch 1 (15923): perplexity: 75.5359, toronto_lm_loss: 4.3246 ||
04/19 06:07:38 PM: Update 20402: task wsj, batch 402 (20402): perplexity: 82.8637, wsj_loss: 4.4172 ||
04/19 06:07:43 PM: Update 16014: task toronto_lm, batch 14 (15936): perplexity: 80.9838, toronto_lm_loss: 4.3942 ||
04/19 06:07:49 PM: Update 20418: task wsj, batch 418 (20418): perplexity: 82.7795, wsj_loss: 4.4162 ||
04/19 06:07:53 PM: Update 16027: task toronto_lm, batch 27 (15949): perplexity: 78.4257, toronto_lm_loss: 4.3622 ||
04/19 06:07:59 PM: Update 20434: task wsj, batch 434 (20434): perplexity: 82.7557, wsj_loss: 4.4159 ||
04/19 06:08:03 PM: Update 16040: task toronto_lm, batch 40 (15962): perplexity: 80.1051, toronto_lm_loss: 4.3833 ||
04/19 06:08:09 PM: Update 20442: task wsj, batch 442 (20442): perplexity: 82.7841, wsj_loss: 4.4162 ||
04/19 06:08:14 PM: Update 16054: task toronto_lm, batch 54 (15976): perplexity: 81.1448, toronto_lm_loss: 4.3962 ||
04/19 06:08:20 PM: Update 20458: task wsj, batch 458 (20458): perplexity: 82.8288, wsj_loss: 4.4168 ||
04/19 06:08:25 PM: Update 16068: task toronto_lm, batch 68 (15990): perplexity: 81.8080, toronto_lm_loss: 4.4044 ||
04/19 06:08:30 PM: Update 20474: task wsj, batch 474 (20474): perplexity: 83.0672, wsj_loss: 4.4196 ||
04/19 06:08:35 PM: Update 16081: task toronto_lm, batch 81 (16003): perplexity: 82.5840, toronto_lm_loss: 4.4138 ||
04/19 06:08:41 PM: Update 20490: task wsj, batch 490 (20490): perplexity: 83.0991, wsj_loss: 4.4200 ||
04/19 06:08:45 PM: Update 16094: task toronto_lm, batch 94 (16016): perplexity: 82.0448, toronto_lm_loss: 4.4073 ||
04/19 06:08:51 PM: Update 20506: task wsj, batch 506 (20506): perplexity: 83.0286, wsj_loss: 4.4192 ||
04/19 06:08:56 PM: Update 16108: task toronto_lm, batch 108 (16030): perplexity: 81.4947, toronto_lm_loss: 4.4005 ||
04/19 06:09:01 PM: Update 20522: task wsj, batch 522 (20522): perplexity: 83.1340, wsj_loss: 4.4205 ||
04/19 06:09:06 PM: Update 16121: task toronto_lm, batch 121 (16043): perplexity: 80.9985, toronto_lm_loss: 4.3944 ||
04/19 06:09:12 PM: Update 20538: task wsj, batch 538 (20538): perplexity: 83.2086, wsj_loss: 4.4214 ||
04/19 06:09:16 PM: Update 16134: task toronto_lm, batch 134 (16056): perplexity: 81.5465, toronto_lm_loss: 4.4012 ||
04/19 06:09:22 PM: Update 20554: task wsj, batch 554 (20554): perplexity: 83.2382, wsj_loss: 4.4217 ||
04/19 06:09:27 PM: Update 16148: task toronto_lm, batch 148 (16070): perplexity: 81.8500, toronto_lm_loss: 4.4049 ||
04/19 06:09:33 PM: Update 20570: task wsj, batch 570 (20570): perplexity: 83.2465, wsj_loss: 4.4218 ||
04/19 06:09:37 PM: Update 16162: task toronto_lm, batch 162 (16084): perplexity: 81.8195, toronto_lm_loss: 4.4045 ||
04/19 06:09:43 PM: Update 20586: task wsj, batch 586 (20586): perplexity: 83.2248, wsj_loss: 4.4215 ||
04/19 06:09:48 PM: Update 16176: task toronto_lm, batch 176 (16098): perplexity: 82.0175, toronto_lm_loss: 4.4069 ||
04/19 06:09:53 PM: Update 16183: task wsj, batch 1 (79): perplexity: 328.1043, wsj_loss: 5.7933 ||
04/19 06:09:56 PM: Update 20598: task wsj, batch 598 (20598): perplexity: 83.2880, wsj_loss: 4.4223 ||
04/19 06:09:59 PM: Update 16190: task toronto_lm, batch 189 (16111): perplexity: 81.6120, toronto_lm_loss: 4.4020 ||
04/19 06:10:06 PM: Update 20614: task wsj, batch 614 (20614): perplexity: 83.2111, wsj_loss: 4.4214 ||
04/19 06:10:09 PM: Update 16203: task toronto_lm, batch 202 (16124): perplexity: 81.5345, toronto_lm_loss: 4.4010 ||
04/19 06:10:16 PM: Update 20630: task wsj, batch 630 (20630): perplexity: 83.1886, wsj_loss: 4.4211 ||
04/19 06:10:20 PM: Update 16217: task toronto_lm, batch 216 (16138): perplexity: 81.6323, toronto_lm_loss: 4.4022 ||
04/19 06:10:27 PM: Update 20646: task wsj, batch 646 (20646): perplexity: 83.1404, wsj_loss: 4.4205 ||
04/19 06:10:30 PM: Update 16231: task toronto_lm, batch 230 (16152): perplexity: 81.4838, toronto_lm_loss: 4.4004 ||
04/19 06:10:37 PM: Update 20662: task wsj, batch 662 (20662): perplexity: 83.0585, wsj_loss: 4.4195 ||
04/19 06:10:40 PM: Update 16244: task toronto_lm, batch 243 (16165): perplexity: 81.2647, toronto_lm_loss: 4.3977 ||
04/19 06:10:48 PM: Update 20678: task wsj, batch 678 (20678): perplexity: 82.9547, wsj_loss: 4.4183 ||
04/19 06:10:51 PM: Update 16258: task toronto_lm, batch 257 (16179): perplexity: 81.0065, toronto_lm_loss: 4.3945 ||
04/19 06:10:58 PM: Update 20694: task wsj, batch 694 (20694): perplexity: 82.9340, wsj_loss: 4.4180 ||
04/19 06:11:02 PM: Update 16272: task toronto_lm, batch 271 (16193): perplexity: 81.1592, toronto_lm_loss: 4.3964 ||
04/19 06:11:08 PM: Update 20710: task wsj, batch 710 (20710): perplexity: 82.8181, wsj_loss: 4.4166 ||
04/19 06:11:10 PM: Update 16283: task wsj, batch 2 (80): perplexity: 286.9340, wsj_loss: 5.6593 ||
04/19 06:11:12 PM: Update 16285: task toronto_lm, batch 283 (16205): perplexity: 81.2042, toronto_lm_loss: 4.3970 ||
04/19 06:11:19 PM: Update 20726: task wsj, batch 726 (20726): perplexity: 82.7648, wsj_loss: 4.4160 ||
04/19 06:11:22 PM: Update 16298: task toronto_lm, batch 296 (16218): perplexity: 81.1954, toronto_lm_loss: 4.3969 ||
04/19 06:11:29 PM: Update 20734: task wsj, batch 734 (20734): perplexity: 82.7757, wsj_loss: 4.4161 ||
04/19 06:11:33 PM: Update 16312: task toronto_lm, batch 310 (16232): perplexity: 81.1770, toronto_lm_loss: 4.3966 ||
04/19 06:11:40 PM: Update 20750: task wsj, batch 750 (20750): perplexity: 82.7630, wsj_loss: 4.4160 ||
04/19 06:11:40 PM: Update 16321: task wsj, batch 3 (81): perplexity: 285.4275, wsj_loss: 5.6540 ||
04/19 06:11:44 PM: Update 16326: task toronto_lm, batch 323 (16245): perplexity: 81.0482, toronto_lm_loss: 4.3950 ||
04/19 06:11:50 PM: Update 20766: task wsj, batch 766 (20766): perplexity: 82.7800, wsj_loss: 4.4162 ||
04/19 06:11:56 PM: Update 16332: task toronto_lm, batch 329 (16251): perplexity: 81.0682, toronto_lm_loss: 4.3953 ||
04/19 06:12:00 PM: Update 20782: task wsj, batch 782 (20782): perplexity: 82.8179, wsj_loss: 4.4166 ||
04/19 06:12:03 PM: Update 16341: task wsj, batch 4 (82): perplexity: 283.8197, wsj_loss: 5.6483 ||
04/19 06:12:06 PM: Update 16345: task toronto_lm, batch 341 (16263): perplexity: 81.4574, toronto_lm_loss: 4.4001 ||
04/19 06:12:11 PM: Update 20798: task wsj, batch 798 (20798): perplexity: 82.8481, wsj_loss: 4.4170 ||
04/19 06:12:16 PM: Update 16358: task toronto_lm, batch 354 (16276): perplexity: 81.6148, toronto_lm_loss: 4.4020 ||
04/19 06:12:21 PM: Update 20814: task wsj, batch 814 (20814): perplexity: 82.9135, wsj_loss: 4.4178 ||
04/19 06:12:27 PM: Update 16372: task toronto_lm, batch 368 (16290): perplexity: 81.7033, toronto_lm_loss: 4.4031 ||
04/19 06:12:31 PM: Update 20830: task wsj, batch 830 (20830): perplexity: 82.9707, wsj_loss: 4.4185 ||
04/19 06:12:37 PM: Update 16385: task toronto_lm, batch 381 (16303): perplexity: 81.5806, toronto_lm_loss: 4.4016 ||
04/19 06:12:42 PM: Update 20846: task wsj, batch 846 (20846): perplexity: 83.0094, wsj_loss: 4.4190 ||
04/19 06:12:47 PM: Update 16398: task toronto_lm, batch 394 (16316): perplexity: 81.4718, toronto_lm_loss: 4.4003 ||
04/19 06:12:52 PM: Update 20862: task wsj, batch 862 (20862): perplexity: 83.0885, wsj_loss: 4.4199 ||
04/19 06:12:57 PM: Update 16411: task toronto_lm, batch 407 (16329): perplexity: 81.3130, toronto_lm_loss: 4.3983 ||
04/19 06:13:03 PM: Update 20878: task wsj, batch 878 (20878): perplexity: 83.0390, wsj_loss: 4.4193 ||
04/19 06:13:08 PM: Update 16425: task toronto_lm, batch 421 (16343): perplexity: 81.2270, toronto_lm_loss: 4.3972 ||
04/19 06:13:16 PM: Update 20890: task wsj, batch 890 (20890): perplexity: 83.1304, wsj_loss: 4.4204 ||
04/19 06:13:18 PM: Update 16438: task toronto_lm, batch 434 (16356): perplexity: 80.9319, toronto_lm_loss: 4.3936 ||
04/19 06:13:25 PM: Update 16447: task wsj, batch 5 (83): perplexity: 288.4764, wsj_loss: 5.6646 ||
04/19 06:13:26 PM: Update 20906: task wsj, batch 906 (20906): perplexity: 83.0528, wsj_loss: 4.4195 ||
04/19 06:13:28 PM: Update 16451: task toronto_lm, batch 446 (16368): perplexity: 80.7206, toronto_lm_loss: 4.3910 ||
04/19 06:13:37 PM: Update 20922: task wsj, batch 922 (20922): perplexity: 83.0192, wsj_loss: 4.4191 ||
04/19 06:13:38 PM: Update 16464: task toronto_lm, batch 459 (16381): perplexity: 80.6184, toronto_lm_loss: 4.3897 ||
04/19 06:13:47 PM: Update 20938: task wsj, batch 938 (20938): perplexity: 82.9277, wsj_loss: 4.4180 ||
04/19 06:13:48 PM: Update 16477: task toronto_lm, batch 472 (16394): perplexity: 80.4598, toronto_lm_loss: 4.3878 ||
04/19 06:13:50 PM: Update 16479: task wsj, batch 6 (84): perplexity: 281.4501, wsj_loss: 5.6400 ||
04/19 06:13:57 PM: Update 20954: task wsj, batch 954 (20954): perplexity: 82.8126, wsj_loss: 4.4166 ||
04/19 06:13:58 PM: Update 16490: task toronto_lm, batch 484 (16406): perplexity: 80.2902, toronto_lm_loss: 4.3856 ||
04/19 06:14:08 PM: Update 20970: task wsj, batch 970 (20970): perplexity: 82.7750, wsj_loss: 4.4161 ||
04/19 06:14:08 PM: Update 16503: task toronto_lm, batch 497 (16419): perplexity: 80.0761, toronto_lm_loss: 4.3830 ||
04/19 06:14:17 PM: Update 16514: task wsj, batch 7 (85): perplexity: 284.2150, wsj_loss: 5.6497 ||
04/19 06:14:18 PM: Update 20986: task wsj, batch 986 (20986): perplexity: 82.7156, wsj_loss: 4.4154 ||
04/19 06:14:18 PM: Update 16516: task toronto_lm, batch 509 (16431): perplexity: 79.9662, toronto_lm_loss: 4.3816 ||
04/19 06:14:27 PM: ***** Pass 21000 / Epoch 21 *****
04/19 06:14:27 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 06:14:27 PM: Validating...
04/19 06:14:29 PM: Update 16529: task toronto_lm, batch 521 (16443): perplexity: 79.7399, toronto_lm_loss: 4.3788 ||
04/19 06:14:29 PM: Batch 5/24: perplexity: 130.5020, wsj_loss: 4.8714 || , for evaluation data
04/19 06:14:33 PM: Best model found for wsj.
04/19 06:14:33 PM: Best model found for micro.
04/19 06:14:33 PM: Best model found for macro.
04/19 06:14:33 PM: Advancing scheduler.
04/19 06:14:33 PM: 	Best macro_avg: 101.271
04/19 06:14:33 PM: 	# bad epochs: 0
04/19 06:14:33 PM: Statistic: wsj_loss
04/19 06:14:33 PM: 	training: 4.415225
04/19 06:14:33 PM: 	validation: 4.617800
04/19 06:14:33 PM: Statistic: macro_avg
04/19 06:14:33 PM: 	validation: 101.270957
04/19 06:14:33 PM: Statistic: micro_avg
04/19 06:14:33 PM: 	validation: 101.270957
04/19 06:14:33 PM: Statistic: wsj_perplexity
04/19 06:14:33 PM: 	training: 82.700449
04/19 06:14:33 PM: 	validation: 101.270957
04/19 06:14:33 PM: global_lr: 0.003000
04/19 06:14:33 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 06:14:39 PM: Update 16542: task toronto_lm, batch 534 (16456): perplexity: 79.6165, toronto_lm_loss: 4.3772 ||
04/19 06:14:39 PM: Update 21009: task wsj, batch 9 (21009): perplexity: 81.1011, wsj_loss: 4.3957 ||
04/19 06:14:49 PM: Update 16555: task toronto_lm, batch 547 (16469): perplexity: 79.4254, toronto_lm_loss: 4.3748 ||
04/19 06:14:55 PM: Update 21025: task wsj, batch 25 (21025): perplexity: 83.7536, wsj_loss: 4.4279 ||
04/19 06:14:59 PM: Update 16568: task toronto_lm, batch 560 (16482): perplexity: 79.2848, toronto_lm_loss: 4.3730 ||
04/19 06:15:05 PM: Update 21041: task wsj, batch 41 (21041): perplexity: 84.0552, wsj_loss: 4.4315 ||
04/19 06:15:09 PM: Update 16581: task toronto_lm, batch 573 (16495): perplexity: 79.0117, toronto_lm_loss: 4.3696 ||
04/19 06:15:16 PM: Update 21057: task wsj, batch 57 (21057): perplexity: 83.7518, wsj_loss: 4.4279 ||
04/19 06:15:19 PM: Update 16594: task toronto_lm, batch 586 (16508): perplexity: 78.7548, toronto_lm_loss: 4.3663 ||
04/19 06:15:26 PM: Update 21073: task wsj, batch 73 (21073): perplexity: 83.9114, wsj_loss: 4.4298 ||
04/19 06:15:30 PM: Update 16608: task toronto_lm, batch 600 (16522): perplexity: 78.5130, toronto_lm_loss: 4.3633 ||
04/19 06:15:36 PM: Update 21089: task wsj, batch 89 (21089): perplexity: 83.7486, wsj_loss: 4.4278 ||
04/19 06:15:40 PM: Update 16621: task toronto_lm, batch 613 (16535): perplexity: 78.2695, toronto_lm_loss: 4.3602 ||
04/19 06:15:47 PM: Update 21105: task wsj, batch 105 (21105): perplexity: 84.0640, wsj_loss: 4.4316 ||
04/19 06:15:50 PM: Update 16635: task toronto_lm, batch 627 (16549): perplexity: 78.1177, toronto_lm_loss: 4.3582 ||
04/19 06:15:51 PM: Update 16636: task wsj, batch 9 (87): perplexity: 276.3671, wsj_loss: 5.6217 ||
04/19 06:15:57 PM: Update 21121: task wsj, batch 121 (21121): perplexity: 84.7093, wsj_loss: 4.4392 ||
04/19 06:16:00 PM: Update 16648: task toronto_lm, batch 639 (16561): perplexity: 77.9670, toronto_lm_loss: 4.3563 ||
04/19 06:16:07 PM: Update 21137: task wsj, batch 137 (21137): perplexity: 84.6284, wsj_loss: 4.4383 ||
04/19 06:16:10 PM: Update 16661: task toronto_lm, batch 652 (16574): perplexity: 77.7932, toronto_lm_loss: 4.3541 ||
04/19 06:16:18 PM: Update 21153: task wsj, batch 153 (21153): perplexity: 84.6406, wsj_loss: 4.4384 ||
04/19 06:16:21 PM: Update 16674: task toronto_lm, batch 665 (16587): perplexity: 77.6304, toronto_lm_loss: 4.3520 ||
04/19 06:16:28 PM: Update 21169: task wsj, batch 169 (21169): perplexity: 84.2747, wsj_loss: 4.4341 ||
04/19 06:16:31 PM: Update 16687: task toronto_lm, batch 678 (16600): perplexity: 77.5131, toronto_lm_loss: 4.3504 ||
04/19 06:16:41 PM: Update 16701: task toronto_lm, batch 692 (16614): perplexity: 77.3013, toronto_lm_loss: 4.3477 ||
04/19 06:16:42 PM: Update 21182: task wsj, batch 182 (21182): perplexity: 84.2163, wsj_loss: 4.4334 ||
04/19 06:16:52 PM: Update 16714: task toronto_lm, batch 705 (16627): perplexity: 77.0840, toronto_lm_loss: 4.3449 ||
04/19 06:16:52 PM: Update 21198: task wsj, batch 198 (21198): perplexity: 83.9470, wsj_loss: 4.4302 ||
04/19 06:17:02 PM: Update 21214: task wsj, batch 214 (21214): perplexity: 83.6476, wsj_loss: 4.4266 ||
04/19 06:17:02 PM: Update 16728: task toronto_lm, batch 719 (16641): perplexity: 76.8801, toronto_lm_loss: 4.3422 ||
04/19 06:17:12 PM: Update 16741: task toronto_lm, batch 732 (16654): perplexity: 76.7840, toronto_lm_loss: 4.3410 ||
04/19 06:17:13 PM: Update 21230: task wsj, batch 230 (21230): perplexity: 83.4573, wsj_loss: 4.4243 ||
04/19 06:17:23 PM: Update 21246: task wsj, batch 246 (21246): perplexity: 83.2512, wsj_loss: 4.4219 ||
04/19 06:17:23 PM: Update 16755: task toronto_lm, batch 746 (16668): perplexity: 76.5617, toronto_lm_loss: 4.3381 ||
04/19 06:17:33 PM: Update 16768: task toronto_lm, batch 759 (16681): perplexity: 76.4359, toronto_lm_loss: 4.3365 ||
04/19 06:17:33 PM: Update 21262: task wsj, batch 262 (21262): perplexity: 82.9738, wsj_loss: 4.4185 ||
04/19 06:17:43 PM: Update 16781: task toronto_lm, batch 772 (16694): perplexity: 76.3079, toronto_lm_loss: 4.3348 ||
04/19 06:17:44 PM: Update 21278: task wsj, batch 278 (21278): perplexity: 82.6365, wsj_loss: 4.4145 ||
04/19 06:17:53 PM: Update 16794: task toronto_lm, batch 785 (16707): perplexity: 76.2190, toronto_lm_loss: 4.3336 ||
04/19 06:17:54 PM: Update 21294: task wsj, batch 294 (21294): perplexity: 82.6436, wsj_loss: 4.4145 ||
04/19 06:18:03 PM: Update 16807: task toronto_lm, batch 798 (16720): perplexity: 76.0386, toronto_lm_loss: 4.3312 ||
04/19 06:18:04 PM: Update 21310: task wsj, batch 310 (21310): perplexity: 82.3107, wsj_loss: 4.4105 ||
04/19 06:18:13 PM: Update 16820: task wsj, batch 10 (88): perplexity: 277.1888, wsj_loss: 5.6247 ||
04/19 06:18:14 PM: Update 16821: task toronto_lm, batch 811 (16733): perplexity: 75.9262, toronto_lm_loss: 4.3298 ||
04/19 06:18:15 PM: Update 21318: task wsj, batch 318 (21318): perplexity: 82.3920, wsj_loss: 4.4115 ||
04/19 06:18:24 PM: Update 16834: task toronto_lm, batch 824 (16746): perplexity: 75.7756, toronto_lm_loss: 4.3278 ||
04/19 06:18:25 PM: Update 21334: task wsj, batch 334 (21334): perplexity: 82.5293, wsj_loss: 4.4132 ||
04/19 06:18:35 PM: Update 16848: task wsj, batch 11 (89): perplexity: 276.4457, wsj_loss: 5.6220 ||
04/19 06:18:35 PM: Update 16849: task toronto_lm, batch 838 (16760): perplexity: 75.6462, toronto_lm_loss: 4.3261 ||
04/19 06:18:36 PM: Update 21350: task wsj, batch 350 (21350): perplexity: 82.6162, wsj_loss: 4.4142 ||
04/19 06:18:46 PM: Update 21366: task wsj, batch 366 (21366): perplexity: 82.8014, wsj_loss: 4.4164 ||
04/19 06:18:46 PM: Update 16863: task toronto_lm, batch 852 (16774): perplexity: 75.4392, toronto_lm_loss: 4.3233 ||
04/19 06:18:56 PM: Update 16876: task toronto_lm, batch 865 (16787): perplexity: 75.2080, toronto_lm_loss: 4.3203 ||
04/19 06:18:56 PM: Update 21382: task wsj, batch 382 (21382): perplexity: 82.7197, wsj_loss: 4.4155 ||
04/19 06:19:07 PM: Update 21398: task wsj, batch 398 (21398): perplexity: 82.7641, wsj_loss: 4.4160 ||
04/19 06:19:07 PM: Update 16890: task toronto_lm, batch 879 (16801): perplexity: 75.1177, toronto_lm_loss: 4.3191 ||
04/19 06:19:17 PM: Update 21414: task wsj, batch 414 (21414): perplexity: 82.6769, wsj_loss: 4.4149 ||
04/19 06:19:18 PM: Update 16904: task toronto_lm, batch 893 (16815): perplexity: 75.0378, toronto_lm_loss: 4.3180 ||
04/19 06:19:28 PM: Update 21430: task wsj, batch 430 (21430): perplexity: 82.8183, wsj_loss: 4.4166 ||
04/19 06:19:28 PM: Update 16917: task toronto_lm, batch 906 (16828): perplexity: 74.8584, toronto_lm_loss: 4.3156 ||
04/19 06:19:38 PM: Update 21446: task wsj, batch 446 (21446): perplexity: 82.6957, wsj_loss: 4.4152 ||
04/19 06:19:39 PM: Update 16931: task toronto_lm, batch 920 (16842): perplexity: 74.7262, toronto_lm_loss: 4.3138 ||
04/19 06:19:48 PM: Update 21462: task wsj, batch 462 (21462): perplexity: 82.8105, wsj_loss: 4.4166 ||
04/19 06:19:49 PM: Update 16944: task toronto_lm, batch 933 (16855): perplexity: 74.5840, toronto_lm_loss: 4.3119 ||
04/19 06:19:59 PM: Update 16957: task toronto_lm, batch 946 (16868): perplexity: 74.5003, toronto_lm_loss: 4.3108 ||
04/19 06:20:02 PM: Update 21474: task wsj, batch 474 (21474): perplexity: 82.7780, wsj_loss: 4.4162 ||
04/19 06:20:12 PM: Update 21490: task wsj, batch 490 (21490): perplexity: 82.5812, wsj_loss: 4.4138 ||
04/19 06:20:13 PM: Update 16965: task toronto_lm, batch 954 (16876): perplexity: 74.4710, toronto_lm_loss: 4.3104 ||
04/19 06:20:22 PM: Update 21506: task wsj, batch 506 (21506): perplexity: 82.4544, wsj_loss: 4.4122 ||
04/19 06:20:23 PM: Update 16978: task toronto_lm, batch 967 (16889): perplexity: 74.8002, toronto_lm_loss: 4.3148 ||
04/19 06:20:33 PM: Update 21522: task wsj, batch 522 (21522): perplexity: 82.4663, wsj_loss: 4.4124 ||
04/19 06:20:34 PM: Update 16992: task toronto_lm, batch 981 (16903): perplexity: 75.0713, toronto_lm_loss: 4.3184 ||
04/19 06:20:40 PM: ***** Pass 17000 / Epoch 17 *****
04/19 06:20:40 PM: toronto_lm: trained on 989 batches, 0.005 epochs
04/19 06:20:40 PM: wsj: trained on 11 batches, 0.013 epochs
04/19 06:20:40 PM: Validating...
04/19 06:20:43 PM: Update 21538: task wsj, batch 538 (21538): perplexity: 82.3765, wsj_loss: 4.4113 ||
04/19 06:20:44 PM: Batch 15/140: perplexity: 94.1977, toronto_lm_loss: 4.5454 || , for evaluation data
04/19 06:20:53 PM: Update 21554: task wsj, batch 554 (21554): perplexity: 82.3364, wsj_loss: 4.4108 ||
04/19 06:20:54 PM: Batch 54/140: perplexity: 97.8995, toronto_lm_loss: 4.5839 || , for evaluation data
04/19 06:21:04 PM: Update 21570: task wsj, batch 570 (21570): perplexity: 82.2404, wsj_loss: 4.4096 ||
04/19 06:21:04 PM: Batch 93/140: perplexity: 90.8948, toronto_lm_loss: 4.5097 || , for evaluation data
04/19 06:21:14 PM: Update 21586: task wsj, batch 586 (21586): perplexity: 82.0854, wsj_loss: 4.4078 ||
04/19 06:21:14 PM: Batch 132/140: perplexity: 84.5006, toronto_lm_loss: 4.4368 || , for evaluation data
04/19 06:21:17 PM: Batch 1/66: perplexity: 371.4904, wsj_loss: 5.9175 || , for evaluation data
04/19 06:21:24 PM: Update 21602: task wsj, batch 602 (21602): perplexity: 82.0193, wsj_loss: 4.4070 ||
04/19 06:21:27 PM: Batch 40/66: perplexity: 262.9133, wsj_loss: 5.5718 || , for evaluation data
04/19 06:21:34 PM: Best model found for toronto_lm.
04/19 06:21:34 PM: Best model found for macro.
04/19 06:21:34 PM: Advancing scheduler.
04/19 06:21:34 PM: 	Best macro_avg: 0.144
04/19 06:21:34 PM: 	# bad epochs: 0
04/19 06:21:34 PM: Statistic: toronto_lm_loss
04/19 06:21:34 PM: 	training: 4.320496
04/19 06:21:34 PM: 	validation: 4.423963
04/19 06:21:34 PM: Statistic: wsj_loss
04/19 06:21:34 PM: 	training: 5.622014
04/19 06:21:34 PM: 	validation: 5.565577
04/19 06:21:34 PM: Statistic: macro_avg
04/19 06:21:34 PM: 	validation: 0.144022
04/19 06:21:34 PM: Statistic: micro_avg
04/19 06:21:34 PM: 	validation: -0.014454
04/19 06:21:34 PM: Statistic: toronto_lm_perplexity
04/19 06:21:34 PM: 	training: 75.225899
04/19 06:21:34 PM: 	validation: 83.426222
04/19 06:21:34 PM: Statistic: wsj_perplexity
04/19 06:21:34 PM: 	training: 276.445669
04/19 06:21:34 PM: 	validation: 261.275924
04/19 06:21:34 PM: global_lr: 0.001000
04/19 06:21:34 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 06:21:35 PM: Update 17001: task toronto_lm, batch 1 (16912): perplexity: 76.2917, toronto_lm_loss: 4.3346 ||
04/19 06:21:35 PM: Update 21611: task wsj, batch 611 (21611): perplexity: 82.0269, wsj_loss: 4.4070 ||
04/19 06:21:45 PM: Update 17015: task toronto_lm, batch 15 (16926): perplexity: 90.6324, toronto_lm_loss: 4.5068 ||
04/19 06:21:45 PM: Update 21627: task wsj, batch 627 (21627): perplexity: 82.0003, wsj_loss: 4.4067 ||
04/19 06:21:52 PM: Update 17024: task wsj, batch 1 (90): perplexity: 177.7873, wsj_loss: 5.1806 ||
04/19 06:21:55 PM: Update 17028: task toronto_lm, batch 27 (16938): perplexity: 88.9203, toronto_lm_loss: 4.4877 ||
04/19 06:21:56 PM: Update 21643: task wsj, batch 643 (21643): perplexity: 82.0405, wsj_loss: 4.4072 ||
04/19 06:22:06 PM: Update 21659: task wsj, batch 659 (21659): perplexity: 82.1110, wsj_loss: 4.4081 ||
04/19 06:22:06 PM: Update 17042: task toronto_lm, batch 41 (16952): perplexity: 89.9310, toronto_lm_loss: 4.4990 ||
04/19 06:22:16 PM: Update 17055: task toronto_lm, batch 54 (16965): perplexity: 89.6682, toronto_lm_loss: 4.4961 ||
04/19 06:22:17 PM: Update 21675: task wsj, batch 675 (21675): perplexity: 82.0570, wsj_loss: 4.4074 ||
04/19 06:22:27 PM: Update 17069: task toronto_lm, batch 68 (16979): perplexity: 89.0093, toronto_lm_loss: 4.4887 ||
04/19 06:22:37 PM: Update 17082: task toronto_lm, batch 81 (16992): perplexity: 87.9306, toronto_lm_loss: 4.4765 ||
04/19 06:22:37 PM: Update 21707: task wsj, batch 707 (21707): perplexity: 82.1812, wsj_loss: 4.4089 ||
04/19 06:22:47 PM: Update 17095: task toronto_lm, batch 94 (17005): perplexity: 87.5438, toronto_lm_loss: 4.4721 ||
04/19 06:22:48 PM: Update 21723: task wsj, batch 723 (21723): perplexity: 82.2137, wsj_loss: 4.4093 ||
04/19 06:22:57 PM: Update 17108: task toronto_lm, batch 107 (17018): perplexity: 87.1671, toronto_lm_loss: 4.4678 ||
04/19 06:22:58 PM: Update 21739: task wsj, batch 739 (21739): perplexity: 82.2246, wsj_loss: 4.4095 ||
04/19 06:23:07 PM: Update 17121: task toronto_lm, batch 120 (17031): perplexity: 85.7604, toronto_lm_loss: 4.4516 ||
04/19 06:23:08 PM: Update 21755: task wsj, batch 755 (21755): perplexity: 82.2774, wsj_loss: 4.4101 ||
04/19 06:23:18 PM: Update 17135: task toronto_lm, batch 134 (17045): perplexity: 84.4542, toronto_lm_loss: 4.4362 ||
04/19 06:23:21 PM: Update 21766: task wsj, batch 766 (21766): perplexity: 82.3196, wsj_loss: 4.4106 ||
04/19 06:23:29 PM: Update 17149: task toronto_lm, batch 148 (17059): perplexity: 83.7522, toronto_lm_loss: 4.4279 ||
04/19 06:23:31 PM: Update 21782: task wsj, batch 782 (21782): perplexity: 82.1882, wsj_loss: 4.4090 ||
04/19 06:23:39 PM: Update 17162: task toronto_lm, batch 161 (17072): perplexity: 83.2755, toronto_lm_loss: 4.4222 ||
04/19 06:23:42 PM: Update 21798: task wsj, batch 798 (21798): perplexity: 82.1052, wsj_loss: 4.4080 ||
04/19 06:23:49 PM: Update 17176: task toronto_lm, batch 175 (17086): perplexity: 82.7365, toronto_lm_loss: 4.4157 ||
04/19 06:23:52 PM: Update 21814: task wsj, batch 814 (21814): perplexity: 82.0296, wsj_loss: 4.4071 ||
04/19 06:24:00 PM: Update 17190: task toronto_lm, batch 189 (17100): perplexity: 82.0024, toronto_lm_loss: 4.4067 ||
04/19 06:24:02 PM: Update 21830: task wsj, batch 830 (21830): perplexity: 82.0446, wsj_loss: 4.4073 ||
04/19 06:24:11 PM: Update 17204: task toronto_lm, batch 203 (17114): perplexity: 82.1975, toronto_lm_loss: 4.4091 ||
04/19 06:24:13 PM: Update 21846: task wsj, batch 846 (21846): perplexity: 81.9658, wsj_loss: 4.4063 ||
04/19 06:24:15 PM: Update 17209: task wsj, batch 2 (91): perplexity: 224.0386, wsj_loss: 5.4118 ||
04/19 06:24:22 PM: Update 17218: task toronto_lm, batch 216 (17127): perplexity: 81.7465, toronto_lm_loss: 4.4036 ||
04/19 06:24:23 PM: Update 21862: task wsj, batch 862 (21862): perplexity: 81.9137, wsj_loss: 4.4057 ||
04/19 06:24:32 PM: Update 17231: task toronto_lm, batch 229 (17140): perplexity: 81.5003, toronto_lm_loss: 4.4006 ||
04/19 06:24:33 PM: Update 21878: task wsj, batch 878 (21878): perplexity: 81.8558, wsj_loss: 4.4050 ||
04/19 06:24:42 PM: Update 17244: task toronto_lm, batch 242 (17153): perplexity: 81.0414, toronto_lm_loss: 4.3950 ||
04/19 06:24:44 PM: Update 21894: task wsj, batch 894 (21894): perplexity: 81.7664, wsj_loss: 4.4039 ||
04/19 06:24:51 PM: Update 17256: task wsj, batch 3 (92): perplexity: 227.4333, wsj_loss: 5.4269 ||
04/19 06:24:52 PM: Update 17257: task toronto_lm, batch 254 (17165): perplexity: 80.7902, toronto_lm_loss: 4.3919 ||
04/19 06:24:54 PM: Update 21902: task wsj, batch 902 (21902): perplexity: 81.7796, wsj_loss: 4.4040 ||
04/19 06:25:02 PM: Update 17270: task toronto_lm, batch 267 (17178): perplexity: 80.3194, toronto_lm_loss: 4.3860 ||
04/19 06:25:04 PM: Update 21918: task wsj, batch 918 (21918): perplexity: 81.8333, wsj_loss: 4.4047 ||
04/19 06:25:12 PM: Update 17283: task toronto_lm, batch 280 (17191): perplexity: 80.0768, toronto_lm_loss: 4.3830 ||
04/19 06:25:15 PM: Update 21934: task wsj, batch 934 (21934): perplexity: 81.8902, wsj_loss: 4.4054 ||
04/19 06:25:22 PM: Update 17296: task toronto_lm, batch 293 (17204): perplexity: 79.8026, toronto_lm_loss: 4.3796 ||
04/19 06:25:25 PM: Update 21950: task wsj, batch 950 (21950): perplexity: 81.8432, wsj_loss: 4.4048 ||
04/19 06:25:32 PM: Update 17309: task toronto_lm, batch 306 (17217): perplexity: 79.5773, toronto_lm_loss: 4.3767 ||
04/19 06:25:36 PM: Update 21966: task wsj, batch 966 (21966): perplexity: 81.9125, wsj_loss: 4.4057 ||
04/19 06:25:42 PM: Update 17322: task toronto_lm, batch 319 (17230): perplexity: 79.3780, toronto_lm_loss: 4.3742 ||
04/19 06:25:46 PM: Update 21982: task wsj, batch 982 (21982): perplexity: 81.9237, wsj_loss: 4.4058 ||
04/19 06:25:52 PM: Update 17335: task toronto_lm, batch 332 (17243): perplexity: 79.1575, toronto_lm_loss: 4.3714 ||
04/19 06:25:56 PM: Update 21998: task wsj, batch 998 (21998): perplexity: 81.8966, wsj_loss: 4.4055 ||
04/19 06:25:58 PM: ***** Pass 22000 / Epoch 22 *****
04/19 06:25:58 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 06:25:58 PM: Validating...
04/19 06:26:03 PM: Update 17349: task toronto_lm, batch 346 (17257): perplexity: 78.7590, toronto_lm_loss: 4.3664 ||
04/19 06:26:04 PM: Advancing scheduler.
04/19 06:26:04 PM: 	Best macro_avg: 101.271
04/19 06:26:04 PM: 	# bad epochs: 1
04/19 06:26:04 PM: Statistic: wsj_loss
04/19 06:26:04 PM: 	training: 4.405619
04/19 06:26:04 PM: 	validation: 4.632402
04/19 06:26:04 PM: Statistic: macro_avg
04/19 06:26:04 PM: 	validation: 102.760552
04/19 06:26:04 PM: Statistic: micro_avg
04/19 06:26:04 PM: 	validation: 102.760552
04/19 06:26:04 PM: Statistic: wsj_perplexity
04/19 06:26:04 PM: 	training: 81.909854
04/19 06:26:04 PM: 	validation: 102.760552
04/19 06:26:04 PM: global_lr: 0.003000
04/19 06:26:04 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 06:26:07 PM: Update 22004: task wsj, batch 4 (22004): perplexity: 76.9275, wsj_loss: 4.3429 ||
04/19 06:26:14 PM: Update 17363: task toronto_lm, batch 360 (17271): perplexity: 78.4887, toronto_lm_loss: 4.3630 ||
04/19 06:26:17 PM: Update 22020: task wsj, batch 20 (22020): perplexity: 83.7811, wsj_loss: 4.4282 ||
04/19 06:26:24 PM: Update 17376: task toronto_lm, batch 373 (17284): perplexity: 78.2035, toronto_lm_loss: 4.3593 ||
04/19 06:26:28 PM: Update 22036: task wsj, batch 36 (22036): perplexity: 83.1434, wsj_loss: 4.4206 ||
04/19 06:26:34 PM: Update 17389: task toronto_lm, batch 386 (17297): perplexity: 78.0362, toronto_lm_loss: 4.3572 ||
04/19 06:26:38 PM: Update 22052: task wsj, batch 52 (22052): perplexity: 83.8749, wsj_loss: 4.4293 ||
04/19 06:26:44 PM: Update 17403: task toronto_lm, batch 400 (17311): perplexity: 77.8546, toronto_lm_loss: 4.3548 ||
04/19 06:26:48 PM: Update 22060: task wsj, batch 60 (22060): perplexity: 83.8970, wsj_loss: 4.4296 ||
04/19 06:26:55 PM: Update 17417: task toronto_lm, batch 414 (17325): perplexity: 77.7404, toronto_lm_loss: 4.3534 ||
04/19 06:26:58 PM: Update 22076: task wsj, batch 76 (22076): perplexity: 82.7089, wsj_loss: 4.4153 ||
04/19 06:27:06 PM: Update 17431: task toronto_lm, batch 428 (17339): perplexity: 77.4812, toronto_lm_loss: 4.3500 ||
04/19 06:27:09 PM: Update 22092: task wsj, batch 92 (22092): perplexity: 82.3012, wsj_loss: 4.4104 ||
04/19 06:27:16 PM: Update 17444: task toronto_lm, batch 441 (17352): perplexity: 77.3168, toronto_lm_loss: 4.3479 ||
04/19 06:27:19 PM: Update 22108: task wsj, batch 108 (22108): perplexity: 81.8335, wsj_loss: 4.4047 ||
04/19 06:27:27 PM: Update 17458: task toronto_lm, batch 455 (17366): perplexity: 77.2265, toronto_lm_loss: 4.3467 ||
04/19 06:27:30 PM: Update 22124: task wsj, batch 124 (22124): perplexity: 81.5090, wsj_loss: 4.4007 ||
04/19 06:27:37 PM: Update 17472: task toronto_lm, batch 469 (17380): perplexity: 77.0102, toronto_lm_loss: 4.3439 ||
04/19 06:27:40 PM: Update 22140: task wsj, batch 140 (22140): perplexity: 80.7668, wsj_loss: 4.3916 ||
04/19 06:27:48 PM: Update 17486: task toronto_lm, batch 483 (17394): perplexity: 76.8253, toronto_lm_loss: 4.3415 ||
04/19 06:27:51 PM: Update 22156: task wsj, batch 156 (22156): perplexity: 80.6614, wsj_loss: 4.3903 ||
04/19 06:27:59 PM: Update 17500: task toronto_lm, batch 497 (17408): perplexity: 76.5959, toronto_lm_loss: 4.3385 ||
04/19 06:28:01 PM: Update 22172: task wsj, batch 172 (22172): perplexity: 80.5451, wsj_loss: 4.3888 ||
04/19 06:28:10 PM: Update 17514: task toronto_lm, batch 511 (17422): perplexity: 76.4663, toronto_lm_loss: 4.3369 ||
04/19 06:28:12 PM: Update 22188: task wsj, batch 188 (22188): perplexity: 80.3568, wsj_loss: 4.3865 ||
04/19 06:28:20 PM: Update 17528: task toronto_lm, batch 525 (17436): perplexity: 76.2946, toronto_lm_loss: 4.3346 ||
04/19 06:28:22 PM: Update 22195: task wsj, batch 195 (22195): perplexity: 80.5669, wsj_loss: 4.3891 ||
04/19 06:28:31 PM: Update 17542: task toronto_lm, batch 539 (17450): perplexity: 76.0998, toronto_lm_loss: 4.3320 ||
04/19 06:28:32 PM: Update 22211: task wsj, batch 211 (22211): perplexity: 80.6489, wsj_loss: 4.3901 ||
04/19 06:28:42 PM: Update 17556: task toronto_lm, batch 553 (17464): perplexity: 75.8627, toronto_lm_loss: 4.3289 ||
04/19 06:28:43 PM: Update 22227: task wsj, batch 227 (22227): perplexity: 80.8091, wsj_loss: 4.3921 ||
04/19 06:28:52 PM: Update 17570: task toronto_lm, batch 567 (17478): perplexity: 75.6648, toronto_lm_loss: 4.3263 ||
04/19 06:28:53 PM: Update 22243: task wsj, batch 243 (22243): perplexity: 80.9237, wsj_loss: 4.3935 ||
04/19 06:29:03 PM: Update 17584: task toronto_lm, batch 581 (17492): perplexity: 75.6488, toronto_lm_loss: 4.3261 ||
04/19 06:29:03 PM: Update 22259: task wsj, batch 259 (22259): perplexity: 81.1097, wsj_loss: 4.3958 ||
04/19 06:29:14 PM: Update 22275: task wsj, batch 275 (22275): perplexity: 81.3558, wsj_loss: 4.3988 ||
04/19 06:29:18 PM: Update 17593: task toronto_lm, batch 590 (17501): perplexity: 75.7296, toronto_lm_loss: 4.3272 ||
04/19 06:29:24 PM: Update 22291: task wsj, batch 291 (22291): perplexity: 81.3315, wsj_loss: 4.3985 ||
04/19 06:29:29 PM: Update 17607: task toronto_lm, batch 604 (17515): perplexity: 76.2904, toronto_lm_loss: 4.3345 ||
04/19 06:29:35 PM: Update 22307: task wsj, batch 307 (22307): perplexity: 81.4970, wsj_loss: 4.4006 ||
04/19 06:29:40 PM: Update 17621: task toronto_lm, batch 618 (17529): perplexity: 76.7862, toronto_lm_loss: 4.3410 ||
04/19 06:29:45 PM: Update 22323: task wsj, batch 323 (22323): perplexity: 81.4763, wsj_loss: 4.4003 ||
04/19 06:29:51 PM: Update 17635: task toronto_lm, batch 632 (17543): perplexity: 77.1768, toronto_lm_loss: 4.3461 ||
04/19 06:29:56 PM: Update 22339: task wsj, batch 339 (22339): perplexity: 81.5089, wsj_loss: 4.4007 ||
04/19 06:30:01 PM: Update 17649: task toronto_lm, batch 646 (17557): perplexity: 77.5642, toronto_lm_loss: 4.3511 ||
04/19 06:30:08 PM: Update 22350: task wsj, batch 350 (22350): perplexity: 81.6188, wsj_loss: 4.4021 ||
04/19 06:30:12 PM: Update 17663: task toronto_lm, batch 660 (17571): perplexity: 77.8731, toronto_lm_loss: 4.3551 ||
04/19 06:30:18 PM: Update 22366: task wsj, batch 366 (22366): perplexity: 81.4628, wsj_loss: 4.4001 ||
04/19 06:30:23 PM: Update 17677: task toronto_lm, batch 674 (17585): perplexity: 78.1674, toronto_lm_loss: 4.3589 ||
04/19 06:30:29 PM: Update 22382: task wsj, batch 382 (22382): perplexity: 81.2736, wsj_loss: 4.3978 ||
04/19 06:30:33 PM: Update 17691: task toronto_lm, batch 688 (17599): perplexity: 78.4213, toronto_lm_loss: 4.3621 ||
04/19 06:30:39 PM: Update 22398: task wsj, batch 398 (22398): perplexity: 81.2654, wsj_loss: 4.3977 ||
04/19 06:30:43 PM: Update 17704: task toronto_lm, batch 701 (17612): perplexity: 78.6292, toronto_lm_loss: 4.3647 ||
04/19 06:30:50 PM: Update 22414: task wsj, batch 414 (22414): perplexity: 81.1545, wsj_loss: 4.3964 ||
04/19 06:30:54 PM: Update 17718: task toronto_lm, batch 715 (17626): perplexity: 78.6816, toronto_lm_loss: 4.3654 ||
04/19 06:31:00 PM: Update 22430: task wsj, batch 430 (22430): perplexity: 80.9571, wsj_loss: 4.3939 ||
04/19 06:31:05 PM: Update 17732: task toronto_lm, batch 729 (17640): perplexity: 78.8305, toronto_lm_loss: 4.3673 ||
04/19 06:31:11 PM: Update 22446: task wsj, batch 446 (22446): perplexity: 80.8373, wsj_loss: 4.3924 ||
04/19 06:31:16 PM: Update 17746: task toronto_lm, batch 743 (17654): perplexity: 78.9665, toronto_lm_loss: 4.3690 ||
04/19 06:31:21 PM: Update 22462: task wsj, batch 462 (22462): perplexity: 80.8443, wsj_loss: 4.3925 ||
04/19 06:31:26 PM: Update 17759: task toronto_lm, batch 756 (17667): perplexity: 79.0500, toronto_lm_loss: 4.3701 ||
04/19 06:31:32 PM: Update 22478: task wsj, batch 478 (22478): perplexity: 80.6859, wsj_loss: 4.3906 ||
04/19 06:31:36 PM: Update 17773: task toronto_lm, batch 770 (17681): perplexity: 79.1324, toronto_lm_loss: 4.3711 ||
04/19 06:31:42 PM: Update 22485: task wsj, batch 485 (22485): perplexity: 80.7232, wsj_loss: 4.3910 ||
04/19 06:31:47 PM: Update 17787: task toronto_lm, batch 784 (17695): perplexity: 79.1942, toronto_lm_loss: 4.3719 ||
04/19 06:31:52 PM: Update 22501: task wsj, batch 501 (22501): perplexity: 80.8042, wsj_loss: 4.3920 ||
04/19 06:31:58 PM: Update 17801: task toronto_lm, batch 798 (17709): perplexity: 79.3218, toronto_lm_loss: 4.3735 ||
04/19 06:32:03 PM: Update 22517: task wsj, batch 517 (22517): perplexity: 80.8261, wsj_loss: 4.3923 ||
04/19 06:32:08 PM: Update 17815: task toronto_lm, batch 812 (17723): perplexity: 79.4442, toronto_lm_loss: 4.3751 ||
04/19 06:32:13 PM: Update 22533: task wsj, batch 533 (22533): perplexity: 80.8795, wsj_loss: 4.3930 ||
04/19 06:32:19 PM: Update 17829: task toronto_lm, batch 826 (17737): perplexity: 79.4217, toronto_lm_loss: 4.3748 ||
04/19 06:32:24 PM: Update 22549: task wsj, batch 549 (22549): perplexity: 80.8768, wsj_loss: 4.3929 ||
04/19 06:32:30 PM: Update 17843: task toronto_lm, batch 840 (17751): perplexity: 79.5211, toronto_lm_loss: 4.3760 ||
04/19 06:32:34 PM: Update 22565: task wsj, batch 565 (22565): perplexity: 80.8804, wsj_loss: 4.3930 ||
04/19 06:32:40 PM: Update 17857: task wsj, batch 4 (93): perplexity: 225.5829, wsj_loss: 5.4187 ||
04/19 06:32:41 PM: Update 17858: task toronto_lm, batch 854 (17765): perplexity: 79.5032, toronto_lm_loss: 4.3758 ||
04/19 06:32:45 PM: Update 22581: task wsj, batch 581 (22581): perplexity: 80.9247, wsj_loss: 4.3935 ||
04/19 06:32:52 PM: Update 17872: task toronto_lm, batch 868 (17779): perplexity: 79.4531, toronto_lm_loss: 4.3752 ||
04/19 06:32:55 PM: Update 22597: task wsj, batch 597 (22597): perplexity: 80.9529, wsj_loss: 4.3939 ||
04/19 06:33:02 PM: Update 17886: task toronto_lm, batch 882 (17793): perplexity: 79.4752, toronto_lm_loss: 4.3754 ||
04/19 06:33:06 PM: Update 22613: task wsj, batch 613 (22613): perplexity: 81.0102, wsj_loss: 4.3946 ||
04/19 06:33:13 PM: Update 17900: task toronto_lm, batch 896 (17807): perplexity: 79.4827, toronto_lm_loss: 4.3755 ||
04/19 06:33:16 PM: Update 22629: task wsj, batch 629 (22629): perplexity: 81.1118, wsj_loss: 4.3958 ||
04/19 06:33:24 PM: Update 17914: task toronto_lm, batch 910 (17821): perplexity: 79.5766, toronto_lm_loss: 4.3767 ||
04/19 06:33:30 PM: Update 22642: task wsj, batch 642 (22642): perplexity: 81.0813, wsj_loss: 4.3955 ||
04/19 06:33:34 PM: Update 17928: task toronto_lm, batch 924 (17835): perplexity: 79.4971, toronto_lm_loss: 4.3757 ||
04/19 06:33:41 PM: Update 22658: task wsj, batch 658 (22658): perplexity: 81.0721, wsj_loss: 4.3953 ||
04/19 06:33:45 PM: Update 17942: task toronto_lm, batch 938 (17849): perplexity: 79.5520, toronto_lm_loss: 4.3764 ||
04/19 06:33:51 PM: Update 22674: task wsj, batch 674 (22674): perplexity: 80.9300, wsj_loss: 4.3936 ||
04/19 06:33:56 PM: Update 17956: task toronto_lm, batch 952 (17863): perplexity: 79.5556, toronto_lm_loss: 4.3765 ||
04/19 06:34:02 PM: Update 22690: task wsj, batch 690 (22690): perplexity: 80.8509, wsj_loss: 4.3926 ||
04/19 06:34:06 PM: Update 17970: task toronto_lm, batch 966 (17877): perplexity: 79.5534, toronto_lm_loss: 4.3764 ||
04/19 06:34:12 PM: Update 22706: task wsj, batch 706 (22706): perplexity: 80.8130, wsj_loss: 4.3921 ||
04/19 06:34:17 PM: Update 17984: task toronto_lm, batch 980 (17891): perplexity: 79.5050, toronto_lm_loss: 4.3758 ||
04/19 06:34:22 PM: Update 22722: task wsj, batch 722 (22722): perplexity: 80.7979, wsj_loss: 4.3920 ||
04/19 06:34:28 PM: Update 17998: task toronto_lm, batch 994 (17905): perplexity: 79.5237, toronto_lm_loss: 4.3761 ||
04/19 06:34:29 PM: ***** Pass 18000 / Epoch 18 *****
04/19 06:34:29 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 06:34:29 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 06:34:29 PM: Validating...
04/19 06:34:33 PM: Update 22738: task wsj, batch 738 (22738): perplexity: 80.7126, wsj_loss: 4.3909 ||
04/19 06:34:38 PM: Batch 33/140: perplexity: 98.1076, toronto_lm_loss: 4.5861 || , for evaluation data
04/19 06:34:43 PM: Update 22754: task wsj, batch 754 (22754): perplexity: 80.6877, wsj_loss: 4.3906 ||
04/19 06:34:48 PM: Batch 72/140: perplexity: 98.4390, toronto_lm_loss: 4.5894 || , for evaluation data
04/19 06:34:54 PM: Update 22770: task wsj, batch 770 (22770): perplexity: 80.5671, wsj_loss: 4.3891 ||
04/19 06:34:58 PM: Batch 111/140: perplexity: 92.7023, toronto_lm_loss: 4.5294 || , for evaluation data
04/19 06:35:04 PM: Update 22778: task wsj, batch 778 (22778): perplexity: 80.5111, wsj_loss: 4.3884 ||
04/19 06:35:06 PM: Batch 1/66: perplexity: 349.8648, wsj_loss: 5.8575 || , for evaluation data
04/19 06:35:15 PM: Update 22794: task wsj, batch 794 (22794): perplexity: 80.5052, wsj_loss: 4.3883 ||
04/19 06:35:16 PM: Batch 40/66: perplexity: 248.0498, wsj_loss: 5.5136 || , for evaluation data
04/19 06:35:23 PM: Best model found for wsj.
04/19 06:35:23 PM: Best model found for micro.
04/19 06:35:23 PM: Best model found for macro.
04/19 06:35:23 PM: Advancing scheduler.
04/19 06:35:23 PM: 	Best macro_avg: 0.168
04/19 06:35:23 PM: 	# bad epochs: 0
04/19 06:35:23 PM: Statistic: toronto_lm_loss
04/19 06:35:23 PM: 	training: 4.376164
04/19 06:35:23 PM: 	validation: 4.486756
04/19 06:35:23 PM: Statistic: wsj_loss
04/19 06:35:23 PM: 	training: 5.418688
04/19 06:35:23 PM: 	validation: 5.507195
04/19 06:35:23 PM: Statistic: macro_avg
04/19 06:35:23 PM: 	validation: 0.168249
04/19 06:35:23 PM: Statistic: micro_avg
04/19 06:35:23 PM: 	validation: 0.004543
04/19 06:35:23 PM: Statistic: toronto_lm_perplexity
04/19 06:35:23 PM: 	training: 79.532331
04/19 06:35:23 PM: 	validation: 88.832827
04/19 06:35:23 PM: Statistic: wsj_perplexity
04/19 06:35:23 PM: 	training: 225.582869
04/19 06:35:23 PM: 	validation: 246.458901
04/19 06:35:23 PM: global_lr: 0.001000
04/19 06:35:23 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 06:35:24 PM: Update 18001: task toronto_lm, batch 1 (17908): perplexity: 74.5676, toronto_lm_loss: 4.3117 ||
04/19 06:35:25 PM: Update 22810: task wsj, batch 810 (22810): perplexity: 80.5773, wsj_loss: 4.3892 ||
04/19 06:35:34 PM: Update 18015: task toronto_lm, batch 15 (17922): perplexity: 76.8880, toronto_lm_loss: 4.3423 ||
04/19 06:35:36 PM: Update 22826: task wsj, batch 826 (22826): perplexity: 80.5571, wsj_loss: 4.3890 ||
04/19 06:35:45 PM: Update 18029: task toronto_lm, batch 29 (17936): perplexity: 79.0698, toronto_lm_loss: 4.3703 ||
04/19 06:35:46 PM: Update 22842: task wsj, batch 842 (22842): perplexity: 80.5510, wsj_loss: 4.3889 ||
04/19 06:35:55 PM: Update 18042: task toronto_lm, batch 42 (17949): perplexity: 79.8546, toronto_lm_loss: 4.3802 ||
04/19 06:35:56 PM: Update 22858: task wsj, batch 858 (22858): perplexity: 80.5811, wsj_loss: 4.3893 ||
04/19 06:36:06 PM: Update 18056: task toronto_lm, batch 56 (17963): perplexity: 80.1128, toronto_lm_loss: 4.3834 ||
04/19 06:36:07 PM: Update 22874: task wsj, batch 874 (22874): perplexity: 80.6228, wsj_loss: 4.3898 ||
04/19 06:36:16 PM: Update 18069: task toronto_lm, batch 69 (17976): perplexity: 79.6499, toronto_lm_loss: 4.3776 ||
04/19 06:36:17 PM: Update 22890: task wsj, batch 890 (22890): perplexity: 80.6651, wsj_loss: 4.3903 ||
04/19 06:36:26 PM: Update 18082: task toronto_lm, batch 82 (17989): perplexity: 80.3795, toronto_lm_loss: 4.3868 ||
04/19 06:36:28 PM: Update 22906: task wsj, batch 906 (22906): perplexity: 80.7163, wsj_loss: 4.3909 ||
04/19 06:36:36 PM: Update 18095: task toronto_lm, batch 95 (18002): perplexity: 80.3901, toronto_lm_loss: 4.3869 ||
04/19 06:36:38 PM: Update 22922: task wsj, batch 922 (22922): perplexity: 80.7441, wsj_loss: 4.3913 ||
04/19 06:36:46 PM: Update 18108: task toronto_lm, batch 108 (18015): perplexity: 80.7173, toronto_lm_loss: 4.3910 ||
04/19 06:36:51 PM: Update 22934: task wsj, batch 934 (22934): perplexity: 80.7627, wsj_loss: 4.3915 ||
04/19 06:36:57 PM: Update 18122: task toronto_lm, batch 122 (18029): perplexity: 80.2946, toronto_lm_loss: 4.3857 ||
04/19 06:37:02 PM: Update 22950: task wsj, batch 950 (22950): perplexity: 80.7404, wsj_loss: 4.3912 ||
04/19 06:37:07 PM: Update 18135: task toronto_lm, batch 135 (18042): perplexity: 79.9535, toronto_lm_loss: 4.3814 ||
04/19 06:37:12 PM: Update 22966: task wsj, batch 966 (22966): perplexity: 80.6271, wsj_loss: 4.3898 ||
04/19 06:37:18 PM: Update 18149: task toronto_lm, batch 149 (18056): perplexity: 79.4600, toronto_lm_loss: 4.3753 ||
04/19 06:37:22 PM: Update 22982: task wsj, batch 982 (22982): perplexity: 80.5729, wsj_loss: 4.3892 ||
04/19 06:37:28 PM: Update 18162: task toronto_lm, batch 162 (18069): perplexity: 79.3309, toronto_lm_loss: 4.3736 ||
04/19 06:37:33 PM: Update 22998: task wsj, batch 998 (22998): perplexity: 80.5235, wsj_loss: 4.3885 ||
04/19 06:37:34 PM: ***** Pass 23000 / Epoch 23 *****
04/19 06:37:34 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 06:37:34 PM: Validating...
04/19 06:37:38 PM: Update 18175: task toronto_lm, batch 175 (18082): perplexity: 79.5887, toronto_lm_loss: 4.3769 ||
04/19 06:37:39 PM: Advancing scheduler.
04/19 06:37:39 PM: 	Best macro_avg: 101.271
04/19 06:37:39 PM: 	# bad epochs: 2
04/19 06:37:39 PM: Statistic: wsj_loss
04/19 06:37:39 PM: 	training: 4.388593
04/19 06:37:39 PM: 	validation: 4.625188
04/19 06:37:39 PM: Statistic: macro_avg
04/19 06:37:39 PM: 	validation: 102.021964
04/19 06:37:39 PM: Statistic: micro_avg
04/19 06:37:39 PM: 	validation: 102.021964
04/19 06:37:39 PM: Statistic: wsj_perplexity
04/19 06:37:39 PM: 	training: 80.527000
04/19 06:37:39 PM: 	validation: 102.021964
04/19 06:37:39 PM: global_lr: 0.003000
04/19 06:37:40 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 06:37:43 PM: Update 23005: task wsj, batch 5 (23005): perplexity: 80.7949, wsj_loss: 4.3919 ||
04/19 06:37:48 PM: Update 18188: task toronto_lm, batch 188 (18095): perplexity: 79.2958, toronto_lm_loss: 4.3732 ||
04/19 06:37:53 PM: Update 23021: task wsj, batch 21 (23021): perplexity: 81.2635, wsj_loss: 4.3977 ||
04/19 06:37:58 PM: Update 18201: task toronto_lm, batch 201 (18108): perplexity: 79.1580, toronto_lm_loss: 4.3714 ||
04/19 06:38:04 PM: Update 23037: task wsj, batch 37 (23037): perplexity: 78.7562, wsj_loss: 4.3664 ||
04/19 06:38:08 PM: Update 18214: task toronto_lm, batch 214 (18121): perplexity: 79.0725, toronto_lm_loss: 4.3704 ||
04/19 06:38:14 PM: Update 23053: task wsj, batch 53 (23053): perplexity: 78.3153, wsj_loss: 4.3607 ||
04/19 06:38:20 PM: Update 18219: task toronto_lm, batch 219 (18126): perplexity: 78.8798, toronto_lm_loss: 4.3679 ||
04/19 06:38:30 PM: Update 23069: task wsj, batch 69 (23069): perplexity: 78.3981, wsj_loss: 4.3618 ||
04/19 06:38:30 PM: Update 18232: task toronto_lm, batch 232 (18139): perplexity: 79.2092, toronto_lm_loss: 4.3721 ||
04/19 06:38:40 PM: Update 23085: task wsj, batch 85 (23085): perplexity: 79.4176, wsj_loss: 4.3747 ||
04/19 06:38:40 PM: Update 18245: task toronto_lm, batch 245 (18152): perplexity: 79.0621, toronto_lm_loss: 4.3702 ||
04/19 06:38:50 PM: Update 18258: task toronto_lm, batch 258 (18165): perplexity: 78.7338, toronto_lm_loss: 4.3661 ||
04/19 06:38:50 PM: Update 23101: task wsj, batch 101 (23101): perplexity: 79.9200, wsj_loss: 4.3810 ||
04/19 06:39:00 PM: Update 18271: task toronto_lm, batch 271 (18178): perplexity: 78.3533, toronto_lm_loss: 4.3612 ||
04/19 06:39:01 PM: Update 23117: task wsj, batch 117 (23117): perplexity: 79.6897, wsj_loss: 4.3781 ||
04/19 06:39:10 PM: Update 18284: task toronto_lm, batch 284 (18191): perplexity: 78.1120, toronto_lm_loss: 4.3581 ||
04/19 06:39:11 PM: Update 23133: task wsj, batch 133 (23133): perplexity: 80.2256, wsj_loss: 4.3848 ||
04/19 06:39:21 PM: Update 18298: task toronto_lm, batch 298 (18205): perplexity: 77.6808, toronto_lm_loss: 4.3526 ||
04/19 06:39:21 PM: Update 23149: task wsj, batch 149 (23149): perplexity: 80.0317, wsj_loss: 4.3824 ||
04/19 06:39:31 PM: Update 18311: task toronto_lm, batch 311 (18218): perplexity: 77.2617, toronto_lm_loss: 4.3472 ||
04/19 06:39:32 PM: Update 23165: task wsj, batch 165 (23165): perplexity: 80.2104, wsj_loss: 4.3847 ||
04/19 06:39:41 PM: Update 18324: task toronto_lm, batch 324 (18231): perplexity: 76.9216, toronto_lm_loss: 4.3428 ||
04/19 06:39:42 PM: Update 23181: task wsj, batch 181 (23181): perplexity: 80.5451, wsj_loss: 4.3888 ||
04/19 06:39:51 PM: Update 18337: task toronto_lm, batch 337 (18244): perplexity: 76.6714, toronto_lm_loss: 4.3395 ||
04/19 06:39:52 PM: Update 18338: task wsj, batch 1 (94): perplexity: 224.1020, wsj_loss: 5.4121 ||
04/19 06:39:52 PM: Update 23197: task wsj, batch 197 (23197): perplexity: 80.5198, wsj_loss: 4.3885 ||
04/19 06:40:01 PM: Update 18350: task toronto_lm, batch 349 (18256): perplexity: 76.2564, toronto_lm_loss: 4.3341 ||
04/19 06:40:03 PM: Update 23213: task wsj, batch 213 (23213): perplexity: 80.6844, wsj_loss: 4.3905 ||
04/19 06:40:11 PM: Update 18363: task toronto_lm, batch 362 (18269): perplexity: 75.8141, toronto_lm_loss: 4.3283 ||
04/19 06:40:16 PM: Update 23226: task wsj, batch 226 (23226): perplexity: 80.8329, wsj_loss: 4.3924 ||
04/19 06:40:21 PM: Update 18376: task toronto_lm, batch 375 (18282): perplexity: 75.4823, toronto_lm_loss: 4.3239 ||
04/19 06:40:26 PM: Update 23242: task wsj, batch 242 (23242): perplexity: 80.4714, wsj_loss: 4.3879 ||
04/19 06:40:32 PM: Update 18389: task toronto_lm, batch 388 (18295): perplexity: 74.9991, toronto_lm_loss: 4.3175 ||
04/19 06:40:37 PM: Update 23258: task wsj, batch 258 (23258): perplexity: 80.1160, wsj_loss: 4.3835 ||
04/19 06:40:42 PM: Update 18402: task toronto_lm, batch 401 (18308): perplexity: 74.5785, toronto_lm_loss: 4.3119 ||
04/19 06:40:47 PM: Update 23274: task wsj, batch 274 (23274): perplexity: 79.9804, wsj_loss: 4.3818 ||
04/19 06:40:52 PM: Update 18415: task toronto_lm, batch 414 (18321): perplexity: 74.1716, toronto_lm_loss: 4.3064 ||
04/19 06:40:58 PM: Update 23290: task wsj, batch 290 (23290): perplexity: 79.9647, wsj_loss: 4.3816 ||
04/19 06:41:02 PM: Update 18428: task toronto_lm, batch 427 (18334): perplexity: 73.8762, toronto_lm_loss: 4.3024 ||
04/19 06:41:08 PM: Update 23306: task wsj, batch 306 (23306): perplexity: 79.6875, wsj_loss: 4.3781 ||
04/19 06:41:12 PM: Update 18441: task toronto_lm, batch 440 (18347): perplexity: 73.6666, toronto_lm_loss: 4.2995 ||
04/19 06:41:18 PM: Update 23322: task wsj, batch 322 (23322): perplexity: 79.6838, wsj_loss: 4.3781 ||
04/19 06:41:22 PM: Update 18454: task toronto_lm, batch 453 (18360): perplexity: 73.2951, toronto_lm_loss: 4.2945 ||
04/19 06:41:29 PM: Update 23338: task wsj, batch 338 (23338): perplexity: 79.6676, wsj_loss: 4.3779 ||
04/19 06:41:32 PM: Update 18467: task toronto_lm, batch 466 (18373): perplexity: 73.0582, toronto_lm_loss: 4.2913 ||
04/19 06:41:39 PM: Update 23354: task wsj, batch 354 (23354): perplexity: 79.5146, wsj_loss: 4.3759 ||
04/19 06:41:42 PM: Update 18480: task toronto_lm, batch 479 (18386): perplexity: 72.6976, toronto_lm_loss: 4.2863 ||
04/19 06:41:49 PM: Update 23361: task wsj, batch 361 (23361): perplexity: 79.4982, wsj_loss: 4.3757 ||
04/19 06:41:52 PM: Update 18493: task toronto_lm, batch 492 (18399): perplexity: 72.4033, toronto_lm_loss: 4.2823 ||
04/19 06:42:00 PM: Update 23377: task wsj, batch 377 (23377): perplexity: 79.4567, wsj_loss: 4.3752 ||
04/19 06:42:02 PM: Update 18506: task toronto_lm, batch 505 (18412): perplexity: 72.1795, toronto_lm_loss: 4.2792 ||
04/19 06:42:04 PM: Update 18508: task wsj, batch 2 (95): perplexity: 218.9645, wsj_loss: 5.3889 ||
04/19 06:42:10 PM: Update 23393: task wsj, batch 393 (23393): perplexity: 79.5113, wsj_loss: 4.3759 ||
04/19 06:42:12 PM: Update 18519: task toronto_lm, batch 517 (18424): perplexity: 71.9361, toronto_lm_loss: 4.2758 ||
04/19 06:42:20 PM: Update 23409: task wsj, batch 409 (23409): perplexity: 79.6087, wsj_loss: 4.3771 ||
04/19 06:42:22 PM: Update 18532: task toronto_lm, batch 530 (18437): perplexity: 71.6303, toronto_lm_loss: 4.2715 ||
04/19 06:42:31 PM: Update 23425: task wsj, batch 425 (23425): perplexity: 79.8264, wsj_loss: 4.3799 ||
04/19 06:42:33 PM: Update 18546: task toronto_lm, batch 544 (18451): perplexity: 71.3263, toronto_lm_loss: 4.2673 ||
04/19 06:42:41 PM: Update 23441: task wsj, batch 441 (23441): perplexity: 79.8175, wsj_loss: 4.3797 ||
04/19 06:42:43 PM: Update 18559: task toronto_lm, batch 557 (18464): perplexity: 71.0446, toronto_lm_loss: 4.2633 ||
04/19 06:42:52 PM: Update 23457: task wsj, batch 457 (23457): perplexity: 79.9133, wsj_loss: 4.3809 ||
04/19 06:42:53 PM: Update 18572: task toronto_lm, batch 570 (18477): perplexity: 70.8134, toronto_lm_loss: 4.2600 ||
04/19 06:43:02 PM: Update 23473: task wsj, batch 473 (23473): perplexity: 79.9084, wsj_loss: 4.3809 ||
04/19 06:43:04 PM: Update 18586: task toronto_lm, batch 584 (18491): perplexity: 70.5838, toronto_lm_loss: 4.2568 ||
04/19 06:43:12 PM: Update 23489: task wsj, batch 489 (23489): perplexity: 79.9490, wsj_loss: 4.3814 ||
04/19 06:43:15 PM: Update 18600: task toronto_lm, batch 598 (18505): perplexity: 70.3303, toronto_lm_loss: 4.2532 ||
04/19 06:43:23 PM: Update 23505: task wsj, batch 505 (23505): perplexity: 80.0193, wsj_loss: 4.3823 ||
04/19 06:43:25 PM: Update 18613: task toronto_lm, batch 611 (18518): perplexity: 70.1195, toronto_lm_loss: 4.2502 ||
04/19 06:43:35 PM: Update 18627: task toronto_lm, batch 625 (18532): perplexity: 69.9964, toronto_lm_loss: 4.2484 ||
04/19 06:43:36 PM: Update 23518: task wsj, batch 518 (23518): perplexity: 80.1901, wsj_loss: 4.3844 ||
04/19 06:43:46 PM: Update 18641: task toronto_lm, batch 639 (18546): perplexity: 69.7697, toronto_lm_loss: 4.2452 ||
04/19 06:43:46 PM: Update 23534: task wsj, batch 534 (23534): perplexity: 80.2316, wsj_loss: 4.3849 ||
04/19 06:43:56 PM: Update 18654: task toronto_lm, batch 652 (18559): perplexity: 69.5856, toronto_lm_loss: 4.2426 ||
04/19 06:43:57 PM: Update 23550: task wsj, batch 550 (23550): perplexity: 80.1089, wsj_loss: 4.3834 ||
04/19 06:44:06 PM: Update 18667: task toronto_lm, batch 665 (18572): perplexity: 69.4549, toronto_lm_loss: 4.2407 ||
04/19 06:44:07 PM: Update 23566: task wsj, batch 566 (23566): perplexity: 79.9257, wsj_loss: 4.3811 ||
04/19 06:44:16 PM: Update 18680: task toronto_lm, batch 678 (18585): perplexity: 69.3207, toronto_lm_loss: 4.2387 ||
04/19 06:44:17 PM: Update 23582: task wsj, batch 582 (23582): perplexity: 79.8940, wsj_loss: 4.3807 ||
04/19 06:44:26 PM: Update 18693: task toronto_lm, batch 691 (18598): perplexity: 69.0692, toronto_lm_loss: 4.2351 ||
04/19 06:44:28 PM: Update 23598: task wsj, batch 598 (23598): perplexity: 79.8514, wsj_loss: 4.3802 ||
04/19 06:44:32 PM: Update 18701: task wsj, batch 3 (96): perplexity: 204.2169, wsj_loss: 5.3192 ||
04/19 06:44:37 PM: Update 18707: task toronto_lm, batch 704 (18611): perplexity: 68.9053, toronto_lm_loss: 4.2327 ||
04/19 06:44:38 PM: Update 23614: task wsj, batch 614 (23614): perplexity: 79.7699, wsj_loss: 4.3791 ||
04/19 06:44:47 PM: Update 18720: task toronto_lm, batch 717 (18624): perplexity: 68.6769, toronto_lm_loss: 4.2294 ||
04/19 06:44:49 PM: Update 23630: task wsj, batch 630 (23630): perplexity: 79.6738, wsj_loss: 4.3779 ||
04/19 06:44:57 PM: Update 18733: task toronto_lm, batch 730 (18637): perplexity: 68.5903, toronto_lm_loss: 4.2282 ||
04/19 06:44:59 PM: Update 23646: task wsj, batch 646 (23646): perplexity: 79.5964, wsj_loss: 4.3770 ||
04/19 06:45:08 PM: Update 18747: task toronto_lm, batch 744 (18651): perplexity: 68.3895, toronto_lm_loss: 4.2252 ||
04/19 06:45:09 PM: Update 23653: task wsj, batch 653 (23653): perplexity: 79.5538, wsj_loss: 4.3764 ||
04/19 06:45:18 PM: Update 18760: task toronto_lm, batch 757 (18664): perplexity: 68.1778, toronto_lm_loss: 4.2221 ||
04/19 06:45:20 PM: Update 23669: task wsj, batch 669 (23669): perplexity: 79.5744, wsj_loss: 4.3767 ||
04/19 06:45:28 PM: Update 18773: task toronto_lm, batch 770 (18677): perplexity: 68.0073, toronto_lm_loss: 4.2196 ||
04/19 06:45:30 PM: Update 23685: task wsj, batch 685 (23685): perplexity: 79.5919, wsj_loss: 4.3769 ||
04/19 06:45:38 PM: Update 18786: task toronto_lm, batch 783 (18690): perplexity: 67.8591, toronto_lm_loss: 4.2174 ||
04/19 06:45:41 PM: Update 23701: task wsj, batch 701 (23701): perplexity: 79.5782, wsj_loss: 4.3767 ||
04/19 06:45:49 PM: Update 18800: task toronto_lm, batch 797 (18704): perplexity: 67.7270, toronto_lm_loss: 4.2155 ||
04/19 06:45:51 PM: Update 23717: task wsj, batch 717 (23717): perplexity: 79.6341, wsj_loss: 4.3774 ||
04/19 06:46:00 PM: Update 18814: task toronto_lm, batch 811 (18718): perplexity: 67.6448, toronto_lm_loss: 4.2143 ||
04/19 06:46:02 PM: Update 23733: task wsj, batch 733 (23733): perplexity: 79.6993, wsj_loss: 4.3783 ||
04/19 06:46:10 PM: Update 18827: task toronto_lm, batch 824 (18731): perplexity: 67.4710, toronto_lm_loss: 4.2117 ||
04/19 06:46:12 PM: Update 23749: task wsj, batch 749 (23749): perplexity: 79.7701, wsj_loss: 4.3791 ||
04/19 06:46:20 PM: Update 18840: task toronto_lm, batch 837 (18744): perplexity: 67.3285, toronto_lm_loss: 4.2096 ||
04/19 06:46:23 PM: Update 23765: task wsj, batch 765 (23765): perplexity: 79.8164, wsj_loss: 4.3797 ||
04/19 06:46:33 PM: Update 23781: task wsj, batch 781 (23781): perplexity: 79.8599, wsj_loss: 4.3803 ||
04/19 06:46:33 PM: Update 18847: task toronto_lm, batch 844 (18751): perplexity: 67.3067, toronto_lm_loss: 4.2093 ||
04/19 06:46:38 PM: Update 18853: task wsj, batch 4 (97): perplexity: 227.7295, wsj_loss: 5.4282 ||
04/19 06:46:43 PM: Update 23797: task wsj, batch 797 (23797): perplexity: 79.8758, wsj_loss: 4.3805 ||
04/19 06:46:43 PM: Update 18860: task toronto_lm, batch 856 (18763): perplexity: 67.6284, toronto_lm_loss: 4.2140 ||
04/19 06:46:54 PM: Update 18873: task toronto_lm, batch 869 (18776): perplexity: 67.9048, toronto_lm_loss: 4.2181 ||
04/19 06:46:57 PM: Update 23810: task wsj, batch 810 (23810): perplexity: 79.8839, wsj_loss: 4.3806 ||
04/19 06:47:04 PM: Update 18886: task toronto_lm, batch 882 (18789): perplexity: 68.1777, toronto_lm_loss: 4.2221 ||
04/19 06:47:07 PM: Update 23826: task wsj, batch 826 (23826): perplexity: 79.8606, wsj_loss: 4.3803 ||
04/19 06:47:14 PM: Update 18899: task toronto_lm, batch 895 (18802): perplexity: 68.4443, toronto_lm_loss: 4.2260 ||
04/19 06:47:18 PM: Update 23842: task wsj, batch 842 (23842): perplexity: 79.8587, wsj_loss: 4.3803 ||
04/19 06:47:24 PM: Update 18913: task toronto_lm, batch 909 (18816): perplexity: 68.6162, toronto_lm_loss: 4.2285 ||
04/19 06:47:28 PM: Update 23858: task wsj, batch 858 (23858): perplexity: 79.8011, wsj_loss: 4.3795 ||
04/19 06:47:34 PM: Update 18926: task toronto_lm, batch 922 (18829): perplexity: 68.7959, toronto_lm_loss: 4.2311 ||
04/19 06:47:39 PM: Update 23874: task wsj, batch 874 (23874): perplexity: 79.7415, wsj_loss: 4.3788 ||
04/19 06:47:44 PM: Update 18939: task toronto_lm, batch 935 (18842): perplexity: 68.9613, toronto_lm_loss: 4.2335 ||
04/19 06:47:49 PM: Update 23890: task wsj, batch 890 (23890): perplexity: 79.6526, wsj_loss: 4.3777 ||
04/19 06:47:55 PM: Update 18953: task toronto_lm, batch 949 (18856): perplexity: 69.0572, toronto_lm_loss: 4.2349 ||
04/19 06:48:00 PM: Update 23906: task wsj, batch 906 (23906): perplexity: 79.5771, wsj_loss: 4.3767 ||
04/19 06:48:05 PM: Update 18966: task toronto_lm, batch 962 (18869): perplexity: 69.1575, toronto_lm_loss: 4.2364 ||
04/19 06:48:10 PM: Update 23922: task wsj, batch 922 (23922): perplexity: 79.4888, wsj_loss: 4.3756 ||
04/19 06:48:15 PM: Update 18979: task toronto_lm, batch 975 (18882): perplexity: 69.2884, toronto_lm_loss: 4.2383 ||
04/19 06:48:21 PM: Update 23938: task wsj, batch 938 (23938): perplexity: 79.4389, wsj_loss: 4.3750 ||
04/19 06:48:25 PM: Update 18992: task toronto_lm, batch 988 (18895): perplexity: 69.3718, toronto_lm_loss: 4.2395 ||
04/19 06:48:31 PM: Update 23945: task wsj, batch 945 (23945): perplexity: 79.4168, wsj_loss: 4.3747 ||
04/19 06:48:31 PM: ***** Pass 19000 / Epoch 19 *****
04/19 06:48:31 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 06:48:31 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 06:48:31 PM: Validating...
04/19 06:48:36 PM: Batch 16/140: perplexity: 97.2254, toronto_lm_loss: 4.5770 || , for evaluation data
04/19 06:48:41 PM: Update 23961: task wsj, batch 961 (23961): perplexity: 79.4958, wsj_loss: 4.3757 ||
04/19 06:48:46 PM: Batch 55/140: perplexity: 99.0026, toronto_lm_loss: 4.5951 || , for evaluation data
04/19 06:48:51 PM: Update 23977: task wsj, batch 977 (23977): perplexity: 79.4431, wsj_loss: 4.3750 ||
04/19 06:48:56 PM: Batch 94/140: perplexity: 91.8757, toronto_lm_loss: 4.5204 || , for evaluation data
04/19 06:49:02 PM: Update 23993: task wsj, batch 993 (23993): perplexity: 79.4657, wsj_loss: 4.3753 ||
04/19 06:49:06 PM: Batch 133/140: perplexity: 85.4945, toronto_lm_loss: 4.4485 || , for evaluation data
04/19 06:49:07 PM: ***** Pass 24000 / Epoch 24 *****
04/19 06:49:07 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 06:49:07 PM: Validating...
04/19 06:49:08 PM: Batch 1/66: perplexity: 357.7574, wsj_loss: 5.8799 || , for evaluation data
04/19 06:49:12 PM: Batch 24/24: perplexity: 102.0107, wsj_loss: 4.6251 || , for evaluation data
04/19 06:49:12 PM: Advancing scheduler.
04/19 06:49:12 PM: 	Best macro_avg: 101.271
04/19 06:49:12 PM: 	# bad epochs: 3
04/19 06:49:12 PM: Statistic: wsj_loss
04/19 06:49:12 PM: 	training: 4.375321
04/19 06:49:12 PM: 	validation: 4.625078
04/19 06:49:12 PM: Statistic: macro_avg
04/19 06:49:12 PM: 	validation: 102.010724
04/19 06:49:12 PM: Statistic: micro_avg
04/19 06:49:12 PM: 	validation: 102.010724
04/19 06:49:12 PM: Statistic: wsj_perplexity
04/19 06:49:12 PM: 	training: 79.465324
04/19 06:49:12 PM: 	validation: 102.010724
04/19 06:49:12 PM: global_lr: 0.003000
04/19 06:49:13 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 06:49:18 PM: Batch 39/66: perplexity: 261.1442, wsj_loss: 5.5651 || , for evaluation data
04/19 06:49:23 PM: Update 24015: task wsj, batch 15 (24015): perplexity: 81.6536, wsj_loss: 4.4025 ||
04/19 06:49:25 PM: Advancing scheduler.
04/19 06:49:25 PM: 	Best macro_avg: 0.168
04/19 06:49:25 PM: 	# bad epochs: 1
04/19 06:49:25 PM: Statistic: toronto_lm_loss
04/19 06:49:25 PM: 	training: 4.240470
04/19 06:49:25 PM: 	validation: 4.435591
04/19 06:49:25 PM: Statistic: wsj_loss
04/19 06:49:25 PM: 	training: 5.428158
04/19 06:49:25 PM: 	validation: 5.542301
04/19 06:49:25 PM: Statistic: macro_avg
04/19 06:49:25 PM: 	validation: 0.155069
04/19 06:49:25 PM: Statistic: micro_avg
04/19 06:49:25 PM: 	validation: -0.006747
04/19 06:49:25 PM: Statistic: toronto_lm_perplexity
04/19 06:49:25 PM: 	training: 69.440455
04/19 06:49:25 PM: 	validation: 84.402016
04/19 06:49:25 PM: Statistic: wsj_perplexity
04/19 06:49:25 PM: 	training: 227.729473
04/19 06:49:25 PM: 	validation: 255.264730
04/19 06:49:25 PM: global_lr: 0.001000
04/19 06:49:25 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 06:49:26 PM: Update 19001: task toronto_lm, batch 1 (18904): perplexity: 73.0980, toronto_lm_loss: 4.2918 ||
04/19 06:49:33 PM: Update 24031: task wsj, batch 31 (24031): perplexity: 80.7117, wsj_loss: 4.3909 ||
04/19 06:49:37 PM: Update 19015: task toronto_lm, batch 15 (18918): perplexity: 74.1590, toronto_lm_loss: 4.3062 ||
04/19 06:49:44 PM: Update 24047: task wsj, batch 47 (24047): perplexity: 80.9929, wsj_loss: 4.3944 ||
04/19 06:49:47 PM: Update 19029: task toronto_lm, batch 29 (18932): perplexity: 73.8738, toronto_lm_loss: 4.3024 ||
04/19 06:49:54 PM: Update 24063: task wsj, batch 63 (24063): perplexity: 81.4167, wsj_loss: 4.3996 ||
04/19 06:49:58 PM: Update 19042: task toronto_lm, batch 42 (18945): perplexity: 74.2641, toronto_lm_loss: 4.3076 ||
04/19 06:50:05 PM: Update 24079: task wsj, batch 79 (24079): perplexity: 81.7431, wsj_loss: 4.4036 ||
04/19 06:50:08 PM: Update 19055: task toronto_lm, batch 55 (18958): perplexity: 73.5164, toronto_lm_loss: 4.2975 ||
04/19 06:50:15 PM: Update 24095: task wsj, batch 95 (24095): perplexity: 81.2461, wsj_loss: 4.3975 ||
04/19 06:50:18 PM: Update 19068: task toronto_lm, batch 68 (18971): perplexity: 73.8173, toronto_lm_loss: 4.3016 ||
04/19 06:50:25 PM: Update 24102: task wsj, batch 102 (24102): perplexity: 80.9226, wsj_loss: 4.3935 ||
04/19 06:50:28 PM: Update 19081: task toronto_lm, batch 81 (18984): perplexity: 73.6241, toronto_lm_loss: 4.2990 ||
04/19 06:50:35 PM: Update 19090: task wsj, batch 1 (98): perplexity: 240.0840, wsj_loss: 5.4810 ||
04/19 06:50:36 PM: Update 24118: task wsj, batch 118 (24118): perplexity: 80.4043, wsj_loss: 4.3871 ||
04/19 06:50:38 PM: Update 19095: task toronto_lm, batch 94 (18997): perplexity: 74.1171, toronto_lm_loss: 4.3056 ||
04/19 06:50:46 PM: Update 24134: task wsj, batch 134 (24134): perplexity: 79.8812, wsj_loss: 4.3805 ||
04/19 06:50:48 PM: Update 19108: task toronto_lm, batch 107 (19010): perplexity: 73.6814, toronto_lm_loss: 4.2997 ||
04/19 06:50:57 PM: Update 24150: task wsj, batch 150 (24150): perplexity: 79.2668, wsj_loss: 4.3728 ||
04/19 06:50:59 PM: Update 19121: task toronto_lm, batch 120 (19023): perplexity: 73.4576, toronto_lm_loss: 4.2967 ||
04/19 06:51:07 PM: Update 24166: task wsj, batch 166 (24166): perplexity: 79.0430, wsj_loss: 4.3700 ||
04/19 06:51:09 PM: Update 19135: task toronto_lm, batch 134 (19037): perplexity: 73.2107, toronto_lm_loss: 4.2933 ||
04/19 06:51:17 PM: Update 24182: task wsj, batch 182 (24182): perplexity: 78.9115, wsj_loss: 4.3683 ||
04/19 06:51:20 PM: Update 19149: task toronto_lm, batch 148 (19051): perplexity: 73.4461, toronto_lm_loss: 4.2966 ||
04/19 06:51:28 PM: Update 24198: task wsj, batch 198 (24198): perplexity: 78.6224, wsj_loss: 4.3647 ||
04/19 06:51:31 PM: Update 19163: task toronto_lm, batch 162 (19065): perplexity: 73.1210, toronto_lm_loss: 4.2921 ||
04/19 06:51:38 PM: Update 24214: task wsj, batch 214 (24214): perplexity: 78.6345, wsj_loss: 4.3648 ||
04/19 06:51:42 PM: Update 19177: task toronto_lm, batch 176 (19079): perplexity: 73.0744, toronto_lm_loss: 4.2915 ||
04/19 06:51:49 PM: Update 24230: task wsj, batch 230 (24230): perplexity: 78.6284, wsj_loss: 4.3647 ||
04/19 06:51:52 PM: Update 19191: task toronto_lm, batch 190 (19093): perplexity: 72.6039, toronto_lm_loss: 4.2850 ||
04/19 06:51:59 PM: Update 24237: task wsj, batch 237 (24237): perplexity: 78.5743, wsj_loss: 4.3640 ||
04/19 06:52:03 PM: Update 19205: task toronto_lm, batch 204 (19107): perplexity: 72.5559, toronto_lm_loss: 4.2844 ||
04/19 06:52:10 PM: Update 24253: task wsj, batch 253 (24253): perplexity: 78.4727, wsj_loss: 4.3628 ||
04/19 06:52:13 PM: Update 19218: task toronto_lm, batch 217 (19120): perplexity: 72.1605, toronto_lm_loss: 4.2789 ||
04/19 06:52:20 PM: Update 24269: task wsj, batch 269 (24269): perplexity: 78.6390, wsj_loss: 4.3649 ||
04/19 06:52:24 PM: Update 19232: task toronto_lm, batch 231 (19134): perplexity: 71.8098, toronto_lm_loss: 4.2740 ||
04/19 06:52:30 PM: Update 24285: task wsj, batch 285 (24285): perplexity: 78.5861, wsj_loss: 4.3642 ||
04/19 06:52:34 PM: Update 19245: task toronto_lm, batch 244 (19147): perplexity: 71.7614, toronto_lm_loss: 4.2733 ||
04/19 06:52:41 PM: Update 24301: task wsj, batch 301 (24301): perplexity: 78.6445, wsj_loss: 4.3649 ||
04/19 06:52:45 PM: Update 19259: task toronto_lm, batch 258 (19161): perplexity: 71.6492, toronto_lm_loss: 4.2718 ||
04/19 06:52:51 PM: Update 24317: task wsj, batch 317 (24317): perplexity: 78.5897, wsj_loss: 4.3642 ||
04/19 06:52:55 PM: Update 19273: task toronto_lm, batch 272 (19175): perplexity: 71.3349, toronto_lm_loss: 4.2674 ||
04/19 06:53:02 PM: Update 24333: task wsj, batch 333 (24333): perplexity: 78.5368, wsj_loss: 4.3636 ||
04/19 06:53:05 PM: Update 19286: task toronto_lm, batch 285 (19188): perplexity: 71.2793, toronto_lm_loss: 4.2666 ||
04/19 06:53:12 PM: Update 24349: task wsj, batch 349 (24349): perplexity: 78.7393, wsj_loss: 4.3661 ||
04/19 06:53:16 PM: Update 19300: task toronto_lm, batch 299 (19202): perplexity: 70.9525, toronto_lm_loss: 4.2620 ||
04/19 06:53:23 PM: Update 24365: task wsj, batch 365 (24365): perplexity: 78.8934, wsj_loss: 4.3681 ||
04/19 06:53:27 PM: Update 19314: task toronto_lm, batch 313 (19216): perplexity: 70.6936, toronto_lm_loss: 4.2584 ||
04/19 06:53:33 PM: Update 24381: task wsj, batch 381 (24381): perplexity: 79.0473, wsj_loss: 4.3700 ||
04/19 06:53:37 PM: Update 19328: task toronto_lm, batch 327 (19230): perplexity: 70.7074, toronto_lm_loss: 4.2586 ||
04/19 06:53:47 PM: Update 24394: task wsj, batch 394 (24394): perplexity: 79.3033, wsj_loss: 4.3733 ||
04/19 06:53:47 PM: Update 19341: task toronto_lm, batch 340 (19243): perplexity: 70.6972, toronto_lm_loss: 4.2584 ||
04/19 06:53:58 PM: Update 24410: task wsj, batch 410 (24410): perplexity: 79.2593, wsj_loss: 4.3727 ||
04/19 06:53:58 PM: Update 19355: task toronto_lm, batch 354 (19257): perplexity: 70.7990, toronto_lm_loss: 4.2598 ||
04/19 06:54:08 PM: Update 24426: task wsj, batch 426 (24426): perplexity: 79.0590, wsj_loss: 4.3702 ||
04/19 06:54:09 PM: Update 19369: task toronto_lm, batch 368 (19271): perplexity: 70.9725, toronto_lm_loss: 4.2623 ||
04/19 06:54:18 PM: Update 24442: task wsj, batch 442 (24442): perplexity: 79.0817, wsj_loss: 4.3705 ||
04/19 06:54:20 PM: Update 19383: task wsj, batch 2 (99): perplexity: 239.5515, wsj_loss: 5.4788 ||
04/19 06:54:20 PM: Update 19384: task toronto_lm, batch 382 (19285): perplexity: 70.8764, toronto_lm_loss: 4.2609 ||
04/19 06:54:29 PM: Update 24458: task wsj, batch 458 (24458): perplexity: 78.8891, wsj_loss: 4.3680 ||
04/19 06:54:30 PM: Update 19397: task toronto_lm, batch 395 (19298): perplexity: 70.6407, toronto_lm_loss: 4.2576 ||
04/19 06:54:39 PM: Update 24474: task wsj, batch 474 (24474): perplexity: 78.7715, wsj_loss: 4.3666 ||
04/19 06:54:41 PM: Update 19411: task toronto_lm, batch 409 (19312): perplexity: 70.8053, toronto_lm_loss: 4.2599 ||
04/19 06:54:50 PM: Update 24490: task wsj, batch 490 (24490): perplexity: 78.7854, wsj_loss: 4.3667 ||
04/19 06:54:52 PM: Update 19425: task toronto_lm, batch 423 (19326): perplexity: 70.6145, toronto_lm_loss: 4.2572 ||
04/19 06:55:00 PM: Update 24506: task wsj, batch 506 (24506): perplexity: 78.5500, wsj_loss: 4.3637 ||
04/19 06:55:02 PM: Update 19438: task toronto_lm, batch 436 (19339): perplexity: 70.4838, toronto_lm_loss: 4.2554 ||
04/19 06:55:11 PM: Update 24522: task wsj, batch 522 (24522): perplexity: 78.5383, wsj_loss: 4.3636 ||
04/19 06:55:12 PM: Update 19451: task toronto_lm, batch 449 (19352): perplexity: 70.3238, toronto_lm_loss: 4.2531 ||
04/19 06:55:21 PM: Update 24530: task wsj, batch 530 (24530): perplexity: 78.4874, wsj_loss: 4.3629 ||
04/19 06:55:22 PM: Update 19464: task toronto_lm, batch 462 (19365): perplexity: 70.2614, toronto_lm_loss: 4.2522 ||
04/19 06:55:32 PM: Update 24546: task wsj, batch 546 (24546): perplexity: 78.5073, wsj_loss: 4.3632 ||
04/19 06:55:39 PM: Update 19475: task toronto_lm, batch 473 (19376): perplexity: 70.2991, toronto_lm_loss: 4.2528 ||
04/19 06:55:42 PM: Update 24562: task wsj, batch 562 (24562): perplexity: 78.5233, wsj_loss: 4.3634 ||
04/19 06:55:50 PM: Update 19489: task toronto_lm, batch 487 (19390): perplexity: 71.1468, toronto_lm_loss: 4.2647 ||
04/19 06:55:53 PM: Update 24578: task wsj, batch 578 (24578): perplexity: 78.4051, wsj_loss: 4.3619 ||
04/19 06:56:00 PM: Update 19502: task toronto_lm, batch 500 (19403): perplexity: 71.8502, toronto_lm_loss: 4.2746 ||
04/19 06:56:03 PM: Update 24594: task wsj, batch 594 (24594): perplexity: 78.4583, wsj_loss: 4.3626 ||
04/19 06:56:10 PM: Update 19516: task wsj, batch 3 (100): perplexity: 236.9780, wsj_loss: 5.4680 ||
04/19 06:56:11 PM: Update 19517: task toronto_lm, batch 514 (19417): perplexity: 72.4078, toronto_lm_loss: 4.2823 ||
04/19 06:56:13 PM: Update 24610: task wsj, batch 610 (24610): perplexity: 78.4777, wsj_loss: 4.3628 ||
04/19 06:56:21 PM: Update 19530: task toronto_lm, batch 527 (19430): perplexity: 72.7676, toronto_lm_loss: 4.2873 ||
04/19 06:56:24 PM: Update 24626: task wsj, batch 626 (24626): perplexity: 78.6227, wsj_loss: 4.3647 ||
04/19 06:56:31 PM: Update 19543: task toronto_lm, batch 540 (19443): perplexity: 73.1835, toronto_lm_loss: 4.2930 ||
04/19 06:56:34 PM: Update 24642: task wsj, batch 642 (24642): perplexity: 78.7233, wsj_loss: 4.3659 ||
04/19 06:56:42 PM: Update 19557: task toronto_lm, batch 554 (19457): perplexity: 73.4162, toronto_lm_loss: 4.2961 ||
04/19 06:56:45 PM: Update 24658: task wsj, batch 658 (24658): perplexity: 78.8125, wsj_loss: 4.3671 ||
04/19 06:56:53 PM: Update 19571: task toronto_lm, batch 568 (19471): perplexity: 73.6084, toronto_lm_loss: 4.2988 ||
04/19 06:56:55 PM: Update 24674: task wsj, batch 674 (24674): perplexity: 78.9107, wsj_loss: 4.3683 ||
04/19 06:57:03 PM: Update 19585: task toronto_lm, batch 582 (19485): perplexity: 73.8940, toronto_lm_loss: 4.3026 ||
04/19 06:57:09 PM: Update 24686: task wsj, batch 686 (24686): perplexity: 78.8872, wsj_loss: 4.3680 ||
04/19 06:57:14 PM: Update 19599: task toronto_lm, batch 596 (19499): perplexity: 74.1984, toronto_lm_loss: 4.3067 ||
04/19 06:57:19 PM: Update 24702: task wsj, batch 702 (24702): perplexity: 78.8601, wsj_loss: 4.3677 ||
04/19 06:57:24 PM: Update 19612: task toronto_lm, batch 609 (19512): perplexity: 74.4538, toronto_lm_loss: 4.3102 ||
04/19 06:57:30 PM: Update 24718: task wsj, batch 718 (24718): perplexity: 78.7548, wsj_loss: 4.3663 ||
04/19 06:57:35 PM: Update 19626: task toronto_lm, batch 623 (19526): perplexity: 74.5826, toronto_lm_loss: 4.3119 ||
04/19 06:57:37 PM: Update 19629: task wsj, batch 4 (101): perplexity: 239.6417, wsj_loss: 5.4791 ||
04/19 06:57:40 PM: Update 24734: task wsj, batch 734 (24734): perplexity: 78.6127, wsj_loss: 4.3645 ||
04/19 06:57:45 PM: Update 19639: task toronto_lm, batch 635 (19538): perplexity: 74.8035, toronto_lm_loss: 4.3149 ||
04/19 06:57:50 PM: Update 24750: task wsj, batch 750 (24750): perplexity: 78.5610, wsj_loss: 4.3639 ||
04/19 06:57:55 PM: Update 19652: task toronto_lm, batch 648 (19551): perplexity: 74.9279, toronto_lm_loss: 4.3165 ||
04/19 06:58:01 PM: Update 24766: task wsj, batch 766 (24766): perplexity: 78.5190, wsj_loss: 4.3633 ||
04/19 06:58:05 PM: Update 19665: task toronto_lm, batch 661 (19564): perplexity: 75.0533, toronto_lm_loss: 4.3182 ||
04/19 06:58:11 PM: Update 24782: task wsj, batch 782 (24782): perplexity: 78.4276, wsj_loss: 4.3622 ||
04/19 06:58:16 PM: Update 19679: task toronto_lm, batch 675 (19578): perplexity: 75.0825, toronto_lm_loss: 4.3186 ||
04/19 06:58:22 PM: Update 24798: task wsj, batch 798 (24798): perplexity: 78.3891, wsj_loss: 4.3617 ||
04/19 06:58:26 PM: Update 19692: task toronto_lm, batch 688 (19591): perplexity: 75.1694, toronto_lm_loss: 4.3197 ||
04/19 06:58:32 PM: Update 24814: task wsj, batch 814 (24814): perplexity: 78.4395, wsj_loss: 4.3623 ||
04/19 06:58:36 PM: Update 19705: task toronto_lm, batch 701 (19604): perplexity: 75.2379, toronto_lm_loss: 4.3207 ||
04/19 06:58:42 PM: Update 24822: task wsj, batch 822 (24822): perplexity: 78.4468, wsj_loss: 4.3624 ||
04/19 06:58:46 PM: Update 19718: task toronto_lm, batch 714 (19617): perplexity: 75.1883, toronto_lm_loss: 4.3200 ||
04/19 06:58:53 PM: Update 24838: task wsj, batch 838 (24838): perplexity: 78.4652, wsj_loss: 4.3627 ||
04/19 06:58:56 PM: Update 19731: task toronto_lm, batch 727 (19630): perplexity: 75.2153, toronto_lm_loss: 4.3204 ||
04/19 06:59:03 PM: Update 24854: task wsj, batch 854 (24854): perplexity: 78.4506, wsj_loss: 4.3625 ||
04/19 06:59:07 PM: Update 19745: task toronto_lm, batch 741 (19644): perplexity: 75.3618, toronto_lm_loss: 4.3223 ||
04/19 06:59:14 PM: Update 24870: task wsj, batch 870 (24870): perplexity: 78.5493, wsj_loss: 4.3637 ||
04/19 06:59:17 PM: Update 19758: task toronto_lm, batch 754 (19657): perplexity: 75.4009, toronto_lm_loss: 4.3228 ||
04/19 06:59:24 PM: Update 24886: task wsj, batch 886 (24886): perplexity: 78.6110, wsj_loss: 4.3645 ||
04/19 06:59:28 PM: Update 19772: task toronto_lm, batch 768 (19671): perplexity: 75.4013, toronto_lm_loss: 4.3228 ||
04/19 06:59:35 PM: Update 24902: task wsj, batch 902 (24902): perplexity: 78.6365, wsj_loss: 4.3648 ||
04/19 06:59:38 PM: Update 19786: task toronto_lm, batch 782 (19685): perplexity: 75.5103, toronto_lm_loss: 4.3243 ||
04/19 06:59:45 PM: Update 24918: task wsj, batch 918 (24918): perplexity: 78.6394, wsj_loss: 4.3649 ||
04/19 06:59:46 PM: Update 19796: task wsj, batch 5 (102): perplexity: 248.2323, wsj_loss: 5.5144 ||
04/19 06:59:49 PM: Update 19800: task toronto_lm, batch 795 (19698): perplexity: 75.5298, toronto_lm_loss: 4.3245 ||
04/19 06:59:55 PM: Update 24934: task wsj, batch 934 (24934): perplexity: 78.6223, wsj_loss: 4.3647 ||
04/19 06:59:59 PM: Update 19813: task toronto_lm, batch 808 (19711): perplexity: 75.5642, toronto_lm_loss: 4.3250 ||
04/19 07:00:06 PM: Update 24950: task wsj, batch 950 (24950): perplexity: 78.6501, wsj_loss: 4.3650 ||
04/19 07:00:10 PM: Update 19827: task toronto_lm, batch 822 (19725): perplexity: 75.5855, toronto_lm_loss: 4.3253 ||
04/19 07:00:16 PM: Update 24966: task wsj, batch 966 (24966): perplexity: 78.6176, wsj_loss: 4.3646 ||
04/19 07:00:20 PM: Update 19840: task toronto_lm, batch 835 (19738): perplexity: 75.6899, toronto_lm_loss: 4.3266 ||
04/19 07:00:30 PM: Update 24978: task wsj, batch 978 (24978): perplexity: 78.6976, wsj_loss: 4.3656 ||
04/19 07:00:30 PM: Update 19853: task toronto_lm, batch 848 (19751): perplexity: 75.7634, toronto_lm_loss: 4.3276 ||
04/19 07:00:40 PM: Update 19866: task toronto_lm, batch 861 (19764): perplexity: 75.8019, toronto_lm_loss: 4.3281 ||
04/19 07:00:40 PM: Update 24994: task wsj, batch 994 (24994): perplexity: 78.6951, wsj_loss: 4.3656 ||
04/19 07:00:44 PM: ***** Pass 25000 / Epoch 25 *****
04/19 07:00:44 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 07:00:44 PM: Validating...
04/19 07:00:50 PM: Advancing scheduler.
04/19 07:00:50 PM: 	Best macro_avg: 101.271
04/19 07:00:50 PM: 	# bad epochs: 4
04/19 07:00:50 PM: Statistic: wsj_loss
04/19 07:00:50 PM: 	training: 4.365182
04/19 07:00:50 PM: 	validation: 4.639691
04/19 07:00:50 PM: Statistic: macro_avg
04/19 07:00:50 PM: 	validation: 103.512313
04/19 07:00:50 PM: Statistic: micro_avg
04/19 07:00:50 PM: 	validation: 103.512313
04/19 07:00:50 PM: Statistic: wsj_perplexity
04/19 07:00:50 PM: 	training: 78.663694
04/19 07:00:50 PM: 	validation: 103.512313
04/19 07:00:50 PM: global_lr: 0.003000
04/19 07:00:50 PM: Update 19879: task toronto_lm, batch 874 (19777): perplexity: 75.7838, toronto_lm_loss: 4.3279 ||
04/19 07:00:50 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 07:00:51 PM: Update 25001: task wsj, batch 1 (25001): perplexity: 82.8141, wsj_loss: 4.4166 ||
04/19 07:01:01 PM: Update 19893: task toronto_lm, batch 888 (19791): perplexity: 75.8616, toronto_lm_loss: 4.3289 ||
04/19 07:01:01 PM: Update 25017: task wsj, batch 17 (25017): perplexity: 78.4233, wsj_loss: 4.3621 ||
04/19 07:01:11 PM: Update 19906: task toronto_lm, batch 901 (19804): perplexity: 75.8294, toronto_lm_loss: 4.3285 ||
04/19 07:01:12 PM: Update 25033: task wsj, batch 33 (25033): perplexity: 76.4705, wsj_loss: 4.3369 ||
04/19 07:01:21 PM: Update 19919: task toronto_lm, batch 914 (19817): perplexity: 75.7655, toronto_lm_loss: 4.3276 ||
04/19 07:01:22 PM: Update 25049: task wsj, batch 49 (25049): perplexity: 76.2082, wsj_loss: 4.3335 ||
04/19 07:01:31 PM: Update 19932: task toronto_lm, batch 927 (19830): perplexity: 75.7447, toronto_lm_loss: 4.3274 ||
04/19 07:01:32 PM: Update 25065: task wsj, batch 65 (25065): perplexity: 75.3381, wsj_loss: 4.3220 ||
04/19 07:01:39 PM: Update 19942: task wsj, batch 6 (103): perplexity: 248.9458, wsj_loss: 5.5172 ||
04/19 07:01:42 PM: Update 19946: task toronto_lm, batch 940 (19843): perplexity: 75.7877, toronto_lm_loss: 4.3279 ||
04/19 07:01:43 PM: Update 25081: task wsj, batch 81 (25081): perplexity: 75.8133, wsj_loss: 4.3283 ||
04/19 07:01:52 PM: Update 19960: task toronto_lm, batch 954 (19857): perplexity: 75.7510, toronto_lm_loss: 4.3275 ||
04/19 07:01:53 PM: Update 25097: task wsj, batch 97 (25097): perplexity: 75.5733, wsj_loss: 4.3251 ||
04/19 07:02:03 PM: Update 19974: task toronto_lm, batch 968 (19871): perplexity: 75.7444, toronto_lm_loss: 4.3274 ||
04/19 07:02:09 PM: Update 25113: task wsj, batch 113 (25113): perplexity: 75.6879, wsj_loss: 4.3266 ||
04/19 07:02:14 PM: Update 19988: task toronto_lm, batch 982 (19885): perplexity: 75.7345, toronto_lm_loss: 4.3272 ||
04/19 07:02:20 PM: Update 25129: task wsj, batch 129 (25129): perplexity: 76.0827, wsj_loss: 4.3318 ||
04/19 07:02:23 PM: ***** Pass 20000 / Epoch 20 *****
04/19 07:02:23 PM: toronto_lm: trained on 994 batches, 0.005 epochs
04/19 07:02:23 PM: wsj: trained on 6 batches, 0.007 epochs
04/19 07:02:23 PM: Validating...
04/19 07:02:24 PM: Batch 4/140: perplexity: 100.9376, toronto_lm_loss: 4.6145 || , for evaluation data
04/19 07:02:30 PM: Update 25145: task wsj, batch 145 (25145): perplexity: 76.5205, wsj_loss: 4.3376 ||
04/19 07:02:34 PM: Batch 43/140: perplexity: 96.4203, toronto_lm_loss: 4.5687 || , for evaluation data
04/19 07:02:40 PM: Update 25161: task wsj, batch 161 (25161): perplexity: 76.7237, wsj_loss: 4.3402 ||
04/19 07:02:44 PM: Batch 82/140: perplexity: 94.3946, toronto_lm_loss: 4.5475 || , for evaluation data
04/19 07:02:51 PM: Update 25177: task wsj, batch 177 (25177): perplexity: 77.1451, wsj_loss: 4.3457 ||
04/19 07:02:54 PM: Batch 121/140: perplexity: 88.4098, toronto_lm_loss: 4.4820 || , for evaluation data
04/19 07:02:59 PM: Batch 1/66: perplexity: 345.4456, wsj_loss: 5.8448 || , for evaluation data
04/19 07:03:01 PM: Update 25193: task wsj, batch 193 (25193): perplexity: 77.4092, wsj_loss: 4.3491 ||
04/19 07:03:09 PM: Batch 39/66: perplexity: 251.9456, wsj_loss: 5.5292 || , for evaluation data
04/19 07:03:12 PM: Update 25209: task wsj, batch 209 (25209): perplexity: 77.3156, wsj_loss: 4.3479 ||
04/19 07:03:16 PM: Best model found for wsj.
04/19 07:03:16 PM: Best model found for micro.
04/19 07:03:16 PM: Best model found for macro.
04/19 07:03:16 PM: Advancing scheduler.
04/19 07:03:16 PM: 	Best macro_avg: 0.172
04/19 07:03:16 PM: 	# bad epochs: 0
04/19 07:03:16 PM: Statistic: toronto_lm_loss
04/19 07:03:16 PM: 	training: 4.327081
04/19 07:03:16 PM: 	validation: 4.452708
04/19 07:03:16 PM: Statistic: wsj_loss
04/19 07:03:16 PM: 	training: 5.517235
04/19 07:03:16 PM: 	validation: 5.505084
04/19 07:03:16 PM: Statistic: macro_avg
04/19 07:03:16 PM: 	validation: 0.172262
04/19 07:03:16 PM: Statistic: micro_avg
04/19 07:03:16 PM: 	validation: 0.005209
04/19 07:03:16 PM: Statistic: toronto_lm_perplexity
04/19 07:03:16 PM: 	training: 75.722897
04/19 07:03:16 PM: 	validation: 85.859124
04/19 07:03:16 PM: Statistic: wsj_perplexity
04/19 07:03:16 PM: 	training: 248.945819
04/19 07:03:16 PM: 	validation: 245.939228
04/19 07:03:16 PM: global_lr: 0.001000
04/19 07:03:17 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 07:03:17 PM: Update 20001: task toronto_lm, batch 1 (19898): perplexity: 77.5269, toronto_lm_loss: 4.3506 ||
04/19 07:03:22 PM: Update 25225: task wsj, batch 225 (25225): perplexity: 77.4813, wsj_loss: 4.3500 ||
04/19 07:03:28 PM: Update 20015: task toronto_lm, batch 15 (19912): perplexity: 77.6623, toronto_lm_loss: 4.3524 ||
04/19 07:03:33 PM: Update 25241: task wsj, batch 241 (25241): perplexity: 77.5163, wsj_loss: 4.3505 ||
04/19 07:03:39 PM: Update 20029: task toronto_lm, batch 29 (19926): perplexity: 77.3121, toronto_lm_loss: 4.3479 ||
04/19 07:03:43 PM: Update 25257: task wsj, batch 257 (25257): perplexity: 77.7981, wsj_loss: 4.3541 ||
04/19 07:03:49 PM: Update 20043: task toronto_lm, batch 43 (19940): perplexity: 76.6319, toronto_lm_loss: 4.3390 ||
04/19 07:03:56 PM: Update 25270: task wsj, batch 270 (25270): perplexity: 78.0758, wsj_loss: 4.3577 ||
04/19 07:04:00 PM: Update 20057: task toronto_lm, batch 57 (19954): perplexity: 75.2129, toronto_lm_loss: 4.3203 ||
04/19 07:04:07 PM: Update 25286: task wsj, batch 286 (25286): perplexity: 77.9886, wsj_loss: 4.3566 ||
04/19 07:04:11 PM: Update 20071: task toronto_lm, batch 71 (19968): perplexity: 75.6149, toronto_lm_loss: 4.3257 ||
04/19 07:04:15 PM: Update 20076: task wsj, batch 1 (104): perplexity: 291.6167, wsj_loss: 5.6754 ||
04/19 07:04:17 PM: Update 25302: task wsj, batch 302 (25302): perplexity: 77.7698, wsj_loss: 4.3538 ||
04/19 07:04:21 PM: Update 20085: task toronto_lm, batch 84 (19981): perplexity: 75.5757, toronto_lm_loss: 4.3251 ||
04/19 07:04:28 PM: Update 25318: task wsj, batch 318 (25318): perplexity: 77.5897, wsj_loss: 4.3514 ||
04/19 07:04:32 PM: Update 20099: task toronto_lm, batch 98 (19995): perplexity: 75.6619, toronto_lm_loss: 4.3263 ||
04/19 07:04:38 PM: Update 25334: task wsj, batch 334 (25334): perplexity: 77.4577, wsj_loss: 4.3497 ||
04/19 07:04:45 PM: Update 20105: task toronto_lm, batch 104 (20001): perplexity: 76.1820, toronto_lm_loss: 4.3331 ||
04/19 07:04:48 PM: Update 25350: task wsj, batch 350 (25350): perplexity: 77.3858, wsj_loss: 4.3488 ||
04/19 07:04:56 PM: Update 20119: task toronto_lm, batch 118 (20015): perplexity: 80.0963, toronto_lm_loss: 4.3832 ||
04/19 07:04:59 PM: Update 25366: task wsj, batch 366 (25366): perplexity: 77.3031, wsj_loss: 4.3477 ||
04/19 07:05:06 PM: Update 20133: task toronto_lm, batch 132 (20029): perplexity: 82.6012, toronto_lm_loss: 4.4140 ||
04/19 07:05:09 PM: Update 25382: task wsj, batch 382 (25382): perplexity: 77.1946, wsj_loss: 4.3463 ||
04/19 07:05:17 PM: Update 20147: task toronto_lm, batch 146 (20043): perplexity: 84.6842, toronto_lm_loss: 4.4389 ||
04/19 07:05:20 PM: Update 25398: task wsj, batch 398 (25398): perplexity: 77.2294, wsj_loss: 4.3468 ||
04/19 07:05:28 PM: Update 20161: task toronto_lm, batch 160 (20057): perplexity: 86.3125, toronto_lm_loss: 4.4580 ||
04/19 07:05:30 PM: Update 25405: task wsj, batch 405 (25405): perplexity: 77.2647, wsj_loss: 4.3472 ||
04/19 07:05:38 PM: Update 20174: task wsj, batch 2 (105): perplexity: 316.8895, wsj_loss: 5.7586 ||
04/19 07:05:38 PM: Update 20175: task toronto_lm, batch 173 (20070): perplexity: 87.5688, toronto_lm_loss: 4.4724 ||
04/19 07:05:40 PM: Update 25421: task wsj, batch 421 (25421): perplexity: 77.3963, wsj_loss: 4.3489 ||
04/19 07:05:49 PM: Update 20189: task toronto_lm, batch 187 (20084): perplexity: 88.5321, toronto_lm_loss: 4.4834 ||
04/19 07:05:51 PM: Update 25437: task wsj, batch 437 (25437): perplexity: 77.4759, wsj_loss: 4.3500 ||
04/19 07:05:55 PM: Update 20197: task wsj, batch 3 (106): perplexity: 279.3096, wsj_loss: 5.6323 ||
04/19 07:06:00 PM: Update 20203: task toronto_lm, batch 200 (20097): perplexity: 88.8710, toronto_lm_loss: 4.4872 ||
04/19 07:06:01 PM: Update 25453: task wsj, batch 453 (25453): perplexity: 77.5590, wsj_loss: 4.3510 ||
04/19 07:06:10 PM: Update 20217: task toronto_lm, batch 214 (20111): perplexity: 89.5561, toronto_lm_loss: 4.4949 ||
04/19 07:06:12 PM: Update 25469: task wsj, batch 469 (25469): perplexity: 77.4948, wsj_loss: 4.3502 ||
04/19 07:06:21 PM: Update 20231: task toronto_lm, batch 228 (20125): perplexity: 90.2678, toronto_lm_loss: 4.5028 ||
04/19 07:06:22 PM: Update 25485: task wsj, batch 485 (25485): perplexity: 77.6418, wsj_loss: 4.3521 ||
04/19 07:06:32 PM: Update 20245: task toronto_lm, batch 242 (20139): perplexity: 90.2909, toronto_lm_loss: 4.5030 ||
04/19 07:06:32 PM: Update 25501: task wsj, batch 501 (25501): perplexity: 77.6883, wsj_loss: 4.3527 ||
04/19 07:06:42 PM: Update 20259: task toronto_lm, batch 256 (20153): perplexity: 90.8862, toronto_lm_loss: 4.5096 ||
04/19 07:06:43 PM: Update 25517: task wsj, batch 517 (25517): perplexity: 77.6921, wsj_loss: 4.3528 ||
04/19 07:06:53 PM: Update 20273: task toronto_lm, batch 270 (20167): perplexity: 90.7972, toronto_lm_loss: 4.5086 ||
04/19 07:06:53 PM: Update 25533: task wsj, batch 533 (25533): perplexity: 77.8295, wsj_loss: 4.3545 ||
04/19 07:07:04 PM: Update 20287: task toronto_lm, batch 284 (20181): perplexity: 90.9747, toronto_lm_loss: 4.5106 ||
04/19 07:07:04 PM: Update 25549: task wsj, batch 549 (25549): perplexity: 77.8597, wsj_loss: 4.3549 ||
04/19 07:07:15 PM: Update 20301: task toronto_lm, batch 298 (20195): perplexity: 91.1521, toronto_lm_loss: 4.5125 ||
04/19 07:07:18 PM: Update 25562: task wsj, batch 562 (25562): perplexity: 77.7745, wsj_loss: 4.3538 ||
04/19 07:07:25 PM: Update 20315: task toronto_lm, batch 312 (20209): perplexity: 91.2626, toronto_lm_loss: 4.5137 ||
04/19 07:07:28 PM: Update 25578: task wsj, batch 578 (25578): perplexity: 77.7670, wsj_loss: 4.3537 ||
04/19 07:07:36 PM: Update 20329: task toronto_lm, batch 326 (20223): perplexity: 91.1209, toronto_lm_loss: 4.5122 ||
04/19 07:07:39 PM: Update 25594: task wsj, batch 594 (25594): perplexity: 77.5409, wsj_loss: 4.3508 ||
04/19 07:07:47 PM: Update 20343: task toronto_lm, batch 340 (20237): perplexity: 91.1568, toronto_lm_loss: 4.5126 ||
04/19 07:07:49 PM: Update 25610: task wsj, batch 610 (25610): perplexity: 77.5098, wsj_loss: 4.3504 ||
04/19 07:07:57 PM: Update 20357: task toronto_lm, batch 354 (20251): perplexity: 91.2665, toronto_lm_loss: 4.5138 ||
04/19 07:08:00 PM: Update 25626: task wsj, batch 626 (25626): perplexity: 77.4451, wsj_loss: 4.3496 ||
04/19 07:08:08 PM: Update 20371: task toronto_lm, batch 368 (20265): perplexity: 91.3094, toronto_lm_loss: 4.5143 ||
04/19 07:08:10 PM: Update 25642: task wsj, batch 642 (25642): perplexity: 77.4177, wsj_loss: 4.3492 ||
04/19 07:08:18 PM: Update 20384: task toronto_lm, batch 381 (20278): perplexity: 91.6068, toronto_lm_loss: 4.5175 ||
04/19 07:08:21 PM: Update 25658: task wsj, batch 658 (25658): perplexity: 77.4025, wsj_loss: 4.3490 ||
04/19 07:08:29 PM: Update 20398: task toronto_lm, batch 395 (20292): perplexity: 91.5550, toronto_lm_loss: 4.5169 ||
04/19 07:08:31 PM: Update 25674: task wsj, batch 674 (25674): perplexity: 77.3683, wsj_loss: 4.3486 ||
04/19 07:08:39 PM: Update 20411: task toronto_lm, batch 408 (20305): perplexity: 91.4111, toronto_lm_loss: 4.5154 ||
04/19 07:08:41 PM: Update 25690: task wsj, batch 690 (25690): perplexity: 77.2871, wsj_loss: 4.3475 ||
04/19 07:08:50 PM: Update 20425: task toronto_lm, batch 422 (20319): perplexity: 91.3092, toronto_lm_loss: 4.5143 ||
04/19 07:08:52 PM: Update 25699: task wsj, batch 699 (25699): perplexity: 77.2624, wsj_loss: 4.3472 ||
04/19 07:09:00 PM: Update 20438: task toronto_lm, batch 435 (20332): perplexity: 91.1565, toronto_lm_loss: 4.5126 ||
04/19 07:09:03 PM: Update 25715: task wsj, batch 715 (25715): perplexity: 77.2149, wsj_loss: 4.3466 ||
04/19 07:09:10 PM: Update 20452: task toronto_lm, batch 449 (20346): perplexity: 91.3371, toronto_lm_loss: 4.5146 ||
04/19 07:09:13 PM: Update 25731: task wsj, batch 731 (25731): perplexity: 77.2073, wsj_loss: 4.3465 ||
04/19 07:09:21 PM: Update 20465: task toronto_lm, batch 462 (20359): perplexity: 91.1939, toronto_lm_loss: 4.5130 ||
04/19 07:09:23 PM: Update 25747: task wsj, batch 747 (25747): perplexity: 77.2496, wsj_loss: 4.3470 ||
04/19 07:09:31 PM: Update 20478: task toronto_lm, batch 475 (20372): perplexity: 91.0437, toronto_lm_loss: 4.5113 ||
04/19 07:09:34 PM: Update 25763: task wsj, batch 763 (25763): perplexity: 77.3098, wsj_loss: 4.3478 ||
04/19 07:09:37 PM: Update 20486: task wsj, batch 4 (107): perplexity: 264.3655, wsj_loss: 5.5773 ||
04/19 07:09:41 PM: Update 20492: task toronto_lm, batch 488 (20385): perplexity: 90.9523, toronto_lm_loss: 4.5103 ||
04/19 07:09:44 PM: Update 25779: task wsj, batch 779 (25779): perplexity: 77.3117, wsj_loss: 4.3478 ||
04/19 07:09:52 PM: Update 20506: task toronto_lm, batch 502 (20399): perplexity: 90.8260, toronto_lm_loss: 4.5089 ||
04/19 07:09:55 PM: Update 25795: task wsj, batch 795 (25795): perplexity: 77.3551, wsj_loss: 4.3484 ||
04/19 07:10:02 PM: Update 20519: task toronto_lm, batch 515 (20412): perplexity: 90.8168, toronto_lm_loss: 4.5088 ||
04/19 07:10:05 PM: Update 25811: task wsj, batch 811 (25811): perplexity: 77.4111, wsj_loss: 4.3491 ||
04/19 07:10:13 PM: Update 20533: task toronto_lm, batch 529 (20426): perplexity: 90.7114, toronto_lm_loss: 4.5077 ||
04/19 07:10:16 PM: Update 25827: task wsj, batch 827 (25827): perplexity: 77.5235, wsj_loss: 4.3506 ||
04/19 07:10:23 PM: Update 20546: task toronto_lm, batch 542 (20439): perplexity: 90.7289, toronto_lm_loss: 4.5079 ||
04/19 07:10:26 PM: Update 25843: task wsj, batch 843 (25843): perplexity: 77.5891, wsj_loss: 4.3514 ||
04/19 07:10:34 PM: Update 20560: task toronto_lm, batch 556 (20453): perplexity: 90.6592, toronto_lm_loss: 4.5071 ||
04/19 07:10:39 PM: Update 25854: task wsj, batch 854 (25854): perplexity: 77.5768, wsj_loss: 4.3513 ||
04/19 07:10:44 PM: Update 20573: task toronto_lm, batch 569 (20466): perplexity: 90.6054, toronto_lm_loss: 4.5065 ||
04/19 07:10:49 PM: Update 25870: task wsj, batch 870 (25870): perplexity: 77.6043, wsj_loss: 4.3516 ||
04/19 07:10:54 PM: Update 20586: task toronto_lm, batch 582 (20479): perplexity: 90.5422, toronto_lm_loss: 4.5058 ||
04/19 07:10:58 PM: Update 20591: task wsj, batch 5 (108): perplexity: 253.3148, wsj_loss: 5.5346 ||
04/19 07:11:00 PM: Update 25886: task wsj, batch 886 (25886): perplexity: 77.5194, wsj_loss: 4.3505 ||
04/19 07:11:04 PM: Update 20599: task toronto_lm, batch 594 (20491): perplexity: 90.4001, toronto_lm_loss: 4.5042 ||
04/19 07:11:10 PM: Update 25902: task wsj, batch 902 (25902): perplexity: 77.5023, wsj_loss: 4.3503 ||
04/19 07:11:14 PM: Update 20612: task toronto_lm, batch 607 (20504): perplexity: 90.3929, toronto_lm_loss: 4.5042 ||
04/19 07:11:21 PM: Update 25918: task wsj, batch 918 (25918): perplexity: 77.4954, wsj_loss: 4.3502 ||
04/19 07:11:24 PM: Update 20625: task toronto_lm, batch 620 (20517): perplexity: 90.3601, toronto_lm_loss: 4.5038 ||
04/19 07:11:31 PM: Update 25934: task wsj, batch 934 (25934): perplexity: 77.4140, wsj_loss: 4.3492 ||
04/19 07:11:34 PM: Update 20638: task toronto_lm, batch 633 (20530): perplexity: 90.2926, toronto_lm_loss: 4.5031 ||
04/19 07:11:42 PM: Update 25950: task wsj, batch 950 (25950): perplexity: 77.3534, wsj_loss: 4.3484 ||
04/19 07:11:45 PM: Update 20652: task toronto_lm, batch 647 (20544): perplexity: 90.2187, toronto_lm_loss: 4.5022 ||
04/19 07:11:52 PM: Update 25966: task wsj, batch 966 (25966): perplexity: 77.3314, wsj_loss: 4.3481 ||
04/19 07:11:55 PM: Update 20665: task toronto_lm, batch 660 (20557): perplexity: 90.1390, toronto_lm_loss: 4.5014 ||
04/19 07:12:02 PM: Update 25982: task wsj, batch 982 (25982): perplexity: 77.2508, wsj_loss: 4.3471 ||
04/19 07:12:05 PM: Update 20678: task toronto_lm, batch 673 (20570): perplexity: 90.0158, toronto_lm_loss: 4.5000 ||
04/19 07:12:13 PM: Update 25990: task wsj, batch 990 (25990): perplexity: 77.2387, wsj_loss: 4.3469 ||
04/19 07:12:16 PM: Update 20692: task toronto_lm, batch 687 (20584): perplexity: 89.9665, toronto_lm_loss: 4.4994 ||
04/19 07:12:19 PM: ***** Pass 26000 / Epoch 26 *****
04/19 07:12:19 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 07:12:19 PM: Validating...
04/19 07:12:23 PM: Batch 16/24: perplexity: 116.6800, wsj_loss: 4.7594 || , for evaluation data
04/19 07:12:25 PM: Advancing scheduler.
04/19 07:12:25 PM: 	Best macro_avg: 101.271
04/19 07:12:25 PM: 	# bad epochs: 5
04/19 07:12:25 PM: Statistic: wsj_loss
04/19 07:12:25 PM: 	training: 4.347440
04/19 07:12:25 PM: 	validation: 4.623587
04/19 07:12:25 PM: Statistic: macro_avg
04/19 07:12:25 PM: 	validation: 101.858697
04/19 07:12:25 PM: Statistic: micro_avg
04/19 07:12:25 PM: 	validation: 101.858697
04/19 07:12:25 PM: Statistic: wsj_perplexity
04/19 07:12:25 PM: 	training: 77.280396
04/19 07:12:25 PM: 	validation: 101.858697
04/19 07:12:25 PM: global_lr: 0.003000
04/19 07:12:25 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 07:12:26 PM: Update 20705: task toronto_lm, batch 700 (20597): perplexity: 89.8551, toronto_lm_loss: 4.4982 ||
04/19 07:12:33 PM: Update 26012: task wsj, batch 12 (26012): perplexity: 79.3716, wsj_loss: 4.3741 ||
04/19 07:12:36 PM: Update 20718: task toronto_lm, batch 713 (20610): perplexity: 89.7458, toronto_lm_loss: 4.4970 ||
04/19 07:12:43 PM: Update 26028: task wsj, batch 28 (26028): perplexity: 76.8490, wsj_loss: 4.3418 ||
04/19 07:12:46 PM: Update 20731: task toronto_lm, batch 726 (20623): perplexity: 89.7753, toronto_lm_loss: 4.4973 ||
04/19 07:12:54 PM: Update 26044: task wsj, batch 44 (26044): perplexity: 77.7977, wsj_loss: 4.3541 ||
04/19 07:12:57 PM: Update 20734: task toronto_lm, batch 729 (20626): perplexity: 89.8021, toronto_lm_loss: 4.4976 ||
04/19 07:13:04 PM: Update 26060: task wsj, batch 60 (26060): perplexity: 78.1751, wsj_loss: 4.3590 ||
04/19 07:13:08 PM: Update 20748: task toronto_lm, batch 743 (20640): perplexity: 90.0406, toronto_lm_loss: 4.5003 ||
04/19 07:13:15 PM: Update 26076: task wsj, batch 76 (26076): perplexity: 78.4543, wsj_loss: 4.3625 ||
04/19 07:13:18 PM: Update 20762: task toronto_lm, batch 757 (20654): perplexity: 90.1626, toronto_lm_loss: 4.5016 ||
04/19 07:13:25 PM: Update 26092: task wsj, batch 92 (26092): perplexity: 78.9593, wsj_loss: 4.3689 ||
04/19 07:13:29 PM: Update 20776: task toronto_lm, batch 771 (20668): perplexity: 90.2919, toronto_lm_loss: 4.5030 ||
04/19 07:13:36 PM: Update 26108: task wsj, batch 108 (26108): perplexity: 78.6673, wsj_loss: 4.3652 ||
04/19 07:13:40 PM: Update 20790: task toronto_lm, batch 785 (20682): perplexity: 90.5402, toronto_lm_loss: 4.5058 ||
04/19 07:13:46 PM: Update 26124: task wsj, batch 124 (26124): perplexity: 79.0652, wsj_loss: 4.3703 ||
04/19 07:13:51 PM: Update 20804: task toronto_lm, batch 799 (20696): perplexity: 90.7839, toronto_lm_loss: 4.5085 ||
04/19 07:13:57 PM: Update 26140: task wsj, batch 140 (26140): perplexity: 79.0202, wsj_loss: 4.3697 ||
04/19 07:14:01 PM: Update 20818: task toronto_lm, batch 813 (20710): perplexity: 90.9093, toronto_lm_loss: 4.5099 ||
04/19 07:14:07 PM: Update 26147: task wsj, batch 147 (26147): perplexity: 78.5439, wsj_loss: 4.3637 ||
04/19 07:14:11 PM: Update 20831: task toronto_lm, batch 826 (20723): perplexity: 91.0292, toronto_lm_loss: 4.5112 ||
04/19 07:14:17 PM: Update 26163: task wsj, batch 163 (26163): perplexity: 77.9491, wsj_loss: 4.3561 ||
04/19 07:14:22 PM: Update 20845: task toronto_lm, batch 840 (20737): perplexity: 91.0963, toronto_lm_loss: 4.5119 ||
04/19 07:14:28 PM: Update 26179: task wsj, batch 179 (26179): perplexity: 77.6198, wsj_loss: 4.3518 ||
04/19 07:14:33 PM: Update 20859: task toronto_lm, batch 854 (20751): perplexity: 91.1412, toronto_lm_loss: 4.5124 ||
04/19 07:14:38 PM: Update 26195: task wsj, batch 195 (26195): perplexity: 77.4515, wsj_loss: 4.3497 ||
04/19 07:14:43 PM: Update 20873: task toronto_lm, batch 868 (20765): perplexity: 91.1210, toronto_lm_loss: 4.5122 ||
04/19 07:14:49 PM: Update 26211: task wsj, batch 211 (26211): perplexity: 77.1510, wsj_loss: 4.3458 ||
04/19 07:14:53 PM: Update 20886: task toronto_lm, batch 881 (20778): perplexity: 91.1460, toronto_lm_loss: 4.5125 ||
04/19 07:14:59 PM: Update 26227: task wsj, batch 227 (26227): perplexity: 77.0634, wsj_loss: 4.3446 ||
04/19 07:15:04 PM: Update 20899: task toronto_lm, batch 894 (20791): perplexity: 90.9928, toronto_lm_loss: 4.5108 ||
04/19 07:15:10 PM: Update 26243: task wsj, batch 243 (26243): perplexity: 77.0036, wsj_loss: 4.3439 ||
04/19 07:15:14 PM: Update 20912: task toronto_lm, batch 907 (20804): perplexity: 90.9323, toronto_lm_loss: 4.5101 ||
04/19 07:15:20 PM: Update 26259: task wsj, batch 259 (26259): perplexity: 76.7496, wsj_loss: 4.3405 ||
04/19 07:15:24 PM: Update 20926: task toronto_lm, batch 921 (20818): perplexity: 90.8962, toronto_lm_loss: 4.5097 ||
04/19 07:15:31 PM: Update 26275: task wsj, batch 275 (26275): perplexity: 76.6882, wsj_loss: 4.3397 ||
04/19 07:15:35 PM: Update 20940: task toronto_lm, batch 935 (20832): perplexity: 90.8723, toronto_lm_loss: 4.5095 ||
04/19 07:15:41 PM: Update 26283: task wsj, batch 283 (26283): perplexity: 76.8349, wsj_loss: 4.3417 ||
04/19 07:15:45 PM: Update 20953: task toronto_lm, batch 948 (20845): perplexity: 90.7763, toronto_lm_loss: 4.5084 ||
04/19 07:15:51 PM: Update 26299: task wsj, batch 299 (26299): perplexity: 76.9573, wsj_loss: 4.3433 ||
04/19 07:15:56 PM: Update 20967: task toronto_lm, batch 962 (20859): perplexity: 90.6988, toronto_lm_loss: 4.5075 ||
04/19 07:16:02 PM: Update 26315: task wsj, batch 315 (26315): perplexity: 76.8812, wsj_loss: 4.3423 ||
04/19 07:16:07 PM: Update 20981: task toronto_lm, batch 976 (20873): perplexity: 90.6702, toronto_lm_loss: 4.5072 ||
04/19 07:16:12 PM: Update 26331: task wsj, batch 331 (26331): perplexity: 77.0063, wsj_loss: 4.3439 ||
04/19 07:16:17 PM: Update 20994: task toronto_lm, batch 989 (20886): perplexity: 90.6674, toronto_lm_loss: 4.5072 ||
04/19 07:16:21 PM: ***** Pass 21000 / Epoch 21 *****
04/19 07:16:21 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 07:16:21 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 07:16:21 PM: Validating...
04/19 07:16:23 PM: Update 26347: task wsj, batch 347 (26347): perplexity: 76.9792, wsj_loss: 4.3435 ||
04/19 07:16:27 PM: Batch 21/140: perplexity: 93.8725, toronto_lm_loss: 4.5419 || , for evaluation data
04/19 07:16:33 PM: Update 26363: task wsj, batch 363 (26363): perplexity: 77.0034, wsj_loss: 4.3438 ||
04/19 07:16:37 PM: Batch 60/140: perplexity: 88.0902, toronto_lm_loss: 4.4784 || , for evaluation data
04/19 07:16:44 PM: Update 26379: task wsj, batch 379 (26379): perplexity: 77.2529, wsj_loss: 4.3471 ||
04/19 07:16:47 PM: Batch 99/140: perplexity: 84.0676, toronto_lm_loss: 4.4316 || , for evaluation data
04/19 07:16:54 PM: Update 26395: task wsj, batch 395 (26395): perplexity: 77.2431, wsj_loss: 4.3470 ||
04/19 07:16:57 PM: Batch 138/140: perplexity: 78.1094, toronto_lm_loss: 4.3581 || , for evaluation data
04/19 07:16:58 PM: Batch 1/66: perplexity: 353.8507, wsj_loss: 5.8689 || , for evaluation data
04/19 07:17:05 PM: Update 26411: task wsj, batch 411 (26411): perplexity: 77.2804, wsj_loss: 4.3474 ||
04/19 07:17:08 PM: Batch 40/66: perplexity: 249.0268, wsj_loss: 5.5176 || , for evaluation data
04/19 07:17:14 PM: Best model found for toronto_lm.
04/19 07:17:14 PM: Best model found for macro.
04/19 07:17:14 PM: Advancing scheduler.
04/19 07:17:14 PM: 	Best macro_avg: 0.177
04/19 07:17:14 PM: 	# bad epochs: 0
04/19 07:17:14 PM: Statistic: toronto_lm_loss
04/19 07:17:14 PM: 	training: 4.506730
04/19 07:17:14 PM: 	validation: 4.360841
04/19 07:17:14 PM: Statistic: wsj_loss
04/19 07:17:14 PM: 	training: 5.534633
04/19 07:17:14 PM: 	validation: 5.510647
04/19 07:17:14 PM: Statistic: macro_avg
04/19 07:17:14 PM: 	validation: 0.177055
04/19 07:17:14 PM: Statistic: micro_avg
04/19 07:17:14 PM: 	validation: 0.003451
04/19 07:17:14 PM: Statistic: toronto_lm_perplexity
04/19 07:17:14 PM: 	training: 90.625025
04/19 07:17:14 PM: 	validation: 78.323006
04/19 07:17:14 PM: Statistic: wsj_perplexity
04/19 07:17:14 PM: 	training: 253.314796
04/19 07:17:14 PM: 	validation: 247.310980
04/19 07:17:14 PM: global_lr: 0.001000
04/19 07:17:15 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 07:17:15 PM: Update 26427: task wsj, batch 427 (26427): perplexity: 77.4317, wsj_loss: 4.3494 ||
04/19 07:17:15 PM: Update 21001: task toronto_lm, batch 1 (20893): perplexity: 92.8799, toronto_lm_loss: 4.5313 ||
04/19 07:17:26 PM: Update 21015: task toronto_lm, batch 15 (20907): perplexity: 84.7659, toronto_lm_loss: 4.4399 ||
04/19 07:17:28 PM: Update 26438: task wsj, batch 438 (26438): perplexity: 77.3335, wsj_loss: 4.3481 ||
04/19 07:17:37 PM: Update 21029: task toronto_lm, batch 29 (20921): perplexity: 87.5027, toronto_lm_loss: 4.4717 ||
04/19 07:17:38 PM: Update 26454: task wsj, batch 454 (26454): perplexity: 77.1335, wsj_loss: 4.3455 ||
04/19 07:17:48 PM: Update 21043: task toronto_lm, batch 43 (20935): perplexity: 86.2591, toronto_lm_loss: 4.4574 ||
04/19 07:17:49 PM: Update 26470: task wsj, batch 470 (26470): perplexity: 77.0167, wsj_loss: 4.3440 ||
04/19 07:17:58 PM: Update 21057: task toronto_lm, batch 57 (20949): perplexity: 86.3920, toronto_lm_loss: 4.4589 ||
04/19 07:17:59 PM: Update 26486: task wsj, batch 486 (26486): perplexity: 76.9362, wsj_loss: 4.3430 ||
04/19 07:18:09 PM: Update 21071: task toronto_lm, batch 71 (20963): perplexity: 87.3144, toronto_lm_loss: 4.4695 ||
04/19 07:18:10 PM: Update 26502: task wsj, batch 502 (26502): perplexity: 76.8506, wsj_loss: 4.3419 ||
04/19 07:18:20 PM: Update 21085: task toronto_lm, batch 85 (20977): perplexity: 86.7795, toronto_lm_loss: 4.4634 ||
04/19 07:18:20 PM: Update 26518: task wsj, batch 518 (26518): perplexity: 76.8524, wsj_loss: 4.3419 ||
04/19 07:18:30 PM: Update 21099: task toronto_lm, batch 99 (20991): perplexity: 86.0618, toronto_lm_loss: 4.4551 ||
04/19 07:18:31 PM: Update 26534: task wsj, batch 534 (26534): perplexity: 76.6816, wsj_loss: 4.3397 ||
04/19 07:18:41 PM: Update 21113: task toronto_lm, batch 113 (21005): perplexity: 86.3277, toronto_lm_loss: 4.4582 ||
04/19 07:18:41 PM: Update 26550: task wsj, batch 550 (26550): perplexity: 76.6070, wsj_loss: 4.3387 ||
04/19 07:18:51 PM: Update 26566: task wsj, batch 566 (26566): perplexity: 76.6469, wsj_loss: 4.3392 ||
04/19 07:18:52 PM: Update 21127: task toronto_lm, batch 127 (21019): perplexity: 86.1342, toronto_lm_loss: 4.4559 ||
04/19 07:19:02 PM: Update 26574: task wsj, batch 574 (26574): perplexity: 76.6239, wsj_loss: 4.3389 ||
04/19 07:19:02 PM: Update 21141: task toronto_lm, batch 141 (21033): perplexity: 85.6806, toronto_lm_loss: 4.4506 ||
04/19 07:19:12 PM: Update 26590: task wsj, batch 590 (26590): perplexity: 76.7279, wsj_loss: 4.3403 ||
04/19 07:19:13 PM: Update 21155: task toronto_lm, batch 155 (21047): perplexity: 85.5457, toronto_lm_loss: 4.4491 ||
04/19 07:19:23 PM: Update 26606: task wsj, batch 606 (26606): perplexity: 76.7623, wsj_loss: 4.3407 ||
04/19 07:19:24 PM: Update 21169: task toronto_lm, batch 169 (21061): perplexity: 85.1757, toronto_lm_loss: 4.4447 ||
04/19 07:19:33 PM: Update 26622: task wsj, batch 622 (26622): perplexity: 76.7753, wsj_loss: 4.3409 ||
04/19 07:19:34 PM: Update 21183: task toronto_lm, batch 183 (21075): perplexity: 85.2046, toronto_lm_loss: 4.4451 ||
04/19 07:19:43 PM: Update 26638: task wsj, batch 638 (26638): perplexity: 76.8549, wsj_loss: 4.3419 ||
04/19 07:19:45 PM: Update 21197: task toronto_lm, batch 197 (21089): perplexity: 84.8121, toronto_lm_loss: 4.4404 ||
04/19 07:19:54 PM: Update 26654: task wsj, batch 654 (26654): perplexity: 76.9526, wsj_loss: 4.3432 ||
04/19 07:19:56 PM: Update 21211: task toronto_lm, batch 211 (21103): perplexity: 84.4536, toronto_lm_loss: 4.4362 ||
04/19 07:20:04 PM: Update 26670: task wsj, batch 670 (26670): perplexity: 76.9198, wsj_loss: 4.3428 ||
04/19 07:20:07 PM: Update 21225: task toronto_lm, batch 225 (21117): perplexity: 84.2123, toronto_lm_loss: 4.4333 ||
04/19 07:20:15 PM: Update 26686: task wsj, batch 686 (26686): perplexity: 77.0011, wsj_loss: 4.3438 ||
04/19 07:20:17 PM: Update 21238: task toronto_lm, batch 238 (21130): perplexity: 84.1257, toronto_lm_loss: 4.4323 ||
04/19 07:20:25 PM: Update 26702: task wsj, batch 702 (26702): perplexity: 77.0412, wsj_loss: 4.3443 ||
04/19 07:20:27 PM: Update 21251: task toronto_lm, batch 251 (21143): perplexity: 83.8994, toronto_lm_loss: 4.4296 ||
04/19 07:20:35 PM: Update 26718: task wsj, batch 718 (26718): perplexity: 77.0022, wsj_loss: 4.3438 ||
04/19 07:20:37 PM: Update 21264: task toronto_lm, batch 264 (21156): perplexity: 84.0734, toronto_lm_loss: 4.4317 ||
04/19 07:20:47 PM: Update 21278: task toronto_lm, batch 278 (21170): perplexity: 83.8734, toronto_lm_loss: 4.4293 ||
04/19 07:20:48 PM: Update 26730: task wsj, batch 730 (26730): perplexity: 76.9283, wsj_loss: 4.3429 ||
04/19 07:20:58 PM: Update 21292: task toronto_lm, batch 292 (21184): perplexity: 83.9707, toronto_lm_loss: 4.4305 ||
04/19 07:20:58 PM: Update 26746: task wsj, batch 746 (26746): perplexity: 76.7993, wsj_loss: 4.3412 ||
04/19 07:21:09 PM: Update 26762: task wsj, batch 762 (26762): perplexity: 76.6897, wsj_loss: 4.3398 ||
04/19 07:21:09 PM: Update 21306: task toronto_lm, batch 306 (21198): perplexity: 83.6585, toronto_lm_loss: 4.4267 ||
04/19 07:21:19 PM: Update 26778: task wsj, batch 778 (26778): perplexity: 76.7147, wsj_loss: 4.3401 ||
04/19 07:21:20 PM: Update 21320: task toronto_lm, batch 320 (21212): perplexity: 83.5228, toronto_lm_loss: 4.4251 ||
04/19 07:21:29 PM: Update 26794: task wsj, batch 794 (26794): perplexity: 76.6822, wsj_loss: 4.3397 ||
04/19 07:21:30 PM: Update 21334: task toronto_lm, batch 334 (21226): perplexity: 83.4074, toronto_lm_loss: 4.4237 ||
04/19 07:21:40 PM: Update 26810: task wsj, batch 810 (26810): perplexity: 76.6202, wsj_loss: 4.3389 ||
04/19 07:21:41 PM: Update 21348: task toronto_lm, batch 348 (21240): perplexity: 83.1553, toronto_lm_loss: 4.4207 ||
04/19 07:21:50 PM: Update 26826: task wsj, batch 826 (26826): perplexity: 76.6649, wsj_loss: 4.3394 ||
04/19 07:21:58 PM: Update 21359: task toronto_lm, batch 359 (21251): perplexity: 83.1065, toronto_lm_loss: 4.4201 ||
04/19 07:22:00 PM: Update 26842: task wsj, batch 842 (26842): perplexity: 76.6292, wsj_loss: 4.3390 ||
04/19 07:22:09 PM: Update 21373: task toronto_lm, batch 373 (21265): perplexity: 82.9555, toronto_lm_loss: 4.4183 ||
04/19 07:22:11 PM: Update 26858: task wsj, batch 858 (26858): perplexity: 76.5610, wsj_loss: 4.3381 ||
04/19 07:22:19 PM: Update 21386: task toronto_lm, batch 386 (21278): perplexity: 82.9391, toronto_lm_loss: 4.4181 ||
04/19 07:22:21 PM: Update 26866: task wsj, batch 866 (26866): perplexity: 76.5337, wsj_loss: 4.3377 ||
04/19 07:22:30 PM: Update 21400: task toronto_lm, batch 400 (21292): perplexity: 82.7507, toronto_lm_loss: 4.4158 ||
04/19 07:22:32 PM: Update 26882: task wsj, batch 882 (26882): perplexity: 76.5298, wsj_loss: 4.3377 ||
04/19 07:22:40 PM: Update 21413: task toronto_lm, batch 413 (21305): perplexity: 82.5874, toronto_lm_loss: 4.4139 ||
04/19 07:22:42 PM: Update 26898: task wsj, batch 898 (26898): perplexity: 76.4893, wsj_loss: 4.3372 ||
04/19 07:22:50 PM: Update 21427: task toronto_lm, batch 427 (21319): perplexity: 82.1749, toronto_lm_loss: 4.4088 ||
04/19 07:22:53 PM: Update 26914: task wsj, batch 914 (26914): perplexity: 76.5216, wsj_loss: 4.3376 ||
04/19 07:23:01 PM: Update 21441: task toronto_lm, batch 441 (21333): perplexity: 81.9777, toronto_lm_loss: 4.4064 ||
04/19 07:23:03 PM: Update 26930: task wsj, batch 930 (26930): perplexity: 76.5702, wsj_loss: 4.3382 ||
04/19 07:23:11 PM: Update 21454: task toronto_lm, batch 454 (21346): perplexity: 81.6376, toronto_lm_loss: 4.4023 ||
04/19 07:23:14 PM: Update 26946: task wsj, batch 946 (26946): perplexity: 76.6237, wsj_loss: 4.3389 ||
04/19 07:23:21 PM: Update 21467: task toronto_lm, batch 467 (21359): perplexity: 81.3103, toronto_lm_loss: 4.3983 ||
04/19 07:23:24 PM: Update 26962: task wsj, batch 962 (26962): perplexity: 76.6818, wsj_loss: 4.3397 ||
04/19 07:23:31 PM: Update 21480: task toronto_lm, batch 480 (21372): perplexity: 81.0991, toronto_lm_loss: 4.3957 ||
04/19 07:23:34 PM: Update 26978: task wsj, batch 978 (26978): perplexity: 76.7084, wsj_loss: 4.3400 ||
04/19 07:23:42 PM: Update 21494: task toronto_lm, batch 494 (21386): perplexity: 80.8176, toronto_lm_loss: 4.3922 ||
04/19 07:23:45 PM: Update 26994: task wsj, batch 994 (26994): perplexity: 76.7447, wsj_loss: 4.3405 ||
04/19 07:23:49 PM: ***** Pass 27000 / Epoch 27 *****
04/19 07:23:49 PM: wsj: trained on 1000 batches, 3.436 epochs
04/19 07:23:49 PM: Validating...
04/19 07:23:53 PM: Update 21508: task toronto_lm, batch 508 (21400): perplexity: 80.2711, toronto_lm_loss: 4.3854 ||
04/19 07:23:54 PM: Out of patience. Stopped tracking wsj
04/19 07:23:54 PM: Out of patience. Stopped tracking micro
04/19 07:23:54 PM: Out of patience. Stopped tracking macro
04/19 07:23:54 PM: Advancing scheduler.
04/19 07:23:54 PM: 	Best macro_avg: 101.271
04/19 07:23:54 PM: 	# bad epochs: 0
04/19 07:23:54 PM: All metrics ran out of patience. Stopping training.
04/19 07:23:54 PM: Statistic: wsj_loss
04/19 07:23:54 PM: 	training: 4.340858
04/19 07:23:54 PM: 	validation: 4.628912
04/19 07:23:54 PM: Statistic: macro_avg
04/19 07:23:54 PM: 	validation: 102.402546
04/19 07:23:54 PM: Statistic: micro_avg
04/19 07:23:54 PM: 	validation: 102.402546
04/19 07:23:54 PM: Statistic: wsj_perplexity
04/19 07:23:54 PM: 	training: 76.773373
04/19 07:23:54 PM: 	validation: 102.402546
04/19 07:23:54 PM: global_lr: 0.001500
04/19 07:23:55 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0
04/19 07:23:55 PM: Stopped training after 27 validation checks
04/19 07:23:55 PM: Trained wsj for 27000 batches or 92.784 epochs
04/19 07:23:55 PM: ***** VALIDATION RESULTS *****
04/19 07:23:55 PM: wsj_perplexity, 21, wsj_loss: 4.61780, macro_avg: 101.27096, micro_avg: 101.27096, wsj_perplexity: 101.27096
04/19 07:23:55 PM: micro_avg, 21, wsj_loss: 4.61780, macro_avg: 101.27096, micro_avg: 101.27096, wsj_perplexity: 101.27096
04/19 07:23:55 PM: macro_avg, 21, wsj_loss: 4.61780, macro_avg: 101.27096, micro_avg: 101.27096, wsj_perplexity: 101.27096
04/19 07:23:55 PM: In strict mode because do_target_task_training is off. Will crash if any tasks are missing from the checkpoint.
04/19 07:23:55 PM: Loaded model state from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/prpn-0/model_state_main_epoch_21.best_macro.th
04/19 07:23:55 PM: Evaluating...
04/19 07:23:55 PM: Evaluating on: wsj, split: val
04/19 07:24:01 PM: Task wsj: has no predictions!
04/19 07:24:01 PM: Writing results for split 'val' to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-2/results.tsv
04/19 07:24:01 PM: micro_avg: 101.271, macro_avg: 101.271, wsj_perplexity: 101.271
04/19 07:24:01 PM: Done!
Epoch    27: reducing learning rate of group 0 to 1.5000e-03.
04/19 07:24:03 PM: Update 21521: task toronto_lm, batch 521 (21413): perplexity: 80.0057, toronto_lm_loss: 4.3821 ||
04/19 07:24:13 PM: Update 21535: task toronto_lm, batch 535 (21427): perplexity: 79.5600, toronto_lm_loss: 4.3765 ||
04/19 07:24:24 PM: Update 21549: task toronto_lm, batch 549 (21441): perplexity: 79.1780, toronto_lm_loss: 4.3717 ||
04/19 07:24:34 PM: Update 21562: task toronto_lm, batch 562 (21454): perplexity: 78.9749, toronto_lm_loss: 4.3691 ||
04/19 07:24:44 PM: Update 21575: task toronto_lm, batch 575 (21467): perplexity: 78.5923, toronto_lm_loss: 4.3643 ||
04/19 07:24:54 PM: Update 21588: task toronto_lm, batch 588 (21480): perplexity: 78.1822, toronto_lm_loss: 4.3590 ||
04/19 07:25:05 PM: Update 21601: task toronto_lm, batch 601 (21493): perplexity: 77.8518, toronto_lm_loss: 4.3548 ||
04/19 07:25:15 PM: Update 21615: task toronto_lm, batch 615 (21507): perplexity: 77.4952, toronto_lm_loss: 4.3502 ||
04/19 07:25:25 PM: Update 21628: task toronto_lm, batch 628 (21520): perplexity: 77.2404, toronto_lm_loss: 4.3469 ||
04/19 07:25:35 PM: Update 21641: task toronto_lm, batch 641 (21533): perplexity: 76.9074, toronto_lm_loss: 4.3426 ||
04/19 07:25:45 PM: Update 21654: task toronto_lm, batch 654 (21546): perplexity: 76.6244, toronto_lm_loss: 4.3389 ||
04/19 07:25:55 PM: Update 21667: task toronto_lm, batch 667 (21559): perplexity: 76.3744, toronto_lm_loss: 4.3356 ||
04/19 07:26:05 PM: Update 21680: task toronto_lm, batch 680 (21572): perplexity: 76.1271, toronto_lm_loss: 4.3324 ||
04/19 07:26:16 PM: Update 21694: task toronto_lm, batch 694 (21586): perplexity: 75.8508, toronto_lm_loss: 4.3288 ||
04/19 07:26:26 PM: Update 21707: task toronto_lm, batch 707 (21599): perplexity: 75.6722, toronto_lm_loss: 4.3264 ||
04/19 07:26:37 PM: Update 21721: task toronto_lm, batch 721 (21613): perplexity: 75.4484, toronto_lm_loss: 4.3234 ||
04/19 07:26:48 PM: Update 21735: task toronto_lm, batch 735 (21627): perplexity: 75.1789, toronto_lm_loss: 4.3199 ||
04/19 07:26:58 PM: Update 21749: task toronto_lm, batch 749 (21641): perplexity: 74.9219, toronto_lm_loss: 4.3164 ||
04/19 07:27:08 PM: Update 21762: task toronto_lm, batch 762 (21654): perplexity: 74.6717, toronto_lm_loss: 4.3131 ||
04/19 07:27:19 PM: Update 21776: task toronto_lm, batch 776 (21668): perplexity: 74.3980, toronto_lm_loss: 4.3094 ||
04/19 07:27:29 PM: Update 21789: task toronto_lm, batch 789 (21681): perplexity: 74.2402, toronto_lm_loss: 4.3073 ||
04/19 07:27:39 PM: Update 21802: task toronto_lm, batch 802 (21694): perplexity: 74.0390, toronto_lm_loss: 4.3046 ||
04/19 07:27:49 PM: Update 21815: task toronto_lm, batch 815 (21707): perplexity: 73.7509, toronto_lm_loss: 4.3007 ||
04/19 07:28:00 PM: Update 21829: task toronto_lm, batch 829 (21721): perplexity: 73.5676, toronto_lm_loss: 4.2982 ||
04/19 07:28:10 PM: Update 21842: task toronto_lm, batch 842 (21734): perplexity: 73.4467, toronto_lm_loss: 4.2966 ||
04/19 07:28:20 PM: Update 21855: task toronto_lm, batch 855 (21747): perplexity: 73.2336, toronto_lm_loss: 4.2937 ||
04/19 07:28:30 PM: Update 21868: task toronto_lm, batch 868 (21760): perplexity: 73.1412, toronto_lm_loss: 4.2924 ||
04/19 07:28:40 PM: Update 21881: task toronto_lm, batch 881 (21773): perplexity: 72.9155, toronto_lm_loss: 4.2893 ||
04/19 07:28:51 PM: Update 21895: task toronto_lm, batch 895 (21787): perplexity: 72.7292, toronto_lm_loss: 4.2867 ||
04/19 07:28:52 PM: Update 21896: task wsj, batch 1 (109): perplexity: 182.7337, wsj_loss: 5.2080 ||
04/19 07:29:02 PM: Update 21909: task toronto_lm, batch 908 (21800): perplexity: 72.5473, toronto_lm_loss: 4.2842 ||
04/19 07:29:12 PM: Update 21922: task toronto_lm, batch 921 (21813): perplexity: 72.4292, toronto_lm_loss: 4.2826 ||
04/19 07:29:21 PM: Update 21934: task wsj, batch 2 (110): perplexity: 215.6189, wsj_loss: 5.3735 ||
04/19 07:29:22 PM: Update 21935: task toronto_lm, batch 933 (21825): perplexity: 72.2745, toronto_lm_loss: 4.2805 ||
04/19 07:29:32 PM: Update 21948: task toronto_lm, batch 946 (21838): perplexity: 72.0910, toronto_lm_loss: 4.2779 ||
04/19 07:29:43 PM: Update 21962: task toronto_lm, batch 960 (21852): perplexity: 71.9732, toronto_lm_loss: 4.2763 ||
04/19 07:29:54 PM: Update 21976: task toronto_lm, batch 974 (21866): perplexity: 71.7354, toronto_lm_loss: 4.2730 ||
04/19 07:30:08 PM: Update 21986: task toronto_lm, batch 984 (21876): perplexity: 71.6084, toronto_lm_loss: 4.2712 ||
04/19 07:30:18 PM: Update 21999: task toronto_lm, batch 997 (21889): perplexity: 71.8431, toronto_lm_loss: 4.2745 ||
04/19 07:30:19 PM: ***** Pass 22000 / Epoch 22 *****
04/19 07:30:19 PM: toronto_lm: trained on 998 batches, 0.005 epochs
04/19 07:30:19 PM: wsj: trained on 2 batches, 0.002 epochs
04/19 07:30:19 PM: Validating...
04/19 07:30:28 PM: Batch 35/140: perplexity: 92.7849, toronto_lm_loss: 4.5303 || , for evaluation data
04/19 07:30:39 PM: Batch 74/140: perplexity: 94.6890, toronto_lm_loss: 4.5506 || , for evaluation data
04/19 07:30:49 PM: Batch 112/140: perplexity: 87.5891, toronto_lm_loss: 4.4727 || , for evaluation data
04/19 07:30:56 PM: Batch 1/66: perplexity: 346.2408, wsj_loss: 5.8471 || , for evaluation data
04/19 07:31:06 PM: Batch 34/66: perplexity: 255.4875, wsj_loss: 5.5432 || , for evaluation data
04/19 07:31:15 PM: Advancing scheduler.
04/19 07:31:15 PM: 	Best macro_avg: 0.177
04/19 07:31:15 PM: 	# bad epochs: 1
04/19 07:31:15 PM: Statistic: toronto_lm_loss
04/19 07:31:15 PM: 	training: 4.274478
04/19 07:31:15 PM: 	validation: 4.416293
04/19 07:31:15 PM: Statistic: wsj_loss
04/19 07:31:15 PM: 	training: 5.373512
04/19 07:31:15 PM: 	validation: 5.511763
04/19 07:31:15 PM: Statistic: macro_avg
04/19 07:31:15 PM: 	validation: 0.172037
04/19 07:31:15 PM: Statistic: micro_avg
04/19 07:31:15 PM: 	validation: 0.003096
04/19 07:31:15 PM: Statistic: toronto_lm_perplexity
04/19 07:31:15 PM: 	training: 71.842604
04/19 07:31:15 PM: 	validation: 82.788784
04/19 07:31:15 PM: Statistic: wsj_perplexity
04/19 07:31:15 PM: 	training: 215.618851
04/19 07:31:15 PM: 	validation: 247.587223
04/19 07:31:15 PM: global_lr: 0.001000
04/19 07:31:15 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 07:31:16 PM: Update 22001: task toronto_lm, batch 1 (21891): perplexity: 78.8928, toronto_lm_loss: 4.3681 ||
04/19 07:31:26 PM: Update 22014: task toronto_lm, batch 14 (21904): perplexity: 85.4841, toronto_lm_loss: 4.4483 ||
04/19 07:31:36 PM: Update 22027: task toronto_lm, batch 27 (21917): perplexity: 84.0407, toronto_lm_loss: 4.4313 ||
04/19 07:31:46 PM: Update 22040: task toronto_lm, batch 40 (21930): perplexity: 82.7467, toronto_lm_loss: 4.4158 ||
04/19 07:31:56 PM: Update 22053: task toronto_lm, batch 53 (21943): perplexity: 80.0298, toronto_lm_loss: 4.3824 ||
04/19 07:32:07 PM: Update 22067: task toronto_lm, batch 67 (21957): perplexity: 79.2121, toronto_lm_loss: 4.3721 ||
04/19 07:32:17 PM: Update 22080: task toronto_lm, batch 80 (21970): perplexity: 78.6781, toronto_lm_loss: 4.3654 ||
04/19 07:32:27 PM: Update 22093: task toronto_lm, batch 93 (21983): perplexity: 78.5468, toronto_lm_loss: 4.3637 ||
04/19 07:32:37 PM: Update 22106: task toronto_lm, batch 106 (21996): perplexity: 77.7022, toronto_lm_loss: 4.3529 ||
04/19 07:32:47 PM: Update 22119: task toronto_lm, batch 119 (22009): perplexity: 77.0084, toronto_lm_loss: 4.3439 ||
04/19 07:32:57 PM: Update 22132: task toronto_lm, batch 132 (22022): perplexity: 76.9805, toronto_lm_loss: 4.3436 ||
04/19 07:33:07 PM: Update 22145: task toronto_lm, batch 145 (22035): perplexity: 76.7550, toronto_lm_loss: 4.3406 ||
04/19 07:33:17 PM: Update 22158: task toronto_lm, batch 158 (22048): perplexity: 76.5495, toronto_lm_loss: 4.3379 ||
04/19 07:33:27 PM: Update 22171: task toronto_lm, batch 171 (22061): perplexity: 76.0817, toronto_lm_loss: 4.3318 ||
04/19 07:33:38 PM: Update 22184: task toronto_lm, batch 184 (22074): perplexity: 75.6410, toronto_lm_loss: 4.3260 ||
04/19 07:33:48 PM: Update 22197: task toronto_lm, batch 197 (22087): perplexity: 75.3203, toronto_lm_loss: 4.3217 ||
04/19 07:33:58 PM: Update 22210: task toronto_lm, batch 210 (22100): perplexity: 75.0534, toronto_lm_loss: 4.3182 ||
04/19 07:34:08 PM: Update 22223: task toronto_lm, batch 223 (22113): perplexity: 74.7009, toronto_lm_loss: 4.3135 ||
04/19 07:34:18 PM: Update 22236: task toronto_lm, batch 236 (22126): perplexity: 74.6768, toronto_lm_loss: 4.3132 ||
04/19 07:34:28 PM: Update 22249: task toronto_lm, batch 249 (22139): perplexity: 74.5680, toronto_lm_loss: 4.3117 ||
04/19 07:34:38 PM: Update 22262: task toronto_lm, batch 262 (22152): perplexity: 74.1912, toronto_lm_loss: 4.3066 ||
04/19 07:34:48 PM: Update 22275: task toronto_lm, batch 275 (22165): perplexity: 74.1882, toronto_lm_loss: 4.3066 ||
04/19 07:34:58 PM: Update 22288: task toronto_lm, batch 288 (22178): perplexity: 74.0283, toronto_lm_loss: 4.3044 ||
04/19 07:35:08 PM: Update 22301: task toronto_lm, batch 301 (22191): perplexity: 73.9020, toronto_lm_loss: 4.3027 ||
04/19 07:35:19 PM: Update 22315: task toronto_lm, batch 315 (22205): perplexity: 73.6185, toronto_lm_loss: 4.2989 ||
04/19 07:35:30 PM: Update 22329: task toronto_lm, batch 329 (22219): perplexity: 73.6501, toronto_lm_loss: 4.2993 ||
04/19 07:35:40 PM: Update 22343: task toronto_lm, batch 343 (22233): perplexity: 73.2040, toronto_lm_loss: 4.2932 ||
04/19 07:35:51 PM: Update 22357: task toronto_lm, batch 357 (22247): perplexity: 72.9446, toronto_lm_loss: 4.2897 ||
04/19 07:36:01 PM: Update 22370: task toronto_lm, batch 370 (22260): perplexity: 72.5607, toronto_lm_loss: 4.2844 ||
04/19 07:36:11 PM: Update 22383: task toronto_lm, batch 383 (22273): perplexity: 72.4934, toronto_lm_loss: 4.2835 ||
04/19 07:36:22 PM: Update 22397: task toronto_lm, batch 397 (22287): perplexity: 72.2790, toronto_lm_loss: 4.2805 ||
04/19 07:36:32 PM: Update 22410: task toronto_lm, batch 410 (22300): perplexity: 71.9349, toronto_lm_loss: 4.2758 ||
04/19 07:36:43 PM: Update 22424: task toronto_lm, batch 424 (22314): perplexity: 71.8268, toronto_lm_loss: 4.2743 ||
04/19 07:36:53 PM: Update 22438: task toronto_lm, batch 438 (22328): perplexity: 71.7271, toronto_lm_loss: 4.2729 ||
04/19 07:37:04 PM: Update 22452: task toronto_lm, batch 452 (22342): perplexity: 71.4568, toronto_lm_loss: 4.2691 ||
04/19 07:37:15 PM: Update 22466: task toronto_lm, batch 466 (22356): perplexity: 71.2605, toronto_lm_loss: 4.2663 ||
04/19 07:37:26 PM: Update 22480: task toronto_lm, batch 480 (22370): perplexity: 71.1840, toronto_lm_loss: 4.2653 ||
04/19 07:37:36 PM: Update 22494: task toronto_lm, batch 494 (22384): perplexity: 70.9750, toronto_lm_loss: 4.2623 ||
04/19 07:37:47 PM: Update 22508: task toronto_lm, batch 508 (22398): perplexity: 70.7741, toronto_lm_loss: 4.2595 ||
04/19 07:37:58 PM: Update 22522: task toronto_lm, batch 522 (22412): perplexity: 70.6454, toronto_lm_loss: 4.2577 ||
04/19 07:38:08 PM: Update 22536: task toronto_lm, batch 536 (22426): perplexity: 70.5313, toronto_lm_loss: 4.2561 ||
04/19 07:38:19 PM: Update 22549: task toronto_lm, batch 549 (22439): perplexity: 70.3712, toronto_lm_loss: 4.2538 ||
04/19 07:38:29 PM: Update 22562: task toronto_lm, batch 562 (22452): perplexity: 70.1849, toronto_lm_loss: 4.2511 ||
04/19 07:38:39 PM: Update 22576: task toronto_lm, batch 576 (22466): perplexity: 70.0604, toronto_lm_loss: 4.2494 ||
04/19 07:38:48 PM: Update 22587: task wsj, batch 1 (111): perplexity: 268.2858, wsj_loss: 5.5921 ||
04/19 07:38:50 PM: Update 22590: task toronto_lm, batch 589 (22479): perplexity: 69.9717, toronto_lm_loss: 4.2481 ||
04/19 07:39:01 PM: Update 22604: task toronto_lm, batch 603 (22493): perplexity: 69.7929, toronto_lm_loss: 4.2455 ||
04/19 07:39:14 PM: Update 22612: task toronto_lm, batch 611 (22501): perplexity: 69.7443, toronto_lm_loss: 4.2448 ||
04/19 07:39:24 PM: Update 22625: task toronto_lm, batch 624 (22514): perplexity: 69.9601, toronto_lm_loss: 4.2479 ||
04/19 07:39:34 PM: Update 22638: task toronto_lm, batch 637 (22527): perplexity: 70.0699, toronto_lm_loss: 4.2495 ||
04/19 07:39:44 PM: Update 22651: task toronto_lm, batch 650 (22540): perplexity: 70.1178, toronto_lm_loss: 4.2502 ||
04/19 07:39:54 PM: Update 22664: task toronto_lm, batch 663 (22553): perplexity: 70.1749, toronto_lm_loss: 4.2510 ||
04/19 07:40:05 PM: Update 22678: task toronto_lm, batch 677 (22567): perplexity: 70.2343, toronto_lm_loss: 4.2518 ||
04/19 07:40:15 PM: Update 22691: task toronto_lm, batch 690 (22580): perplexity: 70.2771, toronto_lm_loss: 4.2524 ||
04/19 07:40:25 PM: Update 22704: task toronto_lm, batch 703 (22593): perplexity: 70.2349, toronto_lm_loss: 4.2518 ||
04/19 07:40:35 PM: Update 22717: task toronto_lm, batch 716 (22606): perplexity: 70.1815, toronto_lm_loss: 4.2511 ||
04/19 07:40:45 PM: Update 22730: task toronto_lm, batch 729 (22619): perplexity: 70.0967, toronto_lm_loss: 4.2499 ||
04/19 07:40:55 PM: Update 22743: task toronto_lm, batch 742 (22632): perplexity: 69.9989, toronto_lm_loss: 4.2485 ||
04/19 07:41:05 PM: Update 22756: task toronto_lm, batch 755 (22645): perplexity: 69.8949, toronto_lm_loss: 4.2470 ||
04/19 07:41:15 PM: Update 22769: task toronto_lm, batch 768 (22658): perplexity: 69.7401, toronto_lm_loss: 4.2448 ||
04/19 07:41:25 PM: Update 22782: task toronto_lm, batch 781 (22671): perplexity: 69.6187, toronto_lm_loss: 4.2430 ||
04/19 07:41:36 PM: Update 22796: task toronto_lm, batch 795 (22685): perplexity: 69.5083, toronto_lm_loss: 4.2414 ||
04/19 07:41:46 PM: Update 22809: task toronto_lm, batch 808 (22698): perplexity: 69.2984, toronto_lm_loss: 4.2384 ||
04/19 07:41:56 PM: Update 22822: task toronto_lm, batch 821 (22711): perplexity: 69.2333, toronto_lm_loss: 4.2375 ||
04/19 07:42:06 PM: Update 22835: task toronto_lm, batch 834 (22724): perplexity: 69.1357, toronto_lm_loss: 4.2361 ||
04/19 07:42:16 PM: Update 22848: task toronto_lm, batch 847 (22737): perplexity: 69.0031, toronto_lm_loss: 4.2342 ||
04/19 07:42:26 PM: Update 22861: task wsj, batch 2 (112): perplexity: 273.3909, wsj_loss: 5.6109 ||
04/19 07:42:27 PM: Update 22862: task toronto_lm, batch 860 (22750): perplexity: 68.8615, toronto_lm_loss: 4.2321 ||
04/19 07:42:37 PM: Update 22875: task toronto_lm, batch 873 (22763): perplexity: 68.6744, toronto_lm_loss: 4.2294 ||
04/19 07:42:47 PM: Update 22888: task toronto_lm, batch 886 (22776): perplexity: 68.5438, toronto_lm_loss: 4.2275 ||
04/19 07:42:57 PM: Update 22901: task toronto_lm, batch 899 (22789): perplexity: 68.3950, toronto_lm_loss: 4.2253 ||
04/19 07:43:04 PM: Update 22909: task wsj, batch 3 (113): perplexity: 251.9688, wsj_loss: 5.5293 ||
04/19 07:43:08 PM: Update 22914: task toronto_lm, batch 911 (22801): perplexity: 68.3504, toronto_lm_loss: 4.2246 ||
04/19 07:43:18 PM: Update 22927: task toronto_lm, batch 924 (22814): perplexity: 68.2279, toronto_lm_loss: 4.2229 ||
04/19 07:43:28 PM: Update 22940: task toronto_lm, batch 937 (22827): perplexity: 68.0858, toronto_lm_loss: 4.2208 ||
04/19 07:43:39 PM: Update 22954: task toronto_lm, batch 951 (22841): perplexity: 67.9527, toronto_lm_loss: 4.2188 ||
04/19 07:43:49 PM: Update 22967: task toronto_lm, batch 964 (22854): perplexity: 67.8155, toronto_lm_loss: 4.2168 ||
04/19 07:43:57 PM: Update 22978: task wsj, batch 4 (114): perplexity: 243.6621, wsj_loss: 5.4958 ||
04/19 07:43:59 PM: Update 22981: task toronto_lm, batch 977 (22867): perplexity: 67.6937, toronto_lm_loss: 4.2150 ||
04/19 07:44:10 PM: Update 22995: task toronto_lm, batch 991 (22881): perplexity: 67.5301, toronto_lm_loss: 4.2126 ||
04/19 07:44:14 PM: ***** Pass 23000 / Epoch 23 *****
04/19 07:44:14 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 07:44:14 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 07:44:14 PM: Validating...
04/19 07:44:21 PM: Batch 22/140: perplexity: 106.7555, toronto_lm_loss: 4.6705 || , for evaluation data
04/19 07:44:31 PM: Batch 61/140: perplexity: 100.2904, toronto_lm_loss: 4.6081 || , for evaluation data
04/19 07:44:41 PM: Batch 100/140: perplexity: 93.7594, toronto_lm_loss: 4.5407 || , for evaluation data
04/19 07:44:51 PM: Batch 139/140: perplexity: 87.5896, toronto_lm_loss: 4.4727 || , for evaluation data
04/19 07:44:52 PM: Batch 1/66: perplexity: 336.5225, wsj_loss: 5.8187 || , for evaluation data
04/19 07:45:02 PM: Batch 40/66: perplexity: 238.3347, wsj_loss: 5.4737 || , for evaluation data
04/19 07:45:09 PM: Best model found for wsj.
04/19 07:45:09 PM: Best model found for micro.
04/19 07:45:09 PM: Best model found for macro.
04/19 07:45:09 PM: Advancing scheduler.
04/19 07:45:09 PM: 	Best macro_avg: 0.189
04/19 07:45:09 PM: 	# bad epochs: 0
04/19 07:45:09 PM: Statistic: toronto_lm_loss
04/19 07:45:09 PM: 	training: 4.211675
04/19 07:45:09 PM: 	validation: 4.474795
04/19 07:45:09 PM: Statistic: wsj_loss
04/19 07:45:09 PM: 	training: 5.495783
04/19 07:45:09 PM: 	validation: 5.466883
04/19 07:45:09 PM: Statistic: macro_avg
04/19 07:45:09 PM: 	validation: 0.188781
04/19 07:45:09 PM: Statistic: micro_avg
04/19 07:45:09 PM: 	validation: 0.017028
04/19 07:45:09 PM: Statistic: toronto_lm_perplexity
04/19 07:45:09 PM: 	training: 67.469423
04/19 07:45:09 PM: 	validation: 87.776613
04/19 07:45:09 PM: Statistic: wsj_perplexity
04/19 07:45:09 PM: 	training: 243.662145
04/19 07:45:09 PM: 	validation: 236.721295
04/19 07:45:09 PM: global_lr: 0.001000
04/19 07:45:09 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 07:45:10 PM: Update 23001: task toronto_lm, batch 1 (22887): perplexity: 51.8635, toronto_lm_loss: 3.9486 ||
04/19 07:45:21 PM: Update 23015: task toronto_lm, batch 15 (22901): perplexity: 55.5349, toronto_lm_loss: 4.0170 ||
04/19 07:45:31 PM: Update 23029: task toronto_lm, batch 29 (22915): perplexity: 57.2477, toronto_lm_loss: 4.0474 ||
04/19 07:45:41 PM: Update 23042: task toronto_lm, batch 42 (22928): perplexity: 57.0186, toronto_lm_loss: 4.0434 ||
04/19 07:45:49 PM: Update 23052: task wsj, batch 1 (115): perplexity: 185.7956, wsj_loss: 5.2246 ||
04/19 07:45:51 PM: Update 23055: task toronto_lm, batch 54 (22940): perplexity: 56.6617, toronto_lm_loss: 4.0371 ||
04/19 07:46:01 PM: Update 23068: task toronto_lm, batch 67 (22953): perplexity: 57.1364, toronto_lm_loss: 4.0454 ||
04/19 07:46:11 PM: Update 23081: task toronto_lm, batch 80 (22966): perplexity: 57.0679, toronto_lm_loss: 4.0442 ||
04/19 07:46:22 PM: Update 23094: task toronto_lm, batch 93 (22979): perplexity: 57.3790, toronto_lm_loss: 4.0497 ||
04/19 07:46:28 PM: Update 23103: task wsj, batch 2 (116): perplexity: 195.9840, wsj_loss: 5.2780 ||
04/19 07:46:32 PM: Update 23107: task toronto_lm, batch 105 (22991): perplexity: 57.0165, toronto_lm_loss: 4.0433 ||
04/19 07:46:42 PM: Update 23121: task toronto_lm, batch 119 (23005): perplexity: 56.9902, toronto_lm_loss: 4.0429 ||
04/19 07:46:53 PM: Update 23135: task toronto_lm, batch 133 (23019): perplexity: 57.0921, toronto_lm_loss: 4.0447 ||
04/19 07:47:04 PM: Update 23149: task toronto_lm, batch 147 (23033): perplexity: 56.8645, toronto_lm_loss: 4.0407 ||
04/19 07:47:15 PM: Update 23163: task toronto_lm, batch 161 (23047): perplexity: 56.7777, toronto_lm_loss: 4.0391 ||
04/19 07:47:25 PM: Update 23177: task toronto_lm, batch 175 (23061): perplexity: 56.8106, toronto_lm_loss: 4.0397 ||
04/19 07:47:35 PM: Update 23190: task toronto_lm, batch 188 (23074): perplexity: 56.8558, toronto_lm_loss: 4.0405 ||
04/19 07:47:45 PM: Update 23203: task toronto_lm, batch 201 (23087): perplexity: 56.8895, toronto_lm_loss: 4.0411 ||
04/19 07:47:55 PM: Update 23216: task toronto_lm, batch 214 (23100): perplexity: 56.7231, toronto_lm_loss: 4.0382 ||
04/19 07:48:05 PM: Update 23229: task toronto_lm, batch 227 (23113): perplexity: 56.7367, toronto_lm_loss: 4.0384 ||
04/19 07:48:24 PM: Update 23242: task toronto_lm, batch 240 (23126): perplexity: 56.9364, toronto_lm_loss: 4.0419 ||
04/19 07:48:34 PM: Update 23255: task toronto_lm, batch 253 (23139): perplexity: 59.2510, toronto_lm_loss: 4.0818 ||
04/19 07:48:45 PM: Update 23269: task toronto_lm, batch 267 (23153): perplexity: 61.5191, toronto_lm_loss: 4.1193 ||
04/19 07:48:55 PM: Update 23282: task toronto_lm, batch 280 (23166): perplexity: 63.1960, toronto_lm_loss: 4.1462 ||
04/19 07:49:05 PM: Update 23295: task toronto_lm, batch 293 (23179): perplexity: 64.6374, toronto_lm_loss: 4.1688 ||
04/19 07:49:15 PM: Update 23309: task toronto_lm, batch 307 (23193): perplexity: 66.0105, toronto_lm_loss: 4.1898 ||
04/19 07:49:26 PM: Update 23323: task toronto_lm, batch 321 (23207): perplexity: 67.4500, toronto_lm_loss: 4.2114 ||
04/19 07:49:37 PM: Update 23337: task toronto_lm, batch 335 (23221): perplexity: 68.8755, toronto_lm_loss: 4.2323 ||
04/19 07:49:47 PM: Update 23351: task toronto_lm, batch 349 (23235): perplexity: 69.9418, toronto_lm_loss: 4.2477 ||
04/19 07:49:58 PM: Update 23365: task toronto_lm, batch 363 (23249): perplexity: 71.0683, toronto_lm_loss: 4.2636 ||
04/19 07:50:09 PM: Update 23379: task toronto_lm, batch 377 (23263): perplexity: 72.0846, toronto_lm_loss: 4.2778 ||
04/19 07:50:19 PM: Update 23393: task toronto_lm, batch 391 (23277): perplexity: 72.8192, toronto_lm_loss: 4.2880 ||
04/19 07:50:30 PM: Update 23407: task toronto_lm, batch 405 (23291): perplexity: 73.6036, toronto_lm_loss: 4.2987 ||
04/19 07:50:41 PM: Update 23421: task toronto_lm, batch 419 (23305): perplexity: 74.3041, toronto_lm_loss: 4.3082 ||
04/19 07:50:52 PM: Update 23435: task toronto_lm, batch 433 (23319): perplexity: 74.8973, toronto_lm_loss: 4.3161 ||
04/19 07:51:02 PM: Update 23449: task toronto_lm, batch 447 (23333): perplexity: 75.4298, toronto_lm_loss: 4.3232 ||
04/19 07:51:13 PM: Update 23463: task toronto_lm, batch 461 (23347): perplexity: 76.0666, toronto_lm_loss: 4.3316 ||
04/19 07:51:24 PM: Update 23477: task toronto_lm, batch 475 (23361): perplexity: 76.6209, toronto_lm_loss: 4.3389 ||
04/19 07:51:34 PM: Update 23491: task toronto_lm, batch 489 (23375): perplexity: 77.1919, toronto_lm_loss: 4.3463 ||
04/19 07:51:45 PM: Update 23505: task toronto_lm, batch 503 (23389): perplexity: 77.7376, toronto_lm_loss: 4.3533 ||
04/19 07:51:56 PM: Update 23519: task toronto_lm, batch 517 (23403): perplexity: 78.2699, toronto_lm_loss: 4.3602 ||
04/19 07:52:07 PM: Update 23533: task toronto_lm, batch 531 (23417): perplexity: 78.6205, toronto_lm_loss: 4.3646 ||
04/19 07:52:17 PM: Update 23547: task toronto_lm, batch 545 (23431): perplexity: 78.8849, toronto_lm_loss: 4.3680 ||
04/19 07:52:28 PM: Update 23561: task toronto_lm, batch 559 (23445): perplexity: 79.3053, toronto_lm_loss: 4.3733 ||
04/19 07:52:39 PM: Update 23575: task toronto_lm, batch 573 (23459): perplexity: 79.6037, toronto_lm_loss: 4.3771 ||
04/19 07:52:49 PM: Update 23589: task toronto_lm, batch 587 (23473): perplexity: 79.8947, toronto_lm_loss: 4.3807 ||
04/19 07:53:00 PM: Update 23603: task toronto_lm, batch 601 (23487): perplexity: 80.1691, toronto_lm_loss: 4.3841 ||
04/19 07:53:11 PM: Update 23617: task toronto_lm, batch 615 (23501): perplexity: 80.4033, toronto_lm_loss: 4.3871 ||
04/19 07:53:21 PM: Update 23631: task toronto_lm, batch 629 (23515): perplexity: 80.6224, toronto_lm_loss: 4.3898 ||
04/19 07:53:32 PM: Update 23645: task toronto_lm, batch 643 (23529): perplexity: 80.9195, toronto_lm_loss: 4.3935 ||
04/19 07:53:43 PM: Update 23659: task toronto_lm, batch 657 (23543): perplexity: 81.0793, toronto_lm_loss: 4.3954 ||
04/19 07:53:53 PM: Update 23673: task toronto_lm, batch 671 (23557): perplexity: 81.3300, toronto_lm_loss: 4.3985 ||
04/19 07:54:04 PM: Update 23687: task toronto_lm, batch 685 (23571): perplexity: 81.6868, toronto_lm_loss: 4.4029 ||
04/19 07:54:15 PM: Update 23701: task toronto_lm, batch 699 (23585): perplexity: 81.8527, toronto_lm_loss: 4.4049 ||
04/19 07:54:16 PM: Update 23703: task wsj, batch 3 (117): perplexity: 214.9024, wsj_loss: 5.3702 ||
04/19 07:54:25 PM: Update 23715: task toronto_lm, batch 712 (23598): perplexity: 82.0213, toronto_lm_loss: 4.4070 ||
04/19 07:54:35 PM: Update 23728: task toronto_lm, batch 725 (23611): perplexity: 82.1956, toronto_lm_loss: 4.4091 ||
04/19 07:54:46 PM: Update 23742: task toronto_lm, batch 739 (23625): perplexity: 82.3741, toronto_lm_loss: 4.4113 ||
04/19 07:54:56 PM: Update 23755: task toronto_lm, batch 752 (23638): perplexity: 82.4281, toronto_lm_loss: 4.4119 ||
04/19 07:55:06 PM: Update 23768: task toronto_lm, batch 765 (23651): perplexity: 82.6620, toronto_lm_loss: 4.4148 ||
04/19 07:55:16 PM: Update 23781: task toronto_lm, batch 778 (23664): perplexity: 82.6908, toronto_lm_loss: 4.4151 ||
04/19 07:55:27 PM: Update 23795: task toronto_lm, batch 792 (23678): perplexity: 82.8879, toronto_lm_loss: 4.4175 ||
04/19 07:55:37 PM: Update 23808: task toronto_lm, batch 805 (23691): perplexity: 82.9953, toronto_lm_loss: 4.4188 ||
04/19 07:55:47 PM: Update 23821: task toronto_lm, batch 818 (23704): perplexity: 83.0739, toronto_lm_loss: 4.4197 ||
04/19 07:55:58 PM: Update 23835: task wsj, batch 4 (118): perplexity: 221.3805, wsj_loss: 5.3999 ||
04/19 07:55:58 PM: Update 23836: task toronto_lm, batch 832 (23718): perplexity: 83.2076, toronto_lm_loss: 4.4213 ||
04/19 07:56:09 PM: Update 23850: task toronto_lm, batch 846 (23732): perplexity: 83.3892, toronto_lm_loss: 4.4235 ||
04/19 07:56:19 PM: Update 23863: task toronto_lm, batch 859 (23745): perplexity: 83.4213, toronto_lm_loss: 4.4239 ||
04/19 07:56:31 PM: Update 23869: task toronto_lm, batch 865 (23751): perplexity: 83.4666, toronto_lm_loss: 4.4244 ||
04/19 07:56:41 PM: Update 23882: task toronto_lm, batch 878 (23764): perplexity: 83.5406, toronto_lm_loss: 4.4253 ||
04/19 07:56:51 PM: Update 23895: task toronto_lm, batch 891 (23777): perplexity: 83.6871, toronto_lm_loss: 4.4271 ||
04/19 07:57:02 PM: Update 23909: task toronto_lm, batch 905 (23791): perplexity: 83.8871, toronto_lm_loss: 4.4295 ||
04/19 07:57:12 PM: Update 23922: task toronto_lm, batch 918 (23804): perplexity: 84.0141, toronto_lm_loss: 4.4310 ||
04/19 07:57:22 PM: Update 23935: task toronto_lm, batch 931 (23817): perplexity: 84.0404, toronto_lm_loss: 4.4313 ||
04/19 07:57:32 PM: Update 23948: task toronto_lm, batch 944 (23830): perplexity: 84.1086, toronto_lm_loss: 4.4321 ||
04/19 07:57:42 PM: Update 23961: task toronto_lm, batch 957 (23843): perplexity: 84.1824, toronto_lm_loss: 4.4330 ||
04/19 07:57:52 PM: Update 23974: task toronto_lm, batch 970 (23856): perplexity: 84.2506, toronto_lm_loss: 4.4338 ||
04/19 07:58:03 PM: Update 23987: task toronto_lm, batch 983 (23869): perplexity: 84.2002, toronto_lm_loss: 4.4332 ||
04/19 07:58:13 PM: Update 24000: task toronto_lm, batch 996 (23882): perplexity: 84.1485, toronto_lm_loss: 4.4326 ||
04/19 07:58:13 PM: ***** Pass 24000 / Epoch 24 *****
04/19 07:58:13 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 07:58:13 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 07:58:13 PM: Validating...
04/19 07:58:23 PM: Batch 38/140: perplexity: 88.8094, toronto_lm_loss: 4.4865 || , for evaluation data
04/19 07:58:33 PM: Batch 76/140: perplexity: 91.1397, toronto_lm_loss: 4.5124 || , for evaluation data
04/19 07:58:43 PM: Batch 109/140: perplexity: 86.4776, toronto_lm_loss: 4.4599 || , for evaluation data
04/19 07:58:51 PM: Batch 1/66: perplexity: 354.1059, wsj_loss: 5.8696 || , for evaluation data
04/19 07:59:01 PM: Batch 39/66: perplexity: 258.5755, wsj_loss: 5.5552 || , for evaluation data
04/19 07:59:08 PM: Advancing scheduler.
04/19 07:59:08 PM: 	Best macro_avg: 0.189
04/19 07:59:08 PM: 	# bad epochs: 1
04/19 07:59:08 PM: Statistic: toronto_lm_loss
04/19 07:59:08 PM: 	training: 4.432583
04/19 07:59:08 PM: 	validation: 4.405861
04/19 07:59:08 PM: Statistic: wsj_loss
04/19 07:59:08 PM: 	training: 5.399883
04/19 07:59:08 PM: 	validation: 5.532443
04/19 07:59:08 PM: Statistic: macro_avg
04/19 07:59:08 PM: 	validation: 0.162549
04/19 07:59:08 PM: Statistic: micro_avg
04/19 07:59:08 PM: 	validation: -0.003536
04/19 07:59:08 PM: Statistic: toronto_lm_perplexity
04/19 07:59:08 PM: 	training: 84.148459
04/19 07:59:08 PM: 	validation: 81.929648
04/19 07:59:08 PM: Statistic: wsj_perplexity
04/19 07:59:08 PM: 	training: 221.380547
04/19 07:59:08 PM: 	validation: 252.760556
04/19 07:59:08 PM: global_lr: 0.001000
04/19 07:59:09 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 07:59:09 PM: Update 24001: task toronto_lm, batch 1 (23883): perplexity: 84.2243, toronto_lm_loss: 4.4335 ||
04/19 07:59:19 PM: Update 24014: task toronto_lm, batch 14 (23896): perplexity: 81.7004, toronto_lm_loss: 4.4031 ||
04/19 07:59:30 PM: Update 24027: task toronto_lm, batch 27 (23909): perplexity: 81.9252, toronto_lm_loss: 4.4058 ||
04/19 07:59:40 PM: Update 24040: task toronto_lm, batch 40 (23922): perplexity: 80.7859, toronto_lm_loss: 4.3918 ||
04/19 07:59:50 PM: Update 24053: task toronto_lm, batch 53 (23935): perplexity: 79.5358, toronto_lm_loss: 4.3762 ||
04/19 08:00:01 PM: Update 24067: task toronto_lm, batch 67 (23949): perplexity: 81.1256, toronto_lm_loss: 4.3960 ||
04/19 08:00:11 PM: Update 24080: task toronto_lm, batch 80 (23962): perplexity: 81.1644, toronto_lm_loss: 4.3965 ||
04/19 08:00:21 PM: Update 24093: task toronto_lm, batch 93 (23975): perplexity: 80.7459, toronto_lm_loss: 4.3913 ||
04/19 08:00:31 PM: Update 24106: task toronto_lm, batch 106 (23988): perplexity: 80.6231, toronto_lm_loss: 4.3898 ||
04/19 08:00:41 PM: Update 24119: task toronto_lm, batch 119 (24001): perplexity: 80.6869, toronto_lm_loss: 4.3906 ||
04/19 08:00:51 PM: Update 24132: task toronto_lm, batch 132 (24014): perplexity: 80.8590, toronto_lm_loss: 4.3927 ||
04/19 08:01:01 PM: Update 24145: task toronto_lm, batch 145 (24027): perplexity: 80.5715, toronto_lm_loss: 4.3891 ||
04/19 08:01:11 PM: Update 24158: task toronto_lm, batch 158 (24040): perplexity: 80.7657, toronto_lm_loss: 4.3916 ||
04/19 08:01:22 PM: Update 24171: task toronto_lm, batch 171 (24053): perplexity: 80.3673, toronto_lm_loss: 4.3866 ||
04/19 08:01:32 PM: Update 24184: task toronto_lm, batch 184 (24066): perplexity: 80.2283, toronto_lm_loss: 4.3849 ||
04/19 08:01:42 PM: Update 24197: task toronto_lm, batch 197 (24079): perplexity: 79.9616, toronto_lm_loss: 4.3815 ||
04/19 08:01:52 PM: Update 24210: task toronto_lm, batch 210 (24092): perplexity: 79.7451, toronto_lm_loss: 4.3788 ||
04/19 08:02:03 PM: Update 24224: task toronto_lm, batch 224 (24106): perplexity: 79.7504, toronto_lm_loss: 4.3789 ||
04/19 08:02:06 PM: Update 24228: task wsj, batch 1 (119): perplexity: 218.4223, wsj_loss: 5.3864 ||
04/19 08:02:13 PM: Update 24237: task toronto_lm, batch 236 (24118): perplexity: 79.5100, toronto_lm_loss: 4.3759 ||
04/19 08:02:23 PM: Update 24250: task toronto_lm, batch 249 (24131): perplexity: 79.4848, toronto_lm_loss: 4.3756 ||
04/19 08:02:33 PM: Update 24263: task toronto_lm, batch 262 (24144): perplexity: 79.3225, toronto_lm_loss: 4.3735 ||
04/19 08:02:43 PM: Update 24276: task toronto_lm, batch 275 (24157): perplexity: 79.0810, toronto_lm_loss: 4.3705 ||
04/19 08:02:54 PM: Update 24290: task toronto_lm, batch 289 (24171): perplexity: 79.0327, toronto_lm_loss: 4.3699 ||
04/19 08:03:03 PM: Update 24302: task wsj, batch 2 (120): perplexity: 219.0696, wsj_loss: 5.3894 ||
04/19 08:03:04 PM: Update 24303: task toronto_lm, batch 301 (24183): perplexity: 79.1499, toronto_lm_loss: 4.3713 ||
04/19 08:03:14 PM: Update 24316: task toronto_lm, batch 314 (24196): perplexity: 79.0844, toronto_lm_loss: 4.3705 ||
04/19 08:03:24 PM: Update 24330: task toronto_lm, batch 328 (24210): perplexity: 78.9425, toronto_lm_loss: 4.3687 ||
04/19 08:03:34 PM: Update 24343: task toronto_lm, batch 341 (24223): perplexity: 78.7276, toronto_lm_loss: 4.3660 ||
04/19 08:03:45 PM: Update 24357: task toronto_lm, batch 355 (24237): perplexity: 78.7427, toronto_lm_loss: 4.3662 ||
04/19 08:03:55 PM: Update 24370: task toronto_lm, batch 368 (24250): perplexity: 78.7630, toronto_lm_loss: 4.3664 ||
04/19 08:04:05 PM: Update 24383: task toronto_lm, batch 381 (24263): perplexity: 78.6074, toronto_lm_loss: 4.3645 ||
04/19 08:04:14 PM: Update 24394: task wsj, batch 3 (121): perplexity: 248.9548, wsj_loss: 5.5173 ||
04/19 08:04:15 PM: Update 24396: task toronto_lm, batch 393 (24275): perplexity: 78.4516, toronto_lm_loss: 4.3625 ||
04/19 08:04:26 PM: Update 24409: task toronto_lm, batch 406 (24288): perplexity: 78.2606, toronto_lm_loss: 4.3600 ||
04/19 08:04:36 PM: Update 24422: task toronto_lm, batch 419 (24301): perplexity: 78.1801, toronto_lm_loss: 4.3590 ||
04/19 08:04:46 PM: Update 24435: task toronto_lm, batch 432 (24314): perplexity: 78.0719, toronto_lm_loss: 4.3576 ||
04/19 08:04:56 PM: Update 24448: task toronto_lm, batch 445 (24327): perplexity: 77.9593, toronto_lm_loss: 4.3562 ||
04/19 08:05:06 PM: Update 24461: task toronto_lm, batch 458 (24340): perplexity: 77.7331, toronto_lm_loss: 4.3533 ||
04/19 08:05:16 PM: Update 24474: task toronto_lm, batch 471 (24353): perplexity: 77.4911, toronto_lm_loss: 4.3502 ||
04/19 08:05:26 PM: Update 24487: task toronto_lm, batch 484 (24366): perplexity: 77.3693, toronto_lm_loss: 4.3486 ||
04/19 08:05:42 PM: Update 24497: task toronto_lm, batch 494 (24376): perplexity: 77.3849, toronto_lm_loss: 4.3488 ||
04/19 08:05:52 PM: Update 24510: task toronto_lm, batch 507 (24389): perplexity: 77.9012, toronto_lm_loss: 4.3554 ||
04/19 08:06:02 PM: Update 24523: task toronto_lm, batch 520 (24402): perplexity: 78.4437, toronto_lm_loss: 4.3624 ||
04/19 08:06:12 PM: Update 24536: task toronto_lm, batch 533 (24415): perplexity: 78.8115, toronto_lm_loss: 4.3671 ||
04/19 08:06:22 PM: Update 24549: task toronto_lm, batch 546 (24428): perplexity: 79.2040, toronto_lm_loss: 4.3720 ||
04/19 08:06:32 PM: Update 24562: task toronto_lm, batch 559 (24441): perplexity: 79.5097, toronto_lm_loss: 4.3759 ||
04/19 08:06:43 PM: Update 24575: task toronto_lm, batch 572 (24454): perplexity: 79.9249, toronto_lm_loss: 4.3811 ||
04/19 08:06:53 PM: Update 24588: task toronto_lm, batch 585 (24467): perplexity: 80.0207, toronto_lm_loss: 4.3823 ||
04/19 08:07:03 PM: Update 24601: task toronto_lm, batch 598 (24480): perplexity: 80.2311, toronto_lm_loss: 4.3849 ||
04/19 08:07:13 PM: Update 24615: task toronto_lm, batch 612 (24494): perplexity: 80.5073, toronto_lm_loss: 4.3883 ||
04/19 08:07:19 PM: Update 24623: task wsj, batch 4 (122): perplexity: 236.5179, wsj_loss: 5.4660 ||
04/19 08:07:24 PM: Update 24629: task toronto_lm, batch 625 (24507): perplexity: 80.6702, toronto_lm_loss: 4.3904 ||
04/19 08:07:35 PM: Update 24643: task toronto_lm, batch 639 (24521): perplexity: 80.7981, toronto_lm_loss: 4.3920 ||
04/19 08:07:45 PM: Update 24657: task toronto_lm, batch 653 (24535): perplexity: 80.8145, toronto_lm_loss: 4.3922 ||
04/19 08:07:56 PM: Update 24671: task toronto_lm, batch 667 (24549): perplexity: 80.9043, toronto_lm_loss: 4.3933 ||
04/19 08:08:07 PM: Update 24685: task toronto_lm, batch 681 (24563): perplexity: 80.9677, toronto_lm_loss: 4.3940 ||
04/19 08:08:17 PM: Update 24699: task toronto_lm, batch 695 (24577): perplexity: 81.0493, toronto_lm_loss: 4.3951 ||
04/19 08:08:28 PM: Update 24713: task toronto_lm, batch 709 (24591): perplexity: 81.2312, toronto_lm_loss: 4.3973 ||
04/19 08:08:39 PM: Update 24727: task toronto_lm, batch 723 (24605): perplexity: 81.3323, toronto_lm_loss: 4.3985 ||
04/19 08:08:49 PM: Update 24741: task toronto_lm, batch 737 (24619): perplexity: 81.3912, toronto_lm_loss: 4.3993 ||
04/19 08:09:00 PM: Update 24755: task toronto_lm, batch 751 (24633): perplexity: 81.4551, toronto_lm_loss: 4.4001 ||
04/19 08:09:11 PM: Update 24769: task toronto_lm, batch 765 (24647): perplexity: 81.4968, toronto_lm_loss: 4.4006 ||
04/19 08:09:21 PM: Update 24782: task toronto_lm, batch 778 (24660): perplexity: 81.5724, toronto_lm_loss: 4.4015 ||
04/19 08:09:32 PM: Update 24796: task toronto_lm, batch 792 (24674): perplexity: 81.5041, toronto_lm_loss: 4.4007 ||
04/19 08:09:42 PM: Update 24810: task toronto_lm, batch 806 (24688): perplexity: 81.5152, toronto_lm_loss: 4.4008 ||
04/19 08:09:53 PM: Update 24824: task toronto_lm, batch 820 (24702): perplexity: 81.4951, toronto_lm_loss: 4.4005 ||
04/19 08:10:04 PM: Update 24838: task toronto_lm, batch 834 (24716): perplexity: 81.5488, toronto_lm_loss: 4.4012 ||
04/19 08:10:14 PM: Update 24852: task toronto_lm, batch 848 (24730): perplexity: 81.4653, toronto_lm_loss: 4.4002 ||
04/19 08:10:25 PM: Update 24866: task toronto_lm, batch 862 (24744): perplexity: 81.3738, toronto_lm_loss: 4.3991 ||
04/19 08:10:36 PM: Update 24880: task toronto_lm, batch 876 (24758): perplexity: 81.3041, toronto_lm_loss: 4.3982 ||
04/19 08:10:46 PM: Update 24893: task toronto_lm, batch 889 (24771): perplexity: 81.2834, toronto_lm_loss: 4.3979 ||
04/19 08:10:56 PM: Update 24906: task toronto_lm, batch 902 (24784): perplexity: 81.2640, toronto_lm_loss: 4.3977 ||
04/19 08:11:07 PM: Update 24920: task toronto_lm, batch 916 (24798): perplexity: 81.1949, toronto_lm_loss: 4.3969 ||
04/19 08:11:18 PM: Update 24934: task toronto_lm, batch 930 (24812): perplexity: 81.1709, toronto_lm_loss: 4.3966 ||
04/19 08:11:28 PM: Update 24948: task toronto_lm, batch 944 (24826): perplexity: 81.1855, toronto_lm_loss: 4.3967 ||
04/19 08:11:39 PM: Update 24962: task toronto_lm, batch 958 (24840): perplexity: 81.2096, toronto_lm_loss: 4.3970 ||
04/19 08:11:50 PM: Update 24976: task toronto_lm, batch 972 (24854): perplexity: 81.1761, toronto_lm_loss: 4.3966 ||
04/19 08:12:00 PM: Update 24989: task toronto_lm, batch 985 (24867): perplexity: 81.1860, toronto_lm_loss: 4.3967 ||
04/19 08:12:08 PM: ***** Pass 25000 / Epoch 25 *****
04/19 08:12:08 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 08:12:08 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 08:12:08 PM: Validating...
04/19 08:12:10 PM: Batch 6/140: perplexity: 88.0932, toronto_lm_loss: 4.4784 || , for evaluation data
04/19 08:12:20 PM: Batch 44/140: perplexity: 86.9276, toronto_lm_loss: 4.4651 || , for evaluation data
04/19 08:12:30 PM: Batch 82/140: perplexity: 83.9473, toronto_lm_loss: 4.4302 || , for evaluation data
04/19 08:12:40 PM: Batch 120/140: perplexity: 80.4051, toronto_lm_loss: 4.3871 || , for evaluation data
04/19 08:12:46 PM: Batch 1/66: perplexity: 326.3891, wsj_loss: 5.7881 || , for evaluation data
04/19 08:12:56 PM: Batch 39/66: perplexity: 235.0352, wsj_loss: 5.4597 || , for evaluation data
04/19 08:13:03 PM: Best model found for wsj.
04/19 08:13:03 PM: Best model found for micro.
04/19 08:13:03 PM: Best model found for macro.
04/19 08:13:03 PM: Advancing scheduler.
04/19 08:13:03 PM: 	Best macro_avg: 0.215
04/19 08:13:03 PM: 	# bad epochs: 0
04/19 08:13:03 PM: Statistic: toronto_lm_loss
04/19 08:13:03 PM: 	training: 4.396367
04/19 08:13:03 PM: 	validation: 4.362467
04/19 08:13:03 PM: Statistic: wsj_loss
04/19 08:13:03 PM: 	training: 5.466024
04/19 08:13:03 PM: 	validation: 5.431130
04/19 08:13:03 PM: Statistic: macro_avg
04/19 08:13:03 PM: 	validation: 0.214735
04/19 08:13:03 PM: Statistic: micro_avg
04/19 08:13:03 PM: 	validation: 0.027688
04/19 08:13:03 PM: Statistic: toronto_lm_perplexity
04/19 08:13:03 PM: 	training: 81.155528
04/19 08:13:03 PM: 	validation: 78.450448
04/19 08:13:03 PM: Statistic: wsj_perplexity
04/19 08:13:03 PM: 	training: 236.517935
04/19 08:13:03 PM: 	validation: 228.407206
04/19 08:13:03 PM: global_lr: 0.001000
04/19 08:13:03 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 08:13:04 PM: Update 25001: task toronto_lm, batch 1 (24879): perplexity: 95.9966, toronto_lm_loss: 4.5643 ||
04/19 08:13:14 PM: Update 25014: task toronto_lm, batch 14 (24892): perplexity: 84.0837, toronto_lm_loss: 4.4318 ||
04/19 08:13:24 PM: Update 25027: task toronto_lm, batch 27 (24905): perplexity: 82.2351, toronto_lm_loss: 4.4096 ||
04/19 08:13:34 PM: Update 25040: task toronto_lm, batch 40 (24918): perplexity: 81.2718, toronto_lm_loss: 4.3978 ||
04/19 08:13:45 PM: Update 25054: task toronto_lm, batch 54 (24932): perplexity: 80.0873, toronto_lm_loss: 4.3831 ||
04/19 08:13:55 PM: Update 25067: task toronto_lm, batch 67 (24945): perplexity: 79.8457, toronto_lm_loss: 4.3801 ||
04/19 08:14:06 PM: Update 25081: task toronto_lm, batch 81 (24959): perplexity: 79.1211, toronto_lm_loss: 4.3710 ||
04/19 08:14:17 PM: Update 25095: task toronto_lm, batch 95 (24973): perplexity: 78.6844, toronto_lm_loss: 4.3654 ||
04/19 08:14:27 PM: Update 25108: task toronto_lm, batch 108 (24986): perplexity: 78.2993, toronto_lm_loss: 4.3605 ||
04/19 08:14:37 PM: Update 25121: task toronto_lm, batch 121 (24999): perplexity: 78.4507, toronto_lm_loss: 4.3625 ||
04/19 08:14:47 PM: Update 25126: task toronto_lm, batch 126 (25004): perplexity: 79.6023, toronto_lm_loss: 4.3770 ||
04/19 08:14:58 PM: Update 25140: task toronto_lm, batch 140 (25018): perplexity: 82.0961, toronto_lm_loss: 4.4079 ||
04/19 08:15:09 PM: Update 25154: task toronto_lm, batch 154 (25032): perplexity: 84.4576, toronto_lm_loss: 4.4362 ||
04/19 08:15:19 PM: Update 25167: task toronto_lm, batch 167 (25045): perplexity: 85.9658, toronto_lm_loss: 4.4539 ||
04/19 08:15:30 PM: Update 25181: task toronto_lm, batch 181 (25059): perplexity: 86.8114, toronto_lm_loss: 4.4637 ||
04/19 08:15:40 PM: Update 25194: task toronto_lm, batch 194 (25072): perplexity: 87.5276, toronto_lm_loss: 4.4720 ||
04/19 08:15:50 PM: Update 25207: task toronto_lm, batch 207 (25085): perplexity: 87.9680, toronto_lm_loss: 4.4770 ||
04/19 08:16:00 PM: Update 25220: task toronto_lm, batch 220 (25098): perplexity: 88.3357, toronto_lm_loss: 4.4811 ||
04/19 08:16:10 PM: Update 25233: task toronto_lm, batch 233 (25111): perplexity: 88.6817, toronto_lm_loss: 4.4851 ||
04/19 08:16:20 PM: Update 25246: task toronto_lm, batch 246 (25124): perplexity: 88.7709, toronto_lm_loss: 4.4861 ||
04/19 08:16:30 PM: Update 25259: task toronto_lm, batch 259 (25137): perplexity: 88.9413, toronto_lm_loss: 4.4880 ||
04/19 08:16:36 PM: Update 25267: task wsj, batch 1 (123): perplexity: 225.3056, wsj_loss: 5.4175 ||
04/19 08:16:40 PM: Update 25272: task toronto_lm, batch 271 (25149): perplexity: 88.8050, toronto_lm_loss: 4.4864 ||
04/19 08:16:50 PM: Update 25285: task toronto_lm, batch 284 (25162): perplexity: 88.9762, toronto_lm_loss: 4.4884 ||
04/19 08:17:00 PM: Update 25298: task toronto_lm, batch 297 (25175): perplexity: 89.1927, toronto_lm_loss: 4.4908 ||
04/19 08:17:11 PM: Update 25311: task toronto_lm, batch 310 (25188): perplexity: 88.9424, toronto_lm_loss: 4.4880 ||
04/19 08:17:21 PM: Update 25325: task toronto_lm, batch 324 (25202): perplexity: 88.7309, toronto_lm_loss: 4.4856 ||
04/19 08:17:32 PM: Update 25339: task toronto_lm, batch 338 (25216): perplexity: 88.5674, toronto_lm_loss: 4.4838 ||
04/19 08:17:43 PM: Update 25353: task toronto_lm, batch 352 (25230): perplexity: 88.7158, toronto_lm_loss: 4.4854 ||
04/19 08:17:53 PM: Update 25366: task toronto_lm, batch 365 (25243): perplexity: 88.8028, toronto_lm_loss: 4.4864 ||
04/19 08:18:03 PM: Update 25379: task toronto_lm, batch 378 (25256): perplexity: 88.8180, toronto_lm_loss: 4.4866 ||
04/19 08:18:14 PM: Update 25393: task toronto_lm, batch 392 (25270): perplexity: 88.6877, toronto_lm_loss: 4.4851 ||
04/19 08:18:24 PM: Update 25407: task toronto_lm, batch 406 (25284): perplexity: 88.6200, toronto_lm_loss: 4.4844 ||
04/19 08:18:31 PM: Update 25416: task wsj, batch 2 (124): perplexity: 236.5703, wsj_loss: 5.4662 ||
04/19 08:18:35 PM: Update 25421: task toronto_lm, batch 419 (25297): perplexity: 88.4366, toronto_lm_loss: 4.4823 ||
04/19 08:18:46 PM: Update 25435: task toronto_lm, batch 433 (25311): perplexity: 88.4836, toronto_lm_loss: 4.4828 ||
04/19 08:18:56 PM: Update 25449: task toronto_lm, batch 447 (25325): perplexity: 88.5147, toronto_lm_loss: 4.4832 ||
04/19 08:19:07 PM: Update 25463: task toronto_lm, batch 461 (25339): perplexity: 88.2202, toronto_lm_loss: 4.4798 ||
04/19 08:19:18 PM: Update 25477: task toronto_lm, batch 475 (25353): perplexity: 88.2210, toronto_lm_loss: 4.4798 ||
04/19 08:19:28 PM: Update 25491: task toronto_lm, batch 489 (25367): perplexity: 88.0108, toronto_lm_loss: 4.4775 ||
04/19 08:19:39 PM: Update 25505: task toronto_lm, batch 503 (25381): perplexity: 87.8016, toronto_lm_loss: 4.4751 ||
04/19 08:19:50 PM: Update 25519: task toronto_lm, batch 517 (25395): perplexity: 87.6855, toronto_lm_loss: 4.4738 ||
04/19 08:20:01 PM: Update 25533: task toronto_lm, batch 531 (25409): perplexity: 87.4778, toronto_lm_loss: 4.4714 ||
04/19 08:20:11 PM: Update 25547: task toronto_lm, batch 545 (25423): perplexity: 87.3991, toronto_lm_loss: 4.4705 ||
04/19 08:20:22 PM: Update 25561: task toronto_lm, batch 559 (25437): perplexity: 87.1951, toronto_lm_loss: 4.4681 ||
04/19 08:20:33 PM: Update 25575: task toronto_lm, batch 573 (25451): perplexity: 87.0671, toronto_lm_loss: 4.4667 ||
04/19 08:20:43 PM: Update 25589: task toronto_lm, batch 587 (25465): perplexity: 86.8474, toronto_lm_loss: 4.4642 ||
04/19 08:20:47 PM: Update 25594: task wsj, batch 3 (125): perplexity: 237.2098, wsj_loss: 5.4689 ||
04/19 08:20:54 PM: Update 25603: task toronto_lm, batch 600 (25478): perplexity: 86.6791, toronto_lm_loss: 4.4622 ||
04/19 08:21:05 PM: Update 25617: task toronto_lm, batch 614 (25492): perplexity: 86.5974, toronto_lm_loss: 4.4613 ||
04/19 08:21:15 PM: Update 25631: task toronto_lm, batch 628 (25506): perplexity: 86.4401, toronto_lm_loss: 4.4595 ||
04/19 08:21:26 PM: Update 25645: task toronto_lm, batch 642 (25520): perplexity: 86.1715, toronto_lm_loss: 4.4563 ||
04/19 08:21:37 PM: Update 25659: task toronto_lm, batch 656 (25534): perplexity: 86.1075, toronto_lm_loss: 4.4556 ||
04/19 08:21:47 PM: Update 25673: task toronto_lm, batch 670 (25548): perplexity: 86.0959, toronto_lm_loss: 4.4555 ||
04/19 08:21:58 PM: Update 25687: task toronto_lm, batch 684 (25562): perplexity: 86.0171, toronto_lm_loss: 4.4545 ||
04/19 08:22:03 PM: Update 25693: task wsj, batch 4 (126): perplexity: 233.8118, wsj_loss: 5.4545 ||
04/19 08:22:09 PM: Update 25701: task toronto_lm, batch 697 (25575): perplexity: 85.7755, toronto_lm_loss: 4.4517 ||
04/19 08:22:19 PM: Update 25715: task toronto_lm, batch 711 (25589): perplexity: 85.5057, toronto_lm_loss: 4.4486 ||
04/19 08:22:30 PM: Update 25729: task toronto_lm, batch 725 (25603): perplexity: 85.3351, toronto_lm_loss: 4.4466 ||
04/19 08:22:40 PM: Update 25742: task toronto_lm, batch 738 (25616): perplexity: 85.2690, toronto_lm_loss: 4.4458 ||
04/19 08:22:56 PM: Update 25752: task toronto_lm, batch 748 (25626): perplexity: 85.1671, toronto_lm_loss: 4.4446 ||
04/19 08:23:06 PM: Update 25765: task toronto_lm, batch 761 (25639): perplexity: 85.4166, toronto_lm_loss: 4.4475 ||
04/19 08:23:17 PM: Update 25779: task toronto_lm, batch 775 (25653): perplexity: 85.5921, toronto_lm_loss: 4.4496 ||
04/19 08:23:27 PM: Update 25792: task toronto_lm, batch 788 (25666): perplexity: 85.8378, toronto_lm_loss: 4.4525 ||
04/19 08:23:37 PM: Update 25806: task toronto_lm, batch 802 (25680): perplexity: 85.9614, toronto_lm_loss: 4.4539 ||
04/19 08:23:47 PM: Update 25819: task toronto_lm, batch 815 (25693): perplexity: 86.1127, toronto_lm_loss: 4.4557 ||
04/19 08:23:58 PM: Update 25833: task toronto_lm, batch 829 (25707): perplexity: 86.3220, toronto_lm_loss: 4.4581 ||
04/19 08:24:09 PM: Update 25847: task toronto_lm, batch 843 (25721): perplexity: 86.3993, toronto_lm_loss: 4.4590 ||
04/19 08:24:19 PM: Update 25860: task toronto_lm, batch 856 (25734): perplexity: 86.5070, toronto_lm_loss: 4.4602 ||
04/19 08:24:29 PM: Update 25873: task toronto_lm, batch 869 (25747): perplexity: 86.5436, toronto_lm_loss: 4.4606 ||
04/19 08:24:39 PM: Update 25886: task toronto_lm, batch 882 (25760): perplexity: 86.6291, toronto_lm_loss: 4.4616 ||
04/19 08:24:49 PM: Update 25899: task toronto_lm, batch 895 (25773): perplexity: 86.6690, toronto_lm_loss: 4.4621 ||
04/19 08:24:59 PM: Update 25912: task toronto_lm, batch 908 (25786): perplexity: 86.7453, toronto_lm_loss: 4.4630 ||
04/19 08:25:10 PM: Update 25926: task toronto_lm, batch 922 (25800): perplexity: 86.7454, toronto_lm_loss: 4.4630 ||
04/19 08:25:20 PM: Update 25939: task toronto_lm, batch 935 (25813): perplexity: 86.6800, toronto_lm_loss: 4.4622 ||
04/19 08:25:30 PM: Update 25952: task toronto_lm, batch 948 (25826): perplexity: 86.6240, toronto_lm_loss: 4.4616 ||
04/19 08:25:40 PM: Update 25965: task toronto_lm, batch 961 (25839): perplexity: 86.5968, toronto_lm_loss: 4.4613 ||
04/19 08:25:51 PM: Update 25979: task toronto_lm, batch 975 (25853): perplexity: 86.6356, toronto_lm_loss: 4.4617 ||
04/19 08:26:01 PM: Update 25993: task toronto_lm, batch 989 (25867): perplexity: 86.5958, toronto_lm_loss: 4.4613 ||
04/19 08:26:07 PM: ***** Pass 26000 / Epoch 26 *****
04/19 08:26:07 PM: toronto_lm: trained on 996 batches, 0.005 epochs
04/19 08:26:07 PM: wsj: trained on 4 batches, 0.005 epochs
04/19 08:26:07 PM: Validating...
04/19 08:26:12 PM: Batch 18/140: perplexity: 89.8561, toronto_lm_loss: 4.4982 || , for evaluation data
04/19 08:26:22 PM: Batch 57/140: perplexity: 88.6835, toronto_lm_loss: 4.4851 || , for evaluation data
04/19 08:26:32 PM: Batch 95/140: perplexity: 83.9006, toronto_lm_loss: 4.4296 || , for evaluation data
04/19 08:26:42 PM: Batch 128/140: perplexity: 80.1991, toronto_lm_loss: 4.3845 || , for evaluation data
04/19 08:26:45 PM: Batch 1/66: perplexity: 332.5288, wsj_loss: 5.8067 || , for evaluation data
04/19 08:26:55 PM: Batch 39/66: perplexity: 240.4618, wsj_loss: 5.4826 || , for evaluation data
04/19 08:27:03 PM: Advancing scheduler.
04/19 08:27:03 PM: 	Best macro_avg: 0.215
04/19 08:27:03 PM: 	# bad epochs: 1
04/19 08:27:03 PM: Statistic: toronto_lm_loss
04/19 08:27:03 PM: 	training: 4.461330
04/19 08:27:03 PM: 	validation: 4.364690
04/19 08:27:03 PM: Statistic: wsj_loss
04/19 08:27:03 PM: 	training: 5.454516
04/19 08:27:03 PM: 	validation: 5.459059
04/19 08:27:03 PM: Statistic: macro_avg
04/19 08:27:03 PM: 	validation: 0.201623
04/19 08:27:03 PM: Statistic: micro_avg
04/19 08:27:03 PM: 	validation: 0.019394
04/19 08:27:03 PM: Statistic: toronto_lm_perplexity
04/19 08:27:03 PM: 	training: 86.602616
04/19 08:27:03 PM: 	validation: 78.625014
04/19 08:27:03 PM: Statistic: wsj_perplexity
04/19 08:27:03 PM: 	training: 233.811775
04/19 08:27:03 PM: 	validation: 234.876202
04/19 08:27:03 PM: global_lr: 0.001000
04/19 08:27:03 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 08:27:04 PM: Update 26001: task toronto_lm, batch 1 (25875): perplexity: 74.0857, toronto_lm_loss: 4.3052 ||
04/19 08:27:14 PM: Update 26014: task toronto_lm, batch 14 (25888): perplexity: 85.6193, toronto_lm_loss: 4.4499 ||
04/19 08:27:24 PM: Update 26027: task toronto_lm, batch 27 (25901): perplexity: 83.5154, toronto_lm_loss: 4.4250 ||
04/19 08:27:34 PM: Update 26040: task toronto_lm, batch 40 (25914): perplexity: 83.8420, toronto_lm_loss: 4.4289 ||
04/19 08:27:38 PM: Update 26045: task wsj, batch 1 (127): perplexity: 245.2981, wsj_loss: 5.5025 ||
04/19 08:27:44 PM: Update 26053: task toronto_lm, batch 52 (25926): perplexity: 82.7096, toronto_lm_loss: 4.4153 ||
04/19 08:27:54 PM: Update 26067: task toronto_lm, batch 66 (25940): perplexity: 82.8007, toronto_lm_loss: 4.4164 ||
04/19 08:28:04 PM: Update 26080: task toronto_lm, batch 79 (25953): perplexity: 83.2600, toronto_lm_loss: 4.4220 ||
04/19 08:28:14 PM: Update 26093: task toronto_lm, batch 92 (25966): perplexity: 83.2836, toronto_lm_loss: 4.4223 ||
04/19 08:28:25 PM: Update 26107: task toronto_lm, batch 106 (25980): perplexity: 82.9903, toronto_lm_loss: 4.4187 ||
04/19 08:28:36 PM: Update 26121: task toronto_lm, batch 120 (25994): perplexity: 83.6912, toronto_lm_loss: 4.4271 ||
04/19 08:28:47 PM: Update 26135: task toronto_lm, batch 134 (26008): perplexity: 83.5028, toronto_lm_loss: 4.4249 ||
04/19 08:28:57 PM: Update 26149: task toronto_lm, batch 148 (26022): perplexity: 83.5389, toronto_lm_loss: 4.4253 ||
04/19 08:29:07 PM: Update 26162: task toronto_lm, batch 161 (26035): perplexity: 83.7064, toronto_lm_loss: 4.4273 ||
04/19 08:29:18 PM: Update 26176: task toronto_lm, batch 175 (26049): perplexity: 83.5132, toronto_lm_loss: 4.4250 ||
04/19 08:29:28 PM: Update 26189: task toronto_lm, batch 188 (26062): perplexity: 83.4856, toronto_lm_loss: 4.4247 ||
04/19 08:29:38 PM: Update 26202: task toronto_lm, batch 201 (26075): perplexity: 83.2556, toronto_lm_loss: 4.4219 ||
04/19 08:29:49 PM: Update 26216: task toronto_lm, batch 215 (26089): perplexity: 83.3883, toronto_lm_loss: 4.4235 ||
04/19 08:29:59 PM: Update 26229: task toronto_lm, batch 228 (26102): perplexity: 83.3558, toronto_lm_loss: 4.4231 ||
04/19 08:30:09 PM: Update 26242: task toronto_lm, batch 241 (26115): perplexity: 83.0506, toronto_lm_loss: 4.4195 ||
04/19 08:30:20 PM: Update 26256: task toronto_lm, batch 255 (26129): perplexity: 82.8305, toronto_lm_loss: 4.4168 ||
04/19 08:30:31 PM: Update 26270: task toronto_lm, batch 269 (26143): perplexity: 82.7583, toronto_lm_loss: 4.4159 ||
04/19 08:30:41 PM: Update 26283: task toronto_lm, batch 282 (26156): perplexity: 82.5704, toronto_lm_loss: 4.4137 ||
04/19 08:30:51 PM: Update 26296: task toronto_lm, batch 295 (26169): perplexity: 82.7049, toronto_lm_loss: 4.4153 ||
04/19 08:31:02 PM: Update 26310: task toronto_lm, batch 309 (26183): perplexity: 82.6649, toronto_lm_loss: 4.4148 ||
04/19 08:31:12 PM: Update 26324: task toronto_lm, batch 323 (26197): perplexity: 82.3365, toronto_lm_loss: 4.4108 ||
04/19 08:31:22 PM: Update 26337: task toronto_lm, batch 336 (26210): perplexity: 82.2762, toronto_lm_loss: 4.4101 ||
04/19 08:31:33 PM: Update 26351: task toronto_lm, batch 350 (26224): perplexity: 82.1398, toronto_lm_loss: 4.4084 ||
04/19 08:31:43 PM: Update 26364: task toronto_lm, batch 363 (26237): perplexity: 82.1200, toronto_lm_loss: 4.4082 ||
04/19 08:31:53 PM: Update 26377: task toronto_lm, batch 376 (26250): perplexity: 81.9903, toronto_lm_loss: 4.4066 ||
04/19 08:32:03 PM: Update 26379: task toronto_lm, batch 378 (26252): perplexity: 82.1008, toronto_lm_loss: 4.4079 ||
04/19 08:32:13 PM: Update 26392: task toronto_lm, batch 391 (26265): perplexity: 82.7396, toronto_lm_loss: 4.4157 ||
04/19 08:32:23 PM: Update 26405: task toronto_lm, batch 404 (26278): perplexity: 83.1465, toronto_lm_loss: 4.4206 ||
04/19 08:32:34 PM: Update 26419: task toronto_lm, batch 418 (26292): perplexity: 83.3777, toronto_lm_loss: 4.4234 ||
04/19 08:32:44 PM: Update 26432: task toronto_lm, batch 431 (26305): perplexity: 83.6876, toronto_lm_loss: 4.4271 ||
04/19 08:32:54 PM: Update 26445: task toronto_lm, batch 444 (26318): perplexity: 83.7603, toronto_lm_loss: 4.4280 ||
04/19 08:33:04 PM: Update 26458: task toronto_lm, batch 457 (26331): perplexity: 83.9510, toronto_lm_loss: 4.4302 ||
04/19 08:33:14 PM: Update 26471: task toronto_lm, batch 470 (26344): perplexity: 84.1249, toronto_lm_loss: 4.4323 ||
04/19 08:33:24 PM: Update 26484: task toronto_lm, batch 483 (26357): perplexity: 84.2383, toronto_lm_loss: 4.4337 ||
04/19 08:33:34 PM: Update 26497: task toronto_lm, batch 496 (26370): perplexity: 84.5060, toronto_lm_loss: 4.4368 ||
04/19 08:33:40 PM: Update 26505: task wsj, batch 2 (128): perplexity: 223.6606, wsj_loss: 5.4101 ||
04/19 08:33:45 PM: Update 26511: task toronto_lm, batch 509 (26383): perplexity: 84.6142, toronto_lm_loss: 4.4381 ||
04/19 08:33:56 PM: Update 26525: task toronto_lm, batch 523 (26397): perplexity: 84.6570, toronto_lm_loss: 4.4386 ||
04/19 08:34:06 PM: Update 26538: task toronto_lm, batch 536 (26410): perplexity: 84.6514, toronto_lm_loss: 4.4385 ||
04/19 08:34:16 PM: Update 26551: task toronto_lm, batch 549 (26423): perplexity: 84.6754, toronto_lm_loss: 4.4388 ||
04/19 08:34:27 PM: Update 26565: task toronto_lm, batch 563 (26437): perplexity: 84.5914, toronto_lm_loss: 4.4378 ||
04/19 08:34:37 PM: Update 26579: task toronto_lm, batch 577 (26451): perplexity: 84.6021, toronto_lm_loss: 4.4380 ||
04/19 08:34:47 PM: Update 26592: task toronto_lm, batch 590 (26464): perplexity: 84.5557, toronto_lm_loss: 4.4374 ||
04/19 08:34:58 PM: Update 26606: task toronto_lm, batch 604 (26478): perplexity: 84.5191, toronto_lm_loss: 4.4370 ||
04/19 08:35:08 PM: Update 26619: task toronto_lm, batch 617 (26491): perplexity: 84.4478, toronto_lm_loss: 4.4361 ||
04/19 08:35:19 PM: Update 26633: task toronto_lm, batch 631 (26505): perplexity: 84.4039, toronto_lm_loss: 4.4356 ||
04/19 08:35:29 PM: Update 26646: task toronto_lm, batch 644 (26518): perplexity: 84.3387, toronto_lm_loss: 4.4348 ||
04/19 08:35:39 PM: Update 26659: task toronto_lm, batch 657 (26531): perplexity: 84.3351, toronto_lm_loss: 4.4348 ||
04/19 08:35:49 PM: Update 26672: task toronto_lm, batch 670 (26544): perplexity: 84.3245, toronto_lm_loss: 4.4347 ||
04/19 08:35:54 PM: Update 26678: task wsj, batch 3 (129): perplexity: 225.6102, wsj_loss: 5.4188 ||
04/19 08:35:59 PM: Update 26685: task toronto_lm, batch 682 (26556): perplexity: 84.2649, toronto_lm_loss: 4.4340 ||
04/19 08:36:09 PM: Update 26698: task toronto_lm, batch 695 (26569): perplexity: 84.2005, toronto_lm_loss: 4.4332 ||
04/19 08:36:20 PM: Update 26712: task toronto_lm, batch 709 (26583): perplexity: 84.1323, toronto_lm_loss: 4.4324 ||
04/19 08:36:30 PM: Update 26725: task toronto_lm, batch 722 (26596): perplexity: 84.1255, toronto_lm_loss: 4.4323 ||
04/19 08:36:40 PM: Update 26738: task toronto_lm, batch 735 (26609): perplexity: 84.0470, toronto_lm_loss: 4.4314 ||
04/19 08:36:50 PM: Update 26751: task toronto_lm, batch 748 (26622): perplexity: 84.0040, toronto_lm_loss: 4.4309 ||
04/19 08:37:01 PM: Update 26765: task toronto_lm, batch 762 (26636): perplexity: 83.9614, toronto_lm_loss: 4.4304 ||
04/19 08:37:12 PM: Update 26779: task toronto_lm, batch 776 (26650): perplexity: 83.7626, toronto_lm_loss: 4.4280 ||
04/19 08:37:22 PM: Update 26792: task toronto_lm, batch 789 (26663): perplexity: 83.6921, toronto_lm_loss: 4.4271 ||
04/19 08:37:32 PM: Update 26805: task toronto_lm, batch 802 (26676): perplexity: 83.6376, toronto_lm_loss: 4.4265 ||
04/19 08:37:42 PM: Update 26818: task toronto_lm, batch 815 (26689): perplexity: 83.5704, toronto_lm_loss: 4.4257 ||
04/19 08:37:53 PM: Update 26832: task toronto_lm, batch 829 (26703): perplexity: 83.5253, toronto_lm_loss: 4.4251 ||
04/19 08:38:03 PM: Update 26845: task toronto_lm, batch 842 (26716): perplexity: 83.4803, toronto_lm_loss: 4.4246 ||
04/19 08:38:13 PM: Update 26858: task toronto_lm, batch 855 (26729): perplexity: 83.3381, toronto_lm_loss: 4.4229 ||
04/19 08:38:23 PM: Update 26871: task toronto_lm, batch 868 (26742): perplexity: 83.2091, toronto_lm_loss: 4.4214 ||
04/19 08:38:33 PM: Update 26884: task toronto_lm, batch 881 (26755): perplexity: 83.1384, toronto_lm_loss: 4.4205 ||
04/19 08:38:43 PM: Update 26897: task toronto_lm, batch 894 (26768): perplexity: 83.0331, toronto_lm_loss: 4.4192 ||
04/19 08:38:53 PM: Update 26910: task toronto_lm, batch 907 (26781): perplexity: 82.9913, toronto_lm_loss: 4.4187 ||
04/19 08:39:03 PM: Update 26923: task toronto_lm, batch 920 (26794): perplexity: 82.9460, toronto_lm_loss: 4.4182 ||
04/19 08:39:13 PM: Update 26936: task toronto_lm, batch 933 (26807): perplexity: 82.9019, toronto_lm_loss: 4.4177 ||
04/19 08:39:24 PM: Update 26949: task toronto_lm, batch 946 (26820): perplexity: 82.8621, toronto_lm_loss: 4.4172 ||
04/19 08:39:34 PM: Update 26963: task toronto_lm, batch 960 (26834): perplexity: 82.8110, toronto_lm_loss: 4.4166 ||
04/19 08:39:44 PM: Update 26976: task toronto_lm, batch 973 (26847): perplexity: 82.7859, toronto_lm_loss: 4.4163 ||
04/19 08:39:55 PM: Update 26989: task toronto_lm, batch 986 (26860): perplexity: 82.7580, toronto_lm_loss: 4.4159 ||
04/19 08:40:03 PM: ***** Pass 27000 / Epoch 27 *****
04/19 08:40:03 PM: toronto_lm: trained on 997 batches, 0.005 epochs
04/19 08:40:03 PM: wsj: trained on 3 batches, 0.004 epochs
04/19 08:40:03 PM: Validating...
04/19 08:40:05 PM: Batch 6/140: perplexity: 95.2276, toronto_lm_loss: 4.5563 || , for evaluation data
04/19 08:40:15 PM: Batch 45/140: perplexity: 96.6919, toronto_lm_loss: 4.5715 || , for evaluation data
04/19 08:40:25 PM: Batch 83/140: perplexity: 91.4123, toronto_lm_loss: 4.5154 || , for evaluation data
04/19 08:40:35 PM: Batch 121/140: perplexity: 85.8982, toronto_lm_loss: 4.4532 || , for evaluation data
04/19 08:40:40 PM: Batch 1/66: perplexity: 329.7620, wsj_loss: 5.7984 || , for evaluation data
04/19 08:40:50 PM: Batch 40/66: perplexity: 231.9885, wsj_loss: 5.4467 || , for evaluation data
04/19 08:40:57 PM: Out of patience. Stopped tracking toronto_lm
04/19 08:40:57 PM: Advancing scheduler.
04/19 08:40:57 PM: 	Best macro_avg: 0.215
04/19 08:40:57 PM: 	# bad epochs: 2
04/19 08:40:57 PM: Statistic: toronto_lm_loss
04/19 08:40:57 PM: 	training: 4.415350
04/19 08:40:57 PM: 	validation: 4.429689
04/19 08:40:57 PM: Statistic: wsj_loss
04/19 08:40:57 PM: 	training: 5.418809
04/19 08:40:57 PM: 	validation: 5.437800
04/19 08:40:57 PM: Statistic: macro_avg
04/19 08:40:57 PM: 	validation: 0.206223
04/19 08:40:57 PM: Statistic: micro_avg
04/19 08:40:57 PM: 	validation: 0.025728
04/19 08:40:57 PM: Statistic: toronto_lm_perplexity
04/19 08:40:57 PM: 	training: 82.710788
04/19 08:40:57 PM: 	validation: 83.905348
04/19 08:40:57 PM: Statistic: wsj_perplexity
04/19 08:40:57 PM: 	training: 225.610175
04/19 08:40:57 PM: 	validation: 229.935677
04/19 08:40:57 PM: global_lr: 0.001000
04/19 08:40:57 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 08:40:58 PM: Update 27001: task toronto_lm, batch 1 (26872): perplexity: 67.5528, toronto_lm_loss: 4.2129 ||
04/19 08:41:08 PM: Update 27005: task toronto_lm, batch 5 (26876): perplexity: 75.2180, toronto_lm_loss: 4.3204 ||
04/19 08:41:18 PM: Update 27018: task toronto_lm, batch 18 (26889): perplexity: 95.8295, toronto_lm_loss: 4.5626 ||
04/19 08:41:28 PM: Update 27031: task toronto_lm, batch 31 (26902): perplexity: 96.4961, toronto_lm_loss: 4.5695 ||
04/19 08:41:38 PM: Update 27044: task toronto_lm, batch 44 (26915): perplexity: 97.9428, toronto_lm_loss: 4.5844 ||
04/19 08:41:49 PM: Update 27057: task toronto_lm, batch 57 (26928): perplexity: 96.5822, toronto_lm_loss: 4.5704 ||
04/19 08:41:59 PM: Update 27070: task toronto_lm, batch 70 (26941): perplexity: 96.2789, toronto_lm_loss: 4.5672 ||
04/19 08:42:09 PM: Update 27084: task toronto_lm, batch 84 (26955): perplexity: 94.7741, toronto_lm_loss: 4.5515 ||
04/19 08:42:20 PM: Update 27098: task toronto_lm, batch 98 (26969): perplexity: 93.9710, toronto_lm_loss: 4.5430 ||
04/19 08:42:30 PM: Update 27111: task toronto_lm, batch 111 (26982): perplexity: 92.8236, toronto_lm_loss: 4.5307 ||
04/19 08:42:40 PM: Update 27124: task toronto_lm, batch 124 (26995): perplexity: 92.8134, toronto_lm_loss: 4.5306 ||
04/19 08:42:50 PM: Update 27137: task toronto_lm, batch 137 (27008): perplexity: 91.9962, toronto_lm_loss: 4.5217 ||
04/19 08:43:00 PM: Update 27150: task toronto_lm, batch 150 (27021): perplexity: 91.1506, toronto_lm_loss: 4.5125 ||
04/19 08:43:10 PM: Update 27163: task toronto_lm, batch 163 (27034): perplexity: 91.2582, toronto_lm_loss: 4.5137 ||
04/19 08:43:21 PM: Update 27176: task toronto_lm, batch 176 (27047): perplexity: 90.2822, toronto_lm_loss: 4.5029 ||
04/19 08:43:31 PM: Update 27189: task toronto_lm, batch 189 (27060): perplexity: 89.9798, toronto_lm_loss: 4.4996 ||
04/19 08:43:41 PM: Update 27202: task toronto_lm, batch 202 (27073): perplexity: 89.5817, toronto_lm_loss: 4.4952 ||
04/19 08:43:51 PM: Update 27215: task toronto_lm, batch 215 (27086): perplexity: 89.0386, toronto_lm_loss: 4.4891 ||
04/19 08:44:01 PM: Update 27228: task toronto_lm, batch 228 (27099): perplexity: 88.8298, toronto_lm_loss: 4.4867 ||
04/19 08:44:11 PM: Update 27241: task toronto_lm, batch 241 (27112): perplexity: 88.4309, toronto_lm_loss: 4.4822 ||
04/19 08:44:21 PM: Update 27254: task toronto_lm, batch 254 (27125): perplexity: 87.9694, toronto_lm_loss: 4.4770 ||
04/19 08:44:31 PM: Update 27267: task toronto_lm, batch 267 (27138): perplexity: 87.6380, toronto_lm_loss: 4.4732 ||
04/19 08:44:41 PM: Update 27280: task toronto_lm, batch 280 (27151): perplexity: 87.2532, toronto_lm_loss: 4.4688 ||
04/19 08:44:51 PM: Update 27293: task toronto_lm, batch 293 (27164): perplexity: 86.6940, toronto_lm_loss: 4.4624 ||
04/19 08:45:01 PM: Update 27306: task toronto_lm, batch 306 (27177): perplexity: 86.3342, toronto_lm_loss: 4.4582 ||
04/19 08:45:11 PM: Update 27319: task toronto_lm, batch 319 (27190): perplexity: 85.9700, toronto_lm_loss: 4.4540 ||
04/19 08:45:22 PM: Update 27332: task toronto_lm, batch 332 (27203): perplexity: 85.7214, toronto_lm_loss: 4.4511 ||
04/19 08:45:32 PM: Update 27345: task toronto_lm, batch 345 (27216): perplexity: 85.2375, toronto_lm_loss: 4.4454 ||
04/19 08:45:42 PM: Update 27358: task toronto_lm, batch 358 (27229): perplexity: 84.9260, toronto_lm_loss: 4.4418 ||
04/19 08:45:52 PM: Update 27371: task toronto_lm, batch 371 (27242): perplexity: 84.5410, toronto_lm_loss: 4.4372 ||
04/19 08:46:02 PM: Update 27384: task toronto_lm, batch 384 (27255): perplexity: 84.2328, toronto_lm_loss: 4.4336 ||
04/19 08:46:12 PM: Update 27397: task toronto_lm, batch 397 (27268): perplexity: 83.9193, toronto_lm_loss: 4.4299 ||
04/19 08:46:22 PM: Update 27410: task toronto_lm, batch 410 (27281): perplexity: 83.5747, toronto_lm_loss: 4.4257 ||
04/19 08:46:32 PM: Update 27423: task toronto_lm, batch 423 (27294): perplexity: 83.4023, toronto_lm_loss: 4.4237 ||
04/19 08:46:43 PM: Update 27437: task toronto_lm, batch 437 (27308): perplexity: 83.0788, toronto_lm_loss: 4.4198 ||
04/19 08:46:53 PM: Update 27450: task toronto_lm, batch 450 (27321): perplexity: 82.7407, toronto_lm_loss: 4.4157 ||
04/19 08:47:03 PM: Update 27463: task toronto_lm, batch 463 (27334): perplexity: 82.6709, toronto_lm_loss: 4.4149 ||
04/19 08:47:13 PM: Update 27477: task toronto_lm, batch 477 (27348): perplexity: 82.5272, toronto_lm_loss: 4.4131 ||
04/19 08:47:24 PM: Update 27490: task toronto_lm, batch 490 (27361): perplexity: 82.2957, toronto_lm_loss: 4.4103 ||
04/19 08:47:34 PM: Update 27503: task toronto_lm, batch 503 (27374): perplexity: 82.0843, toronto_lm_loss: 4.4077 ||
04/19 08:47:42 PM: Update 27514: task wsj, batch 1 (130): perplexity: 233.0114, wsj_loss: 5.4511 ||
04/19 08:47:44 PM: Update 27516: task toronto_lm, batch 515 (27386): perplexity: 81.9192, toronto_lm_loss: 4.4057 ||
04/19 08:47:54 PM: Update 27529: task toronto_lm, batch 528 (27399): perplexity: 81.6923, toronto_lm_loss: 4.4030 ||
04/19 08:48:04 PM: Update 27542: task toronto_lm, batch 541 (27412): perplexity: 81.4730, toronto_lm_loss: 4.4003 ||
04/19 08:48:14 PM: Update 27555: task toronto_lm, batch 554 (27425): perplexity: 81.3605, toronto_lm_loss: 4.3989 ||
04/19 08:48:24 PM: Update 27568: task toronto_lm, batch 567 (27438): perplexity: 81.1451, toronto_lm_loss: 4.3962 ||
04/19 08:48:34 PM: Update 27581: task toronto_lm, batch 580 (27451): perplexity: 80.9442, toronto_lm_loss: 4.3938 ||
04/19 08:48:44 PM: Update 27594: task toronto_lm, batch 593 (27464): perplexity: 80.7923, toronto_lm_loss: 4.3919 ||
04/19 08:48:54 PM: Update 27607: task toronto_lm, batch 606 (27477): perplexity: 80.6323, toronto_lm_loss: 4.3899 ||
04/19 08:49:04 PM: Update 27620: task toronto_lm, batch 619 (27490): perplexity: 80.3751, toronto_lm_loss: 4.3867 ||
04/19 08:49:21 PM: Update 27631: task toronto_lm, batch 630 (27501): perplexity: 80.2054, toronto_lm_loss: 4.3846 ||
04/19 08:49:31 PM: Update 27644: task toronto_lm, batch 643 (27514): perplexity: 80.5685, toronto_lm_loss: 4.3891 ||
04/19 08:49:42 PM: Update 27658: task toronto_lm, batch 657 (27528): perplexity: 81.0945, toronto_lm_loss: 4.3956 ||
04/19 08:49:52 PM: Update 27671: task toronto_lm, batch 670 (27541): perplexity: 81.4564, toronto_lm_loss: 4.4001 ||
04/19 08:50:02 PM: Update 27684: task toronto_lm, batch 683 (27554): perplexity: 81.6869, toronto_lm_loss: 4.4029 ||
04/19 08:50:13 PM: Update 27698: task toronto_lm, batch 697 (27568): perplexity: 81.8988, toronto_lm_loss: 4.4055 ||
04/19 08:50:24 PM: Update 27712: task toronto_lm, batch 711 (27582): perplexity: 82.0883, toronto_lm_loss: 4.4078 ||
04/19 08:50:34 PM: Update 27726: task toronto_lm, batch 725 (27596): perplexity: 82.2402, toronto_lm_loss: 4.4096 ||
04/19 08:50:44 PM: Update 27739: task toronto_lm, batch 738 (27609): perplexity: 82.2186, toronto_lm_loss: 4.4094 ||
04/19 08:50:54 PM: Update 27752: task wsj, batch 2 (131): perplexity: 203.9691, wsj_loss: 5.3180 ||
04/19 08:50:55 PM: Update 27753: task toronto_lm, batch 751 (27622): perplexity: 82.1748, toronto_lm_loss: 4.4088 ||
04/19 08:51:06 PM: Update 27767: task toronto_lm, batch 765 (27636): perplexity: 82.3175, toronto_lm_loss: 4.4106 ||
04/19 08:51:12 PM: Update 27775: task wsj, batch 3 (132): perplexity: 213.2500, wsj_loss: 5.3625 ||
04/19 08:51:16 PM: Update 27780: task toronto_lm, batch 777 (27648): perplexity: 82.3586, toronto_lm_loss: 4.4111 ||
04/19 08:51:26 PM: Update 27793: task toronto_lm, batch 790 (27661): perplexity: 82.4124, toronto_lm_loss: 4.4117 ||
04/19 08:51:36 PM: Update 27806: task toronto_lm, batch 803 (27674): perplexity: 82.4833, toronto_lm_loss: 4.4126 ||
04/19 08:51:46 PM: Update 27819: task toronto_lm, batch 816 (27687): perplexity: 82.5266, toronto_lm_loss: 4.4131 ||
04/19 08:51:56 PM: Update 27832: task toronto_lm, batch 829 (27700): perplexity: 82.4781, toronto_lm_loss: 4.4125 ||
04/19 08:52:06 PM: Update 27845: task toronto_lm, batch 842 (27713): perplexity: 82.5364, toronto_lm_loss: 4.4132 ||
04/19 08:52:16 PM: Update 27858: task toronto_lm, batch 855 (27726): perplexity: 82.5163, toronto_lm_loss: 4.4130 ||
04/19 08:52:27 PM: Update 27872: task toronto_lm, batch 869 (27740): perplexity: 82.5274, toronto_lm_loss: 4.4131 ||
04/19 08:52:38 PM: Update 27886: task toronto_lm, batch 883 (27754): perplexity: 82.4526, toronto_lm_loss: 4.4122 ||
04/19 08:52:48 PM: Update 27899: task toronto_lm, batch 896 (27767): perplexity: 82.5074, toronto_lm_loss: 4.4129 ||
04/19 08:52:58 PM: Update 27913: task toronto_lm, batch 910 (27781): perplexity: 82.4898, toronto_lm_loss: 4.4127 ||
04/19 08:53:09 PM: Update 27927: task toronto_lm, batch 924 (27795): perplexity: 82.4166, toronto_lm_loss: 4.4118 ||
04/19 08:53:19 PM: Update 27940: task toronto_lm, batch 937 (27808): perplexity: 82.3557, toronto_lm_loss: 4.4110 ||
04/19 08:53:30 PM: Update 27954: task toronto_lm, batch 951 (27822): perplexity: 82.2669, toronto_lm_loss: 4.4100 ||
04/19 08:53:40 PM: Update 27967: task toronto_lm, batch 964 (27835): perplexity: 82.2346, toronto_lm_loss: 4.4096 ||
04/19 08:53:50 PM: Update 27980: task toronto_lm, batch 977 (27848): perplexity: 82.1535, toronto_lm_loss: 4.4086 ||
04/19 08:54:00 PM: Update 27993: task toronto_lm, batch 990 (27861): perplexity: 82.1666, toronto_lm_loss: 4.4087 ||
04/19 08:54:06 PM: ***** Pass 28000 / Epoch 28 *****
04/19 08:54:06 PM: toronto_lm: trained on 997 batches, 0.005 epochs
04/19 08:54:06 PM: wsj: trained on 3 batches, 0.004 epochs
04/19 08:54:06 PM: Validating...
04/19 08:54:10 PM: Batch 18/140: perplexity: 97.5631, toronto_lm_loss: 4.5805 || , for evaluation data
04/19 08:54:20 PM: Batch 57/140: perplexity: 96.3070, toronto_lm_loss: 4.5675 || , for evaluation data
04/19 08:54:30 PM: Batch 96/140: perplexity: 89.2602, toronto_lm_loss: 4.4916 || , for evaluation data
04/19 08:54:41 PM: Batch 130/140: perplexity: 83.9936, toronto_lm_loss: 4.4307 || , for evaluation data
04/19 08:54:43 PM: Batch 1/66: perplexity: 336.5548, wsj_loss: 5.8188 || , for evaluation data
04/19 08:54:54 PM: Batch 40/66: perplexity: 236.9018, wsj_loss: 5.4676 || , for evaluation data
04/19 08:55:00 PM: Advancing scheduler.
04/19 08:55:00 PM: 	Best macro_avg: 0.215
04/19 08:55:00 PM: 	# bad epochs: 3
04/19 08:55:00 PM: Statistic: toronto_lm_loss
04/19 08:55:00 PM: 	training: 4.408294
04/19 08:55:00 PM: 	validation: 4.415148
04/19 08:55:00 PM: Statistic: wsj_loss
04/19 08:55:00 PM: 	training: 5.362465
04/19 08:55:00 PM: 	validation: 5.463638
04/19 08:55:00 PM: Statistic: macro_avg
04/19 08:55:00 PM: 	validation: 0.195397
04/19 08:55:00 PM: Statistic: micro_avg
04/19 08:55:00 PM: 	validation: 0.018012
04/19 08:55:00 PM: Statistic: toronto_lm_perplexity
04/19 08:55:00 PM: 	training: 82.129260
04/19 08:55:00 PM: 	validation: 82.694090
04/19 08:55:00 PM: Statistic: wsj_perplexity
04/19 08:55:00 PM: 	training: 213.249974
04/19 08:55:00 PM: 	validation: 235.954226
04/19 08:55:00 PM: global_lr: 0.001000
04/19 08:55:01 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 08:55:01 PM: Update 28001: task toronto_lm, batch 1 (27869): perplexity: 90.5043, toronto_lm_loss: 4.5054 ||
04/19 08:55:11 PM: Update 28014: task toronto_lm, batch 14 (27882): perplexity: 80.5130, toronto_lm_loss: 4.3884 ||
04/19 08:55:22 PM: Update 28027: task toronto_lm, batch 27 (27895): perplexity: 82.4284, toronto_lm_loss: 4.4119 ||
04/19 08:55:32 PM: Update 28040: task toronto_lm, batch 40 (27908): perplexity: 82.0958, toronto_lm_loss: 4.4079 ||
04/19 08:55:42 PM: Update 28053: task toronto_lm, batch 53 (27921): perplexity: 81.3193, toronto_lm_loss: 4.3984 ||
04/19 08:55:45 PM: Update 28058: task wsj, batch 1 (133): perplexity: 259.8502, wsj_loss: 5.5601 ||
04/19 08:55:52 PM: Update 28067: task toronto_lm, batch 66 (27934): perplexity: 81.5607, toronto_lm_loss: 4.4013 ||
04/19 08:56:02 PM: Update 28080: task toronto_lm, batch 79 (27947): perplexity: 80.1826, toronto_lm_loss: 4.3843 ||
04/19 08:56:13 PM: Update 28094: task toronto_lm, batch 93 (27961): perplexity: 79.8657, toronto_lm_loss: 4.3803 ||
04/19 08:56:23 PM: Update 28107: task toronto_lm, batch 106 (27974): perplexity: 79.4154, toronto_lm_loss: 4.3747 ||
04/19 08:56:34 PM: Update 28121: task toronto_lm, batch 120 (27988): perplexity: 78.6310, toronto_lm_loss: 4.3648 ||
04/19 08:56:44 PM: Update 28135: task toronto_lm, batch 134 (28002): perplexity: 78.5265, toronto_lm_loss: 4.3634 ||
04/19 08:56:55 PM: Update 28149: task toronto_lm, batch 148 (28016): perplexity: 78.7697, toronto_lm_loss: 4.3665 ||
04/19 08:57:06 PM: Update 28163: task toronto_lm, batch 162 (28030): perplexity: 78.4608, toronto_lm_loss: 4.3626 ||
04/19 08:57:16 PM: Update 28176: task toronto_lm, batch 175 (28043): perplexity: 78.3244, toronto_lm_loss: 4.3609 ||
04/19 08:57:27 PM: Update 28190: task toronto_lm, batch 189 (28057): perplexity: 78.2987, toronto_lm_loss: 4.3605 ||
04/19 08:57:37 PM: Update 28204: task toronto_lm, batch 203 (28071): perplexity: 78.3313, toronto_lm_loss: 4.3609 ||
04/19 08:57:48 PM: Update 28218: task toronto_lm, batch 217 (28085): perplexity: 78.2693, toronto_lm_loss: 4.3602 ||
04/19 08:57:59 PM: Update 28232: task toronto_lm, batch 231 (28099): perplexity: 78.3649, toronto_lm_loss: 4.3614 ||
04/19 08:58:10 PM: Update 28246: task toronto_lm, batch 245 (28113): perplexity: 78.7461, toronto_lm_loss: 4.3662 ||
04/19 08:58:26 PM: Update 28259: task toronto_lm, batch 258 (28126): perplexity: 78.7287, toronto_lm_loss: 4.3660 ||
04/19 08:58:37 PM: Update 28273: task toronto_lm, batch 272 (28140): perplexity: 80.3719, toronto_lm_loss: 4.3867 ||
04/19 08:58:48 PM: Update 28287: task toronto_lm, batch 286 (28154): perplexity: 81.2394, toronto_lm_loss: 4.3974 ||
04/19 08:58:58 PM: Update 28300: task toronto_lm, batch 299 (28167): perplexity: 82.0938, toronto_lm_loss: 4.4079 ||
04/19 08:59:09 PM: Update 28314: task toronto_lm, batch 313 (28181): perplexity: 82.8096, toronto_lm_loss: 4.4165 ||
04/19 08:59:19 PM: Update 28327: task toronto_lm, batch 326 (28194): perplexity: 83.2905, toronto_lm_loss: 4.4223 ||
04/19 08:59:29 PM: Update 28341: task toronto_lm, batch 340 (28208): perplexity: 83.4344, toronto_lm_loss: 4.4241 ||
04/19 08:59:39 PM: Update 28354: task toronto_lm, batch 353 (28221): perplexity: 83.6127, toronto_lm_loss: 4.4262 ||
04/19 08:59:49 PM: Update 28367: task toronto_lm, batch 366 (28234): perplexity: 83.6696, toronto_lm_loss: 4.4269 ||
04/19 09:00:00 PM: Update 28381: task toronto_lm, batch 380 (28248): perplexity: 83.8495, toronto_lm_loss: 4.4290 ||
04/19 09:00:10 PM: Update 28394: task toronto_lm, batch 393 (28261): perplexity: 83.7195, toronto_lm_loss: 4.4275 ||
04/19 09:00:21 PM: Update 28408: task toronto_lm, batch 407 (28275): perplexity: 83.8940, toronto_lm_loss: 4.4296 ||
04/19 09:00:31 PM: Update 28421: task toronto_lm, batch 420 (28288): perplexity: 83.8446, toronto_lm_loss: 4.4290 ||
04/19 09:00:41 PM: Update 28434: task toronto_lm, batch 433 (28301): perplexity: 83.9112, toronto_lm_loss: 4.4298 ||
04/19 09:00:44 PM: Update 28438: task wsj, batch 2 (134): perplexity: 222.9683, wsj_loss: 5.4070 ||
04/19 09:00:51 PM: Update 28447: task toronto_lm, batch 445 (28313): perplexity: 83.9336, toronto_lm_loss: 4.4300 ||
04/19 09:01:01 PM: Update 28460: task toronto_lm, batch 458 (28326): perplexity: 83.7939, toronto_lm_loss: 4.4284 ||
04/19 09:01:11 PM: Update 28473: task toronto_lm, batch 471 (28339): perplexity: 83.7766, toronto_lm_loss: 4.4282 ||
04/19 09:01:21 PM: Update 28486: task toronto_lm, batch 484 (28352): perplexity: 83.9030, toronto_lm_loss: 4.4297 ||
04/19 09:01:26 PM: Update 28492: task wsj, batch 3 (135): perplexity: 220.4299, wsj_loss: 5.3956 ||
04/19 09:01:31 PM: Update 28499: task toronto_lm, batch 496 (28364): perplexity: 83.7066, toronto_lm_loss: 4.4273 ||
04/19 09:01:42 PM: Update 28513: task toronto_lm, batch 510 (28378): perplexity: 83.4698, toronto_lm_loss: 4.4245 ||
04/19 09:01:52 PM: Update 28526: task toronto_lm, batch 523 (28391): perplexity: 83.4453, toronto_lm_loss: 4.4242 ||
04/19 09:02:03 PM: Update 28540: task toronto_lm, batch 537 (28405): perplexity: 83.2383, toronto_lm_loss: 4.4217 ||
04/19 09:02:14 PM: Update 28554: task toronto_lm, batch 551 (28419): perplexity: 83.1040, toronto_lm_loss: 4.4201 ||
04/19 09:02:18 PM: Update 28560: task wsj, batch 4 (136): perplexity: 229.0387, wsj_loss: 5.4339 ||
04/19 09:02:24 PM: Update 28567: task toronto_lm, batch 562 (28430): perplexity: 82.9848, toronto_lm_loss: 4.4187 ||
04/19 09:02:30 PM: Update 28575: task wsj, batch 6 (138): perplexity: 237.2788, wsj_loss: 5.4692 ||
04/19 09:02:34 PM: Update 28581: task toronto_lm, batch 575 (28443): perplexity: 82.8721, toronto_lm_loss: 4.4173 ||
04/19 09:02:45 PM: Update 28595: task toronto_lm, batch 589 (28457): perplexity: 82.7191, toronto_lm_loss: 4.4155 ||
04/19 09:02:56 PM: Update 28609: task toronto_lm, batch 603 (28471): perplexity: 82.6255, toronto_lm_loss: 4.4143 ||
04/19 09:03:06 PM: Update 28623: task toronto_lm, batch 617 (28485): perplexity: 82.2892, toronto_lm_loss: 4.4102 ||
04/19 09:03:16 PM: Update 28636: task toronto_lm, batch 630 (28498): perplexity: 82.0522, toronto_lm_loss: 4.4074 ||
04/19 09:03:26 PM: Update 28649: task toronto_lm, batch 643 (28511): perplexity: 81.8372, toronto_lm_loss: 4.4047 ||
04/19 09:03:37 PM: Update 28663: task toronto_lm, batch 657 (28525): perplexity: 81.7192, toronto_lm_loss: 4.4033 ||
04/19 09:03:48 PM: Update 28677: task toronto_lm, batch 671 (28539): perplexity: 81.5901, toronto_lm_loss: 4.4017 ||
04/19 09:03:59 PM: Update 28691: task toronto_lm, batch 685 (28553): perplexity: 81.3672, toronto_lm_loss: 4.3990 ||
04/19 09:04:09 PM: Update 28704: task toronto_lm, batch 698 (28566): perplexity: 81.2046, toronto_lm_loss: 4.3970 ||
04/19 09:04:19 PM: Update 28717: task toronto_lm, batch 711 (28579): perplexity: 81.0728, toronto_lm_loss: 4.3953 ||
04/19 09:04:29 PM: Update 28730: task toronto_lm, batch 724 (28592): perplexity: 80.9129, toronto_lm_loss: 4.3934 ||
04/19 09:04:39 PM: Update 28743: task toronto_lm, batch 737 (28605): perplexity: 80.8213, toronto_lm_loss: 4.3922 ||
04/19 09:04:49 PM: Update 28756: task toronto_lm, batch 750 (28618): perplexity: 80.8102, toronto_lm_loss: 4.3921 ||
04/19 09:04:59 PM: Update 28769: task toronto_lm, batch 763 (28631): perplexity: 80.6549, toronto_lm_loss: 4.3902 ||
04/19 09:05:09 PM: Update 28782: task toronto_lm, batch 776 (28644): perplexity: 80.5354, toronto_lm_loss: 4.3887 ||
04/19 09:05:19 PM: Update 28795: task toronto_lm, batch 789 (28657): perplexity: 80.5211, toronto_lm_loss: 4.3885 ||
04/19 09:05:29 PM: Update 28808: task toronto_lm, batch 802 (28670): perplexity: 80.3718, toronto_lm_loss: 4.3867 ||
04/19 09:05:40 PM: Update 28821: task toronto_lm, batch 815 (28683): perplexity: 80.2112, toronto_lm_loss: 4.3847 ||
04/19 09:05:50 PM: Update 28834: task toronto_lm, batch 828 (28696): perplexity: 80.0815, toronto_lm_loss: 4.3830 ||
04/19 09:06:00 PM: Update 28847: task toronto_lm, batch 841 (28709): perplexity: 79.9953, toronto_lm_loss: 4.3820 ||
04/19 09:06:10 PM: Update 28860: task toronto_lm, batch 854 (28722): perplexity: 79.8459, toronto_lm_loss: 4.3801 ||
04/19 09:06:21 PM: Update 28873: task toronto_lm, batch 867 (28735): perplexity: 79.7384, toronto_lm_loss: 4.3788 ||
04/19 09:06:31 PM: Update 28886: task toronto_lm, batch 880 (28748): perplexity: 79.5607, toronto_lm_loss: 4.3765 ||
04/19 09:06:41 PM: Update 28889: task toronto_lm, batch 883 (28751): perplexity: 79.6234, toronto_lm_loss: 4.3773 ||
04/19 09:06:51 PM: Update 28902: task toronto_lm, batch 896 (28764): perplexity: 80.0308, toronto_lm_loss: 4.3824 ||
04/19 09:07:01 PM: Update 28915: task toronto_lm, batch 909 (28777): perplexity: 80.2942, toronto_lm_loss: 4.3857 ||
04/19 09:07:11 PM: Update 28928: task toronto_lm, batch 922 (28790): perplexity: 80.5523, toronto_lm_loss: 4.3889 ||
04/19 09:07:22 PM: Update 28942: task toronto_lm, batch 936 (28804): perplexity: 80.8115, toronto_lm_loss: 4.3921 ||
04/19 09:07:33 PM: Update 28956: task toronto_lm, batch 950 (28818): perplexity: 81.0299, toronto_lm_loss: 4.3948 ||
04/19 09:07:43 PM: Update 28969: task toronto_lm, batch 963 (28831): perplexity: 81.1471, toronto_lm_loss: 4.3963 ||
04/19 09:07:53 PM: Update 28982: task toronto_lm, batch 976 (28844): perplexity: 81.2346, toronto_lm_loss: 4.3973 ||
04/19 09:08:03 PM: Update 28995: task toronto_lm, batch 989 (28857): perplexity: 81.3472, toronto_lm_loss: 4.3987 ||
04/19 09:08:07 PM: ***** Pass 29000 / Epoch 29 *****
04/19 09:08:07 PM: toronto_lm: trained on 994 batches, 0.005 epochs
04/19 09:08:07 PM: wsj: trained on 6 batches, 0.007 epochs
04/19 09:08:07 PM: Validating...
04/19 09:08:13 PM: Batch 23/140: perplexity: 84.5391, toronto_lm_loss: 4.4372 || , for evaluation data
04/19 09:08:23 PM: Batch 62/140: perplexity: 81.9844, toronto_lm_loss: 4.4065 || , for evaluation data
04/19 09:08:33 PM: Batch 101/140: perplexity: 79.8331, toronto_lm_loss: 4.3799 || , for evaluation data
04/19 09:08:44 PM: Batch 135/140: perplexity: 75.5142, toronto_lm_loss: 4.3243 || , for evaluation data
04/19 09:08:45 PM: Batch 1/66: perplexity: 326.3138, wsj_loss: 5.7879 || , for evaluation data
04/19 09:08:55 PM: Batch 39/66: perplexity: 233.6512, wsj_loss: 5.4538 || , for evaluation data
04/19 09:09:03 PM: Best model found for wsj.
04/19 09:09:03 PM: Best model found for micro.
04/19 09:09:03 PM: Best model found for macro.
04/19 09:09:03 PM: Advancing scheduler.
04/19 09:09:03 PM: 	Best macro_avg: 0.219
04/19 09:09:03 PM: 	# bad epochs: 0
04/19 09:09:03 PM: Statistic: toronto_lm_loss
04/19 09:09:03 PM: 	training: 4.399193
04/19 09:09:03 PM: 	validation: 4.317168
04/19 09:09:03 PM: Statistic: wsj_loss
04/19 09:09:03 PM: 	training: 5.469236
04/19 09:09:03 PM: 	validation: 5.429754
04/19 09:09:03 PM: Statistic: macro_avg
04/19 09:09:03 PM: 	validation: 0.218838
04/19 09:09:03 PM: Statistic: micro_avg
04/19 09:09:03 PM: 	validation: 0.028091
04/19 09:09:03 PM: Statistic: toronto_lm_perplexity
04/19 09:09:03 PM: 	training: 81.385198
04/19 09:09:03 PM: 	validation: 74.975991
04/19 09:09:03 PM: Statistic: wsj_perplexity
04/19 09:09:03 PM: 	training: 237.278818
04/19 09:09:03 PM: 	validation: 228.093025
04/19 09:09:03 PM: global_lr: 0.001000
04/19 09:09:03 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 09:09:04 PM: Update 29001: task toronto_lm, batch 1 (28863): perplexity: 105.8689, toronto_lm_loss: 4.6622 ||
04/19 09:09:14 PM: Update 29014: task toronto_lm, batch 14 (28876): perplexity: 89.5865, toronto_lm_loss: 4.4952 ||
04/19 09:09:24 PM: Update 29027: task toronto_lm, batch 27 (28889): perplexity: 88.7476, toronto_lm_loss: 4.4858 ||
04/19 09:09:34 PM: Update 29040: task toronto_lm, batch 40 (28902): perplexity: 87.6864, toronto_lm_loss: 4.4738 ||
04/19 09:09:44 PM: Update 29053: task toronto_lm, batch 53 (28915): perplexity: 87.3354, toronto_lm_loss: 4.4698 ||
04/19 09:09:54 PM: Update 29066: task toronto_lm, batch 66 (28928): perplexity: 86.9831, toronto_lm_loss: 4.4657 ||
04/19 09:10:04 PM: Update 29079: task toronto_lm, batch 79 (28941): perplexity: 86.5297, toronto_lm_loss: 4.4605 ||
04/19 09:10:14 PM: Update 29092: task toronto_lm, batch 92 (28954): perplexity: 86.2462, toronto_lm_loss: 4.4572 ||
04/19 09:10:24 PM: Update 29105: task toronto_lm, batch 105 (28967): perplexity: 85.5192, toronto_lm_loss: 4.4487 ||
04/19 09:10:26 PM: Update 29107: task wsj, batch 1 (139): perplexity: 187.7880, wsj_loss: 5.2353 ||
04/19 09:10:34 PM: Update 29118: task toronto_lm, batch 117 (28979): perplexity: 85.2481, toronto_lm_loss: 4.4456 ||
04/19 09:10:45 PM: Update 29131: task toronto_lm, batch 130 (28992): perplexity: 84.4749, toronto_lm_loss: 4.4365 ||
04/19 09:10:55 PM: Update 29144: task toronto_lm, batch 143 (29005): perplexity: 84.2971, toronto_lm_loss: 4.4343 ||
04/19 09:11:05 PM: Update 29157: task toronto_lm, batch 156 (29018): perplexity: 84.1210, toronto_lm_loss: 4.4323 ||
04/19 09:11:15 PM: Update 29170: task toronto_lm, batch 169 (29031): perplexity: 83.9019, toronto_lm_loss: 4.4296 ||
04/19 09:11:25 PM: Update 29183: task toronto_lm, batch 182 (29044): perplexity: 83.5074, toronto_lm_loss: 4.4249 ||
04/19 09:11:35 PM: Update 29196: task toronto_lm, batch 195 (29057): perplexity: 83.5260, toronto_lm_loss: 4.4252 ||
04/19 09:11:45 PM: Update 29209: task toronto_lm, batch 208 (29070): perplexity: 83.1623, toronto_lm_loss: 4.4208 ||
04/19 09:11:56 PM: Update 29222: task toronto_lm, batch 221 (29083): perplexity: 82.8036, toronto_lm_loss: 4.4165 ||
04/19 09:12:06 PM: Update 29235: task toronto_lm, batch 234 (29096): perplexity: 82.8356, toronto_lm_loss: 4.4169 ||
04/19 09:12:09 PM: Update 29239: task wsj, batch 2 (140): perplexity: 232.7247, wsj_loss: 5.4499 ||
04/19 09:12:16 PM: Update 29248: task toronto_lm, batch 246 (29108): perplexity: 82.4069, toronto_lm_loss: 4.4117 ||
04/19 09:12:26 PM: Update 29261: task toronto_lm, batch 259 (29121): perplexity: 81.9492, toronto_lm_loss: 4.4061 ||
04/19 09:12:36 PM: Update 29274: task toronto_lm, batch 272 (29134): perplexity: 81.5157, toronto_lm_loss: 4.4008 ||
04/19 09:12:46 PM: Update 29287: task toronto_lm, batch 285 (29147): perplexity: 81.4745, toronto_lm_loss: 4.4003 ||
04/19 09:12:56 PM: Update 29300: task toronto_lm, batch 298 (29160): perplexity: 81.4305, toronto_lm_loss: 4.3997 ||
04/19 09:13:06 PM: Update 29313: task toronto_lm, batch 311 (29173): perplexity: 81.1151, toronto_lm_loss: 4.3959 ||
04/19 09:13:17 PM: Update 29327: task toronto_lm, batch 325 (29187): perplexity: 80.8237, toronto_lm_loss: 4.3923 ||
04/19 09:13:27 PM: Update 29340: task toronto_lm, batch 338 (29200): perplexity: 80.4744, toronto_lm_loss: 4.3879 ||
04/19 09:13:37 PM: Update 29353: task toronto_lm, batch 351 (29213): perplexity: 80.3400, toronto_lm_loss: 4.3863 ||
04/19 09:13:48 PM: Update 29366: task toronto_lm, batch 364 (29226): perplexity: 79.9999, toronto_lm_loss: 4.3820 ||
04/19 09:13:58 PM: Update 29379: task toronto_lm, batch 377 (29239): perplexity: 79.8663, toronto_lm_loss: 4.3804 ||
04/19 09:14:08 PM: Update 29392: task toronto_lm, batch 390 (29252): perplexity: 79.7322, toronto_lm_loss: 4.3787 ||
04/19 09:14:18 PM: Update 29405: task toronto_lm, batch 403 (29265): perplexity: 79.6271, toronto_lm_loss: 4.3774 ||
04/19 09:14:28 PM: Update 29418: task toronto_lm, batch 416 (29278): perplexity: 79.3999, toronto_lm_loss: 4.3745 ||
04/19 09:14:38 PM: Update 29431: task toronto_lm, batch 429 (29291): perplexity: 79.2732, toronto_lm_loss: 4.3729 ||
04/19 09:14:48 PM: Update 29444: task toronto_lm, batch 442 (29304): perplexity: 79.2622, toronto_lm_loss: 4.3728 ||
04/19 09:14:58 PM: Update 29457: task toronto_lm, batch 455 (29317): perplexity: 79.1546, toronto_lm_loss: 4.3714 ||
04/19 09:15:08 PM: Update 29470: task toronto_lm, batch 468 (29330): perplexity: 79.1088, toronto_lm_loss: 4.3708 ||
04/19 09:15:14 PM: Update 29477: task wsj, batch 3 (141): perplexity: 227.8218, wsj_loss: 5.4286 ||
04/19 09:15:19 PM: Update 29483: task toronto_lm, batch 479 (29341): perplexity: 78.9090, toronto_lm_loss: 4.3683 ||
04/19 09:15:27 PM: Update 29494: task wsj, batch 5 (143): perplexity: 222.1676, wsj_loss: 5.4034 ||
04/19 09:15:29 PM: Update 29496: task toronto_lm, batch 491 (29353): perplexity: 78.8345, toronto_lm_loss: 4.3674 ||
04/19 09:15:39 PM: Update 29509: task toronto_lm, batch 504 (29366): perplexity: 78.7697, toronto_lm_loss: 4.3665 ||
04/19 09:15:55 PM: Update 29519: task toronto_lm, batch 514 (29376): perplexity: 78.6822, toronto_lm_loss: 4.3654 ||
04/19 09:16:05 PM: Update 29533: task toronto_lm, batch 528 (29390): perplexity: 78.6766, toronto_lm_loss: 4.3653 ||
04/19 09:16:15 PM: Update 29546: task toronto_lm, batch 541 (29403): perplexity: 78.6488, toronto_lm_loss: 4.3650 ||
04/19 09:16:26 PM: Update 29560: task toronto_lm, batch 555 (29417): perplexity: 78.5082, toronto_lm_loss: 4.3632 ||
04/19 09:16:36 PM: Update 29573: task toronto_lm, batch 568 (29430): perplexity: 78.4367, toronto_lm_loss: 4.3623 ||
04/19 09:16:46 PM: Update 29586: task toronto_lm, batch 581 (29443): perplexity: 78.1695, toronto_lm_loss: 4.3589 ||
04/19 09:16:56 PM: Update 29599: task toronto_lm, batch 594 (29456): perplexity: 77.8479, toronto_lm_loss: 4.3548 ||
04/19 09:17:07 PM: Update 29613: task toronto_lm, batch 608 (29470): perplexity: 77.5073, toronto_lm_loss: 4.3504 ||
04/19 09:17:17 PM: Update 29626: task toronto_lm, batch 621 (29483): perplexity: 77.3602, toronto_lm_loss: 4.3485 ||
04/19 09:17:27 PM: Update 29639: task toronto_lm, batch 634 (29496): perplexity: 77.2080, toronto_lm_loss: 4.3465 ||
04/19 09:17:38 PM: Update 29653: task toronto_lm, batch 648 (29510): perplexity: 76.8997, toronto_lm_loss: 4.3425 ||
04/19 09:17:48 PM: Update 29666: task toronto_lm, batch 661 (29523): perplexity: 76.6149, toronto_lm_loss: 4.3388 ||
04/19 09:17:58 PM: Update 29679: task toronto_lm, batch 674 (29536): perplexity: 76.3135, toronto_lm_loss: 4.3348 ||
04/19 09:18:08 PM: Update 29692: task toronto_lm, batch 687 (29549): perplexity: 76.0632, toronto_lm_loss: 4.3316 ||
04/19 09:18:18 PM: Update 29705: task toronto_lm, batch 700 (29562): perplexity: 75.7311, toronto_lm_loss: 4.3272 ||
04/19 09:18:28 PM: Update 29718: task toronto_lm, batch 713 (29575): perplexity: 75.3257, toronto_lm_loss: 4.3218 ||
04/19 09:18:38 PM: Update 29731: task toronto_lm, batch 726 (29588): perplexity: 75.0509, toronto_lm_loss: 4.3182 ||
04/19 09:18:49 PM: Update 29745: task toronto_lm, batch 740 (29602): perplexity: 74.7688, toronto_lm_loss: 4.3144 ||
04/19 09:18:59 PM: Update 29759: task toronto_lm, batch 754 (29616): perplexity: 74.4301, toronto_lm_loss: 4.3099 ||
04/19 09:19:10 PM: Update 29773: task toronto_lm, batch 768 (29630): perplexity: 74.1343, toronto_lm_loss: 4.3059 ||
04/19 09:19:21 PM: Update 29787: task toronto_lm, batch 782 (29644): perplexity: 73.7733, toronto_lm_loss: 4.3010 ||
04/19 09:19:31 PM: Update 29800: task toronto_lm, batch 795 (29657): perplexity: 73.5299, toronto_lm_loss: 4.2977 ||
04/19 09:19:41 PM: Update 29813: task toronto_lm, batch 808 (29670): perplexity: 73.3085, toronto_lm_loss: 4.2947 ||
04/19 09:19:52 PM: Update 29827: task toronto_lm, batch 822 (29684): perplexity: 72.9782, toronto_lm_loss: 4.2902 ||
04/19 09:20:02 PM: Update 29840: task toronto_lm, batch 835 (29697): perplexity: 72.7420, toronto_lm_loss: 4.2869 ||
04/19 09:20:13 PM: Update 29854: task toronto_lm, batch 849 (29711): perplexity: 72.4794, toronto_lm_loss: 4.2833 ||
04/19 09:20:23 PM: Update 29868: task toronto_lm, batch 863 (29725): perplexity: 72.1500, toronto_lm_loss: 4.2787 ||
04/19 09:20:34 PM: Update 29882: task toronto_lm, batch 877 (29739): perplexity: 71.8754, toronto_lm_loss: 4.2749 ||
04/19 09:20:44 PM: Update 29895: task toronto_lm, batch 890 (29752): perplexity: 71.6355, toronto_lm_loss: 4.2716 ||
04/19 09:20:54 PM: Update 29908: task toronto_lm, batch 903 (29765): perplexity: 71.3823, toronto_lm_loss: 4.2681 ||
04/19 09:21:04 PM: Update 29921: task toronto_lm, batch 916 (29778): perplexity: 71.1856, toronto_lm_loss: 4.2653 ||
04/19 09:21:15 PM: Update 29935: task toronto_lm, batch 930 (29792): perplexity: 70.9637, toronto_lm_loss: 4.2622 ||
04/19 09:21:25 PM: Update 29948: task toronto_lm, batch 943 (29805): perplexity: 70.7935, toronto_lm_loss: 4.2598 ||
04/19 09:21:35 PM: Update 29961: task toronto_lm, batch 956 (29818): perplexity: 70.6195, toronto_lm_loss: 4.2573 ||
04/19 09:21:46 PM: Update 29975: task toronto_lm, batch 970 (29832): perplexity: 70.4161, toronto_lm_loss: 4.2544 ||
04/19 09:21:56 PM: Update 29988: task toronto_lm, batch 983 (29845): perplexity: 70.2180, toronto_lm_loss: 4.2516 ||
04/19 09:22:05 PM: ***** Pass 30000 / Epoch 30 *****
04/19 09:22:05 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 09:22:05 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 09:22:05 PM: Validating...
04/19 09:22:06 PM: Batch 3/140: perplexity: 97.6082, toronto_lm_loss: 4.5810 || , for evaluation data
04/19 09:22:16 PM: Batch 42/140: perplexity: 86.3297, toronto_lm_loss: 4.4582 || , for evaluation data
04/19 09:22:26 PM: Batch 81/140: perplexity: 84.9312, toronto_lm_loss: 4.4418 || , for evaluation data
04/19 09:22:36 PM: Batch 120/140: perplexity: 79.8864, toronto_lm_loss: 4.3806 || , for evaluation data
04/19 09:22:42 PM: Batch 1/66: perplexity: 314.2930, wsj_loss: 5.7503 || , for evaluation data
04/19 09:22:52 PM: Batch 40/66: perplexity: 216.3137, wsj_loss: 5.3767 || , for evaluation data
04/19 09:22:58 PM: Best model found for wsj.
04/19 09:22:58 PM: Best model found for micro.
04/19 09:22:58 PM: Best model found for macro.
04/19 09:22:58 PM: Advancing scheduler.
04/19 09:22:58 PM: 	Best macro_avg: 0.244
04/19 09:22:58 PM: 	# bad epochs: 0
04/19 09:22:58 PM: Statistic: toronto_lm_loss
04/19 09:22:58 PM: 	training: 4.248766
04/19 09:22:58 PM: 	validation: 4.346422
04/19 09:22:58 PM: Statistic: wsj_loss
04/19 09:22:58 PM: 	training: 5.403432
04/19 09:22:58 PM: 	validation: 5.366779
04/19 09:22:58 PM: Statistic: macro_avg
04/19 09:22:58 PM: 	validation: 0.244454
04/19 09:22:58 PM: Statistic: micro_avg
04/19 09:22:58 PM: 	validation: 0.045939
04/19 09:22:58 PM: Statistic: toronto_lm_perplexity
04/19 09:22:58 PM: 	training: 70.018978
04/19 09:22:58 PM: 	validation: 77.201709
04/19 09:22:58 PM: Statistic: wsj_perplexity
04/19 09:22:58 PM: 	training: 222.167649
04/19 09:22:58 PM: 	validation: 214.171925
04/19 09:22:58 PM: global_lr: 0.001000
04/19 09:22:59 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 09:22:59 PM: Update 30001: task toronto_lm, batch 1 (29858): perplexity: 63.0455, toronto_lm_loss: 4.1439 ||
04/19 09:23:03 PM: Update 30005: task wsj, batch 1 (144): perplexity: 241.3444, wsj_loss: 5.4862 ||
04/19 09:23:10 PM: Update 30014: task toronto_lm, batch 13 (29870): perplexity: 53.6448, toronto_lm_loss: 3.9824 ||
04/19 09:23:20 PM: Update 30027: task toronto_lm, batch 26 (29883): perplexity: 53.9921, toronto_lm_loss: 3.9888 ||
04/19 09:23:30 PM: Update 30041: task toronto_lm, batch 40 (29897): perplexity: 55.6033, toronto_lm_loss: 4.0182 ||
04/19 09:23:40 PM: Update 30054: task toronto_lm, batch 53 (29910): perplexity: 55.9472, toronto_lm_loss: 4.0244 ||
04/19 09:23:51 PM: Update 30068: task toronto_lm, batch 67 (29924): perplexity: 56.5168, toronto_lm_loss: 4.0345 ||
04/19 09:24:01 PM: Update 30081: task toronto_lm, batch 80 (29937): perplexity: 57.1052, toronto_lm_loss: 4.0449 ||
04/19 09:24:11 PM: Update 30094: task toronto_lm, batch 93 (29950): perplexity: 57.1851, toronto_lm_loss: 4.0463 ||
04/19 09:24:21 PM: Update 30107: task toronto_lm, batch 106 (29963): perplexity: 56.9277, toronto_lm_loss: 4.0418 ||
04/19 09:24:31 PM: Update 30120: task toronto_lm, batch 119 (29976): perplexity: 56.7107, toronto_lm_loss: 4.0380 ||
04/19 09:24:37 PM: Update 30128: task wsj, batch 2 (145): perplexity: 225.5189, wsj_loss: 5.4184 ||
04/19 09:24:42 PM: Update 30134: task toronto_lm, batch 132 (29989): perplexity: 56.4018, toronto_lm_loss: 4.0325 ||
04/19 09:24:58 PM: Update 30146: task toronto_lm, batch 144 (30001): perplexity: 56.2893, toronto_lm_loss: 4.0305 ||
04/19 09:25:08 PM: Update 30159: task toronto_lm, batch 157 (30014): perplexity: 58.3288, toronto_lm_loss: 4.0661 ||
04/19 09:25:18 PM: Update 30172: task toronto_lm, batch 170 (30027): perplexity: 59.4062, toronto_lm_loss: 4.0844 ||
04/19 09:25:29 PM: Update 30186: task toronto_lm, batch 184 (30041): perplexity: 60.3174, toronto_lm_loss: 4.0996 ||
04/19 09:25:39 PM: Update 30199: task toronto_lm, batch 197 (30054): perplexity: 61.2502, toronto_lm_loss: 4.1150 ||
04/19 09:25:49 PM: Update 30212: task toronto_lm, batch 210 (30067): perplexity: 62.1121, toronto_lm_loss: 4.1289 ||
04/19 09:26:00 PM: Update 30225: task toronto_lm, batch 223 (30080): perplexity: 62.5833, toronto_lm_loss: 4.1365 ||
04/19 09:26:10 PM: Update 30238: task toronto_lm, batch 236 (30093): perplexity: 62.9593, toronto_lm_loss: 4.1425 ||
04/19 09:26:20 PM: Update 30251: task toronto_lm, batch 249 (30106): perplexity: 63.2380, toronto_lm_loss: 4.1469 ||
04/19 09:26:30 PM: Update 30264: task toronto_lm, batch 262 (30119): perplexity: 63.2976, toronto_lm_loss: 4.1478 ||
04/19 09:26:40 PM: Update 30277: task toronto_lm, batch 275 (30132): perplexity: 63.5362, toronto_lm_loss: 4.1516 ||
04/19 09:26:50 PM: Update 30290: task toronto_lm, batch 288 (30145): perplexity: 63.7508, toronto_lm_loss: 4.1550 ||
04/19 09:26:52 PM: Update 30292: task wsj, batch 3 (146): perplexity: 208.9060, wsj_loss: 5.3419 ||
04/19 09:27:01 PM: Update 30303: task toronto_lm, batch 300 (30157): perplexity: 63.9296, toronto_lm_loss: 4.1578 ||
04/19 09:27:11 PM: Update 30316: task toronto_lm, batch 313 (30170): perplexity: 64.0493, toronto_lm_loss: 4.1597 ||
04/19 09:27:21 PM: Update 30329: task toronto_lm, batch 326 (30183): perplexity: 64.1231, toronto_lm_loss: 4.1608 ||
04/19 09:27:22 PM: Update 30331: task wsj, batch 4 (147): perplexity: 202.0733, wsj_loss: 5.3086 ||
04/19 09:27:31 PM: Update 30342: task toronto_lm, batch 338 (30195): perplexity: 64.1752, toronto_lm_loss: 4.1616 ||
04/19 09:27:41 PM: Update 30355: task toronto_lm, batch 351 (30208): perplexity: 64.1867, toronto_lm_loss: 4.1618 ||
04/19 09:27:51 PM: Update 30368: task toronto_lm, batch 364 (30221): perplexity: 64.2837, toronto_lm_loss: 4.1633 ||
04/19 09:28:01 PM: Update 30381: task toronto_lm, batch 377 (30234): perplexity: 64.2585, toronto_lm_loss: 4.1629 ||
04/19 09:28:11 PM: Update 30394: task toronto_lm, batch 390 (30247): perplexity: 64.2106, toronto_lm_loss: 4.1622 ||
04/19 09:28:21 PM: Update 30407: task toronto_lm, batch 403 (30260): perplexity: 64.0988, toronto_lm_loss: 4.1604 ||
04/19 09:28:32 PM: Update 30421: task toronto_lm, batch 417 (30274): perplexity: 64.0880, toronto_lm_loss: 4.1603 ||
04/19 09:28:42 PM: Update 30435: task toronto_lm, batch 431 (30288): perplexity: 64.0035, toronto_lm_loss: 4.1589 ||
04/19 09:28:53 PM: Update 30449: task toronto_lm, batch 445 (30302): perplexity: 63.9313, toronto_lm_loss: 4.1578 ||
04/19 09:29:04 PM: Update 30463: task toronto_lm, batch 459 (30316): perplexity: 63.9060, toronto_lm_loss: 4.1574 ||
04/19 09:29:14 PM: Update 30476: task toronto_lm, batch 472 (30329): perplexity: 63.9736, toronto_lm_loss: 4.1585 ||
04/19 09:29:24 PM: Update 30489: task toronto_lm, batch 485 (30342): perplexity: 64.0478, toronto_lm_loss: 4.1596 ||
04/19 09:29:34 PM: Update 30502: task toronto_lm, batch 498 (30355): perplexity: 64.0523, toronto_lm_loss: 4.1597 ||
04/19 09:29:44 PM: Update 30515: task toronto_lm, batch 511 (30368): perplexity: 63.9417, toronto_lm_loss: 4.1580 ||
04/19 09:29:54 PM: Update 30528: task toronto_lm, batch 524 (30381): perplexity: 63.8581, toronto_lm_loss: 4.1567 ||
04/19 09:30:04 PM: Update 30541: task toronto_lm, batch 537 (30394): perplexity: 63.8437, toronto_lm_loss: 4.1564 ||
04/19 09:30:15 PM: Update 30554: task toronto_lm, batch 550 (30407): perplexity: 63.7377, toronto_lm_loss: 4.1548 ||
04/19 09:30:25 PM: Update 30567: task toronto_lm, batch 563 (30420): perplexity: 63.6473, toronto_lm_loss: 4.1534 ||
04/19 09:30:35 PM: Update 30580: task toronto_lm, batch 576 (30433): perplexity: 63.5966, toronto_lm_loss: 4.1526 ||
04/19 09:30:45 PM: Update 30593: task toronto_lm, batch 589 (30446): perplexity: 63.5674, toronto_lm_loss: 4.1521 ||
04/19 09:30:55 PM: Update 30606: task toronto_lm, batch 602 (30459): perplexity: 63.5695, toronto_lm_loss: 4.1521 ||
04/19 09:31:05 PM: Update 30619: task toronto_lm, batch 615 (30472): perplexity: 63.5158, toronto_lm_loss: 4.1513 ||
04/19 09:31:15 PM: Update 30632: task toronto_lm, batch 628 (30485): perplexity: 63.4534, toronto_lm_loss: 4.1503 ||
04/19 09:31:25 PM: Update 30645: task toronto_lm, batch 641 (30498): perplexity: 63.4030, toronto_lm_loss: 4.1495 ||
04/19 09:31:36 PM: Update 30658: task toronto_lm, batch 654 (30511): perplexity: 63.2414, toronto_lm_loss: 4.1470 ||
04/19 09:31:46 PM: Update 30671: task toronto_lm, batch 667 (30524): perplexity: 63.2411, toronto_lm_loss: 4.1470 ||
04/19 09:31:56 PM: Update 30684: task toronto_lm, batch 680 (30537): perplexity: 63.2353, toronto_lm_loss: 4.1469 ||
04/19 09:32:06 PM: Update 30697: task toronto_lm, batch 693 (30550): perplexity: 63.1470, toronto_lm_loss: 4.1455 ||
04/19 09:32:16 PM: Update 30710: task toronto_lm, batch 706 (30563): perplexity: 63.0912, toronto_lm_loss: 4.1446 ||
04/19 09:32:26 PM: Update 30723: task toronto_lm, batch 719 (30576): perplexity: 63.0047, toronto_lm_loss: 4.1432 ||
04/19 09:32:36 PM: Update 30736: task toronto_lm, batch 732 (30589): perplexity: 62.9947, toronto_lm_loss: 4.1431 ||
04/19 09:32:46 PM: Update 30749: task toronto_lm, batch 745 (30602): perplexity: 62.9848, toronto_lm_loss: 4.1429 ||
04/19 09:32:57 PM: Update 30762: task toronto_lm, batch 758 (30615): perplexity: 62.9240, toronto_lm_loss: 4.1419 ||
04/19 09:33:13 PM: Update 30773: task toronto_lm, batch 769 (30626): perplexity: 62.8772, toronto_lm_loss: 4.1412 ||
04/19 09:33:24 PM: Update 30786: task toronto_lm, batch 782 (30639): perplexity: 63.3685, toronto_lm_loss: 4.1490 ||
04/19 09:33:34 PM: Update 30799: task toronto_lm, batch 795 (30652): perplexity: 63.7823, toronto_lm_loss: 4.1555 ||
04/19 09:33:44 PM: Update 30812: task toronto_lm, batch 808 (30665): perplexity: 64.1137, toronto_lm_loss: 4.1607 ||
04/19 09:33:54 PM: Update 30825: task toronto_lm, batch 821 (30678): perplexity: 64.3459, toronto_lm_loss: 4.1643 ||
04/19 09:34:05 PM: Update 30838: task toronto_lm, batch 834 (30691): perplexity: 64.6079, toronto_lm_loss: 4.1683 ||
04/19 09:34:15 PM: Update 30851: task toronto_lm, batch 847 (30704): perplexity: 64.8197, toronto_lm_loss: 4.1716 ||
04/19 09:34:25 PM: Update 30864: task toronto_lm, batch 860 (30717): perplexity: 64.9916, toronto_lm_loss: 4.1743 ||
04/19 09:34:35 PM: Update 30877: task toronto_lm, batch 873 (30730): perplexity: 65.2159, toronto_lm_loss: 4.1777 ||
04/19 09:34:46 PM: Update 30891: task toronto_lm, batch 887 (30744): perplexity: 65.4049, toronto_lm_loss: 4.1806 ||
04/19 09:34:56 PM: Update 30904: task toronto_lm, batch 900 (30757): perplexity: 65.5433, toronto_lm_loss: 4.1827 ||
04/19 09:35:06 PM: Update 30917: task toronto_lm, batch 913 (30770): perplexity: 65.6618, toronto_lm_loss: 4.1845 ||
04/19 09:35:16 PM: Update 30930: task toronto_lm, batch 926 (30783): perplexity: 65.7628, toronto_lm_loss: 4.1861 ||
04/19 09:35:26 PM: Update 30943: task toronto_lm, batch 939 (30796): perplexity: 65.8987, toronto_lm_loss: 4.1881 ||
04/19 09:35:36 PM: Update 30956: task toronto_lm, batch 952 (30809): perplexity: 66.0344, toronto_lm_loss: 4.1902 ||
04/19 09:35:46 PM: Update 30969: task toronto_lm, batch 965 (30822): perplexity: 66.1078, toronto_lm_loss: 4.1913 ||
04/19 09:35:56 PM: Update 30982: task toronto_lm, batch 978 (30835): perplexity: 66.1719, toronto_lm_loss: 4.1923 ||
04/19 09:36:04 PM: Update 30992: task wsj, batch 5 (148): perplexity: 208.7691, wsj_loss: 5.3412 ||
04/19 09:36:06 PM: Update 30995: task toronto_lm, batch 990 (30847): perplexity: 66.2461, toronto_lm_loss: 4.1934 ||
04/19 09:36:10 PM: ***** Pass 31000 / Epoch 31 *****
04/19 09:36:10 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 09:36:10 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 09:36:10 PM: Validating...
04/19 09:36:17 PM: Batch 24/140: perplexity: 86.4614, toronto_lm_loss: 4.4597 || , for evaluation data
04/19 09:36:27 PM: Batch 62/140: perplexity: 84.4800, toronto_lm_loss: 4.4365 || , for evaluation data
04/19 09:36:37 PM: Batch 100/140: perplexity: 80.9319, toronto_lm_loss: 4.3936 || , for evaluation data
04/19 09:36:47 PM: Batch 133/140: perplexity: 76.4403, toronto_lm_loss: 4.3365 || , for evaluation data
04/19 09:36:49 PM: Batch 1/66: perplexity: 330.2669, wsj_loss: 5.7999 || , for evaluation data
04/19 09:36:59 PM: Batch 40/66: perplexity: 230.4443, wsj_loss: 5.4400 || , for evaluation data
04/19 09:37:06 PM: Advancing scheduler.
04/19 09:37:06 PM: 	Best macro_avg: 0.244
04/19 09:37:06 PM: 	# bad epochs: 1
04/19 09:37:06 PM: Statistic: toronto_lm_loss
04/19 09:37:06 PM: 	training: 4.193802
04/19 09:37:06 PM: 	validation: 4.324247
04/19 09:37:06 PM: Statistic: wsj_loss
04/19 09:37:06 PM: 	training: 5.341229
04/19 09:37:06 PM: 	validation: 5.427765
04/19 09:37:06 PM: Statistic: macro_avg
04/19 09:37:06 PM: 	validation: 0.219211
04/19 09:37:06 PM: Statistic: micro_avg
04/19 09:37:06 PM: 	validation: 0.028672
04/19 09:37:06 PM: Statistic: toronto_lm_perplexity
04/19 09:37:06 PM: 	training: 66.274276
04/19 09:37:06 PM: 	validation: 75.508630
04/19 09:37:06 PM: Statistic: wsj_perplexity
04/19 09:37:06 PM: 	training: 208.769062
04/19 09:37:06 PM: 	validation: 227.639995
04/19 09:37:06 PM: global_lr: 0.001000
04/19 09:37:06 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 09:37:07 PM: Update 31001: task toronto_lm, batch 1 (30853): perplexity: 72.4019, toronto_lm_loss: 4.2822 ||
04/19 09:37:17 PM: Update 31014: task wsj, batch 1 (149): perplexity: 213.7469, wsj_loss: 5.3648 ||
04/19 09:37:18 PM: Update 31015: task toronto_lm, batch 14 (30866): perplexity: 71.7703, toronto_lm_loss: 4.2735 ||
04/19 09:37:28 PM: Update 31028: task toronto_lm, batch 27 (30879): perplexity: 73.1842, toronto_lm_loss: 4.2930 ||
04/19 09:37:38 PM: Update 31041: task toronto_lm, batch 40 (30892): perplexity: 70.9423, toronto_lm_loss: 4.2619 ||
04/19 09:37:49 PM: Update 31054: task toronto_lm, batch 53 (30905): perplexity: 70.5292, toronto_lm_loss: 4.2560 ||
04/19 09:37:59 PM: Update 31068: task toronto_lm, batch 67 (30919): perplexity: 70.0330, toronto_lm_loss: 4.2490 ||
04/19 09:38:09 PM: Update 31081: task toronto_lm, batch 80 (30932): perplexity: 69.5989, toronto_lm_loss: 4.2427 ||
04/19 09:38:20 PM: Update 31095: task toronto_lm, batch 94 (30946): perplexity: 69.7742, toronto_lm_loss: 4.2453 ||
04/19 09:38:31 PM: Update 31109: task toronto_lm, batch 108 (30960): perplexity: 69.5810, toronto_lm_loss: 4.2425 ||
04/19 09:38:41 PM: Update 31122: task toronto_lm, batch 121 (30973): perplexity: 69.7527, toronto_lm_loss: 4.2450 ||
04/19 09:38:52 PM: Update 31136: task toronto_lm, batch 135 (30987): perplexity: 69.3890, toronto_lm_loss: 4.2397 ||
04/19 09:39:02 PM: Update 31150: task toronto_lm, batch 149 (31001): perplexity: 69.2720, toronto_lm_loss: 4.2380 ||
04/19 09:39:12 PM: Update 31163: task toronto_lm, batch 162 (31014): perplexity: 69.0762, toronto_lm_loss: 4.2352 ||
04/19 09:39:22 PM: Update 31176: task toronto_lm, batch 175 (31027): perplexity: 69.2179, toronto_lm_loss: 4.2373 ||
04/19 09:39:33 PM: Update 31190: task toronto_lm, batch 189 (31041): perplexity: 69.0572, toronto_lm_loss: 4.2349 ||
04/19 09:39:43 PM: Update 31203: task toronto_lm, batch 202 (31054): perplexity: 68.7491, toronto_lm_loss: 4.2305 ||
04/19 09:39:53 PM: Update 31216: task toronto_lm, batch 215 (31067): perplexity: 68.5277, toronto_lm_loss: 4.2272 ||
04/19 09:40:03 PM: Update 31229: task toronto_lm, batch 228 (31080): perplexity: 68.4511, toronto_lm_loss: 4.2261 ||
04/19 09:40:14 PM: Update 31243: task toronto_lm, batch 242 (31094): perplexity: 68.3301, toronto_lm_loss: 4.2244 ||
04/19 09:40:24 PM: Update 31256: task toronto_lm, batch 255 (31107): perplexity: 68.2751, toronto_lm_loss: 4.2235 ||
04/19 09:40:34 PM: Update 31269: task toronto_lm, batch 268 (31120): perplexity: 68.1699, toronto_lm_loss: 4.2220 ||
04/19 09:40:44 PM: Update 31282: task toronto_lm, batch 281 (31133): perplexity: 67.8982, toronto_lm_loss: 4.2180 ||
04/19 09:40:55 PM: Update 31296: task toronto_lm, batch 295 (31147): perplexity: 67.7014, toronto_lm_loss: 4.2151 ||
04/19 09:41:06 PM: Update 31310: task toronto_lm, batch 309 (31161): perplexity: 67.5013, toronto_lm_loss: 4.2121 ||
04/19 09:41:16 PM: Update 31323: task toronto_lm, batch 322 (31174): perplexity: 67.3920, toronto_lm_loss: 4.2105 ||
04/19 09:41:26 PM: Update 31336: task toronto_lm, batch 335 (31187): perplexity: 67.2362, toronto_lm_loss: 4.2082 ||
04/19 09:41:36 PM: Update 31350: task toronto_lm, batch 349 (31201): perplexity: 67.1543, toronto_lm_loss: 4.2070 ||
04/19 09:41:47 PM: Update 31364: task toronto_lm, batch 363 (31215): perplexity: 67.1024, toronto_lm_loss: 4.2062 ||
04/19 09:41:57 PM: Update 31377: task toronto_lm, batch 376 (31228): perplexity: 66.9817, toronto_lm_loss: 4.2044 ||
04/19 09:42:06 PM: Update 31389: task wsj, batch 2 (150): perplexity: 219.9107, wsj_loss: 5.3932 ||
04/19 09:42:08 PM: Update 31391: task toronto_lm, batch 389 (31241): perplexity: 66.9284, toronto_lm_loss: 4.2036 ||
04/19 09:42:24 PM: Update 31401: task toronto_lm, batch 399 (31251): perplexity: 66.8871, toronto_lm_loss: 4.2030 ||
04/19 09:42:34 PM: Update 31414: task toronto_lm, batch 412 (31264): perplexity: 67.2766, toronto_lm_loss: 4.2088 ||
04/19 09:42:44 PM: Update 31427: task toronto_lm, batch 425 (31277): perplexity: 67.5907, toronto_lm_loss: 4.2135 ||
04/19 09:42:55 PM: Update 31441: task toronto_lm, batch 439 (31291): perplexity: 67.7201, toronto_lm_loss: 4.2154 ||
04/19 09:43:06 PM: Update 31455: task toronto_lm, batch 453 (31305): perplexity: 67.6742, toronto_lm_loss: 4.2147 ||
04/19 09:43:16 PM: Update 31468: task wsj, batch 3 (151): perplexity: 239.2115, wsj_loss: 5.4773 ||
04/19 09:43:16 PM: Update 31469: task toronto_lm, batch 466 (31318): perplexity: 67.8054, toronto_lm_loss: 4.2166 ||
04/19 09:43:26 PM: Update 31482: task toronto_lm, batch 479 (31331): perplexity: 67.7714, toronto_lm_loss: 4.2161 ||
04/19 09:43:36 PM: Update 31495: task toronto_lm, batch 492 (31344): perplexity: 67.7591, toronto_lm_loss: 4.2160 ||
04/19 09:43:46 PM: Update 31508: task toronto_lm, batch 505 (31357): perplexity: 67.6657, toronto_lm_loss: 4.2146 ||
04/19 09:43:57 PM: Update 31521: task toronto_lm, batch 518 (31370): perplexity: 67.6446, toronto_lm_loss: 4.2143 ||
04/19 09:44:07 PM: Update 31534: task toronto_lm, batch 531 (31383): perplexity: 67.4892, toronto_lm_loss: 4.2120 ||
04/19 09:44:17 PM: Update 31547: task toronto_lm, batch 544 (31396): perplexity: 67.5631, toronto_lm_loss: 4.2131 ||
04/19 09:44:27 PM: Update 31561: task toronto_lm, batch 558 (31410): perplexity: 67.3188, toronto_lm_loss: 4.2094 ||
04/19 09:44:37 PM: Update 31574: task toronto_lm, batch 571 (31423): perplexity: 67.1461, toronto_lm_loss: 4.2069 ||
04/19 09:44:48 PM: Update 31588: task toronto_lm, batch 585 (31437): perplexity: 66.9790, toronto_lm_loss: 4.2044 ||
04/19 09:44:58 PM: Update 31601: task toronto_lm, batch 598 (31450): perplexity: 66.8838, toronto_lm_loss: 4.2030 ||
04/19 09:45:08 PM: Update 31614: task toronto_lm, batch 611 (31463): perplexity: 66.7809, toronto_lm_loss: 4.2014 ||
04/19 09:45:18 PM: Update 31627: task toronto_lm, batch 624 (31476): perplexity: 66.6918, toronto_lm_loss: 4.2001 ||
04/19 09:45:29 PM: Update 31641: task toronto_lm, batch 638 (31490): perplexity: 66.4153, toronto_lm_loss: 4.1959 ||
04/19 09:45:40 PM: Update 31655: task toronto_lm, batch 652 (31504): perplexity: 66.3299, toronto_lm_loss: 4.1946 ||
04/19 09:45:51 PM: Update 31669: task toronto_lm, batch 666 (31518): perplexity: 66.2090, toronto_lm_loss: 4.1928 ||
04/19 09:46:01 PM: Update 31683: task toronto_lm, batch 680 (31532): perplexity: 66.1138, toronto_lm_loss: 4.1914 ||
04/19 09:46:11 PM: Update 31696: task toronto_lm, batch 693 (31545): perplexity: 66.0135, toronto_lm_loss: 4.1899 ||
04/19 09:46:13 PM: Update 31698: task wsj, batch 4 (152): perplexity: 248.2308, wsj_loss: 5.5144 ||
04/19 09:46:22 PM: Update 31710: task toronto_lm, batch 705 (31557): perplexity: 65.7614, toronto_lm_loss: 4.1860 ||
04/19 09:46:32 PM: Update 31723: task toronto_lm, batch 718 (31570): perplexity: 65.6722, toronto_lm_loss: 4.1847 ||
04/19 09:46:42 PM: Update 31736: task toronto_lm, batch 731 (31583): perplexity: 65.4454, toronto_lm_loss: 4.1812 ||
04/19 09:46:53 PM: Update 31750: task toronto_lm, batch 745 (31597): perplexity: 65.3604, toronto_lm_loss: 4.1799 ||
04/19 09:47:03 PM: Update 31764: task toronto_lm, batch 759 (31611): perplexity: 65.2384, toronto_lm_loss: 4.1780 ||
04/19 09:47:13 PM: Update 31777: task toronto_lm, batch 772 (31624): perplexity: 65.1159, toronto_lm_loss: 4.1762 ||
04/19 09:47:23 PM: Update 31790: task toronto_lm, batch 785 (31637): perplexity: 64.9662, toronto_lm_loss: 4.1739 ||
04/19 09:47:34 PM: Update 31804: task toronto_lm, batch 799 (31651): perplexity: 64.7979, toronto_lm_loss: 4.1713 ||
04/19 09:47:45 PM: Update 31818: task toronto_lm, batch 813 (31665): perplexity: 64.6796, toronto_lm_loss: 4.1694 ||
04/19 09:47:56 PM: Update 31832: task toronto_lm, batch 827 (31679): perplexity: 64.5475, toronto_lm_loss: 4.1674 ||
04/19 09:48:06 PM: Update 31846: task toronto_lm, batch 841 (31693): perplexity: 64.4378, toronto_lm_loss: 4.1657 ||
04/19 09:48:17 PM: Update 31860: task toronto_lm, batch 855 (31707): perplexity: 64.2846, toronto_lm_loss: 4.1633 ||
04/19 09:48:26 PM: Update 31872: task wsj, batch 6 (154): perplexity: 224.2856, wsj_loss: 5.4129 ||
04/19 09:48:28 PM: Update 31874: task toronto_lm, batch 868 (31720): perplexity: 64.1646, toronto_lm_loss: 4.1615 ||
04/19 09:48:38 PM: Update 31888: task toronto_lm, batch 882 (31734): perplexity: 64.1074, toronto_lm_loss: 4.1606 ||
04/19 09:48:49 PM: Update 31902: task toronto_lm, batch 896 (31748): perplexity: 63.9468, toronto_lm_loss: 4.1581 ||
04/19 09:49:00 PM: Update 31916: task toronto_lm, batch 910 (31762): perplexity: 63.8722, toronto_lm_loss: 4.1569 ||
04/19 09:49:10 PM: Update 31930: task toronto_lm, batch 924 (31776): perplexity: 63.7451, toronto_lm_loss: 4.1549 ||
04/19 09:49:21 PM: Update 31944: task toronto_lm, batch 938 (31790): perplexity: 63.6630, toronto_lm_loss: 4.1536 ||
04/19 09:49:32 PM: Update 31958: task toronto_lm, batch 952 (31804): perplexity: 63.5420, toronto_lm_loss: 4.1517 ||
04/19 09:49:43 PM: Update 31972: task toronto_lm, batch 966 (31818): perplexity: 63.4070, toronto_lm_loss: 4.1496 ||
04/19 09:49:47 PM: Update 31978: task wsj, batch 7 (155): perplexity: 225.5300, wsj_loss: 5.4185 ||
04/19 09:49:53 PM: Update 31986: task toronto_lm, batch 979 (31831): perplexity: 63.3039, toronto_lm_loss: 4.1479 ||
04/19 09:50:04 PM: Update 32000: task toronto_lm, batch 993 (31845): perplexity: 63.1730, toronto_lm_loss: 4.1459 ||
04/19 09:50:04 PM: ***** Pass 32000 / Epoch 32 *****
04/19 09:50:04 PM: toronto_lm: trained on 993 batches, 0.005 epochs
04/19 09:50:04 PM: wsj: trained on 7 batches, 0.008 epochs
04/19 09:50:04 PM: Validating...
04/19 09:50:14 PM: Batch 39/140: perplexity: 92.3905, toronto_lm_loss: 4.5260 || , for evaluation data
04/19 09:50:24 PM: Batch 78/140: perplexity: 92.3944, toronto_lm_loss: 4.5261 || , for evaluation data
04/19 09:50:34 PM: Batch 117/140: perplexity: 86.2530, toronto_lm_loss: 4.4573 || , for evaluation data
04/19 09:50:41 PM: Batch 1/66: perplexity: 319.8502, wsj_loss: 5.7679 || , for evaluation data
04/19 09:50:51 PM: Batch 40/66: perplexity: 219.8109, wsj_loss: 5.3928 || , for evaluation data
04/19 09:50:58 PM: Advancing scheduler.
04/19 09:50:58 PM: 	Best macro_avg: 0.244
04/19 09:50:58 PM: 	# bad epochs: 2
04/19 09:50:58 PM: Statistic: toronto_lm_loss
04/19 09:50:58 PM: 	training: 4.145876
04/19 09:50:58 PM: 	validation: 4.415142
04/19 09:50:58 PM: Statistic: wsj_loss
04/19 09:50:58 PM: 	training: 5.418453
04/19 09:50:58 PM: 	validation: 5.379198
04/19 09:50:58 PM: Statistic: macro_avg
04/19 09:50:58 PM: 	validation: 0.233610
04/19 09:50:58 PM: Statistic: micro_avg
04/19 09:50:58 PM: 	validation: 0.042508
04/19 09:50:58 PM: Statistic: toronto_lm_perplexity
04/19 09:50:58 PM: 	training: 63.172952
04/19 09:50:58 PM: 	validation: 82.693565
04/19 09:50:58 PM: Statistic: wsj_perplexity
04/19 09:50:58 PM: 	training: 225.529991
04/19 09:50:58 PM: 	validation: 216.848320
04/19 09:50:58 PM: global_lr: 0.001000
04/19 09:50:58 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 09:50:59 PM: Update 32001: task toronto_lm, batch 1 (31846): perplexity: 47.4106, toronto_lm_loss: 3.8588 ||
04/19 09:51:09 PM: Update 32015: task toronto_lm, batch 15 (31860): perplexity: 56.3734, toronto_lm_loss: 4.0320 ||
04/19 09:51:20 PM: Update 32029: task toronto_lm, batch 29 (31874): perplexity: 55.1068, toronto_lm_loss: 4.0093 ||
04/19 09:51:31 PM: Update 32034: task toronto_lm, batch 34 (31879): perplexity: 60.4869, toronto_lm_loss: 4.1024 ||
04/19 09:51:41 PM: Update 32048: task toronto_lm, batch 48 (31893): perplexity: 70.0194, toronto_lm_loss: 4.2488 ||
04/19 09:51:52 PM: Update 32062: task toronto_lm, batch 62 (31907): perplexity: 74.8036, toronto_lm_loss: 4.3149 ||
04/19 09:52:03 PM: Update 32076: task toronto_lm, batch 76 (31921): perplexity: 76.4172, toronto_lm_loss: 4.3362 ||
04/19 09:52:13 PM: Update 32090: task toronto_lm, batch 90 (31935): perplexity: 77.5085, toronto_lm_loss: 4.3504 ||
04/19 09:52:24 PM: Update 32104: task toronto_lm, batch 104 (31949): perplexity: 78.0486, toronto_lm_loss: 4.3573 ||
04/19 09:52:35 PM: Update 32118: task toronto_lm, batch 118 (31963): perplexity: 78.1241, toronto_lm_loss: 4.3583 ||
04/19 09:52:45 PM: Update 32132: task toronto_lm, batch 132 (31977): perplexity: 78.3733, toronto_lm_loss: 4.3615 ||
04/19 09:52:56 PM: Update 32146: task toronto_lm, batch 146 (31991): perplexity: 78.0356, toronto_lm_loss: 4.3572 ||
04/19 09:53:07 PM: Update 32160: task toronto_lm, batch 160 (32005): perplexity: 77.5847, toronto_lm_loss: 4.3514 ||
04/19 09:53:17 PM: Update 32174: task toronto_lm, batch 174 (32019): perplexity: 77.6169, toronto_lm_loss: 4.3518 ||
04/19 09:53:28 PM: Update 32188: task toronto_lm, batch 188 (32033): perplexity: 77.1338, toronto_lm_loss: 4.3455 ||
04/19 09:53:39 PM: Update 32202: task toronto_lm, batch 202 (32047): perplexity: 77.0012, toronto_lm_loss: 4.3438 ||
04/19 09:53:49 PM: Update 32216: task toronto_lm, batch 216 (32061): perplexity: 76.6787, toronto_lm_loss: 4.3396 ||
04/19 09:54:00 PM: Update 32230: task toronto_lm, batch 230 (32075): perplexity: 76.2599, toronto_lm_loss: 4.3341 ||
04/19 09:54:11 PM: Update 32244: task toronto_lm, batch 244 (32089): perplexity: 76.1692, toronto_lm_loss: 4.3330 ||
04/19 09:54:21 PM: Update 32258: task toronto_lm, batch 258 (32103): perplexity: 75.9853, toronto_lm_loss: 4.3305 ||
04/19 09:54:32 PM: Update 32272: task toronto_lm, batch 272 (32117): perplexity: 75.5646, toronto_lm_loss: 4.3250 ||
04/19 09:54:43 PM: Update 32286: task toronto_lm, batch 286 (32131): perplexity: 75.1082, toronto_lm_loss: 4.3189 ||
04/19 09:54:53 PM: Update 32300: task toronto_lm, batch 300 (32145): perplexity: 75.0181, toronto_lm_loss: 4.3177 ||
04/19 09:55:04 PM: Update 32314: task toronto_lm, batch 314 (32159): perplexity: 74.7833, toronto_lm_loss: 4.3146 ||
04/19 09:55:15 PM: Update 32328: task toronto_lm, batch 328 (32173): perplexity: 74.5009, toronto_lm_loss: 4.3108 ||
04/19 09:55:25 PM: Update 32342: task toronto_lm, batch 342 (32187): perplexity: 74.3440, toronto_lm_loss: 4.3087 ||
04/19 09:55:36 PM: Update 32356: task toronto_lm, batch 356 (32201): perplexity: 74.2756, toronto_lm_loss: 4.3078 ||
04/19 09:55:47 PM: Update 32370: task toronto_lm, batch 370 (32215): perplexity: 74.1605, toronto_lm_loss: 4.3062 ||
04/19 09:55:57 PM: Update 32384: task toronto_lm, batch 384 (32229): perplexity: 73.9330, toronto_lm_loss: 4.3032 ||
04/19 09:56:08 PM: Update 32398: task toronto_lm, batch 398 (32243): perplexity: 73.8285, toronto_lm_loss: 4.3017 ||
04/19 09:56:19 PM: Update 32412: task toronto_lm, batch 412 (32257): perplexity: 73.6715, toronto_lm_loss: 4.2996 ||
04/19 09:56:29 PM: Update 32426: task toronto_lm, batch 426 (32271): perplexity: 73.4679, toronto_lm_loss: 4.2968 ||
04/19 09:56:40 PM: Update 32440: task toronto_lm, batch 440 (32285): perplexity: 73.2849, toronto_lm_loss: 4.2944 ||
04/19 09:56:50 PM: Update 32453: task toronto_lm, batch 453 (32298): perplexity: 73.1128, toronto_lm_loss: 4.2920 ||
04/19 09:57:01 PM: Update 32467: task toronto_lm, batch 467 (32312): perplexity: 73.0200, toronto_lm_loss: 4.2907 ||
04/19 09:57:12 PM: Update 32481: task toronto_lm, batch 481 (32326): perplexity: 72.7866, toronto_lm_loss: 4.2875 ||
04/19 09:57:22 PM: Update 32495: task toronto_lm, batch 495 (32340): perplexity: 72.6056, toronto_lm_loss: 4.2850 ||
04/19 09:57:28 PM: Update 32502: task wsj, batch 1 (156): perplexity: 234.9017, wsj_loss: 5.4592 ||
04/19 09:57:33 PM: Update 32508: task toronto_lm, batch 507 (32352): perplexity: 72.5224, toronto_lm_loss: 4.2839 ||
04/19 09:57:43 PM: Update 32521: task toronto_lm, batch 520 (32365): perplexity: 72.4062, toronto_lm_loss: 4.2823 ||
04/19 09:57:53 PM: Update 32534: task toronto_lm, batch 533 (32378): perplexity: 72.2655, toronto_lm_loss: 4.2803 ||
04/19 09:58:03 PM: Update 32547: task toronto_lm, batch 546 (32391): perplexity: 72.0336, toronto_lm_loss: 4.2771 ||
04/19 09:58:13 PM: Update 32560: task toronto_lm, batch 559 (32404): perplexity: 71.9797, toronto_lm_loss: 4.2764 ||
04/19 09:58:23 PM: Update 32573: task toronto_lm, batch 572 (32417): perplexity: 71.7812, toronto_lm_loss: 4.2736 ||
04/19 09:58:34 PM: Update 32587: task toronto_lm, batch 586 (32431): perplexity: 71.5697, toronto_lm_loss: 4.2707 ||
04/19 09:58:45 PM: Update 32601: task toronto_lm, batch 600 (32445): perplexity: 71.4724, toronto_lm_loss: 4.2693 ||
04/19 09:58:55 PM: Update 32615: task toronto_lm, batch 614 (32459): perplexity: 71.3423, toronto_lm_loss: 4.2675 ||
04/19 09:59:05 PM: Update 32628: task toronto_lm, batch 627 (32472): perplexity: 71.2038, toronto_lm_loss: 4.2655 ||
04/19 09:59:15 PM: Update 32641: task toronto_lm, batch 640 (32485): perplexity: 71.0511, toronto_lm_loss: 4.2634 ||
04/19 09:59:19 PM: Update 32646: task wsj, batch 2 (157): perplexity: 238.4397, wsj_loss: 5.4741 ||
04/19 09:59:26 PM: Update 32655: task toronto_lm, batch 653 (32498): perplexity: 70.9119, toronto_lm_loss: 4.2614 ||
04/19 09:59:37 PM: Update 32658: task toronto_lm, batch 656 (32501): perplexity: 70.9408, toronto_lm_loss: 4.2618 ||
04/19 09:59:47 PM: Update 32672: task toronto_lm, batch 670 (32515): perplexity: 71.3041, toronto_lm_loss: 4.2670 ||
04/19 09:59:58 PM: Update 32686: task toronto_lm, batch 684 (32529): perplexity: 71.5993, toronto_lm_loss: 4.2711 ||
04/19 10:00:08 PM: Update 32699: task toronto_lm, batch 697 (32542): perplexity: 71.8529, toronto_lm_loss: 4.2746 ||
04/19 10:00:18 PM: Update 32712: task toronto_lm, batch 710 (32555): perplexity: 72.0758, toronto_lm_loss: 4.2777 ||
04/19 10:00:29 PM: Update 32726: task toronto_lm, batch 724 (32569): perplexity: 72.2611, toronto_lm_loss: 4.2803 ||
04/19 10:00:40 PM: Update 32740: task toronto_lm, batch 738 (32583): perplexity: 72.4805, toronto_lm_loss: 4.2833 ||
04/19 10:00:50 PM: Update 32753: task toronto_lm, batch 751 (32596): perplexity: 72.6729, toronto_lm_loss: 4.2860 ||
04/19 10:01:00 PM: Update 32766: task toronto_lm, batch 764 (32609): perplexity: 72.7691, toronto_lm_loss: 4.2873 ||
04/19 10:01:11 PM: Update 32780: task toronto_lm, batch 778 (32623): perplexity: 72.8785, toronto_lm_loss: 4.2888 ||
04/19 10:01:21 PM: Update 32793: task toronto_lm, batch 791 (32636): perplexity: 72.9748, toronto_lm_loss: 4.2901 ||
04/19 10:01:31 PM: Update 32806: task toronto_lm, batch 804 (32649): perplexity: 73.0543, toronto_lm_loss: 4.2912 ||
04/19 10:01:41 PM: Update 32819: task toronto_lm, batch 817 (32662): perplexity: 73.1463, toronto_lm_loss: 4.2925 ||
04/19 10:01:51 PM: Update 32832: task toronto_lm, batch 830 (32675): perplexity: 73.2643, toronto_lm_loss: 4.2941 ||
04/19 10:02:01 PM: Update 32845: task toronto_lm, batch 843 (32688): perplexity: 73.2957, toronto_lm_loss: 4.2945 ||
04/19 10:02:12 PM: Update 32859: task toronto_lm, batch 857 (32702): perplexity: 73.4093, toronto_lm_loss: 4.2961 ||
04/19 10:02:22 PM: Update 32872: task toronto_lm, batch 870 (32715): perplexity: 73.5098, toronto_lm_loss: 4.2974 ||
04/19 10:02:32 PM: Update 32885: task toronto_lm, batch 883 (32728): perplexity: 73.5586, toronto_lm_loss: 4.2981 ||
04/19 10:02:42 PM: Update 32898: task toronto_lm, batch 896 (32741): perplexity: 73.6229, toronto_lm_loss: 4.2990 ||
04/19 10:02:52 PM: Update 32911: task toronto_lm, batch 909 (32754): perplexity: 73.6706, toronto_lm_loss: 4.2996 ||
04/19 10:03:03 PM: Update 32925: task toronto_lm, batch 923 (32768): perplexity: 73.7242, toronto_lm_loss: 4.3003 ||
04/19 10:03:14 PM: Update 32939: task toronto_lm, batch 937 (32782): perplexity: 73.8280, toronto_lm_loss: 4.3017 ||
04/19 10:03:24 PM: Update 32952: task toronto_lm, batch 950 (32795): perplexity: 73.8709, toronto_lm_loss: 4.3023 ||
04/19 10:03:34 PM: Update 32966: task toronto_lm, batch 964 (32809): perplexity: 73.9245, toronto_lm_loss: 4.3030 ||
04/19 10:03:44 PM: Update 32979: task toronto_lm, batch 977 (32822): perplexity: 73.9432, toronto_lm_loss: 4.3033 ||
04/19 10:03:55 PM: Update 32993: task toronto_lm, batch 991 (32836): perplexity: 74.0440, toronto_lm_loss: 4.3047 ||
04/19 10:04:00 PM: ***** Pass 33000 / Epoch 33 *****
04/19 10:04:00 PM: toronto_lm: trained on 998 batches, 0.005 epochs
04/19 10:04:00 PM: wsj: trained on 2 batches, 0.002 epochs
04/19 10:04:00 PM: Validating...
04/19 10:04:05 PM: Batch 19/140: perplexity: 88.7685, toronto_lm_loss: 4.4860 || , for evaluation data
04/19 10:04:15 PM: Batch 58/140: perplexity: 85.3576, toronto_lm_loss: 4.4468 || , for evaluation data
04/19 10:04:26 PM: Batch 97/140: perplexity: 80.3805, toronto_lm_loss: 4.3868 || , for evaluation data
04/19 10:04:36 PM: Batch 136/140: perplexity: 73.8992, toronto_lm_loss: 4.3027 || , for evaluation data
04/19 10:04:38 PM: Batch 1/66: perplexity: 335.7206, wsj_loss: 5.8163 || , for evaluation data
04/19 10:04:49 PM: Batch 40/66: perplexity: 233.3099, wsj_loss: 5.4524 || , for evaluation data
04/19 10:04:55 PM: Advancing scheduler.
04/19 10:04:55 PM: 	Best macro_avg: 0.244
04/19 10:04:55 PM: 	# bad epochs: 3
04/19 10:04:55 PM: Statistic: toronto_lm_loss
04/19 10:04:55 PM: 	training: 4.304674
04/19 10:04:55 PM: 	validation: 4.299188
04/19 10:04:55 PM: Statistic: wsj_loss
04/19 10:04:55 PM: 	training: 5.474116
04/19 10:04:55 PM: 	validation: 5.438669
04/19 10:04:55 PM: Statistic: macro_avg
04/19 10:04:55 PM: 	validation: 0.216089
04/19 10:04:55 PM: Statistic: micro_avg
04/19 10:04:55 PM: 	validation: 0.025472
04/19 10:04:55 PM: Statistic: toronto_lm_perplexity
04/19 10:04:55 PM: 	training: 74.045102
04/19 10:04:55 PM: 	validation: 73.640005
04/19 10:04:55 PM: Statistic: wsj_perplexity
04/19 10:04:55 PM: 	training: 238.439671
04/19 10:04:55 PM: 	validation: 230.135631
04/19 10:04:55 PM: global_lr: 0.001000
04/19 10:04:56 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 10:04:56 PM: Update 33001: task toronto_lm, batch 1 (32844): perplexity: 71.1717, toronto_lm_loss: 4.2651 ||
04/19 10:05:06 PM: Update 33014: task toronto_lm, batch 14 (32857): perplexity: 72.3058, toronto_lm_loss: 4.2809 ||
04/19 10:05:17 PM: Update 33027: task toronto_lm, batch 27 (32870): perplexity: 73.8728, toronto_lm_loss: 4.3023 ||
04/19 10:05:27 PM: Update 33041: task toronto_lm, batch 41 (32884): perplexity: 73.6666, toronto_lm_loss: 4.2995 ||
04/19 10:05:37 PM: Update 33054: task toronto_lm, batch 54 (32897): perplexity: 74.0844, toronto_lm_loss: 4.3052 ||
04/19 10:05:47 PM: Update 33067: task toronto_lm, batch 67 (32910): perplexity: 73.9057, toronto_lm_loss: 4.3028 ||
04/19 10:05:58 PM: Update 33081: task toronto_lm, batch 81 (32924): perplexity: 74.5744, toronto_lm_loss: 4.3118 ||
04/19 10:06:04 PM: Update 33088: task wsj, batch 1 (158): perplexity: 182.0015, wsj_loss: 5.2040 ||
04/19 10:06:08 PM: Update 33094: task toronto_lm, batch 93 (32936): perplexity: 74.0346, toronto_lm_loss: 4.3045 ||
04/19 10:06:18 PM: Update 33107: task toronto_lm, batch 106 (32949): perplexity: 74.1633, toronto_lm_loss: 4.3063 ||
04/19 10:06:29 PM: Update 33121: task toronto_lm, batch 120 (32963): perplexity: 74.6147, toronto_lm_loss: 4.3123 ||
04/19 10:06:40 PM: Update 33135: task toronto_lm, batch 134 (32977): perplexity: 74.7847, toronto_lm_loss: 4.3146 ||
04/19 10:06:50 PM: Update 33149: task toronto_lm, batch 148 (32991): perplexity: 74.3342, toronto_lm_loss: 4.3086 ||
04/19 10:06:57 PM: Update 33158: task wsj, batch 2 (159): perplexity: 225.4863, wsj_loss: 5.4183 ||
04/19 10:07:01 PM: Update 33163: task toronto_lm, batch 161 (33004): perplexity: 74.2587, toronto_lm_loss: 4.3076 ||
04/19 10:07:11 PM: Update 33176: task toronto_lm, batch 174 (33017): perplexity: 74.2010, toronto_lm_loss: 4.3068 ||
04/19 10:07:22 PM: Update 33190: task toronto_lm, batch 188 (33031): perplexity: 73.9774, toronto_lm_loss: 4.3038 ||
04/19 10:07:32 PM: Update 33203: task toronto_lm, batch 201 (33044): perplexity: 73.7326, toronto_lm_loss: 4.3004 ||
04/19 10:07:42 PM: Update 33216: task toronto_lm, batch 214 (33057): perplexity: 73.6726, toronto_lm_loss: 4.2996 ||
04/19 10:07:53 PM: Update 33230: task toronto_lm, batch 228 (33071): perplexity: 73.3664, toronto_lm_loss: 4.2955 ||
04/19 10:08:04 PM: Update 33244: task toronto_lm, batch 242 (33085): perplexity: 73.5457, toronto_lm_loss: 4.2979 ||
04/19 10:08:14 PM: Update 33258: task toronto_lm, batch 256 (33099): perplexity: 73.6622, toronto_lm_loss: 4.2995 ||
04/19 10:08:25 PM: Update 33272: task toronto_lm, batch 270 (33113): perplexity: 73.5877, toronto_lm_loss: 4.2985 ||
04/19 10:08:42 PM: Update 33285: task toronto_lm, batch 283 (33126): perplexity: 73.8077, toronto_lm_loss: 4.3015 ||
04/19 10:08:52 PM: Update 33299: task toronto_lm, batch 297 (33140): perplexity: 74.8892, toronto_lm_loss: 4.3160 ||
04/19 10:09:03 PM: Update 33313: task toronto_lm, batch 311 (33154): perplexity: 75.7712, toronto_lm_loss: 4.3277 ||
04/19 10:09:14 PM: Update 33327: task toronto_lm, batch 325 (33168): perplexity: 76.4047, toronto_lm_loss: 4.3360 ||
04/19 10:09:25 PM: Update 33341: task toronto_lm, batch 339 (33182): perplexity: 77.0265, toronto_lm_loss: 4.3442 ||
04/19 10:09:35 PM: Update 33355: task toronto_lm, batch 353 (33196): perplexity: 77.4736, toronto_lm_loss: 4.3499 ||
04/19 10:09:46 PM: Update 33369: task toronto_lm, batch 367 (33210): perplexity: 77.8552, toronto_lm_loss: 4.3549 ||
04/19 10:09:55 PM: Update 33381: task wsj, batch 3 (160): perplexity: 215.2171, wsj_loss: 5.3716 ||
04/19 10:09:57 PM: Update 33383: task toronto_lm, batch 380 (33223): perplexity: 78.2427, toronto_lm_loss: 4.3598 ||
04/19 10:10:07 PM: Update 33397: task toronto_lm, batch 394 (33237): perplexity: 78.5914, toronto_lm_loss: 4.3643 ||
04/19 10:10:18 PM: Update 33411: task toronto_lm, batch 408 (33251): perplexity: 78.8055, toronto_lm_loss: 4.3670 ||
04/19 10:10:29 PM: Update 33425: task toronto_lm, batch 422 (33265): perplexity: 79.1651, toronto_lm_loss: 4.3715 ||
04/19 10:10:39 PM: Update 33439: task toronto_lm, batch 436 (33279): perplexity: 79.3005, toronto_lm_loss: 4.3732 ||
04/19 10:10:50 PM: Update 33453: task toronto_lm, batch 450 (33293): perplexity: 79.3065, toronto_lm_loss: 4.3733 ||
04/19 10:11:01 PM: Update 33467: task toronto_lm, batch 464 (33307): perplexity: 79.2474, toronto_lm_loss: 4.3726 ||
04/19 10:11:12 PM: Update 33481: task toronto_lm, batch 478 (33321): perplexity: 79.2475, toronto_lm_loss: 4.3726 ||
04/19 10:11:22 PM: Update 33494: task toronto_lm, batch 491 (33334): perplexity: 79.1160, toronto_lm_loss: 4.3709 ||
04/19 10:11:32 PM: Update 33507: task toronto_lm, batch 504 (33347): perplexity: 78.9321, toronto_lm_loss: 4.3686 ||
04/19 10:11:42 PM: Update 33521: task toronto_lm, batch 518 (33361): perplexity: 78.8164, toronto_lm_loss: 4.3671 ||
04/19 10:11:53 PM: Update 33535: task toronto_lm, batch 532 (33375): perplexity: 78.7164, toronto_lm_loss: 4.3659 ||
04/19 10:12:01 PM: Update 33546: task wsj, batch 4 (161): perplexity: 210.8619, wsj_loss: 5.3512 ||
04/19 10:12:04 PM: Update 33549: task toronto_lm, batch 545 (33388): perplexity: 78.5591, toronto_lm_loss: 4.3639 ||
04/19 10:12:14 PM: Update 33563: task toronto_lm, batch 558 (33401): perplexity: 78.5871, toronto_lm_loss: 4.3642 ||
04/19 10:12:25 PM: Update 33577: task toronto_lm, batch 572 (33415): perplexity: 78.4982, toronto_lm_loss: 4.3631 ||
04/19 10:12:35 PM: Update 33590: task toronto_lm, batch 585 (33428): perplexity: 78.4750, toronto_lm_loss: 4.3628 ||
04/19 10:12:45 PM: Update 33603: task toronto_lm, batch 598 (33441): perplexity: 78.4212, toronto_lm_loss: 4.3621 ||
04/19 10:12:55 PM: Update 33616: task toronto_lm, batch 611 (33454): perplexity: 78.3647, toronto_lm_loss: 4.3614 ||
04/19 10:13:06 PM: Update 33629: task toronto_lm, batch 624 (33467): perplexity: 78.3679, toronto_lm_loss: 4.3614 ||
04/19 10:13:14 PM: Update 33640: task wsj, batch 6 (163): perplexity: 215.7260, wsj_loss: 5.3740 ||
04/19 10:13:16 PM: Update 33642: task toronto_lm, batch 636 (33479): perplexity: 78.3308, toronto_lm_loss: 4.3609 ||
04/19 10:13:26 PM: Update 33655: task toronto_lm, batch 649 (33492): perplexity: 78.2174, toronto_lm_loss: 4.3595 ||
04/19 10:13:36 PM: Update 33668: task toronto_lm, batch 662 (33505): perplexity: 78.1558, toronto_lm_loss: 4.3587 ||
04/19 10:13:46 PM: Update 33681: task toronto_lm, batch 675 (33518): perplexity: 78.0786, toronto_lm_loss: 4.3577 ||
04/19 10:13:56 PM: Update 33694: task toronto_lm, batch 688 (33531): perplexity: 77.9680, toronto_lm_loss: 4.3563 ||
04/19 10:14:06 PM: Update 33707: task toronto_lm, batch 701 (33544): perplexity: 77.8656, toronto_lm_loss: 4.3550 ||
04/19 10:14:16 PM: Update 33720: task toronto_lm, batch 714 (33557): perplexity: 77.8251, toronto_lm_loss: 4.3545 ||
04/19 10:14:26 PM: Update 33733: task toronto_lm, batch 727 (33570): perplexity: 77.6704, toronto_lm_loss: 4.3525 ||
04/19 10:14:36 PM: Update 33746: task toronto_lm, batch 740 (33583): perplexity: 77.6125, toronto_lm_loss: 4.3517 ||
04/19 10:14:46 PM: Update 33759: task toronto_lm, batch 753 (33596): perplexity: 77.5613, toronto_lm_loss: 4.3511 ||
04/19 10:14:57 PM: Update 33772: task toronto_lm, batch 766 (33609): perplexity: 77.4622, toronto_lm_loss: 4.3498 ||
04/19 10:15:07 PM: Update 33785: task toronto_lm, batch 779 (33622): perplexity: 77.3051, toronto_lm_loss: 4.3478 ||
04/19 10:15:17 PM: Update 33798: task toronto_lm, batch 792 (33635): perplexity: 77.2254, toronto_lm_loss: 4.3467 ||
04/19 10:15:27 PM: Update 33811: task toronto_lm, batch 805 (33648): perplexity: 77.1409, toronto_lm_loss: 4.3456 ||
04/19 10:15:37 PM: Update 33824: task toronto_lm, batch 818 (33661): perplexity: 77.0548, toronto_lm_loss: 4.3445 ||
04/19 10:15:48 PM: Update 33838: task toronto_lm, batch 832 (33675): perplexity: 76.9308, toronto_lm_loss: 4.3429 ||
04/19 10:15:58 PM: Update 33851: task toronto_lm, batch 845 (33688): perplexity: 76.8475, toronto_lm_loss: 4.3418 ||
04/19 10:16:08 PM: Update 33864: task wsj, batch 7 (164): perplexity: 209.9681, wsj_loss: 5.3470 ||
04/19 10:16:09 PM: Update 33865: task toronto_lm, batch 858 (33701): perplexity: 76.7471, toronto_lm_loss: 4.3405 ||
04/19 10:16:19 PM: Update 33878: task toronto_lm, batch 870 (33713): perplexity: 76.6846, toronto_lm_loss: 4.3397 ||
04/19 10:16:29 PM: Update 33892: task toronto_lm, batch 884 (33727): perplexity: 76.6409, toronto_lm_loss: 4.3391 ||
04/19 10:16:40 PM: Update 33906: task toronto_lm, batch 898 (33741): perplexity: 76.5669, toronto_lm_loss: 4.3382 ||
04/19 10:16:56 PM: Update 33916: task toronto_lm, batch 908 (33751): perplexity: 76.4738, toronto_lm_loss: 4.3369 ||
04/19 10:17:06 PM: Update 33929: task toronto_lm, batch 921 (33764): perplexity: 76.5727, toronto_lm_loss: 4.3382 ||
04/19 10:17:17 PM: Update 33943: task toronto_lm, batch 935 (33778): perplexity: 76.5847, toronto_lm_loss: 4.3384 ||
04/19 10:17:27 PM: Update 33956: task toronto_lm, batch 948 (33791): perplexity: 76.5764, toronto_lm_loss: 4.3383 ||
04/19 10:17:37 PM: Update 33969: task toronto_lm, batch 961 (33804): perplexity: 76.5444, toronto_lm_loss: 4.3379 ||
04/19 10:17:47 PM: Update 33982: task toronto_lm, batch 974 (33817): perplexity: 76.5024, toronto_lm_loss: 4.3373 ||
04/19 10:17:57 PM: Update 33995: task toronto_lm, batch 987 (33830): perplexity: 76.3892, toronto_lm_loss: 4.3358 ||
04/19 10:18:01 PM: ***** Pass 34000 / Epoch 34 *****
04/19 10:18:01 PM: toronto_lm: trained on 992 batches, 0.005 epochs
04/19 10:18:01 PM: wsj: trained on 8 batches, 0.010 epochs
04/19 10:18:01 PM: Validating...
04/19 10:18:07 PM: Batch 23/140: perplexity: 87.3429, toronto_lm_loss: 4.4698 || , for evaluation data
04/19 10:18:17 PM: Batch 61/140: perplexity: 84.3238, toronto_lm_loss: 4.4347 || , for evaluation data
04/19 10:18:27 PM: Batch 99/140: perplexity: 80.3942, toronto_lm_loss: 4.3869 || , for evaluation data
04/19 10:18:37 PM: Batch 132/140: perplexity: 76.0919, toronto_lm_loss: 4.3319 || , for evaluation data
04/19 10:18:40 PM: Batch 1/66: perplexity: 314.8048, wsj_loss: 5.7520 || , for evaluation data
04/19 10:18:50 PM: Batch 39/66: perplexity: 219.7271, wsj_loss: 5.3924 || , for evaluation data
04/19 10:18:57 PM: Best model found for wsj.
04/19 10:18:57 PM: Best model found for micro.
04/19 10:18:57 PM: Best model found for macro.
04/19 10:18:57 PM: Advancing scheduler.
04/19 10:18:57 PM: 	Best macro_avg: 0.249
04/19 10:18:57 PM: 	# bad epochs: 0
04/19 10:18:57 PM: Statistic: toronto_lm_loss
04/19 10:18:57 PM: 	training: 4.335775
04/19 10:18:57 PM: 	validation: 4.319887
04/19 10:18:57 PM: Statistic: wsj_loss
04/19 10:18:57 PM: 	training: 5.363828
04/19 10:18:57 PM: 	validation: 5.361101
04/19 10:18:57 PM: Statistic: macro_avg
04/19 10:18:57 PM: 	validation: 0.248901
04/19 10:18:57 PM: Statistic: micro_avg
04/19 10:18:57 PM: 	validation: 0.047494
04/19 10:18:57 PM: Statistic: toronto_lm_perplexity
04/19 10:18:57 PM: 	training: 76.384145
04/19 10:18:57 PM: 	validation: 75.180109
04/19 10:18:57 PM: Statistic: wsj_perplexity
04/19 10:18:57 PM: 	training: 213.540882
04/19 10:18:57 PM: 	validation: 212.959367
04/19 10:18:57 PM: global_lr: 0.001000
04/19 10:18:57 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 10:18:58 PM: Update 34001: task toronto_lm, batch 1 (33836): perplexity: 58.0815, toronto_lm_loss: 4.0618 ||
04/19 10:19:08 PM: Update 34014: task toronto_lm, batch 14 (33849): perplexity: 68.2307, toronto_lm_loss: 4.2229 ||
04/19 10:19:18 PM: Update 34027: task toronto_lm, batch 27 (33862): perplexity: 67.5782, toronto_lm_loss: 4.2133 ||
04/19 10:19:28 PM: Update 34040: task toronto_lm, batch 40 (33875): perplexity: 67.2440, toronto_lm_loss: 4.2083 ||
04/19 10:19:39 PM: Update 34053: task toronto_lm, batch 53 (33888): perplexity: 65.7802, toronto_lm_loss: 4.1863 ||
04/19 10:19:49 PM: Update 34066: task toronto_lm, batch 66 (33901): perplexity: 66.0333, toronto_lm_loss: 4.1902 ||
04/19 10:19:55 PM: Update 34074: task wsj, batch 1 (166): perplexity: 217.4227, wsj_loss: 5.3818 ||
04/19 10:19:59 PM: Update 34079: task toronto_lm, batch 78 (33913): perplexity: 66.2896, toronto_lm_loss: 4.1940 ||
04/19 10:20:09 PM: Update 34092: task toronto_lm, batch 91 (33926): perplexity: 65.7112, toronto_lm_loss: 4.1853 ||
04/19 10:20:20 PM: Update 34106: task toronto_lm, batch 105 (33940): perplexity: 65.1540, toronto_lm_loss: 4.1768 ||
04/19 10:20:30 PM: Update 34119: task toronto_lm, batch 118 (33953): perplexity: 65.1179, toronto_lm_loss: 4.1762 ||
04/19 10:20:40 PM: Update 34132: task toronto_lm, batch 131 (33966): perplexity: 64.7172, toronto_lm_loss: 4.1700 ||
04/19 10:20:50 PM: Update 34145: task toronto_lm, batch 144 (33979): perplexity: 64.8551, toronto_lm_loss: 4.1722 ||
04/19 10:21:01 PM: Update 34159: task toronto_lm, batch 158 (33993): perplexity: 64.6332, toronto_lm_loss: 4.1687 ||
04/19 10:21:11 PM: Update 34172: task toronto_lm, batch 171 (34006): perplexity: 64.6132, toronto_lm_loss: 4.1684 ||
04/19 10:21:22 PM: Update 34186: task toronto_lm, batch 185 (34020): perplexity: 64.3392, toronto_lm_loss: 4.1642 ||
04/19 10:21:32 PM: Update 34200: task toronto_lm, batch 199 (34034): perplexity: 64.2837, toronto_lm_loss: 4.1633 ||
04/19 10:21:42 PM: Update 34213: task toronto_lm, batch 212 (34047): perplexity: 64.0086, toronto_lm_loss: 4.1590 ||
04/19 10:21:53 PM: Update 34227: task toronto_lm, batch 226 (34061): perplexity: 63.9678, toronto_lm_loss: 4.1584 ||
04/19 10:22:04 PM: Update 34241: task toronto_lm, batch 240 (34075): perplexity: 63.9026, toronto_lm_loss: 4.1574 ||
04/19 10:22:15 PM: Update 34255: task toronto_lm, batch 254 (34089): perplexity: 63.7855, toronto_lm_loss: 4.1555 ||
04/19 10:22:25 PM: Update 34269: task toronto_lm, batch 268 (34103): perplexity: 63.5628, toronto_lm_loss: 4.1520 ||
04/19 10:22:36 PM: Update 34283: task toronto_lm, batch 282 (34117): perplexity: 63.2398, toronto_lm_loss: 4.1469 ||
04/19 10:22:47 PM: Update 34297: task toronto_lm, batch 296 (34131): perplexity: 63.2909, toronto_lm_loss: 4.1477 ||
04/19 10:22:57 PM: Update 34311: task toronto_lm, batch 310 (34145): perplexity: 63.0386, toronto_lm_loss: 4.1437 ||
04/19 10:23:08 PM: Update 34325: task toronto_lm, batch 324 (34159): perplexity: 62.7684, toronto_lm_loss: 4.1395 ||
04/19 10:23:19 PM: Update 34339: task toronto_lm, batch 338 (34173): perplexity: 62.4741, toronto_lm_loss: 4.1348 ||
04/19 10:23:30 PM: Update 34353: task toronto_lm, batch 352 (34187): perplexity: 62.3838, toronto_lm_loss: 4.1333 ||
04/19 10:23:40 PM: Update 34366: task toronto_lm, batch 365 (34200): perplexity: 62.1979, toronto_lm_loss: 4.1303 ||
04/19 10:23:49 PM: Update 34378: task wsj, batch 2 (167): perplexity: 190.0945, wsj_loss: 5.2475 ||
04/19 10:23:50 PM: Update 34380: task toronto_lm, batch 378 (34213): perplexity: 62.1783, toronto_lm_loss: 4.1300 ||
04/19 10:24:01 PM: Update 34394: task toronto_lm, batch 392 (34227): perplexity: 62.1832, toronto_lm_loss: 4.1301 ||
04/19 10:24:11 PM: Update 34407: task toronto_lm, batch 405 (34240): perplexity: 62.1417, toronto_lm_loss: 4.1294 ||
04/19 10:24:22 PM: Update 34421: task toronto_lm, batch 419 (34254): perplexity: 62.1269, toronto_lm_loss: 4.1292 ||
04/19 10:24:32 PM: Update 34434: task toronto_lm, batch 432 (34267): perplexity: 62.1398, toronto_lm_loss: 4.1294 ||
04/19 10:24:42 PM: Update 34447: task toronto_lm, batch 445 (34280): perplexity: 62.0441, toronto_lm_loss: 4.1278 ||
04/19 10:24:53 PM: Update 34461: task toronto_lm, batch 459 (34294): perplexity: 61.9719, toronto_lm_loss: 4.1267 ||
04/19 10:25:04 PM: Update 34475: task toronto_lm, batch 473 (34308): perplexity: 61.8456, toronto_lm_loss: 4.1246 ||
04/19 10:25:14 PM: Update 34489: task toronto_lm, batch 487 (34322): perplexity: 61.7228, toronto_lm_loss: 4.1227 ||
04/19 10:25:25 PM: Update 34503: task toronto_lm, batch 501 (34336): perplexity: 61.6687, toronto_lm_loss: 4.1218 ||
04/19 10:25:35 PM: Update 34516: task toronto_lm, batch 514 (34349): perplexity: 61.5405, toronto_lm_loss: 4.1197 ||
04/19 10:25:46 PM: Update 34530: task toronto_lm, batch 528 (34363): perplexity: 61.3959, toronto_lm_loss: 4.1173 ||
04/19 10:26:03 PM: Update 34543: task toronto_lm, batch 541 (34376): perplexity: 61.4617, toronto_lm_loss: 4.1184 ||
04/19 10:26:13 PM: Update 34557: task toronto_lm, batch 555 (34390): perplexity: 62.0878, toronto_lm_loss: 4.1286 ||
04/19 10:26:24 PM: Update 34571: task toronto_lm, batch 569 (34404): perplexity: 62.3984, toronto_lm_loss: 4.1335 ||
04/19 10:26:34 PM: Update 34584: task toronto_lm, batch 582 (34417): perplexity: 62.6733, toronto_lm_loss: 4.1379 ||
04/19 10:26:45 PM: Update 34598: task toronto_lm, batch 596 (34431): perplexity: 62.8784, toronto_lm_loss: 4.1412 ||
04/19 10:26:55 PM: Update 34612: task toronto_lm, batch 610 (34445): perplexity: 63.1233, toronto_lm_loss: 4.1451 ||
04/19 10:27:06 PM: Update 34626: task toronto_lm, batch 624 (34459): perplexity: 63.3474, toronto_lm_loss: 4.1486 ||
04/19 10:27:17 PM: Update 34640: task toronto_lm, batch 638 (34473): perplexity: 63.5060, toronto_lm_loss: 4.1511 ||
04/19 10:27:28 PM: Update 34654: task toronto_lm, batch 652 (34487): perplexity: 63.6376, toronto_lm_loss: 4.1532 ||
04/19 10:27:38 PM: Update 34667: task toronto_lm, batch 665 (34500): perplexity: 63.7486, toronto_lm_loss: 4.1549 ||
04/19 10:27:49 PM: Update 34681: task toronto_lm, batch 679 (34514): perplexity: 63.9335, toronto_lm_loss: 4.1578 ||
04/19 10:27:59 PM: Update 34695: task toronto_lm, batch 693 (34528): perplexity: 64.0060, toronto_lm_loss: 4.1590 ||
04/19 10:28:10 PM: Update 34709: task toronto_lm, batch 707 (34542): perplexity: 64.1208, toronto_lm_loss: 4.1608 ||
04/19 10:28:20 PM: Update 34722: task toronto_lm, batch 720 (34555): perplexity: 64.2196, toronto_lm_loss: 4.1623 ||
04/19 10:28:30 PM: Update 34735: task toronto_lm, batch 733 (34568): perplexity: 64.2676, toronto_lm_loss: 4.1631 ||
04/19 10:28:41 PM: Update 34749: task toronto_lm, batch 747 (34582): perplexity: 64.3311, toronto_lm_loss: 4.1640 ||
04/19 10:28:51 PM: Update 34762: task toronto_lm, batch 760 (34595): perplexity: 64.3270, toronto_lm_loss: 4.1640 ||
04/19 10:29:01 PM: Update 34775: task toronto_lm, batch 773 (34608): perplexity: 64.3609, toronto_lm_loss: 4.1645 ||
04/19 10:29:11 PM: Update 34788: task toronto_lm, batch 786 (34621): perplexity: 64.5063, toronto_lm_loss: 4.1668 ||
04/19 10:29:22 PM: Update 34802: task toronto_lm, batch 800 (34635): perplexity: 64.5935, toronto_lm_loss: 4.1681 ||
04/19 10:29:32 PM: Update 34816: task toronto_lm, batch 814 (34649): perplexity: 64.6678, toronto_lm_loss: 4.1693 ||
04/19 10:29:42 PM: Update 34829: task toronto_lm, batch 827 (34662): perplexity: 64.7006, toronto_lm_loss: 4.1698 ||
04/19 10:29:53 PM: Update 34843: task toronto_lm, batch 841 (34676): perplexity: 64.6659, toronto_lm_loss: 4.1692 ||
04/19 10:30:03 PM: Update 34856: task toronto_lm, batch 854 (34689): perplexity: 64.6324, toronto_lm_loss: 4.1687 ||
04/19 10:30:13 PM: Update 34869: task toronto_lm, batch 867 (34702): perplexity: 64.6662, toronto_lm_loss: 4.1692 ||
04/19 10:30:24 PM: Update 34883: task toronto_lm, batch 881 (34716): perplexity: 64.6522, toronto_lm_loss: 4.1690 ||
04/19 10:30:34 PM: Update 34896: task toronto_lm, batch 894 (34729): perplexity: 64.6411, toronto_lm_loss: 4.1689 ||
04/19 10:30:42 PM: Update 34907: task wsj, batch 3 (168): perplexity: 214.0021, wsj_loss: 5.3660 ||
04/19 10:30:44 PM: Update 34909: task toronto_lm, batch 906 (34741): perplexity: 64.6249, toronto_lm_loss: 4.1686 ||
04/19 10:30:55 PM: Update 34923: task toronto_lm, batch 920 (34755): perplexity: 64.6651, toronto_lm_loss: 4.1692 ||
04/19 10:31:05 PM: Update 34937: task toronto_lm, batch 934 (34769): perplexity: 64.6625, toronto_lm_loss: 4.1692 ||
04/19 10:31:15 PM: Update 34950: task toronto_lm, batch 947 (34782): perplexity: 64.7042, toronto_lm_loss: 4.1698 ||
04/19 10:31:25 PM: Update 34963: task toronto_lm, batch 960 (34795): perplexity: 64.6902, toronto_lm_loss: 4.1696 ||
04/19 10:31:35 PM: Update 34976: task toronto_lm, batch 973 (34808): perplexity: 64.6463, toronto_lm_loss: 4.1689 ||
04/19 10:31:46 PM: Update 34990: task toronto_lm, batch 987 (34822): perplexity: 64.6006, toronto_lm_loss: 4.1682 ||
04/19 10:31:54 PM: ***** Pass 35000 / Epoch 35 *****
04/19 10:31:54 PM: toronto_lm: trained on 997 batches, 0.005 epochs
04/19 10:31:54 PM: wsj: trained on 3 batches, 0.004 epochs
04/19 10:31:54 PM: Validating...
04/19 10:31:56 PM: Batch 4/140: perplexity: 86.4929, toronto_lm_loss: 4.4601 || , for evaluation data
04/19 10:32:06 PM: Batch 43/140: perplexity: 83.2272, toronto_lm_loss: 4.4216 || , for evaluation data
04/19 10:32:16 PM: Batch 82/140: perplexity: 81.6433, toronto_lm_loss: 4.4024 || , for evaluation data
04/19 10:32:27 PM: Batch 121/140: perplexity: 76.6405, toronto_lm_loss: 4.3391 || , for evaluation data
04/19 10:32:32 PM: Batch 1/66: perplexity: 303.8419, wsj_loss: 5.7165 || , for evaluation data
04/19 10:32:42 PM: Batch 40/66: perplexity: 206.6998, wsj_loss: 5.3313 || , for evaluation data
04/19 10:32:49 PM: Best model found for wsj.
04/19 10:32:49 PM: Best model found for micro.
04/19 10:32:49 PM: Best model found for macro.
04/19 10:32:49 PM: Advancing scheduler.
04/19 10:32:49 PM: 	Best macro_avg: 0.265
04/19 10:32:49 PM: 	# bad epochs: 0
04/19 10:32:49 PM: Statistic: toronto_lm_loss
04/19 10:32:49 PM: 	training: 4.168156
04/19 10:32:49 PM: 	validation: 4.305749
04/19 10:32:49 PM: Statistic: wsj_loss
04/19 10:32:49 PM: 	training: 5.365986
04/19 10:32:49 PM: 	validation: 5.324874
04/19 10:32:49 PM: Statistic: macro_avg
04/19 10:32:49 PM: 	validation: 0.265110
04/19 10:32:49 PM: Statistic: micro_avg
04/19 10:32:49 PM: 	validation: 0.057209
04/19 10:32:49 PM: Statistic: toronto_lm_perplexity
04/19 10:32:49 PM: 	training: 64.596252
04/19 10:32:49 PM: 	validation: 74.124700
04/19 10:32:49 PM: Statistic: wsj_perplexity
04/19 10:32:49 PM: 	training: 214.002075
04/19 10:32:49 PM: 	validation: 205.382443
04/19 10:32:49 PM: global_lr: 0.001000
04/19 10:32:49 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 10:32:50 PM: Update 35001: task toronto_lm, batch 1 (34833): perplexity: 58.3069, toronto_lm_loss: 4.0657 ||
04/19 10:33:00 PM: Update 35015: task toronto_lm, batch 15 (34847): perplexity: 64.9826, toronto_lm_loss: 4.1741 ||
04/19 10:33:10 PM: Update 35028: task toronto_lm, batch 28 (34860): perplexity: 65.5379, toronto_lm_loss: 4.1826 ||
04/19 10:33:21 PM: Update 35042: task toronto_lm, batch 42 (34874): perplexity: 65.1536, toronto_lm_loss: 4.1767 ||
04/19 10:33:32 PM: Update 35056: task toronto_lm, batch 56 (34888): perplexity: 65.1774, toronto_lm_loss: 4.1771 ||
04/19 10:33:43 PM: Update 35070: task toronto_lm, batch 70 (34902): perplexity: 64.8037, toronto_lm_loss: 4.1714 ||
04/19 10:33:53 PM: Update 35084: task toronto_lm, batch 84 (34916): perplexity: 64.7337, toronto_lm_loss: 4.1703 ||
04/19 10:34:03 PM: Update 35097: task toronto_lm, batch 97 (34929): perplexity: 64.6167, toronto_lm_loss: 4.1685 ||
04/19 10:34:14 PM: Update 35110: task toronto_lm, batch 110 (34942): perplexity: 64.5991, toronto_lm_loss: 4.1682 ||
04/19 10:34:24 PM: Update 35123: task toronto_lm, batch 123 (34955): perplexity: 64.3835, toronto_lm_loss: 4.1649 ||
04/19 10:34:34 PM: Update 35136: task toronto_lm, batch 136 (34968): perplexity: 64.0320, toronto_lm_loss: 4.1594 ||
04/19 10:34:44 PM: Update 35149: task toronto_lm, batch 149 (34981): perplexity: 63.9396, toronto_lm_loss: 4.1579 ||
04/19 10:34:54 PM: Update 35162: task toronto_lm, batch 162 (34994): perplexity: 63.9044, toronto_lm_loss: 4.1574 ||
04/19 10:35:07 PM: Update 35169: task toronto_lm, batch 169 (35001): perplexity: 63.8693, toronto_lm_loss: 4.1568 ||
04/19 10:35:18 PM: Update 35182: task toronto_lm, batch 182 (35014): perplexity: 65.0798, toronto_lm_loss: 4.1756 ||
04/19 10:35:28 PM: Update 35195: task toronto_lm, batch 195 (35027): perplexity: 65.6917, toronto_lm_loss: 4.1850 ||
04/19 10:35:37 PM: Update 35207: task wsj, batch 1 (169): perplexity: 243.6096, wsj_loss: 5.4956 ||
04/19 10:35:38 PM: Update 35209: task toronto_lm, batch 208 (35040): perplexity: 66.4211, toronto_lm_loss: 4.1960 ||
04/19 10:35:49 PM: Update 35223: task toronto_lm, batch 222 (35054): perplexity: 66.8549, toronto_lm_loss: 4.2025 ||
04/19 10:35:59 PM: Update 35236: task toronto_lm, batch 235 (35067): perplexity: 67.4390, toronto_lm_loss: 4.2112 ||
04/19 10:36:09 PM: Update 35249: task wsj, batch 2 (170): perplexity: 259.3688, wsj_loss: 5.5583 ||
04/19 10:36:10 PM: Update 35250: task toronto_lm, batch 248 (35080): perplexity: 67.6700, toronto_lm_loss: 4.2146 ||
04/19 10:36:20 PM: Update 35263: task toronto_lm, batch 261 (35093): perplexity: 67.8699, toronto_lm_loss: 4.2176 ||
04/19 10:36:31 PM: Update 35277: task toronto_lm, batch 275 (35107): perplexity: 68.1027, toronto_lm_loss: 4.2210 ||
04/19 10:36:41 PM: Update 35290: task toronto_lm, batch 288 (35120): perplexity: 68.2072, toronto_lm_loss: 4.2225 ||
04/19 10:36:52 PM: Update 35304: task toronto_lm, batch 302 (35134): perplexity: 68.3623, toronto_lm_loss: 4.2248 ||
04/19 10:37:02 PM: Update 35317: task toronto_lm, batch 315 (35147): perplexity: 68.4368, toronto_lm_loss: 4.2259 ||
04/19 10:37:12 PM: Update 35331: task toronto_lm, batch 329 (35161): perplexity: 68.3836, toronto_lm_loss: 4.2251 ||
04/19 10:37:22 PM: Update 35344: task toronto_lm, batch 342 (35174): perplexity: 68.3537, toronto_lm_loss: 4.2247 ||
04/19 10:37:32 PM: Update 35357: task toronto_lm, batch 355 (35187): perplexity: 68.1699, toronto_lm_loss: 4.2220 ||
04/19 10:37:43 PM: Update 35371: task toronto_lm, batch 369 (35201): perplexity: 68.2693, toronto_lm_loss: 4.2235 ||
04/19 10:37:54 PM: Update 35385: task toronto_lm, batch 383 (35215): perplexity: 68.3124, toronto_lm_loss: 4.2241 ||
04/19 10:38:04 PM: Update 35398: task toronto_lm, batch 396 (35228): perplexity: 68.2962, toronto_lm_loss: 4.2239 ||
04/19 10:38:14 PM: Update 35412: task toronto_lm, batch 410 (35242): perplexity: 68.1841, toronto_lm_loss: 4.2222 ||
04/19 10:38:18 PM: Update 35417: task wsj, batch 3 (171): perplexity: 240.0526, wsj_loss: 5.4809 ||
04/19 10:38:24 PM: Update 35425: task toronto_lm, batch 422 (35254): perplexity: 68.1378, toronto_lm_loss: 4.2215 ||
04/19 10:38:35 PM: Update 35438: task toronto_lm, batch 435 (35267): perplexity: 68.0448, toronto_lm_loss: 4.2202 ||
04/19 10:38:45 PM: Update 35452: task toronto_lm, batch 449 (35281): perplexity: 68.0545, toronto_lm_loss: 4.2203 ||
04/19 10:38:56 PM: Update 35466: task toronto_lm, batch 463 (35295): perplexity: 67.9028, toronto_lm_loss: 4.2181 ||
04/19 10:39:06 PM: Update 35479: task toronto_lm, batch 476 (35308): perplexity: 67.7292, toronto_lm_loss: 4.2155 ||
04/19 10:39:16 PM: Update 35492: task toronto_lm, batch 489 (35321): perplexity: 67.6506, toronto_lm_loss: 4.2144 ||
04/19 10:39:26 PM: Update 35505: task toronto_lm, batch 502 (35334): perplexity: 67.7130, toronto_lm_loss: 4.2153 ||
04/19 10:39:36 PM: Update 35518: task toronto_lm, batch 515 (35347): perplexity: 67.6243, toronto_lm_loss: 4.2140 ||
04/19 10:39:38 PM: Update 35521: task wsj, batch 4 (172): perplexity: 237.0851, wsj_loss: 5.4684 ||
04/19 10:39:47 PM: Update 35532: task toronto_lm, batch 528 (35360): perplexity: 67.6401, toronto_lm_loss: 4.2142 ||
04/19 10:39:57 PM: Update 35545: task toronto_lm, batch 541 (35373): perplexity: 67.6162, toronto_lm_loss: 4.2138 ||
04/19 10:40:07 PM: Update 35558: task toronto_lm, batch 554 (35386): perplexity: 67.4748, toronto_lm_loss: 4.2118 ||
04/19 10:40:18 PM: Update 35572: task toronto_lm, batch 568 (35400): perplexity: 67.2806, toronto_lm_loss: 4.2089 ||
04/19 10:40:28 PM: Update 35586: task toronto_lm, batch 582 (35414): perplexity: 67.2027, toronto_lm_loss: 4.2077 ||
04/19 10:40:39 PM: Update 35600: task toronto_lm, batch 596 (35428): perplexity: 67.0910, toronto_lm_loss: 4.2061 ||
04/19 10:40:49 PM: Update 35613: task toronto_lm, batch 609 (35441): perplexity: 67.0220, toronto_lm_loss: 4.2050 ||
04/19 10:40:59 PM: Update 35626: task toronto_lm, batch 622 (35454): perplexity: 66.9428, toronto_lm_loss: 4.2038 ||
04/19 10:41:06 PM: Update 35635: task wsj, batch 5 (173): perplexity: 246.9715, wsj_loss: 5.5093 ||
04/19 10:41:09 PM: Update 35639: task toronto_lm, batch 634 (35466): perplexity: 66.8193, toronto_lm_loss: 4.2020 ||
04/19 10:41:19 PM: Update 35652: task toronto_lm, batch 647 (35479): perplexity: 66.7264, toronto_lm_loss: 4.2006 ||
04/19 10:41:30 PM: Update 35665: task toronto_lm, batch 660 (35492): perplexity: 66.6121, toronto_lm_loss: 4.1989 ||
04/19 10:41:40 PM: Update 35678: task toronto_lm, batch 673 (35505): perplexity: 66.5848, toronto_lm_loss: 4.1985 ||
04/19 10:41:50 PM: Update 35691: task toronto_lm, batch 686 (35518): perplexity: 66.5122, toronto_lm_loss: 4.1974 ||
04/19 10:42:00 PM: Update 35704: task toronto_lm, batch 699 (35531): perplexity: 66.4066, toronto_lm_loss: 4.1958 ||
04/19 10:42:10 PM: Update 35717: task toronto_lm, batch 712 (35544): perplexity: 66.3559, toronto_lm_loss: 4.1950 ||
04/19 10:42:20 PM: Update 35730: task toronto_lm, batch 725 (35557): perplexity: 66.2285, toronto_lm_loss: 4.1931 ||
04/19 10:42:30 PM: Update 35743: task toronto_lm, batch 738 (35570): perplexity: 66.1728, toronto_lm_loss: 4.1923 ||
04/19 10:42:40 PM: Update 35756: task toronto_lm, batch 751 (35583): perplexity: 66.1238, toronto_lm_loss: 4.1915 ||
04/19 10:42:50 PM: Update 35770: task toronto_lm, batch 765 (35597): perplexity: 66.0913, toronto_lm_loss: 4.1910 ||
04/19 10:43:01 PM: Update 35784: task toronto_lm, batch 779 (35611): perplexity: 66.0251, toronto_lm_loss: 4.1900 ||
04/19 10:43:11 PM: Update 35797: task toronto_lm, batch 792 (35624): perplexity: 65.9494, toronto_lm_loss: 4.1889 ||
04/19 10:43:22 PM: Update 35802: task toronto_lm, batch 797 (35629): perplexity: 66.0358, toronto_lm_loss: 4.1902 ||
04/19 10:43:32 PM: Update 35815: task toronto_lm, batch 810 (35642): perplexity: 66.3150, toronto_lm_loss: 4.1944 ||
04/19 10:43:42 PM: Update 35828: task toronto_lm, batch 823 (35655): perplexity: 66.4495, toronto_lm_loss: 4.1964 ||
04/19 10:43:52 PM: Update 35841: task toronto_lm, batch 836 (35668): perplexity: 66.5948, toronto_lm_loss: 4.1986 ||
04/19 10:44:02 PM: Update 35854: task toronto_lm, batch 849 (35681): perplexity: 66.6684, toronto_lm_loss: 4.1997 ||
04/19 10:44:12 PM: Update 35867: task toronto_lm, batch 862 (35694): perplexity: 66.7893, toronto_lm_loss: 4.2015 ||
04/19 10:44:22 PM: Update 35880: task toronto_lm, batch 875 (35707): perplexity: 66.8929, toronto_lm_loss: 4.2031 ||
04/19 10:44:32 PM: Update 35893: task toronto_lm, batch 888 (35720): perplexity: 66.9514, toronto_lm_loss: 4.2040 ||
04/19 10:44:43 PM: Update 35907: task toronto_lm, batch 902 (35734): perplexity: 67.0348, toronto_lm_loss: 4.2052 ||
04/19 10:44:53 PM: Update 35920: task toronto_lm, batch 915 (35747): perplexity: 67.0835, toronto_lm_loss: 4.2059 ||
04/19 10:45:03 PM: Update 35933: task toronto_lm, batch 928 (35760): perplexity: 67.1863, toronto_lm_loss: 4.2075 ||
04/19 10:45:13 PM: Update 35946: task toronto_lm, batch 941 (35773): perplexity: 67.1936, toronto_lm_loss: 4.2076 ||
04/19 10:45:22 PM: Update 35958: task wsj, batch 6 (174): perplexity: 234.2589, wsj_loss: 5.4564 ||
04/19 10:45:23 PM: Update 35959: task toronto_lm, batch 953 (35785): perplexity: 67.2189, toronto_lm_loss: 4.2080 ||
04/19 10:45:34 PM: Update 35973: task toronto_lm, batch 967 (35799): perplexity: 67.2990, toronto_lm_loss: 4.2091 ||
04/19 10:45:44 PM: Update 35986: task toronto_lm, batch 980 (35812): perplexity: 67.3441, toronto_lm_loss: 4.2098 ||
04/19 10:45:51 PM: Update 35996: task wsj, batch 7 (175): perplexity: 237.4514, wsj_loss: 5.4700 ||
04/19 10:45:55 PM: Update 36000: task toronto_lm, batch 993 (35825): perplexity: 67.3891, toronto_lm_loss: 4.2105 ||
04/19 10:45:55 PM: ***** Pass 36000 / Epoch 36 *****
04/19 10:45:55 PM: toronto_lm: trained on 993 batches, 0.005 epochs
04/19 10:45:55 PM: wsj: trained on 7 batches, 0.008 epochs
04/19 10:45:55 PM: Validating...
04/19 10:46:05 PM: Batch 39/140: perplexity: 81.5778, toronto_lm_loss: 4.4016 || , for evaluation data
04/19 10:46:15 PM: Batch 73/140: perplexity: 82.6886, toronto_lm_loss: 4.4151 || , for evaluation data
04/19 10:46:25 PM: Batch 112/140: perplexity: 77.1116, toronto_lm_loss: 4.3453 || , for evaluation data
04/19 10:46:33 PM: Batch 1/66: perplexity: 295.8533, wsj_loss: 5.6899 || , for evaluation data
04/19 10:46:43 PM: Batch 40/66: perplexity: 206.8347, wsj_loss: 5.3319 || , for evaluation data
04/19 10:46:50 PM: Best model found for wsj.
04/19 10:46:50 PM: Best model found for micro.
04/19 10:46:50 PM: Best model found for macro.
04/19 10:46:50 PM: Advancing scheduler.
04/19 10:46:50 PM: 	Best macro_avg: 0.267
04/19 10:46:50 PM: 	# bad epochs: 0
04/19 10:46:50 PM: Statistic: toronto_lm_loss
04/19 10:46:50 PM: 	training: 4.210483
04/19 10:46:50 PM: 	validation: 4.287055
04/19 10:46:50 PM: Statistic: wsj_loss
04/19 10:46:50 PM: 	training: 5.469963
04/19 10:46:50 PM: 	validation: 5.323610
04/19 10:46:50 PM: Statistic: macro_avg
04/19 10:46:50 PM: 	validation: 0.267002
04/19 10:46:50 PM: Statistic: micro_avg
04/19 10:46:50 PM: 	validation: 0.057541
04/19 10:46:50 PM: Statistic: toronto_lm_perplexity
04/19 10:46:50 PM: 	training: 67.389108
04/19 10:46:50 PM: 	validation: 72.751867
04/19 10:46:50 PM: Statistic: wsj_perplexity
04/19 10:46:50 PM: 	training: 237.451392
04/19 10:46:50 PM: 	validation: 205.123012
04/19 10:46:50 PM: global_lr: 0.001000
04/19 10:46:50 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 10:46:51 PM: Update 36001: task toronto_lm, batch 1 (35826): perplexity: 56.7915, toronto_lm_loss: 4.0394 ||
04/19 10:47:01 PM: Update 36015: task toronto_lm, batch 15 (35840): perplexity: 67.0576, toronto_lm_loss: 4.2056 ||
04/19 10:47:12 PM: Update 36029: task toronto_lm, batch 29 (35854): perplexity: 67.5059, toronto_lm_loss: 4.2122 ||
04/19 10:47:23 PM: Update 36043: task toronto_lm, batch 43 (35868): perplexity: 67.9197, toronto_lm_loss: 4.2183 ||
04/19 10:47:34 PM: Update 36057: task toronto_lm, batch 57 (35882): perplexity: 67.0663, toronto_lm_loss: 4.2057 ||
04/19 10:47:44 PM: Update 36070: task toronto_lm, batch 70 (35895): perplexity: 67.0413, toronto_lm_loss: 4.2053 ||
04/19 10:47:54 PM: Update 36084: task toronto_lm, batch 84 (35909): perplexity: 67.0160, toronto_lm_loss: 4.2049 ||
04/19 10:48:04 PM: Update 36097: task toronto_lm, batch 97 (35922): perplexity: 67.5942, toronto_lm_loss: 4.2135 ||
04/19 10:48:15 PM: Update 36111: task toronto_lm, batch 111 (35936): perplexity: 67.8829, toronto_lm_loss: 4.2178 ||
04/19 10:48:25 PM: Update 36124: task toronto_lm, batch 124 (35949): perplexity: 68.4070, toronto_lm_loss: 4.2255 ||
04/19 10:48:35 PM: Update 36137: task toronto_lm, batch 137 (35962): perplexity: 67.9971, toronto_lm_loss: 4.2195 ||
04/19 10:48:46 PM: Update 36151: task toronto_lm, batch 151 (35976): perplexity: 67.9297, toronto_lm_loss: 4.2185 ||
04/19 10:48:54 PM: Update 36161: task wsj, batch 1 (176): perplexity: 243.0780, wsj_loss: 5.4934 ||
04/19 10:48:56 PM: Update 36164: task toronto_lm, batch 163 (35988): perplexity: 67.8310, toronto_lm_loss: 4.2170 ||
04/19 10:49:06 PM: Update 36177: task toronto_lm, batch 175 (36000): perplexity: 67.6201, toronto_lm_loss: 4.2139 ||
04/19 10:49:17 PM: Update 36191: task toronto_lm, batch 189 (36014): perplexity: 67.4965, toronto_lm_loss: 4.2121 ||
04/19 10:49:28 PM: Update 36205: task toronto_lm, batch 203 (36028): perplexity: 67.4386, toronto_lm_loss: 4.2112 ||
04/19 10:49:38 PM: Update 36219: task toronto_lm, batch 217 (36042): perplexity: 67.1609, toronto_lm_loss: 4.2071 ||
04/19 10:49:48 PM: Update 36232: task toronto_lm, batch 230 (36055): perplexity: 67.1188, toronto_lm_loss: 4.2065 ||
04/19 10:49:58 PM: Update 36245: task toronto_lm, batch 243 (36068): perplexity: 66.9977, toronto_lm_loss: 4.2047 ||
04/19 10:50:09 PM: Update 36258: task toronto_lm, batch 256 (36081): perplexity: 66.9904, toronto_lm_loss: 4.2046 ||
04/19 10:50:11 PM: Update 36261: task wsj, batch 3 (178): perplexity: 243.8224, wsj_loss: 5.4964 ||
04/19 10:50:19 PM: Update 36271: task toronto_lm, batch 268 (36093): perplexity: 67.0045, toronto_lm_loss: 4.2048 ||
04/19 10:50:29 PM: Update 36284: task toronto_lm, batch 281 (36106): perplexity: 66.9417, toronto_lm_loss: 4.2038 ||
04/19 10:50:39 PM: Update 36297: task toronto_lm, batch 294 (36119): perplexity: 66.7911, toronto_lm_loss: 4.2016 ||
04/19 10:50:49 PM: Update 36310: task toronto_lm, batch 307 (36132): perplexity: 66.8658, toronto_lm_loss: 4.2027 ||
04/19 10:50:59 PM: Update 36323: task toronto_lm, batch 320 (36145): perplexity: 66.7379, toronto_lm_loss: 4.2008 ||
04/19 10:51:09 PM: Update 36336: task toronto_lm, batch 333 (36158): perplexity: 66.8550, toronto_lm_loss: 4.2025 ||
04/19 10:51:19 PM: Update 36349: task toronto_lm, batch 346 (36171): perplexity: 66.6907, toronto_lm_loss: 4.2001 ||
04/19 10:51:29 PM: Update 36362: task toronto_lm, batch 359 (36184): perplexity: 66.6435, toronto_lm_loss: 4.1994 ||
04/19 10:51:39 PM: Update 36375: task toronto_lm, batch 372 (36197): perplexity: 66.5692, toronto_lm_loss: 4.1982 ||
04/19 10:51:49 PM: Update 36388: task toronto_lm, batch 385 (36210): perplexity: 66.5792, toronto_lm_loss: 4.1984 ||
04/19 10:51:59 PM: Update 36401: task toronto_lm, batch 398 (36223): perplexity: 66.5976, toronto_lm_loss: 4.1987 ||
04/19 10:52:10 PM: Update 36415: task toronto_lm, batch 412 (36237): perplexity: 66.5823, toronto_lm_loss: 4.1984 ||
04/19 10:52:20 PM: Update 36428: task toronto_lm, batch 425 (36250): perplexity: 66.6531, toronto_lm_loss: 4.1995 ||
04/19 10:52:30 PM: Update 36430: task toronto_lm, batch 427 (36252): perplexity: 66.7139, toronto_lm_loss: 4.2004 ||
04/19 10:52:41 PM: Update 36444: task toronto_lm, batch 441 (36266): perplexity: 67.0978, toronto_lm_loss: 4.2062 ||
04/19 10:52:51 PM: Update 36457: task toronto_lm, batch 454 (36279): perplexity: 67.5434, toronto_lm_loss: 4.2128 ||
04/19 10:53:01 PM: Update 36470: task toronto_lm, batch 467 (36292): perplexity: 67.8468, toronto_lm_loss: 4.2173 ||
04/19 10:53:12 PM: Update 36484: task toronto_lm, batch 481 (36306): perplexity: 68.0727, toronto_lm_loss: 4.2206 ||
04/19 10:53:22 PM: Update 36498: task toronto_lm, batch 495 (36320): perplexity: 68.4448, toronto_lm_loss: 4.2260 ||
04/19 10:53:32 PM: Update 36511: task toronto_lm, batch 508 (36333): perplexity: 68.6373, toronto_lm_loss: 4.2288 ||
04/19 10:53:43 PM: Update 36524: task toronto_lm, batch 521 (36346): perplexity: 68.6264, toronto_lm_loss: 4.2287 ||
04/19 10:53:53 PM: Update 36537: task toronto_lm, batch 534 (36359): perplexity: 68.6178, toronto_lm_loss: 4.2286 ||
04/19 10:54:03 PM: Update 36550: task toronto_lm, batch 547 (36372): perplexity: 68.7286, toronto_lm_loss: 4.2302 ||
04/19 10:54:13 PM: Update 36563: task toronto_lm, batch 560 (36385): perplexity: 68.7938, toronto_lm_loss: 4.2311 ||
04/19 10:54:14 PM: Update 36564: task wsj, batch 4 (179): perplexity: 237.1346, wsj_loss: 5.4686 ||
04/19 10:54:23 PM: Update 36576: task toronto_lm, batch 572 (36397): perplexity: 68.9046, toronto_lm_loss: 4.2327 ||
04/19 10:54:24 PM: Update 36578: task wsj, batch 5 (180): perplexity: 235.0634, wsj_loss: 5.4599 ||
04/19 10:54:34 PM: Update 36590: task toronto_lm, batch 585 (36410): perplexity: 68.8734, toronto_lm_loss: 4.2323 ||
04/19 10:54:44 PM: Update 36603: task toronto_lm, batch 598 (36423): perplexity: 68.8723, toronto_lm_loss: 4.2323 ||
04/19 10:54:54 PM: Update 36617: task toronto_lm, batch 612 (36437): perplexity: 68.8284, toronto_lm_loss: 4.2316 ||
04/19 10:55:04 PM: Update 36630: task toronto_lm, batch 625 (36450): perplexity: 68.9098, toronto_lm_loss: 4.2328 ||
04/19 10:55:14 PM: Update 36643: task toronto_lm, batch 638 (36463): perplexity: 68.9526, toronto_lm_loss: 4.2334 ||
04/19 10:55:25 PM: Update 36656: task toronto_lm, batch 651 (36476): perplexity: 68.8998, toronto_lm_loss: 4.2327 ||
04/19 10:55:35 PM: Update 36670: task toronto_lm, batch 665 (36490): perplexity: 68.8344, toronto_lm_loss: 4.2317 ||
04/19 10:55:45 PM: Update 36683: task toronto_lm, batch 678 (36503): perplexity: 68.9091, toronto_lm_loss: 4.2328 ||
04/19 10:55:55 PM: Update 36696: task toronto_lm, batch 691 (36516): perplexity: 68.8334, toronto_lm_loss: 4.2317 ||
04/19 10:56:05 PM: Update 36709: task toronto_lm, batch 704 (36529): perplexity: 68.7829, toronto_lm_loss: 4.2310 ||
04/19 10:56:16 PM: Update 36723: task toronto_lm, batch 718 (36543): perplexity: 68.7534, toronto_lm_loss: 4.2305 ||
04/19 10:56:26 PM: Update 36736: task toronto_lm, batch 731 (36556): perplexity: 68.7750, toronto_lm_loss: 4.2308 ||
04/19 10:56:36 PM: Update 36749: task toronto_lm, batch 744 (36569): perplexity: 68.7507, toronto_lm_loss: 4.2305 ||
04/19 10:56:47 PM: Update 36763: task toronto_lm, batch 758 (36583): perplexity: 68.7092, toronto_lm_loss: 4.2299 ||
04/19 10:56:57 PM: Update 36776: task toronto_lm, batch 771 (36596): perplexity: 68.6775, toronto_lm_loss: 4.2294 ||
04/19 10:57:07 PM: Update 36789: task toronto_lm, batch 784 (36609): perplexity: 68.5990, toronto_lm_loss: 4.2283 ||
04/19 10:57:18 PM: Update 36803: task toronto_lm, batch 798 (36623): perplexity: 68.5210, toronto_lm_loss: 4.2271 ||
04/19 10:57:28 PM: Update 36816: task toronto_lm, batch 811 (36636): perplexity: 68.4442, toronto_lm_loss: 4.2260 ||
04/19 10:57:38 PM: Update 36830: task toronto_lm, batch 825 (36650): perplexity: 68.4428, toronto_lm_loss: 4.2260 ||
04/19 10:57:49 PM: Update 36844: task toronto_lm, batch 839 (36664): perplexity: 68.4728, toronto_lm_loss: 4.2264 ||
04/19 10:57:59 PM: Update 36857: task toronto_lm, batch 852 (36677): perplexity: 68.4054, toronto_lm_loss: 4.2255 ||
04/19 10:58:10 PM: Update 36871: task toronto_lm, batch 866 (36691): perplexity: 68.3010, toronto_lm_loss: 4.2239 ||
04/19 10:58:20 PM: Update 36884: task toronto_lm, batch 879 (36704): perplexity: 68.1974, toronto_lm_loss: 4.2224 ||
04/19 10:58:30 PM: Update 36897: task toronto_lm, batch 892 (36717): perplexity: 68.1548, toronto_lm_loss: 4.2218 ||
04/19 10:58:40 PM: Update 36910: task toronto_lm, batch 905 (36730): perplexity: 68.0536, toronto_lm_loss: 4.2203 ||
04/19 10:58:50 PM: Update 36923: task toronto_lm, batch 918 (36743): perplexity: 67.9768, toronto_lm_loss: 4.2192 ||
04/19 10:59:00 PM: Update 36936: task toronto_lm, batch 931 (36756): perplexity: 67.9414, toronto_lm_loss: 4.2186 ||
04/19 10:59:10 PM: Update 36949: task toronto_lm, batch 944 (36769): perplexity: 67.8348, toronto_lm_loss: 4.2171 ||
04/19 10:59:20 PM: Update 36962: task toronto_lm, batch 957 (36782): perplexity: 67.7196, toronto_lm_loss: 4.2154 ||
04/19 10:59:30 PM: Update 36975: task toronto_lm, batch 970 (36795): perplexity: 67.5976, toronto_lm_loss: 4.2136 ||
04/19 10:59:40 PM: Update 36988: task toronto_lm, batch 983 (36808): perplexity: 67.5291, toronto_lm_loss: 4.2126 ||
04/19 10:59:50 PM: ***** Pass 37000 / Epoch 37 *****
04/19 10:59:50 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 10:59:50 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 10:59:50 PM: Validating...
04/19 10:59:50 PM: Batch 3/140: perplexity: 96.1060, toronto_lm_loss: 4.5655 || , for evaluation data
04/19 11:00:00 PM: Batch 41/140: perplexity: 85.2908, toronto_lm_loss: 4.4461 || , for evaluation data
04/19 11:00:10 PM: Batch 79/140: perplexity: 84.8211, toronto_lm_loss: 4.4405 || , for evaluation data
04/19 11:00:20 PM: Batch 117/140: perplexity: 79.4264, toronto_lm_loss: 4.3748 || , for evaluation data
04/19 11:00:27 PM: Batch 1/66: perplexity: 318.7734, wsj_loss: 5.7645 || , for evaluation data
04/19 11:00:37 PM: Batch 39/66: perplexity: 224.5544, wsj_loss: 5.4141 || , for evaluation data
04/19 11:00:44 PM: Advancing scheduler.
04/19 11:00:44 PM: 	Best macro_avg: 0.267
04/19 11:00:44 PM: 	# bad epochs: 1
04/19 11:00:44 PM: Statistic: toronto_lm_loss
04/19 11:00:44 PM: 	training: 4.211115
04/19 11:00:44 PM: 	validation: 4.326222
04/19 11:00:44 PM: Statistic: wsj_loss
04/19 11:00:44 PM: 	training: 5.459855
04/19 11:00:44 PM: 	validation: 5.385004
04/19 11:00:44 PM: Statistic: macro_avg
04/19 11:00:44 PM: 	validation: 0.238120
04/19 11:00:44 PM: Statistic: micro_avg
04/19 11:00:44 PM: 	validation: 0.040889
04/19 11:00:44 PM: Statistic: toronto_lm_perplexity
04/19 11:00:44 PM: 	training: 67.431653
04/19 11:00:44 PM: 	validation: 75.657883
04/19 11:00:44 PM: Statistic: wsj_perplexity
04/19 11:00:44 PM: 	training: 235.063379
04/19 11:00:44 PM: 	validation: 218.110955
04/19 11:00:44 PM: global_lr: 0.001000
04/19 11:00:44 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 11:00:45 PM: Update 37001: task toronto_lm, batch 1 (36821): perplexity: 84.1660, toronto_lm_loss: 4.4328 ||
04/19 11:00:55 PM: Update 37014: task toronto_lm, batch 14 (36834): perplexity: 69.0123, toronto_lm_loss: 4.2343 ||
04/19 11:01:06 PM: Update 37027: task toronto_lm, batch 27 (36847): perplexity: 65.3283, toronto_lm_loss: 4.1794 ||
04/19 11:01:16 PM: Update 37040: task toronto_lm, batch 40 (36860): perplexity: 64.3713, toronto_lm_loss: 4.1647 ||
04/19 11:01:26 PM: Update 37053: task toronto_lm, batch 53 (36873): perplexity: 63.6255, toronto_lm_loss: 4.1530 ||
04/19 11:01:37 PM: Update 37056: task toronto_lm, batch 56 (36876): perplexity: 64.0240, toronto_lm_loss: 4.1593 ||
04/19 11:01:47 PM: Update 37069: task toronto_lm, batch 69 (36889): perplexity: 66.3646, toronto_lm_loss: 4.1952 ||
04/19 11:01:50 PM: Update 37073: task wsj, batch 1 (181): perplexity: 225.4883, wsj_loss: 5.4183 ||
04/19 11:01:57 PM: Update 37082: task toronto_lm, batch 81 (36901): perplexity: 67.2597, toronto_lm_loss: 4.2086 ||
04/19 11:02:07 PM: Update 37095: task toronto_lm, batch 94 (36914): perplexity: 67.6654, toronto_lm_loss: 4.2146 ||
04/19 11:02:14 PM: Update 37103: task wsj, batch 2 (182): perplexity: 199.2268, wsj_loss: 5.2944 ||
04/19 11:02:17 PM: Update 37108: task toronto_lm, batch 106 (36926): perplexity: 68.6359, toronto_lm_loss: 4.2288 ||
04/19 11:02:28 PM: Update 37121: task toronto_lm, batch 119 (36939): perplexity: 69.5279, toronto_lm_loss: 4.2417 ||
04/19 11:02:36 PM: Update 37132: task wsj, batch 3 (183): perplexity: 200.6586, wsj_loss: 5.3016 ||
04/19 11:02:38 PM: Update 37134: task toronto_lm, batch 131 (36951): perplexity: 69.7390, toronto_lm_loss: 4.2448 ||
04/19 11:02:48 PM: Update 37147: task toronto_lm, batch 144 (36964): perplexity: 70.0051, toronto_lm_loss: 4.2486 ||
04/19 11:02:58 PM: Update 37160: task toronto_lm, batch 157 (36977): perplexity: 69.9016, toronto_lm_loss: 4.2471 ||
04/19 11:03:08 PM: Update 37173: task toronto_lm, batch 170 (36990): perplexity: 69.5093, toronto_lm_loss: 4.2415 ||
04/19 11:03:18 PM: Update 37186: task toronto_lm, batch 183 (37003): perplexity: 69.2844, toronto_lm_loss: 4.2382 ||
04/19 11:03:28 PM: Update 37199: task toronto_lm, batch 196 (37016): perplexity: 69.2917, toronto_lm_loss: 4.2383 ||
04/19 11:03:38 PM: Update 37212: task toronto_lm, batch 209 (37029): perplexity: 69.4299, toronto_lm_loss: 4.2403 ||
04/19 11:03:48 PM: Update 37225: task toronto_lm, batch 222 (37042): perplexity: 69.5096, toronto_lm_loss: 4.2415 ||
04/19 11:03:59 PM: Update 37239: task toronto_lm, batch 236 (37056): perplexity: 69.5397, toronto_lm_loss: 4.2419 ||
04/19 11:04:09 PM: Update 37252: task toronto_lm, batch 249 (37069): perplexity: 69.4995, toronto_lm_loss: 4.2413 ||
04/19 11:04:19 PM: Update 37265: task toronto_lm, batch 262 (37082): perplexity: 69.3051, toronto_lm_loss: 4.2385 ||
04/19 11:04:29 PM: Update 37278: task toronto_lm, batch 275 (37095): perplexity: 69.2747, toronto_lm_loss: 4.2381 ||
04/19 11:04:39 PM: Update 37291: task toronto_lm, batch 288 (37108): perplexity: 69.3878, toronto_lm_loss: 4.2397 ||
04/19 11:04:50 PM: Update 37304: task toronto_lm, batch 301 (37121): perplexity: 69.2146, toronto_lm_loss: 4.2372 ||
04/19 11:05:00 PM: Update 37317: task toronto_lm, batch 314 (37134): perplexity: 69.0427, toronto_lm_loss: 4.2347 ||
04/19 11:05:10 PM: Update 37330: task toronto_lm, batch 327 (37147): perplexity: 69.0685, toronto_lm_loss: 4.2351 ||
04/19 11:05:20 PM: Update 37343: task toronto_lm, batch 340 (37160): perplexity: 68.8058, toronto_lm_loss: 4.2313 ||
04/19 11:05:30 PM: Update 37356: task toronto_lm, batch 353 (37173): perplexity: 68.6490, toronto_lm_loss: 4.2290 ||
04/19 11:05:40 PM: Update 37370: task toronto_lm, batch 367 (37187): perplexity: 68.3841, toronto_lm_loss: 4.2251 ||
04/19 11:05:50 PM: Update 37383: task toronto_lm, batch 380 (37200): perplexity: 68.2660, toronto_lm_loss: 4.2234 ||
04/19 11:05:57 PM: Update 37392: task wsj, batch 4 (184): perplexity: 204.0609, wsj_loss: 5.3184 ||
04/19 11:06:01 PM: Update 37397: task toronto_lm, batch 393 (37213): perplexity: 68.1755, toronto_lm_loss: 4.2221 ||
04/19 11:06:12 PM: Update 37411: task toronto_lm, batch 407 (37227): perplexity: 68.0074, toronto_lm_loss: 4.2196 ||
04/19 11:06:23 PM: Update 37425: task toronto_lm, batch 421 (37241): perplexity: 67.9942, toronto_lm_loss: 4.2194 ||
04/19 11:06:33 PM: Update 37439: task toronto_lm, batch 435 (37255): perplexity: 67.7781, toronto_lm_loss: 4.2162 ||
04/19 11:06:44 PM: Update 37453: task toronto_lm, batch 449 (37269): perplexity: 67.7005, toronto_lm_loss: 4.2151 ||
04/19 11:06:55 PM: Update 37467: task toronto_lm, batch 463 (37283): perplexity: 67.4619, toronto_lm_loss: 4.2116 ||
04/19 11:07:06 PM: Update 37481: task toronto_lm, batch 477 (37297): perplexity: 67.4214, toronto_lm_loss: 4.2110 ||
04/19 11:07:16 PM: Update 37495: task toronto_lm, batch 491 (37311): perplexity: 67.3891, toronto_lm_loss: 4.2105 ||
04/19 11:07:26 PM: Update 37508: task toronto_lm, batch 504 (37324): perplexity: 67.2659, toronto_lm_loss: 4.2087 ||
04/19 11:07:36 PM: Update 37521: task toronto_lm, batch 517 (37337): perplexity: 67.1369, toronto_lm_loss: 4.2067 ||
04/19 11:07:47 PM: Update 37535: task toronto_lm, batch 531 (37351): perplexity: 67.1400, toronto_lm_loss: 4.2068 ||
04/19 11:07:57 PM: Update 37548: task toronto_lm, batch 544 (37364): perplexity: 67.0338, toronto_lm_loss: 4.2052 ||
04/19 11:08:08 PM: Update 37562: task toronto_lm, batch 558 (37378): perplexity: 66.8793, toronto_lm_loss: 4.2029 ||
04/19 11:08:19 PM: Update 37576: task toronto_lm, batch 572 (37392): perplexity: 66.7665, toronto_lm_loss: 4.2012 ||
04/19 11:08:29 PM: Update 37589: task toronto_lm, batch 585 (37405): perplexity: 66.7452, toronto_lm_loss: 4.2009 ||
04/19 11:08:39 PM: Update 37603: task toronto_lm, batch 599 (37419): perplexity: 66.6534, toronto_lm_loss: 4.1995 ||
04/19 11:08:50 PM: Update 37617: task toronto_lm, batch 613 (37433): perplexity: 66.5978, toronto_lm_loss: 4.1987 ||
04/19 11:09:00 PM: Update 37630: task toronto_lm, batch 626 (37446): perplexity: 66.6383, toronto_lm_loss: 4.1993 ||
04/19 11:09:10 PM: Update 37643: task toronto_lm, batch 639 (37459): perplexity: 66.6724, toronto_lm_loss: 4.1998 ||
04/19 11:09:20 PM: Update 37656: task toronto_lm, batch 652 (37472): perplexity: 66.6240, toronto_lm_loss: 4.1991 ||
04/19 11:09:30 PM: Update 37669: task toronto_lm, batch 665 (37485): perplexity: 66.5950, toronto_lm_loss: 4.1986 ||
04/19 11:09:41 PM: Update 37683: task toronto_lm, batch 679 (37499): perplexity: 66.6148, toronto_lm_loss: 4.1989 ||
04/19 11:09:51 PM: Update 37687: task toronto_lm, batch 683 (37503): perplexity: 66.6421, toronto_lm_loss: 4.1993 ||
04/19 11:10:01 PM: Update 37700: task toronto_lm, batch 696 (37516): perplexity: 66.9799, toronto_lm_loss: 4.2044 ||
04/19 11:10:12 PM: Update 37714: task toronto_lm, batch 710 (37530): perplexity: 67.2541, toronto_lm_loss: 4.2085 ||
04/19 11:10:23 PM: Update 37728: task toronto_lm, batch 724 (37544): perplexity: 67.4795, toronto_lm_loss: 4.2118 ||
04/19 11:10:33 PM: Update 37741: task toronto_lm, batch 737 (37557): perplexity: 67.6767, toronto_lm_loss: 4.2147 ||
04/19 11:10:43 PM: Update 37754: task toronto_lm, batch 750 (37570): perplexity: 67.8848, toronto_lm_loss: 4.2178 ||
04/19 11:10:53 PM: Update 37767: task toronto_lm, batch 763 (37583): perplexity: 68.0441, toronto_lm_loss: 4.2202 ||
04/19 11:11:03 PM: Update 37780: task toronto_lm, batch 776 (37596): perplexity: 68.1928, toronto_lm_loss: 4.2223 ||
04/19 11:11:11 PM: Update 37791: task wsj, batch 5 (185): perplexity: 212.3509, wsj_loss: 5.3582 ||
04/19 11:11:13 PM: Update 37793: task toronto_lm, batch 788 (37608): perplexity: 68.2403, toronto_lm_loss: 4.2230 ||
04/19 11:11:23 PM: Update 37806: task toronto_lm, batch 801 (37621): perplexity: 68.3172, toronto_lm_loss: 4.2242 ||
04/19 11:11:33 PM: Update 37819: task toronto_lm, batch 814 (37634): perplexity: 68.3262, toronto_lm_loss: 4.2243 ||
04/19 11:11:43 PM: Update 37832: task toronto_lm, batch 827 (37647): perplexity: 68.4410, toronto_lm_loss: 4.2260 ||
04/19 11:11:54 PM: Update 37846: task toronto_lm, batch 841 (37661): perplexity: 68.5415, toronto_lm_loss: 4.2274 ||
04/19 11:12:04 PM: Update 37859: task toronto_lm, batch 854 (37674): perplexity: 68.6177, toronto_lm_loss: 4.2286 ||
04/19 11:12:15 PM: Update 37873: task toronto_lm, batch 868 (37688): perplexity: 68.6975, toronto_lm_loss: 4.2297 ||
04/19 11:12:25 PM: Update 37886: task toronto_lm, batch 881 (37701): perplexity: 68.7463, toronto_lm_loss: 4.2304 ||
04/19 11:12:35 PM: Update 37899: task toronto_lm, batch 894 (37714): perplexity: 68.7654, toronto_lm_loss: 4.2307 ||
04/19 11:12:45 PM: Update 37913: task toronto_lm, batch 908 (37728): perplexity: 68.8096, toronto_lm_loss: 4.2313 ||
04/19 11:12:56 PM: Update 37927: task toronto_lm, batch 922 (37742): perplexity: 68.8495, toronto_lm_loss: 4.2319 ||
04/19 11:13:07 PM: Update 37941: task toronto_lm, batch 936 (37756): perplexity: 68.8751, toronto_lm_loss: 4.2323 ||
04/19 11:13:17 PM: Update 37955: task toronto_lm, batch 950 (37770): perplexity: 68.9072, toronto_lm_loss: 4.2328 ||
04/19 11:13:28 PM: Update 37969: task toronto_lm, batch 964 (37784): perplexity: 68.9497, toronto_lm_loss: 4.2334 ||
04/19 11:13:39 PM: Update 37983: task toronto_lm, batch 978 (37798): perplexity: 68.9306, toronto_lm_loss: 4.2331 ||
04/19 11:13:49 PM: Update 37997: task toronto_lm, batch 992 (37812): perplexity: 69.0174, toronto_lm_loss: 4.2344 ||
04/19 11:13:52 PM: ***** Pass 38000 / Epoch 38 *****
04/19 11:13:52 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 11:13:52 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 11:13:52 PM: Validating...
04/19 11:13:59 PM: Batch 30/140: perplexity: 86.1117, toronto_lm_loss: 4.4556 || , for evaluation data
04/19 11:14:10 PM: Batch 69/140: perplexity: 86.8505, toronto_lm_loss: 4.4642 || , for evaluation data
04/19 11:14:20 PM: Batch 108/140: perplexity: 81.0355, toronto_lm_loss: 4.3949 || , for evaluation data
04/19 11:14:28 PM: Batch 1/66: perplexity: 318.8569, wsj_loss: 5.7647 || , for evaluation data
04/19 11:14:39 PM: Batch 40/66: perplexity: 217.0740, wsj_loss: 5.3802 || , for evaluation data
04/19 11:14:47 PM: Advancing scheduler.
04/19 11:14:47 PM: 	Best macro_avg: 0.267
04/19 11:14:47 PM: 	# bad epochs: 2
04/19 11:14:47 PM: Statistic: toronto_lm_loss
04/19 11:14:47 PM: 	training: 4.234469
04/19 11:14:47 PM: 	validation: 4.329872
04/19 11:14:47 PM: Statistic: wsj_loss
04/19 11:14:47 PM: 	training: 5.358240
04/19 11:14:47 PM: 	validation: 5.370095
04/19 11:14:47 PM: Statistic: macro_avg
04/19 11:14:47 PM: 	validation: 0.244299
04/19 11:14:47 PM: Statistic: micro_avg
04/19 11:14:47 PM: 	validation: 0.045027
04/19 11:14:47 PM: Statistic: toronto_lm_perplexity
04/19 11:14:47 PM: 	training: 69.025043
04/19 11:14:47 PM: 	validation: 75.934532
04/19 11:14:47 PM: Statistic: wsj_perplexity
04/19 11:14:47 PM: 	training: 212.350947
04/19 11:14:47 PM: 	validation: 214.883323
04/19 11:14:47 PM: global_lr: 0.001000
04/19 11:14:47 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 11:14:48 PM: Update 38001: task toronto_lm, batch 1 (37816): perplexity: 73.2182, toronto_lm_loss: 4.2934 ||
04/19 11:14:58 PM: Update 38015: task toronto_lm, batch 15 (37830): perplexity: 69.5885, toronto_lm_loss: 4.2426 ||
04/19 11:15:09 PM: Update 38029: task toronto_lm, batch 29 (37844): perplexity: 69.8995, toronto_lm_loss: 4.2471 ||
04/19 11:15:20 PM: Update 38043: task toronto_lm, batch 43 (37858): perplexity: 69.9719, toronto_lm_loss: 4.2481 ||
04/19 11:15:31 PM: Update 38057: task toronto_lm, batch 57 (37872): perplexity: 70.2172, toronto_lm_loss: 4.2516 ||
04/19 11:15:36 PM: Update 38064: task wsj, batch 1 (186): perplexity: 150.6431, wsj_loss: 5.0149 ||
04/19 11:15:41 PM: Update 38071: task toronto_lm, batch 70 (37885): perplexity: 70.5606, toronto_lm_loss: 4.2565 ||
04/19 11:15:52 PM: Update 38085: task toronto_lm, batch 84 (37899): perplexity: 70.2123, toronto_lm_loss: 4.2515 ||
04/19 11:16:02 PM: Update 38098: task toronto_lm, batch 97 (37912): perplexity: 69.5697, toronto_lm_loss: 4.2423 ||
04/19 11:16:13 PM: Update 38112: task toronto_lm, batch 111 (37926): perplexity: 69.7078, toronto_lm_loss: 4.2443 ||
04/19 11:16:23 PM: Update 38125: task toronto_lm, batch 124 (37939): perplexity: 70.1054, toronto_lm_loss: 4.2500 ||
04/19 11:16:33 PM: Update 38138: task toronto_lm, batch 137 (37952): perplexity: 70.2240, toronto_lm_loss: 4.2517 ||
04/19 11:16:43 PM: Update 38151: task toronto_lm, batch 150 (37965): perplexity: 70.2130, toronto_lm_loss: 4.2515 ||
04/19 11:16:54 PM: Update 38165: task toronto_lm, batch 164 (37979): perplexity: 70.0045, toronto_lm_loss: 4.2486 ||
04/19 11:17:04 PM: Update 38178: task toronto_lm, batch 177 (37992): perplexity: 69.7936, toronto_lm_loss: 4.2455 ||
04/19 11:17:14 PM: Update 38191: task toronto_lm, batch 190 (38005): perplexity: 69.8044, toronto_lm_loss: 4.2457 ||
04/19 11:17:24 PM: Update 38204: task toronto_lm, batch 203 (38018): perplexity: 70.0620, toronto_lm_loss: 4.2494 ||
04/19 11:17:31 PM: Update 38214: task wsj, batch 2 (187): perplexity: 159.5908, wsj_loss: 5.0726 ||
04/19 11:17:34 PM: Update 38217: task toronto_lm, batch 215 (38030): perplexity: 69.6969, toronto_lm_loss: 4.2442 ||
04/19 11:17:44 PM: Update 38230: task toronto_lm, batch 228 (38043): perplexity: 69.8125, toronto_lm_loss: 4.2458 ||
04/19 11:17:54 PM: Update 38243: task toronto_lm, batch 241 (38056): perplexity: 69.7735, toronto_lm_loss: 4.2453 ||
04/19 11:18:04 PM: Update 38256: task toronto_lm, batch 254 (38069): perplexity: 69.6082, toronto_lm_loss: 4.2429 ||
04/19 11:18:14 PM: Update 38269: task toronto_lm, batch 267 (38082): perplexity: 69.7649, toronto_lm_loss: 4.2451 ||
04/19 11:18:18 PM: Update 38274: task wsj, batch 3 (188): perplexity: 176.1826, wsj_loss: 5.1715 ||
04/19 11:18:24 PM: Update 38282: task toronto_lm, batch 279 (38094): perplexity: 69.8856, toronto_lm_loss: 4.2469 ||
04/19 11:18:30 PM: Update 38290: task wsj, batch 4 (189): perplexity: 176.9091, wsj_loss: 5.1756 ||
04/19 11:18:35 PM: Update 38296: task toronto_lm, batch 292 (38107): perplexity: 69.7866, toronto_lm_loss: 4.2454 ||
04/19 11:18:46 PM: Update 38310: task toronto_lm, batch 306 (38121): perplexity: 69.6591, toronto_lm_loss: 4.2436 ||
04/19 11:18:56 PM: Update 38315: task toronto_lm, batch 311 (38126): perplexity: 69.7176, toronto_lm_loss: 4.2445 ||
04/19 11:19:06 PM: Update 38328: task toronto_lm, batch 324 (38139): perplexity: 71.0904, toronto_lm_loss: 4.2640 ||
04/19 11:19:16 PM: Update 38341: task toronto_lm, batch 337 (38152): perplexity: 72.1780, toronto_lm_loss: 4.2791 ||
04/19 11:19:27 PM: Update 38354: task toronto_lm, batch 350 (38165): perplexity: 72.9405, toronto_lm_loss: 4.2896 ||
04/19 11:19:37 PM: Update 38367: task toronto_lm, batch 363 (38178): perplexity: 73.5733, toronto_lm_loss: 4.2983 ||
04/19 11:19:47 PM: Update 38380: task toronto_lm, batch 376 (38191): perplexity: 74.1167, toronto_lm_loss: 4.3056 ||
04/19 11:19:57 PM: Update 38393: task toronto_lm, batch 389 (38204): perplexity: 74.6374, toronto_lm_loss: 4.3126 ||
04/19 11:20:07 PM: Update 38406: task toronto_lm, batch 402 (38217): perplexity: 75.1456, toronto_lm_loss: 4.3194 ||
04/19 11:20:17 PM: Update 38419: task toronto_lm, batch 415 (38230): perplexity: 75.6447, toronto_lm_loss: 4.3260 ||
04/19 11:20:27 PM: Update 38432: task toronto_lm, batch 428 (38243): perplexity: 75.8856, toronto_lm_loss: 4.3292 ||
04/19 11:20:37 PM: Update 38445: task toronto_lm, batch 441 (38256): perplexity: 76.2148, toronto_lm_loss: 4.3336 ||
04/19 11:20:47 PM: Update 38458: task toronto_lm, batch 454 (38269): perplexity: 76.4778, toronto_lm_loss: 4.3370 ||
04/19 11:20:57 PM: Update 38471: task toronto_lm, batch 467 (38282): perplexity: 76.6489, toronto_lm_loss: 4.3392 ||
04/19 11:21:07 PM: Update 38484: task toronto_lm, batch 480 (38295): perplexity: 76.8547, toronto_lm_loss: 4.3419 ||
04/19 11:21:17 PM: Update 38497: task toronto_lm, batch 493 (38308): perplexity: 77.0363, toronto_lm_loss: 4.3443 ||
04/19 11:21:28 PM: Update 38511: task toronto_lm, batch 507 (38322): perplexity: 77.0849, toronto_lm_loss: 4.3449 ||
04/19 11:21:38 PM: Update 38524: task toronto_lm, batch 520 (38335): perplexity: 77.2440, toronto_lm_loss: 4.3470 ||
04/19 11:21:48 PM: Update 38537: task toronto_lm, batch 533 (38348): perplexity: 77.3588, toronto_lm_loss: 4.3485 ||
04/19 11:21:58 PM: Update 38550: task toronto_lm, batch 546 (38361): perplexity: 77.5013, toronto_lm_loss: 4.3503 ||
04/19 11:22:09 PM: Update 38564: task toronto_lm, batch 560 (38375): perplexity: 77.4839, toronto_lm_loss: 4.3501 ||
04/19 11:22:19 PM: Update 38577: task toronto_lm, batch 573 (38388): perplexity: 77.6443, toronto_lm_loss: 4.3521 ||
04/19 11:22:30 PM: Update 38591: task toronto_lm, batch 587 (38402): perplexity: 77.5858, toronto_lm_loss: 4.3514 ||
04/19 11:22:40 PM: Update 38604: task toronto_lm, batch 600 (38415): perplexity: 77.7335, toronto_lm_loss: 4.3533 ||
04/19 11:22:53 PM: Update 38618: task toronto_lm, batch 614 (38429): perplexity: 77.7491, toronto_lm_loss: 4.3535 ||
04/19 11:23:04 PM: Update 38632: task toronto_lm, batch 628 (38443): perplexity: 77.8414, toronto_lm_loss: 4.3547 ||
04/19 11:23:14 PM: Update 38645: task toronto_lm, batch 641 (38456): perplexity: 77.9591, toronto_lm_loss: 4.3562 ||
04/19 11:23:24 PM: Update 38658: task toronto_lm, batch 654 (38469): perplexity: 77.9398, toronto_lm_loss: 4.3559 ||
04/19 11:23:35 PM: Update 38672: task toronto_lm, batch 668 (38483): perplexity: 77.8423, toronto_lm_loss: 4.3547 ||
04/19 11:23:46 PM: Update 38686: task toronto_lm, batch 682 (38497): perplexity: 77.8483, toronto_lm_loss: 4.3548 ||
04/19 11:23:56 PM: Update 38699: task toronto_lm, batch 695 (38510): perplexity: 77.8317, toronto_lm_loss: 4.3545 ||
04/19 11:24:06 PM: Update 38712: task toronto_lm, batch 708 (38523): perplexity: 77.9134, toronto_lm_loss: 4.3556 ||
04/19 11:24:17 PM: Update 38726: task toronto_lm, batch 722 (38537): perplexity: 77.9517, toronto_lm_loss: 4.3561 ||
04/19 11:24:27 PM: Update 38740: task toronto_lm, batch 736 (38551): perplexity: 77.9041, toronto_lm_loss: 4.3555 ||
04/19 11:24:38 PM: Update 38754: task toronto_lm, batch 750 (38565): perplexity: 77.8871, toronto_lm_loss: 4.3553 ||
04/19 11:24:49 PM: Update 38768: task toronto_lm, batch 764 (38579): perplexity: 77.8513, toronto_lm_loss: 4.3548 ||
04/19 11:24:59 PM: Update 38781: task toronto_lm, batch 777 (38592): perplexity: 77.8140, toronto_lm_loss: 4.3543 ||
04/19 11:25:09 PM: Update 38795: task toronto_lm, batch 791 (38606): perplexity: 77.7950, toronto_lm_loss: 4.3541 ||
04/19 11:25:20 PM: Update 38809: task toronto_lm, batch 805 (38620): perplexity: 77.7649, toronto_lm_loss: 4.3537 ||
04/19 11:25:30 PM: Update 38822: task toronto_lm, batch 818 (38633): perplexity: 77.6701, toronto_lm_loss: 4.3525 ||
04/19 11:25:40 PM: Update 38835: task toronto_lm, batch 831 (38646): perplexity: 77.5726, toronto_lm_loss: 4.3512 ||
04/19 11:25:50 PM: Update 38848: task toronto_lm, batch 844 (38659): perplexity: 77.5900, toronto_lm_loss: 4.3514 ||
04/19 11:26:01 PM: Update 38861: task wsj, batch 5 (190): perplexity: 187.6646, wsj_loss: 5.2347 ||
04/19 11:26:01 PM: Update 38862: task toronto_lm, batch 857 (38672): perplexity: 77.5057, toronto_lm_loss: 4.3504 ||
04/19 11:26:11 PM: Update 38875: task toronto_lm, batch 870 (38685): perplexity: 77.4389, toronto_lm_loss: 4.3495 ||
04/19 11:26:21 PM: Update 38888: task toronto_lm, batch 883 (38698): perplexity: 77.4035, toronto_lm_loss: 4.3490 ||
04/19 11:26:32 PM: Update 38902: task toronto_lm, batch 897 (38712): perplexity: 77.3896, toronto_lm_loss: 4.3489 ||
04/19 11:26:42 PM: Update 38915: task toronto_lm, batch 910 (38725): perplexity: 77.3613, toronto_lm_loss: 4.3485 ||
04/19 11:26:52 PM: Update 38928: task toronto_lm, batch 923 (38738): perplexity: 77.2691, toronto_lm_loss: 4.3473 ||
04/19 11:27:11 PM: Update 38941: task toronto_lm, batch 936 (38751): perplexity: 77.2378, toronto_lm_loss: 4.3469 ||
04/19 11:27:21 PM: Update 38954: task toronto_lm, batch 949 (38764): perplexity: 77.5150, toronto_lm_loss: 4.3505 ||
04/19 11:27:32 PM: Update 38968: task toronto_lm, batch 963 (38778): perplexity: 77.6722, toronto_lm_loss: 4.3525 ||
04/19 11:27:42 PM: Update 38981: task toronto_lm, batch 976 (38791): perplexity: 77.7636, toronto_lm_loss: 4.3537 ||
04/19 11:27:52 PM: Update 38994: task toronto_lm, batch 989 (38804): perplexity: 77.8854, toronto_lm_loss: 4.3552 ||
04/19 11:27:57 PM: ***** Pass 39000 / Epoch 39 *****
04/19 11:27:57 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 11:27:57 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 11:27:57 PM: Validating...
04/19 11:28:02 PM: Batch 21/140: perplexity: 86.6065, toronto_lm_loss: 4.4614 || , for evaluation data
04/19 11:28:12 PM: Batch 59/140: perplexity: 82.7525, toronto_lm_loss: 4.4159 || , for evaluation data
04/19 11:28:22 PM: Batch 97/140: perplexity: 78.7582, toronto_lm_loss: 4.3664 || , for evaluation data
04/19 11:28:32 PM: Batch 135/140: perplexity: 74.0112, toronto_lm_loss: 4.3042 || , for evaluation data
04/19 11:28:34 PM: Batch 1/66: perplexity: 323.2565, wsj_loss: 5.7784 || , for evaluation data
04/19 11:28:44 PM: Batch 39/66: perplexity: 223.1958, wsj_loss: 5.4080 || , for evaluation data
04/19 11:28:51 PM: Advancing scheduler.
04/19 11:28:51 PM: 	Best macro_avg: 0.267
04/19 11:28:51 PM: 	# bad epochs: 3
04/19 11:28:51 PM: Statistic: toronto_lm_loss
04/19 11:28:51 PM: 	training: 4.355704
04/19 11:28:51 PM: 	validation: 4.296402
04/19 11:28:51 PM: Statistic: wsj_loss
04/19 11:28:51 PM: 	training: 5.234656
04/19 11:28:51 PM: 	validation: 5.374991
04/19 11:28:51 PM: Statistic: macro_avg
04/19 11:28:51 PM: 	validation: 0.244689
04/19 11:28:51 PM: Statistic: micro_avg
04/19 11:28:51 PM: 	validation: 0.043675
04/19 11:28:51 PM: Statistic: toronto_lm_perplexity
04/19 11:28:51 PM: 	training: 77.921649
04/19 11:28:51 PM: 	validation: 73.435075
04/19 11:28:51 PM: Statistic: wsj_perplexity
04/19 11:28:51 PM: 	training: 187.664601
04/19 11:28:51 PM: 	validation: 215.937932
04/19 11:28:51 PM: global_lr: 0.001000
04/19 11:28:51 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 11:28:52 PM: Update 39001: task toronto_lm, batch 1 (38811): perplexity: 83.2697, toronto_lm_loss: 4.4221 ||
04/19 11:29:02 PM: Update 39014: task toronto_lm, batch 14 (38824): perplexity: 84.3741, toronto_lm_loss: 4.4353 ||
04/19 11:29:12 PM: Update 39027: task toronto_lm, batch 27 (38837): perplexity: 83.8344, toronto_lm_loss: 4.4288 ||
04/19 11:29:22 PM: Update 39039: task wsj, batch 1 (191): perplexity: 189.5969, wsj_loss: 5.2449 ||
04/19 11:29:22 PM: Update 39040: task toronto_lm, batch 39 (38849): perplexity: 84.2716, toronto_lm_loss: 4.4340 ||
04/19 11:29:33 PM: Update 39053: task toronto_lm, batch 52 (38862): perplexity: 83.8492, toronto_lm_loss: 4.4290 ||
04/19 11:29:33 PM: Update 39054: task wsj, batch 2 (192): perplexity: 194.6202, wsj_loss: 5.2710 ||
04/19 11:29:43 PM: Update 39066: task toronto_lm, batch 64 (38874): perplexity: 83.8636, toronto_lm_loss: 4.4292 ||
04/19 11:29:53 PM: Update 39079: task toronto_lm, batch 77 (38887): perplexity: 83.1455, toronto_lm_loss: 4.4206 ||
04/19 11:30:03 PM: Update 39092: task toronto_lm, batch 90 (38900): perplexity: 82.7754, toronto_lm_loss: 4.4161 ||
04/19 11:30:13 PM: Update 39105: task toronto_lm, batch 103 (38913): perplexity: 82.0338, toronto_lm_loss: 4.4071 ||
04/19 11:30:24 PM: Update 39119: task toronto_lm, batch 117 (38927): perplexity: 81.4210, toronto_lm_loss: 4.3996 ||
04/19 11:30:34 PM: Update 39132: task toronto_lm, batch 130 (38940): perplexity: 81.2630, toronto_lm_loss: 4.3977 ||
04/19 11:30:44 PM: Update 39145: task toronto_lm, batch 143 (38953): perplexity: 80.5897, toronto_lm_loss: 4.3894 ||
04/19 11:30:54 PM: Update 39158: task toronto_lm, batch 156 (38966): perplexity: 80.2439, toronto_lm_loss: 4.3851 ||
04/19 11:31:04 PM: Update 39171: task toronto_lm, batch 169 (38979): perplexity: 80.3148, toronto_lm_loss: 4.3860 ||
04/19 11:31:14 PM: Update 39184: task wsj, batch 3 (193): perplexity: 199.0805, wsj_loss: 5.2937 ||
04/19 11:31:15 PM: Update 39185: task toronto_lm, batch 182 (38992): perplexity: 80.2218, toronto_lm_loss: 4.3848 ||
04/19 11:31:25 PM: Update 39198: task toronto_lm, batch 195 (39005): perplexity: 80.1382, toronto_lm_loss: 4.3838 ||
04/19 11:31:35 PM: Update 39211: task toronto_lm, batch 208 (39018): perplexity: 79.7730, toronto_lm_loss: 4.3792 ||
04/19 11:31:45 PM: Update 39224: task toronto_lm, batch 221 (39031): perplexity: 79.6012, toronto_lm_loss: 4.3770 ||
04/19 11:31:55 PM: Update 39237: task toronto_lm, batch 234 (39044): perplexity: 79.3683, toronto_lm_loss: 4.3741 ||
04/19 11:32:05 PM: Update 39250: task toronto_lm, batch 247 (39057): perplexity: 79.1084, toronto_lm_loss: 4.3708 ||
04/19 11:32:16 PM: Update 39264: task toronto_lm, batch 261 (39071): perplexity: 78.7498, toronto_lm_loss: 4.3663 ||
04/19 11:32:27 PM: Update 39278: task toronto_lm, batch 275 (39085): perplexity: 78.7397, toronto_lm_loss: 4.3661 ||
04/19 11:32:37 PM: Update 39292: task toronto_lm, batch 289 (39099): perplexity: 78.5317, toronto_lm_loss: 4.3635 ||
04/19 11:32:48 PM: Update 39306: task toronto_lm, batch 303 (39113): perplexity: 78.2534, toronto_lm_loss: 4.3600 ||
04/19 11:32:58 PM: Update 39319: task toronto_lm, batch 316 (39126): perplexity: 78.3113, toronto_lm_loss: 4.3607 ||
04/19 11:33:08 PM: Update 39332: task toronto_lm, batch 329 (39139): perplexity: 77.8414, toronto_lm_loss: 4.3547 ||
04/19 11:33:19 PM: Update 39346: task toronto_lm, batch 343 (39153): perplexity: 77.5583, toronto_lm_loss: 4.3510 ||
04/19 11:33:21 PM: Update 39349: task wsj, batch 4 (194): perplexity: 188.8659, wsj_loss: 5.2410 ||
04/19 11:33:29 PM: Update 39359: task toronto_lm, batch 355 (39165): perplexity: 77.2009, toronto_lm_loss: 4.3464 ||
04/19 11:33:40 PM: Update 39373: task toronto_lm, batch 369 (39179): perplexity: 76.9428, toronto_lm_loss: 4.3431 ||
04/19 11:33:50 PM: Update 39386: task toronto_lm, batch 382 (39192): perplexity: 76.7664, toronto_lm_loss: 4.3408 ||
04/19 11:34:00 PM: Update 39399: task toronto_lm, batch 395 (39205): perplexity: 76.5401, toronto_lm_loss: 4.3378 ||
04/19 11:34:11 PM: Update 39413: task toronto_lm, batch 409 (39219): perplexity: 76.4031, toronto_lm_loss: 4.3360 ||
04/19 11:34:21 PM: Update 39426: task toronto_lm, batch 422 (39232): perplexity: 76.2316, toronto_lm_loss: 4.3338 ||
04/19 11:34:31 PM: Update 39440: task toronto_lm, batch 436 (39246): perplexity: 76.2118, toronto_lm_loss: 4.3335 ||
04/19 11:34:41 PM: Update 39453: task toronto_lm, batch 449 (39259): perplexity: 76.0972, toronto_lm_loss: 4.3320 ||
04/19 11:34:51 PM: Update 39466: task toronto_lm, batch 462 (39272): perplexity: 76.0170, toronto_lm_loss: 4.3310 ||
04/19 11:35:02 PM: Update 39479: task toronto_lm, batch 475 (39285): perplexity: 75.7973, toronto_lm_loss: 4.3281 ||
04/19 11:35:12 PM: Update 39492: task toronto_lm, batch 488 (39298): perplexity: 75.6624, toronto_lm_loss: 4.3263 ||
04/19 11:35:22 PM: Update 39505: task toronto_lm, batch 501 (39311): perplexity: 75.4805, toronto_lm_loss: 4.3239 ||
04/19 11:35:32 PM: Update 39518: task toronto_lm, batch 514 (39324): perplexity: 75.3015, toronto_lm_loss: 4.3215 ||
04/19 11:35:42 PM: Update 39531: task toronto_lm, batch 527 (39337): perplexity: 75.3359, toronto_lm_loss: 4.3220 ||
04/19 11:35:52 PM: Update 39544: task toronto_lm, batch 540 (39350): perplexity: 75.1971, toronto_lm_loss: 4.3201 ||
04/19 11:36:02 PM: Update 39557: task toronto_lm, batch 553 (39363): perplexity: 75.2443, toronto_lm_loss: 4.3207 ||
04/19 11:36:20 PM: Update 39570: task toronto_lm, batch 566 (39376): perplexity: 75.2083, toronto_lm_loss: 4.3203 ||
04/19 11:36:30 PM: Update 39583: task toronto_lm, batch 579 (39389): perplexity: 75.7340, toronto_lm_loss: 4.3272 ||
04/19 11:36:41 PM: Update 39597: task toronto_lm, batch 593 (39403): perplexity: 76.0798, toronto_lm_loss: 4.3318 ||
04/19 11:36:52 PM: Update 39611: task toronto_lm, batch 607 (39417): perplexity: 76.4857, toronto_lm_loss: 4.3371 ||
04/19 11:36:54 PM: Update 39614: task wsj, batch 5 (195): perplexity: 186.9755, wsj_loss: 5.2310 ||
04/19 11:37:02 PM: Update 39625: task toronto_lm, batch 620 (39430): perplexity: 76.7596, toronto_lm_loss: 4.3407 ||
04/19 11:37:13 PM: Update 39639: task toronto_lm, batch 634 (39444): perplexity: 77.1399, toronto_lm_loss: 4.3456 ||
04/19 11:37:24 PM: Update 39653: task toronto_lm, batch 648 (39458): perplexity: 77.4673, toronto_lm_loss: 4.3499 ||
04/19 11:37:34 PM: Update 39667: task toronto_lm, batch 662 (39472): perplexity: 77.6188, toronto_lm_loss: 4.3518 ||
04/19 11:37:45 PM: Update 39681: task toronto_lm, batch 676 (39486): perplexity: 77.8065, toronto_lm_loss: 4.3542 ||
04/19 11:37:56 PM: Update 39695: task toronto_lm, batch 690 (39500): perplexity: 78.0731, toronto_lm_loss: 4.3576 ||
04/19 11:38:07 PM: Update 39709: task toronto_lm, batch 704 (39514): perplexity: 78.4316, toronto_lm_loss: 4.3622 ||
04/19 11:38:17 PM: Update 39723: task toronto_lm, batch 718 (39528): perplexity: 78.6271, toronto_lm_loss: 4.3647 ||
04/19 11:38:28 PM: Update 39737: task toronto_lm, batch 732 (39542): perplexity: 78.7704, toronto_lm_loss: 4.3665 ||
04/19 11:38:39 PM: Update 39751: task toronto_lm, batch 746 (39556): perplexity: 78.9102, toronto_lm_loss: 4.3683 ||
04/19 11:38:49 PM: Update 39765: task toronto_lm, batch 760 (39570): perplexity: 79.1616, toronto_lm_loss: 4.3715 ||
04/19 11:39:00 PM: Update 39778: task toronto_lm, batch 773 (39583): perplexity: 79.3472, toronto_lm_loss: 4.3738 ||
04/19 11:39:10 PM: Update 39792: task toronto_lm, batch 787 (39597): perplexity: 79.4675, toronto_lm_loss: 4.3753 ||
04/19 11:39:21 PM: Update 39806: task toronto_lm, batch 801 (39611): perplexity: 79.5388, toronto_lm_loss: 4.3762 ||
04/19 11:39:32 PM: Update 39820: task toronto_lm, batch 815 (39625): perplexity: 79.6019, toronto_lm_loss: 4.3770 ||
04/19 11:39:42 PM: Update 39834: task toronto_lm, batch 829 (39639): perplexity: 79.6559, toronto_lm_loss: 4.3777 ||
04/19 11:39:52 PM: Update 39847: task toronto_lm, batch 842 (39652): perplexity: 79.8132, toronto_lm_loss: 4.3797 ||
04/19 11:40:03 PM: Update 39861: task toronto_lm, batch 856 (39666): perplexity: 79.7769, toronto_lm_loss: 4.3792 ||
04/19 11:40:13 PM: Update 39874: task toronto_lm, batch 869 (39679): perplexity: 79.7851, toronto_lm_loss: 4.3793 ||
04/19 11:40:24 PM: Update 39888: task toronto_lm, batch 883 (39693): perplexity: 79.8008, toronto_lm_loss: 4.3795 ||
04/19 11:40:34 PM: Update 39901: task toronto_lm, batch 896 (39706): perplexity: 79.8478, toronto_lm_loss: 4.3801 ||
04/19 11:40:45 PM: Update 39915: task toronto_lm, batch 910 (39720): perplexity: 79.8812, toronto_lm_loss: 4.3805 ||
04/19 11:40:55 PM: Update 39928: task toronto_lm, batch 923 (39733): perplexity: 79.8780, toronto_lm_loss: 4.3805 ||
04/19 11:41:05 PM: Update 39942: task toronto_lm, batch 937 (39747): perplexity: 79.9309, toronto_lm_loss: 4.3812 ||
04/19 11:41:16 PM: Update 39956: task toronto_lm, batch 951 (39761): perplexity: 79.9010, toronto_lm_loss: 4.3808 ||
04/19 11:41:26 PM: Update 39969: task toronto_lm, batch 964 (39774): perplexity: 79.8917, toronto_lm_loss: 4.3807 ||
04/19 11:41:36 PM: Update 39982: task toronto_lm, batch 977 (39787): perplexity: 79.9220, toronto_lm_loss: 4.3811 ||
04/19 11:41:47 PM: Update 39996: task toronto_lm, batch 991 (39801): perplexity: 79.9035, toronto_lm_loss: 4.3808 ||
04/19 11:41:50 PM: ***** Pass 40000 / Epoch 40 *****
04/19 11:41:50 PM: toronto_lm: trained on 995 batches, 0.005 epochs
04/19 11:41:50 PM: wsj: trained on 5 batches, 0.006 epochs
04/19 11:41:50 PM: Validating...
04/19 11:41:57 PM: Batch 27/140: perplexity: 86.5361, toronto_lm_loss: 4.4606 || , for evaluation data
04/19 11:42:07 PM: Batch 66/140: perplexity: 85.2111, toronto_lm_loss: 4.4451 || , for evaluation data
04/19 11:42:17 PM: Batch 105/140: perplexity: 80.2331, toronto_lm_loss: 4.3849 || , for evaluation data
04/19 11:42:28 PM: Batch 139/140: perplexity: 74.7428, toronto_lm_loss: 4.3141 || , for evaluation data
04/19 11:42:28 PM: Batch 1/66: perplexity: 314.5560, wsj_loss: 5.7512 || , for evaluation data
04/19 11:42:38 PM: Batch 40/66: perplexity: 209.2679, wsj_loss: 5.3436 || , for evaluation data
04/19 11:42:45 PM: Advancing scheduler.
04/19 11:42:45 PM: 	Best macro_avg: 0.267
04/19 11:42:45 PM: 	# bad epochs: 4
04/19 11:42:45 PM: Statistic: toronto_lm_loss
04/19 11:42:45 PM: 	training: 4.381198
04/19 11:42:45 PM: 	validation: 4.316409
04/19 11:42:45 PM: Statistic: wsj_loss
04/19 11:42:45 PM: 	training: 5.230977
04/19 11:42:45 PM: 	validation: 5.330745
04/19 11:42:45 PM: Statistic: macro_avg
04/19 11:42:45 PM: 	validation: 0.261897
04/19 11:42:45 PM: Statistic: micro_avg
04/19 11:42:45 PM: 	validation: 0.055658
04/19 11:42:45 PM: Statistic: toronto_lm_perplexity
04/19 11:42:45 PM: 	training: 79.933755
04/19 11:42:45 PM: 	validation: 74.919085
04/19 11:42:45 PM: Statistic: wsj_perplexity
04/19 11:42:45 PM: 	training: 186.975472
04/19 11:42:45 PM: 	validation: 206.591808
04/19 11:42:45 PM: global_lr: 0.001000
04/19 11:42:45 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 11:42:46 PM: Update 40001: task toronto_lm, batch 1 (39806): perplexity: 91.3033, toronto_lm_loss: 4.5142 ||
04/19 11:42:56 PM: Update 40014: task toronto_lm, batch 14 (39819): perplexity: 81.6811, toronto_lm_loss: 4.4028 ||
04/19 11:43:07 PM: Update 40028: task toronto_lm, batch 28 (39833): perplexity: 81.9844, toronto_lm_loss: 4.4065 ||
04/19 11:43:17 PM: Update 40041: task toronto_lm, batch 41 (39846): perplexity: 81.1572, toronto_lm_loss: 4.3964 ||
04/19 11:43:27 PM: Update 40054: task toronto_lm, batch 54 (39859): perplexity: 81.8334, toronto_lm_loss: 4.4047 ||
04/19 11:43:38 PM: Update 40068: task toronto_lm, batch 68 (39873): perplexity: 81.6071, toronto_lm_loss: 4.4019 ||
04/19 11:43:48 PM: Update 40082: task toronto_lm, batch 82 (39887): perplexity: 81.5798, toronto_lm_loss: 4.4016 ||
04/19 11:43:58 PM: Update 40095: task toronto_lm, batch 95 (39900): perplexity: 81.9438, toronto_lm_loss: 4.4060 ||
04/19 11:44:09 PM: Update 40109: task toronto_lm, batch 109 (39914): perplexity: 81.9642, toronto_lm_loss: 4.4063 ||
04/19 11:44:12 PM: Update 40113: task wsj, batch 1 (196): perplexity: 198.7017, wsj_loss: 5.2918 ||
04/19 11:44:19 PM: Update 40122: task toronto_lm, batch 121 (39926): perplexity: 81.9191, toronto_lm_loss: 4.4057 ||
04/19 11:44:29 PM: Update 40135: task toronto_lm, batch 134 (39939): perplexity: 81.4061, toronto_lm_loss: 4.3994 ||
04/19 11:44:31 PM: Update 40137: task wsj, batch 2 (197): perplexity: 184.8564, wsj_loss: 5.2196 ||
04/19 11:44:40 PM: Update 40148: task toronto_lm, batch 146 (39951): perplexity: 81.4822, toronto_lm_loss: 4.4004 ||
04/19 11:44:50 PM: Update 40161: task toronto_lm, batch 159 (39964): perplexity: 81.1005, toronto_lm_loss: 4.3957 ||
04/19 11:45:00 PM: Update 40174: task toronto_lm, batch 172 (39977): perplexity: 81.3390, toronto_lm_loss: 4.3986 ||
04/19 11:45:10 PM: Update 40187: task toronto_lm, batch 185 (39990): perplexity: 81.3542, toronto_lm_loss: 4.3988 ||
04/19 11:45:27 PM: Update 40198: task toronto_lm, batch 196 (40001): perplexity: 81.0643, toronto_lm_loss: 4.3952 ||
04/19 11:45:37 PM: Update 40211: task toronto_lm, batch 209 (40014): perplexity: 80.9752, toronto_lm_loss: 4.3941 ||
04/19 11:45:48 PM: Update 40224: task toronto_lm, batch 222 (40027): perplexity: 80.6985, toronto_lm_loss: 4.3907 ||
04/19 11:45:58 PM: Update 40237: task toronto_lm, batch 235 (40040): perplexity: 80.2199, toronto_lm_loss: 4.3848 ||
04/19 11:46:08 PM: Update 40250: task toronto_lm, batch 248 (40053): perplexity: 79.9372, toronto_lm_loss: 4.3812 ||
04/19 11:46:18 PM: Update 40263: task toronto_lm, batch 261 (40066): perplexity: 79.4357, toronto_lm_loss: 4.3749 ||
04/19 11:46:29 PM: Update 40277: task toronto_lm, batch 275 (40080): perplexity: 79.1853, toronto_lm_loss: 4.3718 ||
04/19 11:46:39 PM: Update 40291: task toronto_lm, batch 289 (40094): perplexity: 78.8309, toronto_lm_loss: 4.3673 ||
04/19 11:46:50 PM: Update 40305: task toronto_lm, batch 303 (40108): perplexity: 78.5410, toronto_lm_loss: 4.3636 ||
04/19 11:47:01 PM: Update 40319: task toronto_lm, batch 317 (40122): perplexity: 78.2975, toronto_lm_loss: 4.3605 ||
04/19 11:47:12 PM: Update 40333: task toronto_lm, batch 331 (40136): perplexity: 77.8326, toronto_lm_loss: 4.3546 ||
04/19 11:47:22 PM: Update 40347: task toronto_lm, batch 345 (40150): perplexity: 77.5444, toronto_lm_loss: 4.3509 ||
04/19 11:47:33 PM: Update 40361: task toronto_lm, batch 359 (40164): perplexity: 77.1976, toronto_lm_loss: 4.3464 ||
04/19 11:47:44 PM: Update 40375: task toronto_lm, batch 373 (40178): perplexity: 76.8329, toronto_lm_loss: 4.3416 ||
04/19 11:47:54 PM: Update 40389: task toronto_lm, batch 387 (40192): perplexity: 76.5132, toronto_lm_loss: 4.3375 ||
04/19 11:48:05 PM: Update 40403: task toronto_lm, batch 401 (40206): perplexity: 76.2929, toronto_lm_loss: 4.3346 ||
04/19 11:48:16 PM: Update 40417: task toronto_lm, batch 415 (40220): perplexity: 75.8544, toronto_lm_loss: 4.3288 ||
04/19 11:48:26 PM: Update 40431: task toronto_lm, batch 429 (40234): perplexity: 75.5887, toronto_lm_loss: 4.3253 ||
04/19 11:48:37 PM: Update 40445: task toronto_lm, batch 443 (40248): perplexity: 75.2450, toronto_lm_loss: 4.3207 ||
04/19 11:48:48 PM: Update 40459: task toronto_lm, batch 457 (40262): perplexity: 74.9967, toronto_lm_loss: 4.3174 ||
04/19 11:48:58 PM: Update 40473: task toronto_lm, batch 471 (40276): perplexity: 74.6352, toronto_lm_loss: 4.3126 ||
04/19 11:49:09 PM: Update 40486: task toronto_lm, batch 484 (40289): perplexity: 74.4541, toronto_lm_loss: 4.3102 ||
04/19 11:49:19 PM: Update 40499: task toronto_lm, batch 497 (40302): perplexity: 74.2894, toronto_lm_loss: 4.3080 ||
04/19 11:49:29 PM: Update 40512: task toronto_lm, batch 510 (40315): perplexity: 74.0608, toronto_lm_loss: 4.3049 ||
04/19 11:49:39 PM: Update 40526: task toronto_lm, batch 524 (40329): perplexity: 73.7580, toronto_lm_loss: 4.3008 ||
04/19 11:49:50 PM: Update 40540: task toronto_lm, batch 538 (40343): perplexity: 73.5608, toronto_lm_loss: 4.2981 ||
04/19 11:50:01 PM: Update 40554: task toronto_lm, batch 552 (40357): perplexity: 73.2789, toronto_lm_loss: 4.2943 ||
04/19 11:50:11 PM: Update 40567: task toronto_lm, batch 565 (40370): perplexity: 73.0593, toronto_lm_loss: 4.2913 ||
04/19 11:50:22 PM: Update 40581: task toronto_lm, batch 579 (40384): perplexity: 72.9002, toronto_lm_loss: 4.2891 ||
04/19 11:50:29 PM: Update 40590: task wsj, batch 3 (198): perplexity: 202.0829, wsj_loss: 5.3087 ||
04/19 11:50:32 PM: Update 40594: task toronto_lm, batch 591 (40396): perplexity: 72.6436, toronto_lm_loss: 4.2856 ||
04/19 11:50:42 PM: Update 40607: task toronto_lm, batch 604 (40409): perplexity: 72.4861, toronto_lm_loss: 4.2834 ||
04/19 11:50:47 PM: Update 40614: task wsj, batch 4 (199): perplexity: 212.9204, wsj_loss: 5.3609 ||
04/19 11:50:52 PM: Update 40621: task toronto_lm, batch 617 (40422): perplexity: 72.3427, toronto_lm_loss: 4.2814 ||
04/19 11:51:03 PM: Update 40634: task toronto_lm, batch 630 (40435): perplexity: 72.1839, toronto_lm_loss: 4.2792 ||
04/19 11:51:13 PM: Update 40647: task toronto_lm, batch 643 (40448): perplexity: 71.9460, toronto_lm_loss: 4.2759 ||
04/19 11:51:23 PM: Update 40660: task toronto_lm, batch 656 (40461): perplexity: 71.7797, toronto_lm_loss: 4.2736 ||
04/19 11:51:33 PM: Update 40674: task toronto_lm, batch 670 (40475): perplexity: 71.5236, toronto_lm_loss: 4.2700 ||
04/19 11:51:43 PM: Update 40687: task toronto_lm, batch 683 (40488): perplexity: 71.3926, toronto_lm_loss: 4.2682 ||
04/19 11:51:54 PM: Update 40700: task toronto_lm, batch 696 (40501): perplexity: 71.1504, toronto_lm_loss: 4.2648 ||
04/19 11:52:04 PM: Update 40713: task toronto_lm, batch 709 (40514): perplexity: 71.0440, toronto_lm_loss: 4.2633 ||
04/19 11:52:14 PM: Update 40726: task toronto_lm, batch 722 (40527): perplexity: 70.8564, toronto_lm_loss: 4.2607 ||
04/19 11:52:24 PM: Update 40739: task toronto_lm, batch 735 (40540): perplexity: 70.7497, toronto_lm_loss: 4.2591 ||
04/19 11:52:34 PM: Update 40752: task toronto_lm, batch 748 (40553): perplexity: 70.6001, toronto_lm_loss: 4.2570 ||
04/19 11:52:44 PM: Update 40765: task toronto_lm, batch 761 (40566): perplexity: 70.4564, toronto_lm_loss: 4.2550 ||
04/19 11:52:55 PM: Update 40779: task toronto_lm, batch 775 (40580): perplexity: 70.2741, toronto_lm_loss: 4.2524 ||
04/19 11:53:05 PM: Update 40792: task toronto_lm, batch 788 (40593): perplexity: 70.1743, toronto_lm_loss: 4.2510 ||
04/19 11:53:15 PM: Update 40805: task toronto_lm, batch 801 (40606): perplexity: 70.0183, toronto_lm_loss: 4.2488 ||
04/19 11:53:25 PM: Update 40818: task toronto_lm, batch 814 (40619): perplexity: 69.8872, toronto_lm_loss: 4.2469 ||
04/19 11:53:38 PM: Update 40825: task toronto_lm, batch 821 (40626): perplexity: 69.8233, toronto_lm_loss: 4.2460 ||
04/19 11:53:48 PM: Update 40838: task toronto_lm, batch 834 (40639): perplexity: 69.6815, toronto_lm_loss: 4.2439 ||
04/19 11:53:53 PM: Update 40844: task wsj, batch 5 (200): perplexity: 211.3387, wsj_loss: 5.3535 ||
04/19 11:53:58 PM: Update 40851: task toronto_lm, batch 846 (40651): perplexity: 69.5511, toronto_lm_loss: 4.2421 ||
04/19 11:54:08 PM: Update 40864: task toronto_lm, batch 859 (40664): perplexity: 69.4901, toronto_lm_loss: 4.2412 ||
04/19 11:54:15 PM: Update 40873: task wsj, batch 6 (201): perplexity: 215.7900, wsj_loss: 5.3743 ||
04/19 11:54:18 PM: Update 40877: task toronto_lm, batch 871 (40676): perplexity: 69.4171, toronto_lm_loss: 4.2401 ||
04/19 11:54:28 PM: Update 40890: task toronto_lm, batch 884 (40689): perplexity: 69.2456, toronto_lm_loss: 4.2377 ||
04/19 11:54:38 PM: Update 40903: task toronto_lm, batch 897 (40702): perplexity: 69.1198, toronto_lm_loss: 4.2358 ||
04/19 11:54:48 PM: Update 40916: task toronto_lm, batch 910 (40715): perplexity: 69.0643, toronto_lm_loss: 4.2350 ||
04/19 11:54:50 PM: Update 40918: task wsj, batch 7 (202): perplexity: 210.5666, wsj_loss: 5.3498 ||
04/19 11:54:59 PM: Update 40929: task toronto_lm, batch 922 (40727): perplexity: 68.9290, toronto_lm_loss: 4.2331 ||
04/19 11:55:09 PM: Update 40942: task toronto_lm, batch 935 (40740): perplexity: 68.8495, toronto_lm_loss: 4.2319 ||
04/19 11:55:19 PM: Update 40955: task toronto_lm, batch 948 (40753): perplexity: 68.6965, toronto_lm_loss: 4.2297 ||
04/19 11:55:21 PM: Update 40958: task wsj, batch 8 (203): perplexity: 211.5105, wsj_loss: 5.3543 ||
04/19 11:55:29 PM: Update 40968: task toronto_lm, batch 960 (40765): perplexity: 68.5715, toronto_lm_loss: 4.2279 ||
04/19 11:55:40 PM: Update 40982: task toronto_lm, batch 974 (40779): perplexity: 68.4113, toronto_lm_loss: 4.2255 ||
04/19 11:55:50 PM: Update 40996: task toronto_lm, batch 988 (40793): perplexity: 68.2798, toronto_lm_loss: 4.2236 ||
04/19 11:55:52 PM: Update 40998: task wsj, batch 9 (204): perplexity: 210.0836, wsj_loss: 5.3475 ||
04/19 11:55:54 PM: ***** Pass 41000 / Epoch 41 *****
04/19 11:55:54 PM: toronto_lm: trained on 991 batches, 0.005 epochs
04/19 11:55:54 PM: wsj: trained on 9 batches, 0.011 epochs
04/19 11:55:54 PM: Validating...
04/19 11:56:01 PM: Batch 27/140: perplexity: 86.5221, toronto_lm_loss: 4.4604 || , for evaluation data
04/19 11:56:11 PM: Batch 65/140: perplexity: 85.0511, toronto_lm_loss: 4.4433 || , for evaluation data
04/19 11:56:21 PM: Batch 103/140: perplexity: 81.0255, toronto_lm_loss: 4.3948 || , for evaluation data
04/19 11:56:31 PM: Batch 1/66: perplexity: 289.4424, wsj_loss: 5.6680 || , for evaluation data
04/19 11:56:41 PM: Batch 39/66: perplexity: 194.8826, wsj_loss: 5.2724 || , for evaluation data
04/19 11:56:48 PM: Best model found for wsj.
04/19 11:56:48 PM: Best model found for micro.
04/19 11:56:48 PM: Best model found for macro.
04/19 11:56:48 PM: Advancing scheduler.
04/19 11:56:48 PM: 	Best macro_avg: 0.298
04/19 11:56:48 PM: 	# bad epochs: 0
04/19 11:56:48 PM: Statistic: toronto_lm_loss
04/19 11:56:48 PM: 	training: 4.223149
04/19 11:56:48 PM: 	validation: 4.317875
04/19 11:56:48 PM: Statistic: wsj_loss
04/19 11:56:48 PM: 	training: 5.347506
04/19 11:56:48 PM: 	validation: 5.239609
04/19 11:56:48 PM: Statistic: macro_avg
04/19 11:56:48 PM: 	validation: 0.297778
04/19 11:56:48 PM: Statistic: micro_avg
04/19 11:56:48 PM: 	validation: 0.078731
04/19 11:56:48 PM: Statistic: toronto_lm_perplexity
04/19 11:56:48 PM: 	training: 68.248051
04/19 11:56:48 PM: 	validation: 75.029025
04/19 11:56:48 PM: Statistic: wsj_perplexity
04/19 11:56:48 PM: 	training: 210.083616
04/19 11:56:48 PM: 	validation: 188.596357
04/19 11:56:48 PM: global_lr: 0.001000
04/19 11:56:48 PM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/19 11:56:49 PM: Update 41001: task toronto_lm, batch 1 (40797): perplexity: 53.6255, toronto_lm_loss: 3.9820 ||
04/19 11:56:59 PM: Update 41014: task toronto_lm, batch 14 (40810): perplexity: 59.6411, toronto_lm_loss: 4.0883 ||
04/19 11:57:09 PM: Update 41027: task toronto_lm, batch 27 (40823): perplexity: 57.0592, toronto_lm_loss: 4.0441 ||
04/19 11:57:19 PM: Update 41040: task toronto_lm, batch 40 (40836): perplexity: 55.3338, toronto_lm_loss: 4.0134 ||
04/19 11:57:29 PM: Update 41053: task toronto_lm, batch 53 (40849): perplexity: 55.3502, toronto_lm_loss: 4.0137 ||
04/19 11:57:40 PM: Update 41066: task toronto_lm, batch 66 (40862): perplexity: 55.6072, toronto_lm_loss: 4.0183 ||
04/19 11:57:50 PM: Update 41079: task toronto_lm, batch 79 (40875): perplexity: 55.6851, toronto_lm_loss: 4.0197 ||
04/19 11:57:54 PM: Update 41084: task wsj, batch 1 (205): perplexity: 215.9733, wsj_loss: 5.3752 ||
04/19 11:58:00 PM: Update 41092: task toronto_lm, batch 91 (40887): perplexity: 55.8107, toronto_lm_loss: 4.0220 ||
04/19 11:58:10 PM: Update 41105: task toronto_lm, batch 104 (40900): perplexity: 55.8759, toronto_lm_loss: 4.0231 ||
04/19 11:58:20 PM: Update 41118: task toronto_lm, batch 117 (40913): perplexity: 55.7012, toronto_lm_loss: 4.0200 ||
04/19 11:58:30 PM: Update 41131: task toronto_lm, batch 130 (40926): perplexity: 55.9536, toronto_lm_loss: 4.0245 ||
04/19 11:58:40 PM: Update 41144: task toronto_lm, batch 143 (40939): perplexity: 56.0632, toronto_lm_loss: 4.0265 ||
04/19 11:58:50 PM: Update 41157: task toronto_lm, batch 156 (40952): perplexity: 55.9482, toronto_lm_loss: 4.0244 ||
04/19 11:59:01 PM: Update 41170: task toronto_lm, batch 169 (40965): perplexity: 55.7109, toronto_lm_loss: 4.0202 ||
04/19 11:59:11 PM: Update 41183: task toronto_lm, batch 182 (40978): perplexity: 55.7526, toronto_lm_loss: 4.0209 ||
04/19 11:59:21 PM: Update 41196: task toronto_lm, batch 195 (40991): perplexity: 55.6992, toronto_lm_loss: 4.0200 ||
04/19 11:59:31 PM: Update 41210: task toronto_lm, batch 209 (41005): perplexity: 55.7082, toronto_lm_loss: 4.0201 ||
04/19 11:59:42 PM: Update 41224: task toronto_lm, batch 223 (41019): perplexity: 55.9570, toronto_lm_loss: 4.0246 ||
04/19 11:59:53 PM: Update 41238: task toronto_lm, batch 237 (41033): perplexity: 55.7939, toronto_lm_loss: 4.0217 ||
04/20 12:00:03 AM: Update 41252: task toronto_lm, batch 251 (41047): perplexity: 55.6222, toronto_lm_loss: 4.0186 ||
04/20 12:00:04 AM: Update 41253: task wsj, batch 2 (206): perplexity: 254.2127, wsj_loss: 5.5382 ||
04/20 12:00:13 AM: Update 41265: task toronto_lm, batch 263 (41059): perplexity: 55.5260, toronto_lm_loss: 4.0169 ||
04/20 12:00:24 AM: Update 41279: task toronto_lm, batch 277 (41073): perplexity: 55.2731, toronto_lm_loss: 4.0123 ||
04/20 12:00:35 AM: Update 41293: task toronto_lm, batch 291 (41087): perplexity: 55.0181, toronto_lm_loss: 4.0077 ||
04/20 12:00:45 AM: Update 41306: task toronto_lm, batch 304 (41100): perplexity: 54.9637, toronto_lm_loss: 4.0067 ||
04/20 12:00:55 AM: Update 41319: task toronto_lm, batch 317 (41113): perplexity: 54.8959, toronto_lm_loss: 4.0054 ||
04/20 12:01:06 AM: Update 41333: task toronto_lm, batch 331 (41127): perplexity: 54.8270, toronto_lm_loss: 4.0042 ||
04/20 12:01:16 AM: Update 41346: task toronto_lm, batch 344 (41140): perplexity: 54.7499, toronto_lm_loss: 4.0028 ||
04/20 12:01:23 AM: Update 41356: task wsj, batch 3 (207): perplexity: 223.0233, wsj_loss: 5.4073 ||
04/20 12:01:26 AM: Update 41359: task toronto_lm, batch 356 (41152): perplexity: 54.6514, toronto_lm_loss: 4.0010 ||
04/20 12:01:36 AM: Update 41372: task toronto_lm, batch 369 (41165): perplexity: 54.5754, toronto_lm_loss: 3.9996 ||
04/20 12:01:46 AM: Update 41385: task toronto_lm, batch 382 (41178): perplexity: 54.4847, toronto_lm_loss: 3.9979 ||
04/20 12:01:57 AM: Update 41399: task toronto_lm, batch 396 (41192): perplexity: 54.4864, toronto_lm_loss: 3.9980 ||
04/20 12:02:07 AM: Update 41412: task toronto_lm, batch 409 (41205): perplexity: 54.4421, toronto_lm_loss: 3.9971 ||
04/20 12:02:17 AM: Update 41425: task toronto_lm, batch 422 (41218): perplexity: 54.4015, toronto_lm_loss: 3.9964 ||
04/20 12:02:27 AM: Update 41438: task toronto_lm, batch 435 (41231): perplexity: 54.4243, toronto_lm_loss: 3.9968 ||
04/20 12:02:37 AM: Update 41451: task toronto_lm, batch 448 (41244): perplexity: 54.4418, toronto_lm_loss: 3.9971 ||
04/20 12:02:50 AM: Update 41458: task toronto_lm, batch 455 (41251): perplexity: 54.4952, toronto_lm_loss: 3.9981 ||
04/20 12:03:00 AM: Update 41471: task toronto_lm, batch 468 (41264): perplexity: 55.1856, toronto_lm_loss: 4.0107 ||
04/20 12:03:11 AM: Update 41485: task toronto_lm, batch 482 (41278): perplexity: 55.7917, toronto_lm_loss: 4.0216 ||
04/20 12:03:21 AM: Update 41498: task toronto_lm, batch 495 (41291): perplexity: 56.3427, toronto_lm_loss: 4.0315 ||
04/20 12:03:31 AM: Update 41511: task toronto_lm, batch 508 (41304): perplexity: 56.7785, toronto_lm_loss: 4.0392 ||
04/20 12:03:41 AM: Update 41524: task toronto_lm, batch 521 (41317): perplexity: 57.3129, toronto_lm_loss: 4.0485 ||
04/20 12:03:51 AM: Update 41537: task toronto_lm, batch 534 (41330): perplexity: 57.6582, toronto_lm_loss: 4.0545 ||
04/20 12:04:02 AM: Update 41551: task toronto_lm, batch 548 (41344): perplexity: 57.9467, toronto_lm_loss: 4.0595 ||
04/20 12:04:12 AM: Update 41564: task toronto_lm, batch 561 (41357): perplexity: 58.2100, toronto_lm_loss: 4.0641 ||
04/20 12:04:22 AM: Update 41577: task toronto_lm, batch 574 (41370): perplexity: 58.4957, toronto_lm_loss: 4.0690 ||
04/20 12:04:32 AM: Update 41590: task toronto_lm, batch 587 (41383): perplexity: 58.7745, toronto_lm_loss: 4.0737 ||
04/20 12:04:42 AM: Update 41603: task toronto_lm, batch 600 (41396): perplexity: 58.9622, toronto_lm_loss: 4.0769 ||
04/20 12:04:53 AM: Update 41617: task toronto_lm, batch 614 (41410): perplexity: 59.1264, toronto_lm_loss: 4.0797 ||
04/20 12:04:54 AM: Update 41618: task wsj, batch 4 (208): perplexity: 231.0118, wsj_loss: 5.4425 ||
04/20 12:05:04 AM: Update 41631: task toronto_lm, batch 626 (41422): perplexity: 59.3647, toronto_lm_loss: 4.0837 ||
04/20 12:05:14 AM: Update 41644: task toronto_lm, batch 639 (41435): perplexity: 59.4590, toronto_lm_loss: 4.0853 ||
04/20 12:05:24 AM: Update 41657: task toronto_lm, batch 652 (41448): perplexity: 59.5443, toronto_lm_loss: 4.0867 ||
04/20 12:05:34 AM: Update 41670: task toronto_lm, batch 665 (41461): perplexity: 59.7268, toronto_lm_loss: 4.0898 ||
04/20 12:05:44 AM: Update 41683: task toronto_lm, batch 678 (41474): perplexity: 59.8434, toronto_lm_loss: 4.0917 ||
04/20 12:05:46 AM: Update 41685: task wsj, batch 6 (210): perplexity: 213.0743, wsj_loss: 5.3616 ||
04/20 12:05:54 AM: Update 41696: task toronto_lm, batch 690 (41486): perplexity: 59.9908, toronto_lm_loss: 4.0942 ||
04/20 12:06:04 AM: Update 41709: task toronto_lm, batch 703 (41499): perplexity: 60.1518, toronto_lm_loss: 4.0969 ||
04/20 12:06:14 AM: Update 41722: task toronto_lm, batch 716 (41512): perplexity: 60.2675, toronto_lm_loss: 4.0988 ||
04/20 12:06:25 AM: Update 41735: task toronto_lm, batch 729 (41525): perplexity: 60.3619, toronto_lm_loss: 4.1004 ||
04/20 12:06:35 AM: Update 41748: task toronto_lm, batch 742 (41538): perplexity: 60.4624, toronto_lm_loss: 4.1020 ||
04/20 12:06:45 AM: Update 41761: task toronto_lm, batch 755 (41551): perplexity: 60.5561, toronto_lm_loss: 4.1036 ||
04/20 12:06:55 AM: Update 41774: task toronto_lm, batch 768 (41564): perplexity: 60.5500, toronto_lm_loss: 4.1035 ||
04/20 12:07:05 AM: Update 41787: task toronto_lm, batch 781 (41577): perplexity: 60.6031, toronto_lm_loss: 4.1043 ||
04/20 12:07:15 AM: Update 41800: task toronto_lm, batch 794 (41590): perplexity: 60.6675, toronto_lm_loss: 4.1054 ||
04/20 12:07:25 AM: Update 41813: task toronto_lm, batch 807 (41603): perplexity: 60.7375, toronto_lm_loss: 4.1066 ||
04/20 12:07:35 AM: Update 41826: task toronto_lm, batch 820 (41616): perplexity: 60.8599, toronto_lm_loss: 4.1086 ||
04/20 12:07:46 AM: Update 41840: task toronto_lm, batch 834 (41630): perplexity: 60.9099, toronto_lm_loss: 4.1094 ||
04/20 12:07:56 AM: Update 41853: task toronto_lm, batch 847 (41643): perplexity: 60.9502, toronto_lm_loss: 4.1101 ||
04/20 12:08:06 AM: Update 41866: task toronto_lm, batch 860 (41656): perplexity: 61.0094, toronto_lm_loss: 4.1110 ||
04/20 12:08:16 AM: Update 41879: task toronto_lm, batch 873 (41669): perplexity: 61.0585, toronto_lm_loss: 4.1118 ||
04/20 12:08:26 AM: Update 41892: task toronto_lm, batch 886 (41682): perplexity: 61.0956, toronto_lm_loss: 4.1124 ||
04/20 12:08:36 AM: Update 41905: task toronto_lm, batch 899 (41695): perplexity: 61.1513, toronto_lm_loss: 4.1134 ||
04/20 12:08:46 AM: Update 41918: task toronto_lm, batch 912 (41708): perplexity: 61.2032, toronto_lm_loss: 4.1142 ||
04/20 12:08:53 AM: Update 41927: task wsj, batch 7 (211): perplexity: 212.4911, wsj_loss: 5.3589 ||
04/20 12:08:57 AM: Update 41932: task toronto_lm, batch 925 (41721): perplexity: 61.2061, toronto_lm_loss: 4.1142 ||
04/20 12:09:08 AM: Update 41946: task toronto_lm, batch 939 (41735): perplexity: 61.2396, toronto_lm_loss: 4.1148 ||
04/20 12:09:18 AM: Update 41959: task toronto_lm, batch 952 (41748): perplexity: 61.2403, toronto_lm_loss: 4.1148 ||
04/20 12:09:28 AM: Update 41972: task toronto_lm, batch 965 (41761): perplexity: 61.3093, toronto_lm_loss: 4.1159 ||
04/20 12:09:38 AM: Update 41985: task toronto_lm, batch 978 (41774): perplexity: 61.3572, toronto_lm_loss: 4.1167 ||
04/20 12:09:49 AM: Update 41999: task toronto_lm, batch 992 (41788): perplexity: 61.3912, toronto_lm_loss: 4.1173 ||
04/20 12:09:49 AM: ***** Pass 42000 / Epoch 42 *****
04/20 12:09:49 AM: toronto_lm: trained on 993 batches, 0.005 epochs
04/20 12:09:49 AM: wsj: trained on 7 batches, 0.008 epochs
04/20 12:09:49 AM: Validating...
04/20 12:09:59 AM: Batch 35/140: perplexity: 86.4689, toronto_lm_loss: 4.4598 || , for evaluation data
04/20 12:10:09 AM: Batch 73/140: perplexity: 87.8998, toronto_lm_loss: 4.4762 || , for evaluation data
04/20 12:10:19 AM: Batch 111/140: perplexity: 81.8473, toronto_lm_loss: 4.4049 || , for evaluation data
04/20 12:10:27 AM: Batch 1/66: perplexity: 298.2287, wsj_loss: 5.6979 || , for evaluation data
04/20 12:10:37 AM: Batch 39/66: perplexity: 203.2011, wsj_loss: 5.3142 || , for evaluation data
04/20 12:10:44 AM: Advancing scheduler.
04/20 12:10:44 AM: 	Best macro_avg: 0.298
04/20 12:10:44 AM: 	# bad epochs: 1
04/20 12:10:44 AM: Statistic: toronto_lm_loss
04/20 12:10:44 AM: 	training: 4.117460
04/20 12:10:44 AM: 	validation: 4.353266
04/20 12:10:44 AM: Statistic: wsj_loss
04/20 12:10:44 AM: 	training: 5.358900
04/20 12:10:44 AM: 	validation: 5.280997
04/20 12:10:44 AM: Statistic: macro_avg
04/20 12:10:44 AM: 	validation: 0.279136
04/20 12:10:44 AM: Statistic: micro_avg
04/20 12:10:44 AM: 	validation: 0.068513
04/20 12:10:44 AM: Statistic: toronto_lm_perplexity
04/20 12:10:44 AM: 	training: 61.403096
04/20 12:10:44 AM: 	validation: 77.731919
04/20 12:10:44 AM: Statistic: wsj_perplexity
04/20 12:10:44 AM: 	training: 212.491078
04/20 12:10:44 AM: 	validation: 196.565838
04/20 12:10:44 AM: global_lr: 0.001000
04/20 12:10:44 AM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/20 12:10:45 AM: Update 42001: task toronto_lm, batch 1 (41790): perplexity: 60.7225, toronto_lm_loss: 4.1063 ||
04/20 12:10:55 AM: Update 42014: task toronto_lm, batch 14 (41803): perplexity: 61.9290, toronto_lm_loss: 4.1260 ||
04/20 12:11:06 AM: Update 42028: task toronto_lm, batch 28 (41817): perplexity: 62.8649, toronto_lm_loss: 4.1410 ||
04/20 12:11:17 AM: Update 42042: task toronto_lm, batch 42 (41831): perplexity: 61.9662, toronto_lm_loss: 4.1266 ||
04/20 12:11:27 AM: Update 42056: task toronto_lm, batch 56 (41845): perplexity: 61.9088, toronto_lm_loss: 4.1257 ||
04/20 12:11:38 AM: Update 42070: task toronto_lm, batch 70 (41859): perplexity: 61.1965, toronto_lm_loss: 4.1141 ||
04/20 12:11:49 AM: Update 42084: task toronto_lm, batch 84 (41873): perplexity: 61.5179, toronto_lm_loss: 4.1193 ||
04/20 12:11:59 AM: Update 42087: task toronto_lm, batch 87 (41876): perplexity: 61.7273, toronto_lm_loss: 4.1227 ||
04/20 12:12:09 AM: Update 42100: task toronto_lm, batch 100 (41889): perplexity: 63.3467, toronto_lm_loss: 4.1486 ||
04/20 12:12:19 AM: Update 42113: task toronto_lm, batch 113 (41902): perplexity: 63.5663, toronto_lm_loss: 4.1521 ||
04/20 12:12:29 AM: Update 42126: task toronto_lm, batch 126 (41915): perplexity: 63.5691, toronto_lm_loss: 4.1521 ||
04/20 12:12:40 AM: Update 42139: task toronto_lm, batch 139 (41928): perplexity: 63.3950, toronto_lm_loss: 4.1494 ||
04/20 12:12:50 AM: Update 42153: task toronto_lm, batch 153 (41942): perplexity: 63.0960, toronto_lm_loss: 4.1447 ||
04/20 12:13:00 AM: Update 42166: task toronto_lm, batch 166 (41955): perplexity: 62.8980, toronto_lm_loss: 4.1415 ||
04/20 12:13:10 AM: Update 42179: task toronto_lm, batch 179 (41968): perplexity: 62.7720, toronto_lm_loss: 4.1395 ||
04/20 12:13:21 AM: Update 42193: task toronto_lm, batch 193 (41982): perplexity: 62.7142, toronto_lm_loss: 4.1386 ||
04/20 12:13:31 AM: Update 42206: task toronto_lm, batch 206 (41995): perplexity: 62.3059, toronto_lm_loss: 4.1321 ||
04/20 12:13:41 AM: Update 42219: task toronto_lm, batch 219 (42008): perplexity: 62.0775, toronto_lm_loss: 4.1284 ||
04/20 12:13:51 AM: Update 42232: task toronto_lm, batch 232 (42021): perplexity: 61.2851, toronto_lm_loss: 4.1155 ||
04/20 12:13:55 AM: Update 42237: task wsj, batch 1 (212): perplexity: 201.6083, wsj_loss: 5.3063 ||
04/20 12:14:01 AM: Update 42245: task toronto_lm, batch 244 (42033): perplexity: 61.0121, toronto_lm_loss: 4.1111 ||
04/20 12:14:11 AM: Update 42258: task toronto_lm, batch 257 (42046): perplexity: 60.7057, toronto_lm_loss: 4.1060 ||
04/20 12:14:21 AM: Update 42271: task toronto_lm, batch 270 (42059): perplexity: 60.1886, toronto_lm_loss: 4.0975 ||
04/20 12:14:31 AM: Update 42284: task toronto_lm, batch 283 (42072): perplexity: 59.9700, toronto_lm_loss: 4.0938 ||
04/20 12:14:41 AM: Update 42297: task toronto_lm, batch 296 (42085): perplexity: 59.6735, toronto_lm_loss: 4.0889 ||
04/20 12:14:52 AM: Update 42310: task toronto_lm, batch 309 (42098): perplexity: 59.3356, toronto_lm_loss: 4.0832 ||
04/20 12:15:02 AM: Update 42324: task toronto_lm, batch 323 (42112): perplexity: 59.1428, toronto_lm_loss: 4.0800 ||
04/20 12:15:12 AM: Update 42337: task toronto_lm, batch 336 (42125): perplexity: 58.8838, toronto_lm_loss: 4.0756 ||
04/20 12:15:23 AM: Update 42351: task toronto_lm, batch 350 (42139): perplexity: 58.3818, toronto_lm_loss: 4.0670 ||
04/20 12:15:33 AM: Update 42364: task toronto_lm, batch 363 (42152): perplexity: 58.0238, toronto_lm_loss: 4.0609 ||
04/20 12:15:43 AM: Update 42377: task toronto_lm, batch 376 (42165): perplexity: 57.8066, toronto_lm_loss: 4.0571 ||
04/20 12:15:53 AM: Update 42390: task toronto_lm, batch 389 (42178): perplexity: 57.5361, toronto_lm_loss: 4.0524 ||
04/20 12:16:03 AM: Update 42403: task toronto_lm, batch 402 (42191): perplexity: 57.3503, toronto_lm_loss: 4.0492 ||
04/20 12:16:14 AM: Update 42417: task toronto_lm, batch 416 (42205): perplexity: 57.1889, toronto_lm_loss: 4.0464 ||
04/20 12:16:24 AM: Update 42430: task toronto_lm, batch 429 (42218): perplexity: 56.8844, toronto_lm_loss: 4.0410 ||
04/20 12:16:35 AM: Update 42444: task toronto_lm, batch 443 (42232): perplexity: 56.6679, toronto_lm_loss: 4.0372 ||
04/20 12:16:45 AM: Update 42457: task toronto_lm, batch 456 (42245): perplexity: 56.4463, toronto_lm_loss: 4.0333 ||
04/20 12:16:53 AM: Update 42468: task wsj, batch 2 (213): perplexity: 199.3093, wsj_loss: 5.2949 ||
04/20 12:16:56 AM: Update 42471: task toronto_lm, batch 469 (42258): perplexity: 56.2341, toronto_lm_loss: 4.0295 ||
04/20 12:17:06 AM: Update 42484: task toronto_lm, batch 482 (42271): perplexity: 55.9390, toronto_lm_loss: 4.0243 ||
04/20 12:17:16 AM: Update 42497: task toronto_lm, batch 495 (42284): perplexity: 55.7816, toronto_lm_loss: 4.0214 ||
04/20 12:17:24 AM: Update 42508: task wsj, batch 3 (214): perplexity: 194.1287, wsj_loss: 5.2685 ||
04/20 12:17:26 AM: Update 42510: task toronto_lm, batch 507 (42296): perplexity: 55.5553, toronto_lm_loss: 4.0174 ||
04/20 12:17:36 AM: Update 42523: task toronto_lm, batch 520 (42309): perplexity: 55.3712, toronto_lm_loss: 4.0141 ||
04/20 12:17:46 AM: Update 42536: task toronto_lm, batch 533 (42322): perplexity: 55.2308, toronto_lm_loss: 4.0115 ||
04/20 12:17:57 AM: Update 42550: task toronto_lm, batch 547 (42336): perplexity: 55.0535, toronto_lm_loss: 4.0083 ||
04/20 12:18:07 AM: Update 42563: task toronto_lm, batch 560 (42349): perplexity: 54.8991, toronto_lm_loss: 4.0055 ||
04/20 12:18:17 AM: Update 42576: task toronto_lm, batch 573 (42362): perplexity: 54.7063, toronto_lm_loss: 4.0020 ||
04/20 12:18:27 AM: Update 42589: task toronto_lm, batch 586 (42375): perplexity: 54.6151, toronto_lm_loss: 4.0003 ||
04/20 12:18:37 AM: Update 42602: task toronto_lm, batch 599 (42388): perplexity: 54.5083, toronto_lm_loss: 3.9984 ||
04/20 12:18:47 AM: Update 42616: task toronto_lm, batch 613 (42402): perplexity: 54.3411, toronto_lm_loss: 3.9953 ||
04/20 12:18:57 AM: Update 42629: task toronto_lm, batch 626 (42415): perplexity: 54.2172, toronto_lm_loss: 3.9930 ||
04/20 12:19:07 AM: Update 42642: task toronto_lm, batch 639 (42428): perplexity: 54.0411, toronto_lm_loss: 3.9897 ||
04/20 12:19:18 AM: Update 42656: task toronto_lm, batch 653 (42442): perplexity: 53.8973, toronto_lm_loss: 3.9871 ||
04/20 12:19:28 AM: Update 42669: task toronto_lm, batch 666 (42455): perplexity: 53.7752, toronto_lm_loss: 3.9848 ||
04/20 12:19:38 AM: Update 42682: task toronto_lm, batch 679 (42468): perplexity: 53.6358, toronto_lm_loss: 3.9822 ||
04/20 12:19:48 AM: Update 42695: task toronto_lm, batch 692 (42481): perplexity: 53.5254, toronto_lm_loss: 3.9802 ||
04/20 12:19:58 AM: Update 42708: task toronto_lm, batch 705 (42494): perplexity: 53.3769, toronto_lm_loss: 3.9774 ||
04/20 12:20:12 AM: Update 42715: task toronto_lm, batch 712 (42501): perplexity: 53.3467, toronto_lm_loss: 3.9768 ||
04/20 12:20:22 AM: Update 42728: task toronto_lm, batch 725 (42514): perplexity: 53.7524, toronto_lm_loss: 3.9844 ||
04/20 12:20:32 AM: Update 42741: task toronto_lm, batch 738 (42527): perplexity: 54.1340, toronto_lm_loss: 3.9915 ||
04/20 12:20:43 AM: Update 42755: task toronto_lm, batch 752 (42541): perplexity: 54.4984, toronto_lm_loss: 3.9982 ||
04/20 12:20:54 AM: Update 42769: task toronto_lm, batch 766 (42555): perplexity: 54.7964, toronto_lm_loss: 4.0036 ||
04/20 12:21:04 AM: Update 42782: task toronto_lm, batch 779 (42568): perplexity: 54.9989, toronto_lm_loss: 4.0073 ||
04/20 12:21:15 AM: Update 42796: task toronto_lm, batch 793 (42582): perplexity: 55.1816, toronto_lm_loss: 4.0106 ||
04/20 12:21:24 AM: Update 42808: task wsj, batch 4 (215): perplexity: 202.3349, wsj_loss: 5.3099 ||
04/20 12:21:25 AM: Update 42809: task toronto_lm, batch 805 (42594): perplexity: 55.3420, toronto_lm_loss: 4.0135 ||
04/20 12:21:35 AM: Update 42822: task toronto_lm, batch 818 (42607): perplexity: 55.4896, toronto_lm_loss: 4.0162 ||
04/20 12:21:45 AM: Update 42835: task toronto_lm, batch 831 (42620): perplexity: 55.6730, toronto_lm_loss: 4.0195 ||
04/20 12:21:55 AM: Update 42848: task toronto_lm, batch 844 (42633): perplexity: 55.8488, toronto_lm_loss: 4.0226 ||
04/20 12:22:05 AM: Update 42862: task toronto_lm, batch 858 (42647): perplexity: 55.9805, toronto_lm_loss: 4.0250 ||
04/20 12:22:16 AM: Update 42875: task toronto_lm, batch 871 (42660): perplexity: 56.1050, toronto_lm_loss: 4.0272 ||
04/20 12:22:26 AM: Update 42888: task toronto_lm, batch 884 (42673): perplexity: 56.2080, toronto_lm_loss: 4.0291 ||
04/20 12:22:36 AM: Update 42901: task toronto_lm, batch 897 (42686): perplexity: 56.2701, toronto_lm_loss: 4.0302 ||
04/20 12:22:46 AM: Update 42914: task toronto_lm, batch 910 (42699): perplexity: 56.3169, toronto_lm_loss: 4.0310 ||
04/20 12:22:56 AM: Update 42927: task toronto_lm, batch 923 (42712): perplexity: 56.4053, toronto_lm_loss: 4.0326 ||
04/20 12:23:06 AM: Update 42940: task toronto_lm, batch 936 (42725): perplexity: 56.4823, toronto_lm_loss: 4.0339 ||
04/20 12:23:16 AM: Update 42953: task toronto_lm, batch 949 (42738): perplexity: 56.5345, toronto_lm_loss: 4.0349 ||
04/20 12:23:26 AM: Update 42966: task toronto_lm, batch 962 (42751): perplexity: 56.6126, toronto_lm_loss: 4.0362 ||
04/20 12:23:37 AM: Update 42980: task toronto_lm, batch 976 (42765): perplexity: 56.6902, toronto_lm_loss: 4.0376 ||
04/20 12:23:47 AM: Update 42993: task toronto_lm, batch 989 (42778): perplexity: 56.7391, toronto_lm_loss: 4.0385 ||
04/20 12:23:52 AM: ***** Pass 43000 / Epoch 43 *****
04/20 12:23:52 AM: toronto_lm: trained on 996 batches, 0.005 epochs
04/20 12:23:52 AM: wsj: trained on 4 batches, 0.005 epochs
04/20 12:23:52 AM: Validating...
04/20 12:23:57 AM: Batch 18/140: perplexity: 89.3793, toronto_lm_loss: 4.4929 || , for evaluation data
04/20 12:24:07 AM: Batch 56/140: perplexity: 87.7931, toronto_lm_loss: 4.4750 || , for evaluation data
04/20 12:24:17 AM: Batch 94/140: perplexity: 82.6299, toronto_lm_loss: 4.4144 || , for evaluation data
04/20 12:24:27 AM: Batch 132/140: perplexity: 76.6941, toronto_lm_loss: 4.3398 || , for evaluation data
04/20 12:24:29 AM: Batch 1/66: perplexity: 316.2971, wsj_loss: 5.7567 || , for evaluation data
04/20 12:24:39 AM: Batch 39/66: perplexity: 214.6285, wsj_loss: 5.3689 || , for evaluation data
04/20 12:24:47 AM: Advancing scheduler.
04/20 12:24:47 AM: 	Best macro_avg: 0.298
04/20 12:24:47 AM: 	# bad epochs: 2
04/20 12:24:47 AM: Statistic: toronto_lm_loss
04/20 12:24:47 AM: 	training: 4.038978
04/20 12:24:47 AM: 	validation: 4.326661
04/20 12:24:47 AM: Statistic: wsj_loss
04/20 12:24:47 AM: 	training: 5.309924
04/20 12:24:47 AM: 	validation: 5.336059
04/20 12:24:47 AM: Statistic: macro_avg
04/20 12:24:47 AM: 	validation: 0.258924
04/20 12:24:47 AM: Statistic: micro_avg
04/20 12:24:47 AM: 	validation: 0.054247
04/20 12:24:47 AM: Statistic: toronto_lm_perplexity
04/20 12:24:47 AM: 	training: 56.768287
04/20 12:24:47 AM: 	validation: 75.691107
04/20 12:24:47 AM: Statistic: wsj_perplexity
04/20 12:24:47 AM: 	training: 202.334948
04/20 12:24:47 AM: 	validation: 207.692514
04/20 12:24:47 AM: global_lr: 0.001000
04/20 12:24:47 AM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/20 12:24:48 AM: Update 43001: task toronto_lm, batch 1 (42786): perplexity: 69.9687, toronto_lm_loss: 4.2480 ||
04/20 12:24:58 AM: Update 43014: task toronto_lm, batch 14 (42799): perplexity: 62.7663, toronto_lm_loss: 4.1394 ||
04/20 12:25:08 AM: Update 43027: task toronto_lm, batch 27 (42812): perplexity: 60.4229, toronto_lm_loss: 4.1014 ||
04/20 12:25:19 AM: Update 43041: task toronto_lm, batch 41 (42826): perplexity: 60.4450, toronto_lm_loss: 4.1017 ||
04/20 12:25:29 AM: Update 43054: task toronto_lm, batch 54 (42839): perplexity: 61.0138, toronto_lm_loss: 4.1111 ||
04/20 12:25:39 AM: Update 43067: task toronto_lm, batch 67 (42852): perplexity: 60.3422, toronto_lm_loss: 4.1000 ||
04/20 12:25:49 AM: Update 43080: task toronto_lm, batch 80 (42865): perplexity: 60.2175, toronto_lm_loss: 4.0980 ||
04/20 12:25:59 AM: Update 43093: task toronto_lm, batch 93 (42878): perplexity: 59.8920, toronto_lm_loss: 4.0925 ||
04/20 12:26:09 AM: Update 43107: task toronto_lm, batch 107 (42892): perplexity: 59.8652, toronto_lm_loss: 4.0921 ||
04/20 12:26:20 AM: Update 43120: task toronto_lm, batch 120 (42905): perplexity: 60.2877, toronto_lm_loss: 4.0991 ||
04/20 12:26:30 AM: Update 43133: task toronto_lm, batch 133 (42918): perplexity: 60.0480, toronto_lm_loss: 4.0951 ||
04/20 12:26:40 AM: Update 43146: task toronto_lm, batch 146 (42931): perplexity: 59.8994, toronto_lm_loss: 4.0927 ||
04/20 12:26:50 AM: Update 43159: task toronto_lm, batch 159 (42944): perplexity: 59.9511, toronto_lm_loss: 4.0935 ||
04/20 12:27:00 AM: Update 43172: task toronto_lm, batch 172 (42957): perplexity: 59.7868, toronto_lm_loss: 4.0908 ||
04/20 12:27:10 AM: Update 43185: task toronto_lm, batch 185 (42970): perplexity: 59.7636, toronto_lm_loss: 4.0904 ||
04/20 12:27:20 AM: Update 43198: task toronto_lm, batch 198 (42983): perplexity: 59.5234, toronto_lm_loss: 4.0864 ||
04/20 12:27:31 AM: Update 43212: task toronto_lm, batch 212 (42997): perplexity: 59.6924, toronto_lm_loss: 4.0892 ||
04/20 12:27:32 AM: Update 43214: task wsj, batch 1 (216): perplexity: 145.3551, wsj_loss: 4.9792 ||
04/20 12:27:41 AM: Update 43225: task toronto_lm, batch 224 (43009): perplexity: 59.5452, toronto_lm_loss: 4.0867 ||
04/20 12:27:52 AM: Update 43239: task toronto_lm, batch 238 (43023): perplexity: 59.3324, toronto_lm_loss: 4.0832 ||
04/20 12:28:02 AM: Update 43253: task toronto_lm, batch 252 (43037): perplexity: 59.2679, toronto_lm_loss: 4.0821 ||
04/20 12:28:12 AM: Update 43266: task toronto_lm, batch 265 (43050): perplexity: 59.2435, toronto_lm_loss: 4.0817 ||
04/20 12:28:22 AM: Update 43279: task toronto_lm, batch 278 (43063): perplexity: 59.3373, toronto_lm_loss: 4.0832 ||
04/20 12:28:33 AM: Update 43292: task toronto_lm, batch 291 (43076): perplexity: 59.2580, toronto_lm_loss: 4.0819 ||
04/20 12:28:43 AM: Update 43305: task toronto_lm, batch 304 (43089): perplexity: 59.2798, toronto_lm_loss: 4.0823 ||
04/20 12:28:52 AM: Update 43318: task wsj, batch 2 (217): perplexity: 185.4063, wsj_loss: 5.2225 ||
04/20 12:28:53 AM: Update 43319: task toronto_lm, batch 317 (43102): perplexity: 59.1085, toronto_lm_loss: 4.0794 ||
04/20 12:29:04 AM: Update 43333: task toronto_lm, batch 331 (43116): perplexity: 59.0210, toronto_lm_loss: 4.0779 ||
04/20 12:29:20 AM: Update 43343: task toronto_lm, batch 341 (43126): perplexity: 58.9707, toronto_lm_loss: 4.0770 ||
04/20 12:29:30 AM: Update 43356: task toronto_lm, batch 354 (43139): perplexity: 59.9257, toronto_lm_loss: 4.0931 ||
04/20 12:29:39 AM: Update 43367: task wsj, batch 3 (218): perplexity: 186.3643, wsj_loss: 5.2277 ||
04/20 12:29:40 AM: Update 43369: task toronto_lm, batch 366 (43151): perplexity: 60.8050, toronto_lm_loss: 4.1077 ||
04/20 12:29:51 AM: Update 43383: task toronto_lm, batch 380 (43165): perplexity: 61.5417, toronto_lm_loss: 4.1197 ||
04/20 12:30:01 AM: Update 43396: task toronto_lm, batch 393 (43178): perplexity: 62.1826, toronto_lm_loss: 4.1301 ||
04/20 12:30:12 AM: Update 43410: task toronto_lm, batch 407 (43192): perplexity: 62.8528, toronto_lm_loss: 4.1408 ||
04/20 12:30:22 AM: Update 43423: task toronto_lm, batch 420 (43205): perplexity: 63.4133, toronto_lm_loss: 4.1497 ||
04/20 12:30:32 AM: Update 43436: task toronto_lm, batch 433 (43218): perplexity: 63.9005, toronto_lm_loss: 4.1573 ||
04/20 12:30:43 AM: Update 43450: task toronto_lm, batch 447 (43232): perplexity: 64.3573, toronto_lm_loss: 4.1645 ||
04/20 12:30:53 AM: Update 43464: task toronto_lm, batch 461 (43246): perplexity: 64.7815, toronto_lm_loss: 4.1710 ||
04/20 12:31:03 AM: Update 43477: task toronto_lm, batch 474 (43259): perplexity: 65.1708, toronto_lm_loss: 4.1770 ||
04/20 12:31:13 AM: Update 43490: task toronto_lm, batch 487 (43272): perplexity: 65.5105, toronto_lm_loss: 4.1822 ||
04/20 12:31:23 AM: Update 43503: task toronto_lm, batch 500 (43285): perplexity: 65.7831, toronto_lm_loss: 4.1864 ||
04/20 12:31:30 AM: Update 43511: task wsj, batch 4 (219): perplexity: 183.3322, wsj_loss: 5.2113 ||
04/20 12:31:33 AM: Update 43516: task toronto_lm, batch 512 (43297): perplexity: 66.0440, toronto_lm_loss: 4.1903 ||
04/20 12:31:43 AM: Update 43529: task toronto_lm, batch 525 (43310): perplexity: 66.3276, toronto_lm_loss: 4.1946 ||
04/20 12:31:54 AM: Update 43543: task toronto_lm, batch 539 (43324): perplexity: 66.5894, toronto_lm_loss: 4.1985 ||
04/20 12:32:04 AM: Update 43556: task toronto_lm, batch 552 (43337): perplexity: 66.7915, toronto_lm_loss: 4.2016 ||
04/20 12:32:14 AM: Update 43569: task toronto_lm, batch 565 (43350): perplexity: 66.9143, toronto_lm_loss: 4.2034 ||
04/20 12:32:24 AM: Update 43582: task toronto_lm, batch 578 (43363): perplexity: 67.0980, toronto_lm_loss: 4.2062 ||
04/20 12:32:34 AM: Update 43595: task toronto_lm, batch 591 (43376): perplexity: 67.2267, toronto_lm_loss: 4.2081 ||
04/20 12:32:42 AM: Update 43605: task wsj, batch 5 (220): perplexity: 185.4082, wsj_loss: 5.2226 ||
04/20 12:32:44 AM: Update 43608: task toronto_lm, batch 603 (43388): perplexity: 67.4081, toronto_lm_loss: 4.2108 ||
04/20 12:32:55 AM: Update 43621: task toronto_lm, batch 616 (43401): perplexity: 67.6271, toronto_lm_loss: 4.2140 ||
04/20 12:33:05 AM: Update 43635: task toronto_lm, batch 630 (43415): perplexity: 67.7864, toronto_lm_loss: 4.2164 ||
04/20 12:33:16 AM: Update 43649: task toronto_lm, batch 644 (43429): perplexity: 67.8427, toronto_lm_loss: 4.2172 ||
04/20 12:33:27 AM: Update 43663: task toronto_lm, batch 658 (43443): perplexity: 68.0054, toronto_lm_loss: 4.2196 ||
04/20 12:33:37 AM: Update 43676: task toronto_lm, batch 671 (43456): perplexity: 68.1494, toronto_lm_loss: 4.2217 ||
04/20 12:33:47 AM: Update 43689: task toronto_lm, batch 684 (43469): perplexity: 68.2497, toronto_lm_loss: 4.2232 ||
04/20 12:33:53 AM: Update 43697: task wsj, batch 6 (221): perplexity: 184.7498, wsj_loss: 5.2190 ||
04/20 12:33:58 AM: Update 43703: task toronto_lm, batch 697 (43482): perplexity: 68.2877, toronto_lm_loss: 4.2237 ||
04/20 12:34:08 AM: Update 43717: task toronto_lm, batch 711 (43496): perplexity: 68.4443, toronto_lm_loss: 4.2260 ||
04/20 12:34:14 AM: Update 43725: task wsj, batch 7 (222): perplexity: 183.7278, wsj_loss: 5.2135 ||
04/20 12:34:18 AM: Update 43730: task toronto_lm, batch 723 (43508): perplexity: 68.5363, toronto_lm_loss: 4.2274 ||
04/20 12:34:28 AM: Update 43743: task toronto_lm, batch 736 (43521): perplexity: 68.5800, toronto_lm_loss: 4.2280 ||
04/20 12:34:39 AM: Update 43757: task toronto_lm, batch 750 (43535): perplexity: 68.6475, toronto_lm_loss: 4.2290 ||
04/20 12:34:50 AM: Update 43771: task toronto_lm, batch 764 (43549): perplexity: 68.7266, toronto_lm_loss: 4.2301 ||
04/20 12:35:01 AM: Update 43785: task toronto_lm, batch 778 (43563): perplexity: 68.7787, toronto_lm_loss: 4.2309 ||
04/20 12:35:11 AM: Update 43798: task toronto_lm, batch 791 (43576): perplexity: 68.8132, toronto_lm_loss: 4.2314 ||
04/20 12:35:21 AM: Update 43811: task toronto_lm, batch 804 (43589): perplexity: 68.7830, toronto_lm_loss: 4.2310 ||
04/20 12:35:31 AM: Update 43824: task toronto_lm, batch 817 (43602): perplexity: 68.8118, toronto_lm_loss: 4.2314 ||
04/20 12:35:41 AM: Update 43837: task toronto_lm, batch 830 (43615): perplexity: 68.8549, toronto_lm_loss: 4.2320 ||
04/20 12:35:51 AM: Update 43850: task toronto_lm, batch 843 (43628): perplexity: 68.9081, toronto_lm_loss: 4.2328 ||
04/20 12:36:01 AM: Update 43864: task toronto_lm, batch 857 (43642): perplexity: 68.9621, toronto_lm_loss: 4.2336 ||
04/20 12:36:12 AM: Update 43878: task toronto_lm, batch 871 (43656): perplexity: 68.9169, toronto_lm_loss: 4.2329 ||
04/20 12:36:23 AM: Update 43892: task toronto_lm, batch 885 (43670): perplexity: 68.9633, toronto_lm_loss: 4.2336 ||
04/20 12:36:34 AM: Update 43906: task toronto_lm, batch 899 (43684): perplexity: 68.9434, toronto_lm_loss: 4.2333 ||
04/20 12:36:44 AM: Update 43919: task toronto_lm, batch 912 (43697): perplexity: 68.9935, toronto_lm_loss: 4.2340 ||
04/20 12:36:55 AM: Update 43933: task toronto_lm, batch 926 (43711): perplexity: 69.0476, toronto_lm_loss: 4.2348 ||
04/20 12:37:05 AM: Update 43947: task toronto_lm, batch 940 (43725): perplexity: 69.0278, toronto_lm_loss: 4.2345 ||
04/20 12:37:15 AM: Update 43960: task toronto_lm, batch 953 (43738): perplexity: 69.0258, toronto_lm_loss: 4.2345 ||
04/20 12:37:33 AM: Update 43973: task toronto_lm, batch 966 (43751): perplexity: 69.0469, toronto_lm_loss: 4.2348 ||
04/20 12:37:43 AM: Update 43986: task toronto_lm, batch 979 (43764): perplexity: 69.1842, toronto_lm_loss: 4.2368 ||
04/20 12:37:53 AM: Update 43999: task toronto_lm, batch 992 (43777): perplexity: 69.3085, toronto_lm_loss: 4.2386 ||
04/20 12:37:53 AM: ***** Pass 44000 / Epoch 44 *****
04/20 12:37:53 AM: toronto_lm: trained on 993 batches, 0.005 epochs
04/20 12:37:53 AM: wsj: trained on 7 batches, 0.008 epochs
04/20 12:37:53 AM: Validating...
04/20 12:38:03 AM: Batch 36/140: perplexity: 80.9414, toronto_lm_loss: 4.3937 || , for evaluation data
04/20 12:38:13 AM: Batch 75/140: perplexity: 82.9395, toronto_lm_loss: 4.4181 || , for evaluation data
04/20 12:38:24 AM: Batch 112/140: perplexity: 77.2529, toronto_lm_loss: 4.3471 || , for evaluation data
04/20 12:38:31 AM: Batch 1/66: perplexity: 309.5158, wsj_loss: 5.7350 || , for evaluation data
04/20 12:38:42 AM: Batch 40/66: perplexity: 204.5689, wsj_loss: 5.3209 || , for evaluation data
04/20 12:38:48 AM: Advancing scheduler.
04/20 12:38:48 AM: 	Best macro_avg: 0.298
04/20 12:38:48 AM: 	# bad epochs: 3
04/20 12:38:48 AM: Statistic: toronto_lm_loss
04/20 12:38:48 AM: 	training: 4.238739
04/20 12:38:48 AM: 	validation: 4.296097
04/20 12:38:48 AM: Statistic: wsj_loss
04/20 12:38:48 AM: 	training: 5.213455
04/20 12:38:48 AM: 	validation: 5.304835
04/20 12:38:48 AM: Statistic: macro_avg
04/20 12:38:48 AM: 	validation: 0.273972
04/20 12:38:48 AM: Statistic: micro_avg
04/20 12:38:48 AM: 	validation: 0.062433
04/20 12:38:48 AM: Statistic: toronto_lm_perplexity
04/20 12:38:48 AM: 	training: 69.320357
04/20 12:38:48 AM: 	validation: 73.412704
04/20 12:38:48 AM: Statistic: wsj_perplexity
04/20 12:38:48 AM: 	training: 183.727804
04/20 12:38:48 AM: 	validation: 201.307858
04/20 12:38:48 AM: global_lr: 0.001000
04/20 12:38:49 AM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/20 12:38:49 AM: Update 44001: task toronto_lm, batch 1 (43779): perplexity: 82.2648, toronto_lm_loss: 4.4099 ||
04/20 12:38:59 AM: Update 44014: task toronto_lm, batch 14 (43792): perplexity: 78.5378, toronto_lm_loss: 4.3636 ||
04/20 12:39:09 AM: Update 44027: task toronto_lm, batch 27 (43805): perplexity: 75.3431, toronto_lm_loss: 4.3221 ||
04/20 12:39:20 AM: Update 44040: task toronto_lm, batch 40 (43818): perplexity: 72.7110, toronto_lm_loss: 4.2865 ||
04/20 12:39:30 AM: Update 44053: task toronto_lm, batch 53 (43831): perplexity: 72.3096, toronto_lm_loss: 4.2810 ||
04/20 12:39:40 AM: Update 44066: task toronto_lm, batch 66 (43844): perplexity: 72.7231, toronto_lm_loss: 4.2867 ||
04/20 12:39:50 AM: Update 44079: task toronto_lm, batch 79 (43857): perplexity: 72.0561, toronto_lm_loss: 4.2774 ||
04/20 12:40:00 AM: Update 44092: task toronto_lm, batch 92 (43870): perplexity: 71.4729, toronto_lm_loss: 4.2693 ||
04/20 12:40:10 AM: Update 44106: task toronto_lm, batch 106 (43884): perplexity: 71.2005, toronto_lm_loss: 4.2655 ||
04/20 12:40:21 AM: Update 44120: task toronto_lm, batch 120 (43898): perplexity: 70.8359, toronto_lm_loss: 4.2604 ||
04/20 12:40:31 AM: Update 44133: task toronto_lm, batch 133 (43911): perplexity: 70.7349, toronto_lm_loss: 4.2589 ||
04/20 12:40:41 AM: Update 44146: task toronto_lm, batch 146 (43924): perplexity: 70.7316, toronto_lm_loss: 4.2589 ||
04/20 12:40:52 AM: Update 44160: task toronto_lm, batch 160 (43938): perplexity: 70.7258, toronto_lm_loss: 4.2588 ||
04/20 12:40:53 AM: Update 44162: task wsj, batch 1 (223): perplexity: 222.9604, wsj_loss: 5.4070 ||
04/20 12:41:03 AM: Update 44174: task toronto_lm, batch 173 (43951): perplexity: 70.4502, toronto_lm_loss: 4.2549 ||
04/20 12:41:13 AM: Update 44187: task toronto_lm, batch 186 (43964): perplexity: 70.2944, toronto_lm_loss: 4.2527 ||
04/20 12:41:23 AM: Update 44200: task toronto_lm, batch 199 (43977): perplexity: 70.2431, toronto_lm_loss: 4.2520 ||
04/20 12:41:33 AM: Update 44213: task toronto_lm, batch 212 (43990): perplexity: 70.1148, toronto_lm_loss: 4.2501 ||
04/20 12:41:43 AM: Update 44226: task toronto_lm, batch 225 (44003): perplexity: 70.0075, toronto_lm_loss: 4.2486 ||
04/20 12:41:53 AM: Update 44239: task toronto_lm, batch 238 (44016): perplexity: 69.7474, toronto_lm_loss: 4.2449 ||
04/20 12:41:58 AM: Update 44246: task wsj, batch 2 (224): perplexity: 230.5807, wsj_loss: 5.4406 ||
04/20 12:42:04 AM: Update 44253: task toronto_lm, batch 251 (44029): perplexity: 69.9293, toronto_lm_loss: 4.2475 ||
04/20 12:42:15 AM: Update 44267: task toronto_lm, batch 265 (44043): perplexity: 69.6926, toronto_lm_loss: 4.2441 ||
04/20 12:42:25 AM: Update 44280: task toronto_lm, batch 278 (44056): perplexity: 69.4793, toronto_lm_loss: 4.2410 ||
04/20 12:42:32 AM: Update 44290: task wsj, batch 3 (225): perplexity: 228.2093, wsj_loss: 5.4303 ||
04/20 12:42:35 AM: Update 44294: task toronto_lm, batch 291 (44069): perplexity: 69.4057, toronto_lm_loss: 4.2400 ||
04/20 12:42:46 AM: Update 44308: task toronto_lm, batch 305 (44083): perplexity: 69.3968, toronto_lm_loss: 4.2398 ||
04/20 12:42:57 AM: Update 44322: task toronto_lm, batch 319 (44097): perplexity: 69.1155, toronto_lm_loss: 4.2358 ||
04/20 12:43:08 AM: Update 44336: task toronto_lm, batch 333 (44111): perplexity: 68.9928, toronto_lm_loss: 4.2340 ||
04/20 12:43:18 AM: Update 44350: task toronto_lm, batch 347 (44125): perplexity: 69.0015, toronto_lm_loss: 4.2341 ||
04/20 12:43:29 AM: Update 44364: task toronto_lm, batch 361 (44139): perplexity: 68.8537, toronto_lm_loss: 4.2320 ||
04/20 12:43:40 AM: Update 44378: task toronto_lm, batch 375 (44153): perplexity: 68.7536, toronto_lm_loss: 4.2305 ||
04/20 12:43:50 AM: Update 44392: task toronto_lm, batch 389 (44167): perplexity: 68.6593, toronto_lm_loss: 4.2292 ||
04/20 12:44:01 AM: Update 44406: task toronto_lm, batch 403 (44181): perplexity: 68.5275, toronto_lm_loss: 4.2272 ||
04/20 12:44:10 AM: Update 44418: task wsj, batch 4 (226): perplexity: 226.1767, wsj_loss: 5.4213 ||
04/20 12:44:12 AM: Update 44420: task toronto_lm, batch 416 (44194): perplexity: 68.3242, toronto_lm_loss: 4.2243 ||
04/20 12:44:23 AM: Update 44434: task toronto_lm, batch 430 (44208): perplexity: 68.2211, toronto_lm_loss: 4.2228 ||
04/20 12:44:33 AM: Update 44448: task toronto_lm, batch 444 (44222): perplexity: 67.9979, toronto_lm_loss: 4.2195 ||
04/20 12:44:44 AM: Update 44462: task toronto_lm, batch 458 (44236): perplexity: 67.7570, toronto_lm_loss: 4.2159 ||
04/20 12:44:55 AM: Update 44476: task toronto_lm, batch 472 (44250): perplexity: 67.6210, toronto_lm_loss: 4.2139 ||
04/20 12:45:05 AM: Update 44489: task toronto_lm, batch 485 (44263): perplexity: 67.5736, toronto_lm_loss: 4.2132 ||
04/20 12:45:15 AM: Update 44502: task toronto_lm, batch 498 (44276): perplexity: 67.4376, toronto_lm_loss: 4.2112 ||
04/20 12:45:25 AM: Update 44516: task toronto_lm, batch 512 (44290): perplexity: 67.3422, toronto_lm_loss: 4.2098 ||
04/20 12:45:36 AM: Update 44529: task toronto_lm, batch 525 (44303): perplexity: 67.1480, toronto_lm_loss: 4.2069 ||
04/20 12:45:46 AM: Update 44543: task toronto_lm, batch 539 (44317): perplexity: 67.1553, toronto_lm_loss: 4.2070 ||
04/20 12:45:57 AM: Update 44557: task toronto_lm, batch 553 (44331): perplexity: 67.0868, toronto_lm_loss: 4.2060 ||
04/20 12:46:07 AM: Update 44570: task toronto_lm, batch 566 (44344): perplexity: 67.0424, toronto_lm_loss: 4.2053 ||
04/20 12:46:17 AM: Update 44583: task toronto_lm, batch 579 (44357): perplexity: 67.0602, toronto_lm_loss: 4.2056 ||
04/20 12:46:27 AM: Update 44596: task toronto_lm, batch 592 (44370): perplexity: 66.9840, toronto_lm_loss: 4.2045 ||
04/20 12:46:40 AM: Update 44602: task toronto_lm, batch 598 (44376): perplexity: 66.9583, toronto_lm_loss: 4.2041 ||
04/20 12:46:50 AM: Update 44615: task toronto_lm, batch 611 (44389): perplexity: 67.3070, toronto_lm_loss: 4.2093 ||
04/20 12:47:00 AM: Update 44628: task toronto_lm, batch 624 (44402): perplexity: 67.5443, toronto_lm_loss: 4.2128 ||
04/20 12:47:11 AM: Update 44642: task toronto_lm, batch 638 (44416): perplexity: 67.7261, toronto_lm_loss: 4.2155 ||
04/20 12:47:14 AM: Update 44646: task wsj, batch 5 (227): perplexity: 219.1976, wsj_loss: 5.3900 ||
04/20 12:47:22 AM: Update 44656: task toronto_lm, batch 651 (44429): perplexity: 67.9033, toronto_lm_loss: 4.2181 ||
04/20 12:47:32 AM: Update 44669: task toronto_lm, batch 664 (44442): perplexity: 68.0383, toronto_lm_loss: 4.2201 ||
04/20 12:47:33 AM: Update 44670: task wsj, batch 6 (228): perplexity: 230.2319, wsj_loss: 5.4391 ||
04/20 12:47:42 AM: Update 44682: task toronto_lm, batch 676 (44454): perplexity: 68.1729, toronto_lm_loss: 4.2220 ||
04/20 12:47:52 AM: Update 44695: task toronto_lm, batch 689 (44467): perplexity: 68.3001, toronto_lm_loss: 4.2239 ||
04/20 12:48:03 AM: Update 44709: task toronto_lm, batch 703 (44481): perplexity: 68.3121, toronto_lm_loss: 4.2241 ||
04/20 12:48:13 AM: Update 44722: task toronto_lm, batch 716 (44494): perplexity: 68.2540, toronto_lm_loss: 4.2232 ||
04/20 12:48:23 AM: Update 44735: task toronto_lm, batch 729 (44507): perplexity: 68.3137, toronto_lm_loss: 4.2241 ||
04/20 12:48:34 AM: Update 44749: task toronto_lm, batch 743 (44521): perplexity: 68.3263, toronto_lm_loss: 4.2243 ||
04/20 12:48:44 AM: Update 44763: task toronto_lm, batch 757 (44535): perplexity: 68.3125, toronto_lm_loss: 4.2241 ||
04/20 12:48:55 AM: Update 44776: task toronto_lm, batch 770 (44548): perplexity: 68.2485, toronto_lm_loss: 4.2232 ||
04/20 12:49:05 AM: Update 44789: task toronto_lm, batch 783 (44561): perplexity: 68.2835, toronto_lm_loss: 4.2237 ||
04/20 12:49:07 AM: Update 44792: task wsj, batch 7 (229): perplexity: 229.2443, wsj_loss: 5.4348 ||
04/20 12:49:15 AM: Update 44802: task toronto_lm, batch 795 (44573): perplexity: 68.2398, toronto_lm_loss: 4.2230 ||
04/20 12:49:25 AM: Update 44815: task toronto_lm, batch 808 (44586): perplexity: 68.1422, toronto_lm_loss: 4.2216 ||
04/20 12:49:35 AM: Update 44828: task toronto_lm, batch 821 (44599): perplexity: 68.1340, toronto_lm_loss: 4.2215 ||
04/20 12:49:45 AM: Update 44842: task toronto_lm, batch 835 (44613): perplexity: 68.0702, toronto_lm_loss: 4.2205 ||
04/20 12:49:55 AM: Update 44855: task toronto_lm, batch 848 (44626): perplexity: 68.0392, toronto_lm_loss: 4.2201 ||
04/20 12:50:05 AM: Update 44868: task toronto_lm, batch 861 (44639): perplexity: 68.0186, toronto_lm_loss: 4.2198 ||
04/20 12:50:16 AM: Update 44881: task toronto_lm, batch 874 (44652): perplexity: 68.0070, toronto_lm_loss: 4.2196 ||
04/20 12:50:26 AM: Update 44894: task toronto_lm, batch 887 (44665): perplexity: 67.9034, toronto_lm_loss: 4.2181 ||
04/20 12:50:36 AM: Update 44907: task toronto_lm, batch 900 (44678): perplexity: 67.8152, toronto_lm_loss: 4.2168 ||
04/20 12:50:46 AM: Update 44920: task toronto_lm, batch 913 (44691): perplexity: 67.7492, toronto_lm_loss: 4.2158 ||
04/20 12:50:56 AM: Update 44933: task toronto_lm, batch 926 (44704): perplexity: 67.6854, toronto_lm_loss: 4.2149 ||
04/20 12:51:06 AM: Update 44946: task toronto_lm, batch 939 (44717): perplexity: 67.6869, toronto_lm_loss: 4.2149 ||
04/20 12:51:16 AM: Update 44959: task toronto_lm, batch 952 (44730): perplexity: 67.6008, toronto_lm_loss: 4.2136 ||
04/20 12:51:26 AM: Update 44972: task toronto_lm, batch 965 (44743): perplexity: 67.5370, toronto_lm_loss: 4.2127 ||
04/20 12:51:36 AM: Update 44985: task toronto_lm, batch 978 (44756): perplexity: 67.4714, toronto_lm_loss: 4.2117 ||
04/20 12:51:47 AM: Update 44999: task toronto_lm, batch 992 (44770): perplexity: 67.4715, toronto_lm_loss: 4.2117 ||
04/20 12:51:48 AM: ***** Pass 45000 / Epoch 45 *****
04/20 12:51:48 AM: toronto_lm: trained on 993 batches, 0.005 epochs
04/20 12:51:48 AM: wsj: trained on 7 batches, 0.008 epochs
04/20 12:51:48 AM: Validating...
04/20 12:51:57 AM: Batch 36/140: perplexity: 81.9386, toronto_lm_loss: 4.4060 || , for evaluation data
04/20 12:52:07 AM: Batch 74/140: perplexity: 83.5430, toronto_lm_loss: 4.4254 || , for evaluation data
04/20 12:52:17 AM: Batch 112/140: perplexity: 77.4298, toronto_lm_loss: 4.3494 || , for evaluation data
04/20 12:52:25 AM: Batch 1/66: perplexity: 301.2278, wsj_loss: 5.7079 || , for evaluation data
04/20 12:52:35 AM: Batch 39/66: perplexity: 205.5606, wsj_loss: 5.3257 || , for evaluation data
04/20 12:52:42 AM: Advancing scheduler.
04/20 12:52:42 AM: 	Best macro_avg: 0.298
04/20 12:52:42 AM: 	# bad epochs: 4
04/20 12:52:42 AM: Statistic: toronto_lm_loss
04/20 12:52:42 AM: 	training: 4.211231
04/20 12:52:42 AM: 	validation: 4.293152
04/20 12:52:42 AM: Statistic: wsj_loss
04/20 12:52:42 AM: 	training: 5.434788
04/20 12:52:42 AM: 	validation: 5.295493
04/20 12:52:42 AM: Statistic: macro_avg
04/20 12:52:42 AM: 	validation: 0.277931
04/20 12:52:42 AM: Statistic: micro_avg
04/20 12:52:42 AM: 	validation: 0.064833
04/20 12:52:42 AM: Statistic: toronto_lm_perplexity
04/20 12:52:42 AM: 	training: 67.439479
04/20 12:52:42 AM: 	validation: 73.196838
04/20 12:52:42 AM: Statistic: wsj_perplexity
04/20 12:52:42 AM: 	training: 229.244295
04/20 12:52:42 AM: 	validation: 199.435956
04/20 12:52:42 AM: global_lr: 0.001000
04/20 12:52:42 AM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/20 12:52:43 AM: Update 45001: task toronto_lm, batch 1 (44772): perplexity: 54.1017, toronto_lm_loss: 3.9909 ||
04/20 12:52:53 AM: Update 45014: task toronto_lm, batch 14 (44785): perplexity: 59.8578, toronto_lm_loss: 4.0920 ||
04/20 12:53:04 AM: Update 45028: task toronto_lm, batch 28 (44799): perplexity: 60.7655, toronto_lm_loss: 4.1070 ||
04/20 12:53:14 AM: Update 45041: task toronto_lm, batch 41 (44812): perplexity: 62.0170, toronto_lm_loss: 4.1274 ||
04/20 12:53:24 AM: Update 45054: task wsj, batch 1 (230): perplexity: 170.3327, wsj_loss: 5.1378 ||
04/20 12:53:25 AM: Update 45055: task toronto_lm, batch 54 (44825): perplexity: 62.1539, toronto_lm_loss: 4.1296 ||
04/20 12:53:35 AM: Update 45069: task toronto_lm, batch 68 (44839): perplexity: 62.2839, toronto_lm_loss: 4.1317 ||
04/20 12:53:46 AM: Update 45083: task toronto_lm, batch 82 (44853): perplexity: 61.8803, toronto_lm_loss: 4.1252 ||
04/20 12:53:56 AM: Update 45096: task toronto_lm, batch 95 (44866): perplexity: 61.6669, toronto_lm_loss: 4.1217 ||
04/20 12:54:06 AM: Update 45109: task toronto_lm, batch 108 (44879): perplexity: 61.0543, toronto_lm_loss: 4.1118 ||
04/20 12:54:16 AM: Update 45122: task toronto_lm, batch 121 (44892): perplexity: 60.9244, toronto_lm_loss: 4.1096 ||
04/20 12:54:27 AM: Update 45135: task toronto_lm, batch 134 (44905): perplexity: 60.8921, toronto_lm_loss: 4.1091 ||
04/20 12:54:37 AM: Update 45148: task toronto_lm, batch 147 (44918): perplexity: 61.1121, toronto_lm_loss: 4.1127 ||
04/20 12:54:47 AM: Update 45161: task toronto_lm, batch 160 (44931): perplexity: 60.8765, toronto_lm_loss: 4.1088 ||
04/20 12:54:57 AM: Update 45174: task toronto_lm, batch 173 (44944): perplexity: 60.9760, toronto_lm_loss: 4.1105 ||
04/20 12:55:07 AM: Update 45187: task toronto_lm, batch 186 (44957): perplexity: 61.0306, toronto_lm_loss: 4.1114 ||
04/20 12:55:17 AM: Update 45200: task toronto_lm, batch 199 (44970): perplexity: 61.2322, toronto_lm_loss: 4.1147 ||
04/20 12:55:27 AM: Update 45213: task toronto_lm, batch 212 (44983): perplexity: 61.3011, toronto_lm_loss: 4.1158 ||
04/20 12:55:37 AM: Update 45226: task toronto_lm, batch 225 (44996): perplexity: 61.3644, toronto_lm_loss: 4.1168 ||
04/20 12:55:48 AM: Update 45231: task toronto_lm, batch 230 (45001): perplexity: 61.3161, toronto_lm_loss: 4.1160 ||
04/20 12:55:58 AM: Update 45244: task toronto_lm, batch 243 (45014): perplexity: 62.6046, toronto_lm_loss: 4.1368 ||
04/20 12:56:08 AM: Update 45257: task toronto_lm, batch 256 (45027): perplexity: 63.8655, toronto_lm_loss: 4.1568 ||
04/20 12:56:18 AM: Update 45270: task toronto_lm, batch 269 (45040): perplexity: 64.8658, toronto_lm_loss: 4.1723 ||
04/20 12:56:28 AM: Update 45283: task toronto_lm, batch 282 (45053): perplexity: 65.6896, toronto_lm_loss: 4.1849 ||
04/20 12:56:39 AM: Update 45296: task toronto_lm, batch 295 (45066): perplexity: 66.3856, toronto_lm_loss: 4.1955 ||
04/20 12:56:49 AM: Update 45309: task toronto_lm, batch 308 (45079): perplexity: 67.1486, toronto_lm_loss: 4.2069 ||
04/20 12:56:59 AM: Update 45322: task toronto_lm, batch 321 (45092): perplexity: 67.7589, toronto_lm_loss: 4.2160 ||
04/20 12:57:09 AM: Update 45335: task toronto_lm, batch 334 (45105): perplexity: 68.3610, toronto_lm_loss: 4.2248 ||
04/20 12:57:20 AM: Update 45349: task toronto_lm, batch 348 (45119): perplexity: 68.8706, toronto_lm_loss: 4.2322 ||
04/20 12:57:30 AM: Update 45363: task toronto_lm, batch 362 (45133): perplexity: 69.1643, toronto_lm_loss: 4.2365 ||
04/20 12:57:41 AM: Update 45377: task toronto_lm, batch 376 (45147): perplexity: 69.5423, toronto_lm_loss: 4.2419 ||
04/20 12:57:51 AM: Update 45390: task toronto_lm, batch 389 (45160): perplexity: 69.7713, toronto_lm_loss: 4.2452 ||
04/20 12:58:01 AM: Update 45403: task toronto_lm, batch 402 (45173): perplexity: 70.0377, toronto_lm_loss: 4.2490 ||
04/20 12:58:11 AM: Update 45416: task toronto_lm, batch 415 (45186): perplexity: 70.3888, toronto_lm_loss: 4.2540 ||
04/20 12:58:21 AM: Update 45429: task toronto_lm, batch 428 (45199): perplexity: 70.6028, toronto_lm_loss: 4.2571 ||
04/20 12:58:31 AM: Update 45442: task toronto_lm, batch 441 (45212): perplexity: 70.8458, toronto_lm_loss: 4.2605 ||
04/20 12:58:42 AM: Update 45456: task toronto_lm, batch 455 (45226): perplexity: 71.0478, toronto_lm_loss: 4.2634 ||
04/20 12:58:52 AM: Update 45469: task toronto_lm, batch 468 (45239): perplexity: 71.2714, toronto_lm_loss: 4.2665 ||
04/20 12:59:02 AM: Update 45482: task toronto_lm, batch 481 (45252): perplexity: 71.4207, toronto_lm_loss: 4.2686 ||
04/20 12:59:09 AM: Update 45491: task wsj, batch 2 (231): perplexity: 165.6961, wsj_loss: 5.1102 ||
04/20 12:59:13 AM: Update 45496: task toronto_lm, batch 494 (45265): perplexity: 71.6739, toronto_lm_loss: 4.2721 ||
04/20 12:59:23 AM: Update 45509: task toronto_lm, batch 507 (45278): perplexity: 71.7605, toronto_lm_loss: 4.2733 ||
04/20 12:59:33 AM: Update 45522: task toronto_lm, batch 520 (45291): perplexity: 71.8418, toronto_lm_loss: 4.2745 ||
04/20 12:59:43 AM: Update 45535: task toronto_lm, batch 533 (45304): perplexity: 71.8649, toronto_lm_loss: 4.2748 ||
04/20 12:59:53 AM: Update 45548: task toronto_lm, batch 546 (45317): perplexity: 72.0205, toronto_lm_loss: 4.2770 ||
04/20 01:00:02 AM: Update 45560: task wsj, batch 3 (232): perplexity: 181.1868, wsj_loss: 5.1995 ||
04/20 01:00:03 AM: Update 45561: task toronto_lm, batch 558 (45329): perplexity: 72.1045, toronto_lm_loss: 4.2781 ||
04/20 01:00:13 AM: Update 45574: task toronto_lm, batch 571 (45342): perplexity: 72.1797, toronto_lm_loss: 4.2792 ||
04/20 01:00:23 AM: Update 45587: task toronto_lm, batch 584 (45355): perplexity: 72.2090, toronto_lm_loss: 4.2796 ||
04/20 01:00:30 AM: Update 45596: task wsj, batch 4 (233): perplexity: 185.7497, wsj_loss: 5.2244 ||
04/20 01:00:33 AM: Update 45600: task toronto_lm, batch 596 (45367): perplexity: 72.2967, toronto_lm_loss: 4.2808 ||
04/20 01:00:44 AM: Update 45614: task toronto_lm, batch 610 (45381): perplexity: 72.4011, toronto_lm_loss: 4.2822 ||
04/20 01:00:54 AM: Update 45627: task toronto_lm, batch 623 (45394): perplexity: 72.3299, toronto_lm_loss: 4.2812 ||
04/20 01:01:04 AM: Update 45640: task toronto_lm, batch 636 (45407): perplexity: 72.4607, toronto_lm_loss: 4.2830 ||
04/20 01:01:15 AM: Update 45654: task toronto_lm, batch 650 (45421): perplexity: 72.5570, toronto_lm_loss: 4.2844 ||
04/20 01:01:25 AM: Update 45667: task toronto_lm, batch 663 (45434): perplexity: 72.5839, toronto_lm_loss: 4.2847 ||
04/20 01:01:35 AM: Update 45680: task toronto_lm, batch 676 (45447): perplexity: 72.6459, toronto_lm_loss: 4.2856 ||
04/20 01:01:45 AM: Update 45693: task toronto_lm, batch 689 (45460): perplexity: 72.5980, toronto_lm_loss: 4.2849 ||
04/20 01:01:55 AM: Update 45706: task toronto_lm, batch 702 (45473): perplexity: 72.5921, toronto_lm_loss: 4.2849 ||
04/20 01:02:06 AM: Update 45720: task toronto_lm, batch 716 (45487): perplexity: 72.6347, toronto_lm_loss: 4.2854 ||
04/20 01:02:17 AM: Update 45734: task toronto_lm, batch 730 (45501): perplexity: 72.5795, toronto_lm_loss: 4.2847 ||
04/20 01:02:27 AM: Update 45748: task toronto_lm, batch 744 (45515): perplexity: 72.5565, toronto_lm_loss: 4.2844 ||
04/20 01:02:38 AM: Update 45762: task toronto_lm, batch 758 (45529): perplexity: 72.6247, toronto_lm_loss: 4.2853 ||
04/20 01:02:49 AM: Update 45776: task toronto_lm, batch 772 (45543): perplexity: 72.6583, toronto_lm_loss: 4.2858 ||
04/20 01:02:59 AM: Update 45789: task toronto_lm, batch 785 (45556): perplexity: 72.6945, toronto_lm_loss: 4.2863 ||
04/20 01:03:09 AM: Update 45802: task toronto_lm, batch 798 (45569): perplexity: 72.7286, toronto_lm_loss: 4.2867 ||
04/20 01:03:19 AM: Update 45815: task toronto_lm, batch 811 (45582): perplexity: 72.7379, toronto_lm_loss: 4.2869 ||
04/20 01:03:30 AM: Update 45829: task toronto_lm, batch 825 (45596): perplexity: 72.7882, toronto_lm_loss: 4.2876 ||
04/20 01:03:40 AM: Update 45842: task toronto_lm, batch 838 (45609): perplexity: 72.6631, toronto_lm_loss: 4.2858 ||
04/20 01:03:51 AM: Update 45856: task toronto_lm, batch 852 (45623): perplexity: 72.6627, toronto_lm_loss: 4.2858 ||
04/20 01:04:01 AM: Update 45859: task toronto_lm, batch 855 (45626): perplexity: 72.6860, toronto_lm_loss: 4.2861 ||
04/20 01:04:12 AM: Update 45873: task toronto_lm, batch 869 (45640): perplexity: 72.8144, toronto_lm_loss: 4.2879 ||
04/20 01:04:23 AM: Update 45887: task toronto_lm, batch 883 (45654): perplexity: 72.8982, toronto_lm_loss: 4.2891 ||
04/20 01:04:33 AM: Update 45901: task toronto_lm, batch 897 (45668): perplexity: 72.9313, toronto_lm_loss: 4.2895 ||
04/20 01:04:44 AM: Update 45915: task toronto_lm, batch 911 (45682): perplexity: 72.9296, toronto_lm_loss: 4.2895 ||
04/20 01:04:54 AM: Update 45928: task toronto_lm, batch 924 (45695): perplexity: 72.8902, toronto_lm_loss: 4.2890 ||
04/20 01:05:04 AM: Update 45941: task toronto_lm, batch 937 (45708): perplexity: 72.8502, toronto_lm_loss: 4.2884 ||
04/20 01:05:14 AM: Update 45954: task toronto_lm, batch 950 (45721): perplexity: 72.8104, toronto_lm_loss: 4.2879 ||
04/20 01:05:25 AM: Update 45968: task toronto_lm, batch 964 (45735): perplexity: 72.7243, toronto_lm_loss: 4.2867 ||
04/20 01:05:35 AM: Update 45982: task toronto_lm, batch 978 (45749): perplexity: 72.7157, toronto_lm_loss: 4.2866 ||
04/20 01:05:46 AM: Update 45996: task toronto_lm, batch 992 (45763): perplexity: 72.6740, toronto_lm_loss: 4.2860 ||
04/20 01:05:49 AM: ***** Pass 46000 / Epoch 46 *****
04/20 01:05:49 AM: toronto_lm: trained on 996 batches, 0.005 epochs
04/20 01:05:49 AM: wsj: trained on 4 batches, 0.005 epochs
04/20 01:05:49 AM: Validating...
04/20 01:05:56 AM: Batch 27/140: perplexity: 81.3146, toronto_lm_loss: 4.3983 || , for evaluation data
04/20 01:06:06 AM: Batch 66/140: perplexity: 80.1076, toronto_lm_loss: 4.3834 || , for evaluation data
04/20 01:06:17 AM: Batch 105/140: perplexity: 76.1751, toronto_lm_loss: 4.3330 || , for evaluation data
04/20 01:06:27 AM: Batch 1/66: perplexity: 297.8605, wsj_loss: 5.6966 || , for evaluation data
04/20 01:06:38 AM: Batch 40/66: perplexity: 198.1408, wsj_loss: 5.2890 || , for evaluation data
04/20 01:06:44 AM: Advancing scheduler.
04/20 01:06:44 AM: 	Best macro_avg: 0.298
04/20 01:06:44 AM: 	# bad epochs: 5
04/20 01:06:44 AM: Statistic: toronto_lm_loss
04/20 01:06:44 AM: 	training: 4.285920
04/20 01:06:44 AM: 	validation: 4.272392
04/20 01:06:44 AM: Statistic: wsj_loss
04/20 01:06:44 AM: 	training: 5.224400
04/20 01:06:44 AM: 	validation: 5.278369
04/20 01:06:44 AM: Statistic: macro_avg
04/20 01:06:44 AM: 	validation: 0.286207
04/20 01:06:44 AM: Statistic: micro_avg
04/20 01:06:44 AM: 	validation: 0.069174
04/20 01:06:44 AM: Statistic: toronto_lm_perplexity
04/20 01:06:44 AM: 	training: 72.669355
04/20 01:06:44 AM: 	validation: 71.692905
04/20 01:06:44 AM: Statistic: wsj_perplexity
04/20 01:06:44 AM: 	training: 185.749651
04/20 01:06:44 AM: 	validation: 196.049920
04/20 01:06:44 AM: global_lr: 0.001000
04/20 01:06:45 AM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/20 01:06:45 AM: Update 46001: task toronto_lm, batch 1 (45768): perplexity: 56.1320, toronto_lm_loss: 4.0277 ||
04/20 01:06:56 AM: Update 46015: task toronto_lm, batch 15 (45782): perplexity: 66.4494, toronto_lm_loss: 4.1964 ||
04/20 01:07:07 AM: Update 46029: task toronto_lm, batch 29 (45796): perplexity: 66.4007, toronto_lm_loss: 4.1957 ||
04/20 01:07:17 AM: Update 46043: task toronto_lm, batch 43 (45810): perplexity: 66.4696, toronto_lm_loss: 4.1967 ||
04/20 01:07:28 AM: Update 46057: task toronto_lm, batch 57 (45824): perplexity: 65.8471, toronto_lm_loss: 4.1873 ||
04/20 01:07:39 AM: Update 46071: task toronto_lm, batch 71 (45838): perplexity: 65.6477, toronto_lm_loss: 4.1843 ||
04/20 01:07:50 AM: Update 46085: task toronto_lm, batch 85 (45852): perplexity: 65.4514, toronto_lm_loss: 4.1813 ||
04/20 01:08:00 AM: Update 46099: task toronto_lm, batch 99 (45866): perplexity: 65.7687, toronto_lm_loss: 4.1861 ||
04/20 01:08:11 AM: Update 46113: task toronto_lm, batch 113 (45880): perplexity: 65.9306, toronto_lm_loss: 4.1886 ||
04/20 01:08:21 AM: Update 46126: task toronto_lm, batch 126 (45893): perplexity: 65.6645, toronto_lm_loss: 4.1846 ||
04/20 01:08:32 AM: Update 46140: task toronto_lm, batch 140 (45907): perplexity: 65.0358, toronto_lm_loss: 4.1749 ||
04/20 01:08:43 AM: Update 46154: task toronto_lm, batch 154 (45921): perplexity: 64.5370, toronto_lm_loss: 4.1672 ||
04/20 01:08:53 AM: Update 46168: task toronto_lm, batch 168 (45935): perplexity: 64.1956, toronto_lm_loss: 4.1619 ||
04/20 01:09:04 AM: Update 46182: task toronto_lm, batch 182 (45949): perplexity: 64.3782, toronto_lm_loss: 4.1648 ||
04/20 01:09:14 AM: Update 46195: task toronto_lm, batch 195 (45962): perplexity: 64.2179, toronto_lm_loss: 4.1623 ||
04/20 01:09:25 AM: Update 46209: task toronto_lm, batch 209 (45976): perplexity: 64.1243, toronto_lm_loss: 4.1608 ||
04/20 01:09:35 AM: Update 46223: task toronto_lm, batch 223 (45990): perplexity: 63.9649, toronto_lm_loss: 4.1583 ||
04/20 01:09:46 AM: Update 46237: task toronto_lm, batch 237 (46004): perplexity: 63.7599, toronto_lm_loss: 4.1551 ||
04/20 01:09:57 AM: Update 46251: task toronto_lm, batch 251 (46018): perplexity: 63.5237, toronto_lm_loss: 4.1514 ||
04/20 01:10:07 AM: Update 46264: task toronto_lm, batch 264 (46031): perplexity: 63.6706, toronto_lm_loss: 4.1537 ||
04/20 01:10:18 AM: Update 46278: task toronto_lm, batch 278 (46045): perplexity: 63.6445, toronto_lm_loss: 4.1533 ||
04/20 01:10:28 AM: Update 46291: task toronto_lm, batch 291 (46058): perplexity: 63.5613, toronto_lm_loss: 4.1520 ||
04/20 01:10:38 AM: Update 46304: task toronto_lm, batch 304 (46071): perplexity: 63.5679, toronto_lm_loss: 4.1521 ||
04/20 01:10:48 AM: Update 46317: task toronto_lm, batch 317 (46084): perplexity: 63.5192, toronto_lm_loss: 4.1513 ||
04/20 01:10:58 AM: Update 46330: task toronto_lm, batch 330 (46097): perplexity: 63.3518, toronto_lm_loss: 4.1487 ||
04/20 01:11:09 AM: Update 46344: task toronto_lm, batch 344 (46111): perplexity: 63.4035, toronto_lm_loss: 4.1495 ||
04/20 01:11:19 AM: Update 46357: task toronto_lm, batch 357 (46124): perplexity: 63.4066, toronto_lm_loss: 4.1496 ||
04/20 01:11:29 AM: Update 46370: task toronto_lm, batch 370 (46137): perplexity: 63.3227, toronto_lm_loss: 4.1482 ||
04/20 01:11:39 AM: Update 46384: task wsj, batch 1 (234): perplexity: 205.9520, wsj_loss: 5.3276 ||
04/20 01:11:40 AM: Update 46385: task toronto_lm, batch 384 (46151): perplexity: 63.2569, toronto_lm_loss: 4.1472 ||
04/20 01:11:51 AM: Update 46399: task toronto_lm, batch 398 (46165): perplexity: 63.1798, toronto_lm_loss: 4.1460 ||
04/20 01:12:02 AM: Update 46413: task toronto_lm, batch 412 (46179): perplexity: 63.1059, toronto_lm_loss: 4.1448 ||
04/20 01:12:12 AM: Update 46426: task toronto_lm, batch 425 (46192): perplexity: 63.0280, toronto_lm_loss: 4.1436 ||
04/20 01:12:22 AM: Update 46439: task toronto_lm, batch 438 (46205): perplexity: 62.8224, toronto_lm_loss: 4.1403 ||
04/20 01:12:32 AM: Update 46453: task toronto_lm, batch 452 (46219): perplexity: 62.7061, toronto_lm_loss: 4.1385 ||
04/20 01:12:43 AM: Update 46467: task toronto_lm, batch 466 (46233): perplexity: 62.6419, toronto_lm_loss: 4.1374 ||
04/20 01:12:53 AM: Update 46480: task toronto_lm, batch 479 (46246): perplexity: 62.6367, toronto_lm_loss: 4.1374 ||
04/20 01:13:04 AM: Update 46485: task toronto_lm, batch 484 (46251): perplexity: 62.5789, toronto_lm_loss: 4.1364 ||
04/20 01:13:14 AM: Update 46498: task toronto_lm, batch 497 (46264): perplexity: 63.0006, toronto_lm_loss: 4.1431 ||
04/20 01:13:24 AM: Update 46511: task toronto_lm, batch 510 (46277): perplexity: 63.3385, toronto_lm_loss: 4.1485 ||
04/20 01:13:35 AM: Update 46525: task toronto_lm, batch 524 (46291): perplexity: 63.6773, toronto_lm_loss: 4.1538 ||
04/20 01:13:46 AM: Update 46539: task toronto_lm, batch 538 (46305): perplexity: 64.0270, toronto_lm_loss: 4.1593 ||
04/20 01:13:56 AM: Update 46552: task toronto_lm, batch 551 (46318): perplexity: 64.2624, toronto_lm_loss: 4.1630 ||
04/20 01:14:06 AM: Update 46565: task toronto_lm, batch 564 (46331): perplexity: 64.4554, toronto_lm_loss: 4.1660 ||
04/20 01:14:16 AM: Update 46578: task toronto_lm, batch 577 (46344): perplexity: 64.6087, toronto_lm_loss: 4.1683 ||
04/20 01:14:26 AM: Update 46591: task toronto_lm, batch 590 (46357): perplexity: 64.7370, toronto_lm_loss: 4.1703 ||
04/20 01:14:37 AM: Update 46605: task toronto_lm, batch 604 (46371): perplexity: 64.8441, toronto_lm_loss: 4.1720 ||
04/20 01:14:47 AM: Update 46618: task toronto_lm, batch 617 (46384): perplexity: 64.9395, toronto_lm_loss: 4.1735 ||
04/20 01:14:57 AM: Update 46631: task toronto_lm, batch 630 (46397): perplexity: 65.0633, toronto_lm_loss: 4.1754 ||
04/20 01:15:07 AM: Update 46644: task toronto_lm, batch 643 (46410): perplexity: 65.2776, toronto_lm_loss: 4.1786 ||
04/20 01:15:17 AM: Update 46657: task toronto_lm, batch 656 (46423): perplexity: 65.3644, toronto_lm_loss: 4.1800 ||
04/20 01:15:27 AM: Update 46670: task toronto_lm, batch 669 (46436): perplexity: 65.4285, toronto_lm_loss: 4.1810 ||
04/20 01:15:32 AM: Update 46677: task wsj, batch 2 (235): perplexity: 195.9417, wsj_loss: 5.2778 ||
04/20 01:15:37 AM: Update 46683: task toronto_lm, batch 681 (46448): perplexity: 65.4762, toronto_lm_loss: 4.1817 ||
04/20 01:15:47 AM: Update 46696: task toronto_lm, batch 694 (46461): perplexity: 65.5076, toronto_lm_loss: 4.1822 ||
04/20 01:15:57 AM: Update 46709: task toronto_lm, batch 707 (46474): perplexity: 65.5324, toronto_lm_loss: 4.1825 ||
04/20 01:16:07 AM: Update 46722: task toronto_lm, batch 720 (46487): perplexity: 65.5311, toronto_lm_loss: 4.1825 ||
04/20 01:16:17 AM: Update 46735: task toronto_lm, batch 733 (46500): perplexity: 65.5736, toronto_lm_loss: 4.1832 ||
04/20 01:16:27 AM: Update 46748: task toronto_lm, batch 746 (46513): perplexity: 65.6293, toronto_lm_loss: 4.1840 ||
04/20 01:16:37 AM: Update 46761: task toronto_lm, batch 759 (46526): perplexity: 65.6611, toronto_lm_loss: 4.1845 ||
04/20 01:16:47 AM: Update 46774: task toronto_lm, batch 772 (46539): perplexity: 65.6300, toronto_lm_loss: 4.1840 ||
04/20 01:16:57 AM: Update 46787: task toronto_lm, batch 785 (46552): perplexity: 65.6714, toronto_lm_loss: 4.1847 ||
04/20 01:17:07 AM: Update 46800: task toronto_lm, batch 798 (46565): perplexity: 65.7072, toronto_lm_loss: 4.1852 ||
04/20 01:17:18 AM: Update 46813: task toronto_lm, batch 811 (46578): perplexity: 65.6741, toronto_lm_loss: 4.1847 ||
04/20 01:17:28 AM: Update 46826: task toronto_lm, batch 824 (46591): perplexity: 65.6735, toronto_lm_loss: 4.1847 ||
04/20 01:17:38 AM: Update 46839: task toronto_lm, batch 837 (46604): perplexity: 65.6997, toronto_lm_loss: 4.1851 ||
04/20 01:17:48 AM: Update 46852: task toronto_lm, batch 850 (46617): perplexity: 65.7221, toronto_lm_loss: 4.1854 ||
04/20 01:17:58 AM: Update 46865: task toronto_lm, batch 863 (46630): perplexity: 65.7374, toronto_lm_loss: 4.1857 ||
04/20 01:18:08 AM: Update 46878: task toronto_lm, batch 876 (46643): perplexity: 65.7496, toronto_lm_loss: 4.1859 ||
04/20 01:18:18 AM: Update 46891: task toronto_lm, batch 889 (46656): perplexity: 65.6977, toronto_lm_loss: 4.1851 ||
04/20 01:18:19 AM: Update 46892: task wsj, batch 3 (236): perplexity: 200.9446, wsj_loss: 5.3030 ||
04/20 01:18:28 AM: Update 46904: task toronto_lm, batch 901 (46668): perplexity: 65.6670, toronto_lm_loss: 4.1846 ||
04/20 01:18:38 AM: Update 46917: task toronto_lm, batch 914 (46681): perplexity: 65.6578, toronto_lm_loss: 4.1845 ||
04/20 01:18:48 AM: Update 46930: task toronto_lm, batch 927 (46694): perplexity: 65.6364, toronto_lm_loss: 4.1841 ||
04/20 01:18:58 AM: Update 46943: task toronto_lm, batch 940 (46707): perplexity: 65.5977, toronto_lm_loss: 4.1835 ||
04/20 01:19:08 AM: Update 46956: task toronto_lm, batch 953 (46720): perplexity: 65.5218, toronto_lm_loss: 4.1824 ||
04/20 01:19:19 AM: Update 46969: task toronto_lm, batch 966 (46733): perplexity: 65.5248, toronto_lm_loss: 4.1824 ||
04/20 01:19:29 AM: Update 46982: task toronto_lm, batch 979 (46746): perplexity: 65.4988, toronto_lm_loss: 4.1820 ||
04/20 01:19:39 AM: Update 46995: task toronto_lm, batch 992 (46759): perplexity: 65.4567, toronto_lm_loss: 4.1814 ||
04/20 01:19:42 AM: ***** Pass 47000 / Epoch 47 *****
04/20 01:19:42 AM: toronto_lm: trained on 997 batches, 0.005 epochs
04/20 01:19:42 AM: wsj: trained on 3 batches, 0.004 epochs
04/20 01:19:42 AM: Validating...
04/20 01:19:49 AM: Batch 19/140: perplexity: 85.5785, toronto_lm_loss: 4.4494 || , for evaluation data
04/20 01:19:59 AM: Batch 57/140: perplexity: 83.5355, toronto_lm_loss: 4.4253 || , for evaluation data
04/20 01:20:09 AM: Batch 95/140: perplexity: 78.0210, toronto_lm_loss: 4.3570 || , for evaluation data
04/20 01:20:19 AM: Batch 133/140: perplexity: 72.2694, toronto_lm_loss: 4.2804 || , for evaluation data
04/20 01:20:21 AM: Batch 1/66: perplexity: 300.9016, wsj_loss: 5.7068 || , for evaluation data
04/20 01:20:31 AM: Batch 39/66: perplexity: 202.8721, wsj_loss: 5.3126 || , for evaluation data
04/20 01:20:38 AM: Out of patience. Stopped tracking wsj
04/20 01:20:38 AM: Out of patience. Stopped tracking micro
04/20 01:20:38 AM: Out of patience. Stopped tracking macro
04/20 01:20:38 AM: Advancing scheduler.
04/20 01:20:38 AM: 	Best macro_avg: 0.298
04/20 01:20:38 AM: 	# bad epochs: 0
04/20 01:20:38 AM: All metrics ran out of patience. Stopping training.
04/20 01:20:38 AM: Statistic: toronto_lm_loss
04/20 01:20:38 AM: 	training: 4.181123
04/20 01:20:38 AM: 	validation: 4.266839
04/20 01:20:38 AM: Statistic: wsj_loss
04/20 01:20:38 AM: 	training: 5.303029
04/20 01:20:38 AM: 	validation: 5.280863
04/20 01:20:38 AM: Statistic: macro_avg
04/20 01:20:38 AM: 	validation: 0.285625
04/20 01:20:38 AM: Statistic: micro_avg
04/20 01:20:38 AM: 	validation: 0.068547
04/20 01:20:38 AM: Statistic: toronto_lm_perplexity
04/20 01:20:38 AM: 	training: 65.439277
04/20 01:20:38 AM: 	validation: 71.295927
04/20 01:20:38 AM: Statistic: wsj_perplexity
04/20 01:20:38 AM: 	training: 200.944626
04/20 01:20:38 AM: 	validation: 196.539452
04/20 01:20:38 AM: global_lr: 0.000500
04/20 01:20:38 AM: Saved files to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0
04/20 01:20:38 AM: Stopped training after 47 validation checks
04/20 01:20:38 AM: Trained toronto_lm for 46764 batches or 0.257 epochs
04/20 01:20:38 AM: Trained wsj for 236 batches or 0.284 epochs
04/20 01:20:38 AM: ***** VALIDATION RESULTS *****
04/20 01:20:38 AM: toronto_lm_perplexity, 21, toronto_lm_loss: 4.36084, wsj_loss: 5.51065, macro_avg: 0.17706, micro_avg: 0.00345, toronto_lm_perplexity: 78.32301, wsj_perplexity: 247.31098
04/20 01:20:38 AM: wsj_perplexity, 41, toronto_lm_loss: 4.31788, wsj_loss: 5.23961, macro_avg: 0.29778, micro_avg: 0.07873, toronto_lm_perplexity: 75.02903, wsj_perplexity: 188.59636
04/20 01:20:38 AM: micro_avg, 41, toronto_lm_loss: 4.31788, wsj_loss: 5.23961, macro_avg: 0.29778, micro_avg: 0.07873, toronto_lm_perplexity: 75.02903, wsj_perplexity: 188.59636
04/20 01:20:38 AM: macro_avg, 41, toronto_lm_loss: 4.31788, wsj_loss: 5.23961, macro_avg: 0.29778, micro_avg: 0.07873, toronto_lm_perplexity: 75.02903, wsj_perplexity: 188.59636
04/20 01:20:38 AM: In strict mode because do_target_task_training is off. Will crash if any tasks are missing from the checkpoint.
04/20 01:20:39 AM: Loaded model state from /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/prpn-0/model_state_main_epoch_41.best_macro.th
04/20 01:20:39 AM: Evaluating...
04/20 01:20:39 AM: Evaluating on: wsj, split: val
04/20 01:20:56 AM: Task wsj: has no predictions!
04/20 01:20:56 AM: Writing results for split 'val' to /beegfs/pmh330/jiant-prpn-outs/prpn-wsj-toronto/results.tsv
04/20 01:20:56 AM: micro_avg: 188.596, macro_avg: 188.596, wsj_perplexity: 188.596
04/20 01:20:56 AM: Done!
Epoch    47: reducing learning rate of group 0 to 5.0000e-04.
